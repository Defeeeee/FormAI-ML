{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Set up important landmarks and functions\n",
    "Generate Data Frame\n",
    "According to my research the correct form for a squat is analyzed through the position of:\n",
    "\n",
    "Back\n",
    "Hip\n",
    "Legs\n",
    "Therefore, there will be 9 keypoints which will be extract from mediapipe in order to train or detect a correct form of a squat:\n",
    "\n",
    "\"NOSE\",\n",
    "\"LEFT_SHOULDER\",\n",
    "\"RIGHT_SHOULDER\",\n",
    "\"LEFT_HIP\",\n",
    "\"RIGHT_HIP\",\n",
    "\"LEFT_KNEE\",\n",
    "\"RIGHT_KNEE\",\n",
    "\"LEFT_ANKLE\",\n",
    "\"RIGHT_ANKLE\"\n",
    "The data frame will be saved in a .csv file.\n",
    "\n",
    "A data frame will contains a \"Label\" columns which represent the label of a data point.\n",
    "\n",
    "There are another 9 x 4 columns represent 9 features of a human pose that are important for a squat. In that each landmark's info will be flatten\n",
    "\n",
    "According to the Mediapipe documentation, Each landmark consists of the following:\n",
    "\n",
    "x and y: Landmark coordinates normalized to [0.0, 1.0] by the image width and height respectively.\n",
    "z: Represents the landmark depth with the depth at the midpoint of hips being the origin, and the smaller the value the closer the landmark is to the camera. The magnitude of z uses roughly the same scale as x.\n",
    "visibility: A value in [0.0, 1.0] indicating the likelihood of the landmark being visible (present and not occluded) in the image."
   ],
   "id": "2ee51883a963379d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:50:08.736542Z",
     "start_time": "2024-10-16T11:50:08.718432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ],
   "id": "39050f46dcf04f2b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:50:08.778687Z",
     "start_time": "2024-10-16T11:50:08.774858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the landmarks\n",
    "imp_landmarks = [\"NOSE\", \"LEFT_SHOULDER\", \"RIGHT_SHOULDER\", \"LEFT_HIP\", \"RIGHT_HIP\", \"LEFT_KNEE\", \"RIGHT_KNEE\", \"LEFT_ANKLE\", \"RIGHT_ANKLE\"]"
   ],
   "id": "39785d0b8ff0010d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:50:08.786730Z",
     "start_time": "2024-10-16T11:50:08.783773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "landmarks = [\"label\"]\n",
    "\n",
    "for landmark in imp_landmarks:\n",
    "    landmarks += [f\"{landmark.lower()}_x\", f\"{landmark.lower()}_y\", f\"{landmark.lower()}_z\", f\"{landmark.lower()}_v\"]"
   ],
   "id": "566c8828ff440277",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training based on the data",
   "id": "24ec8e2ca5562588"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:50:09.135613Z",
     "start_time": "2024-10-16T11:50:08.793558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"/Users/defeee/Documents/GitHub/FormAI-ML/Computer_Vision/squat_data.csv\")\n",
    "data.head()"
   ],
   "id": "ff3aa1316944f0d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   nose_x  nose_y  left_shoulder_x  left_shoulder_y  right_shoulder_x  \\\n",
       "0  0.0000  0.0000         0.000000         0.000000          0.000000   \n",
       "1  0.0000  0.0000         0.000000         0.000000          0.000000   \n",
       "2  0.0000  0.0000         0.000000         0.000000          0.000000   \n",
       "3  0.0000  0.0000         0.000000         0.000000          0.000000   \n",
       "4  0.0000  0.0000         0.000000         0.000000          0.000000   \n",
       "\n",
       "   right_shoulder_y  left_hip_x  left_hip_y  right_hip_x  right_hip_y  \\\n",
       "0          0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "1          0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "2          0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "3          0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "4          0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "\n",
       "   ...  right_knee_y  left_ankle_x  left_ankle_y  right_ankle_x  \\\n",
       "0  ...      0.000000      0.000000      0.000000       0.000000   \n",
       "1  ...      0.000000      0.000000      0.000000       0.000000   \n",
       "2  ...      0.000000      0.000000      0.000000       0.000000   \n",
       "3  ...      0.000000      0.000000      0.000000       0.000000   \n",
       "4  ...      0.000000      0.000000      0.000000       0.000000   \n",
       "\n",
       "   right_ankle_y  label  \n",
       "0       0.000000      0  \n",
       "1       0.000000      0  \n",
       "2       0.000000      0  \n",
       "3       0.000000      0  \n",
       "4       0.000000      0  \n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(\"label\", axis=1)\n",
    "y = data[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "229225155e8bc9a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train the NN model using pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "40fa09830d334438"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(18, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "id": "2cfa372c4eb168e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert the data to tensor\n",
    "X_train = torch.tensor(X_train.values).float()\n",
    "X_test = torch.tensor(X_test.values).float()\n",
    "y_train = torch.tensor(y_train.values).long()\n",
    "y_test = torch.tensor(y_test.values).long()"
   ],
   "id": "f7bc08121adb9995"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train the model\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)"
   ],
   "id": "19ba43fe9a83380f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train the model\n",
    "n_epochs = 100\n",
    "train_losses = np.zeros(n_epochs)\n",
    "test_losses = np.zeros(n_epochs)\n",
    "\n",
    "for it in range(n_epochs):\n",
    "    net.train()\n",
    "    for inputs, targets in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses[it] = loss.item()\n",
    "\n",
    "    net.eval()\n",
    "    for inputs, targets in testloader:\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_losses[it] = loss.item()\n",
    "\n",
    "    print(f'Epoch {it+1}/{n_epochs}, Train Loss: {train_losses[it]:.4f}, Test Loss: {test_losses[it]:.4f}')"
   ],
   "id": "7665e100ed111d5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "with torch.no_grad():\n",
    "    y_pred = net(X_test)\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ],
   "id": "3c2475de057eb434"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "c3ae7b4dcd8c62a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(), \"/Users/defeee/Documents/GitHub/FormAI-ML/Models/Core/Squat/model.pth\")"
   ],
   "id": "f6bd14e493b1430d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
