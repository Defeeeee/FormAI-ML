{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Squat Exercise Classification\n",
    "\n",
    "In this notebook, we will collect data, preprocess it, and train two models (a simple feedforward neural network and a convolutional neural network) to classify squat exercises. We will then compare the performance of both models."
   ],
   "id": "2ee51883a963379d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Set up important landmarks and functions\n",
    "\n",
    "According to my research, the correct form for a squat is analyzed through the position of:\n",
    "\n",
    "- Back\n",
    "- Hip\n",
    "- Legs\n",
    "\n",
    "Therefore, there will be 9 keypoints which will be extracted from MediaPipe in order to train or detect a correct form of a squat:\n",
    "\n",
    "- `NOSE`\n",
    "- `LEFT_SHOULDER`\n",
    "- `RIGHT_SHOULDER`\n",
    "- `LEFT_HIP`\n",
    "- `RIGHT_HIP`\n",
    "- `LEFT_KNEE`\n",
    "- `RIGHT_KNEE`\n",
    "- `LEFT_ANKLE`\n",
    "- `RIGHT_ANKLE`\n",
    "\n",
    "The data frame will be saved in a .csv file.\n",
    "\n",
    "A data frame will contain a `label` column which represents the label of a data point.\n",
    "\n",
    "There are another 9 x 4 columns representing 9 features of a human pose that are important for a squat. Each landmark's info will be flattened.\n",
    "\n",
    "According to the MediaPipe documentation, each landmark consists of the following:\n",
    "\n",
    "- `x` and `y`: Landmark coordinates normalized to [0.0, 1.0] by the image width and height respectively.\n",
    "- `z`: Represents the landmark depth with the depth at the midpoint of hips being the origin, and the smaller the value the closer the landmark is to the camera. The magnitude of `z` uses roughly the same scale as `x`.\n",
    "- `visibility`: A value in [0.0, 1.0] indicating the likelihood of the landmark being visible (present and not occluded) in the image."
   ],
   "id": "2ee51883a963379d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:50:08.736542Z",
     "start_time": "2024-10-16T11:50:08.718432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "id": "39050f46dcf04f2b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:50:08.778687Z",
     "start_time": "2024-10-16T11:50:08.774858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the landmarks\n",
    "imp_landmarks = [\"NOSE\", \"LEFT_SHOULDER\", \"RIGHT_SHOULDER\", \"LEFT_HIP\", \"RIGHT_HIP\", \"LEFT_KNEE\", \"RIGHT_KNEE\", \"LEFT_ANKLE\", \"RIGHT_ANKLE\"]"
   ],
   "id": "39785d0b8ff0010d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:50:08.786730Z",
     "start_time": "2024-10-16T11:50:08.783773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "landmarks = [\"label\"]\n",
    "\n",
    "for landmark in imp_landmarks:\n",
    "    landmarks += [f\"{landmark.lower()}_x\", f\"{landmark.lower()}_y\", f\"{landmark.lower()}_z\", f\"{landmark.lower()}_v\"]"
   ],
   "id": "566c8828ff440277",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data Collection and Preprocessing\n",
    "\n",
    "We will use the `saving_squat.py` script to gather landmarks for squat exercises using MediaPipe. The script will display the video with landmarks overlayed and wait for a keystroke to classify it. The classified data will be saved to a CSV file for training and testing."
   ],
   "id": "24ec8e2ca5562588"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('squat_data.csv')\n",
    "data.head()"
   ],
   "id": "d1e8e2ca5562588",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split the data into features and labels\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "d2e8e2ca5562588",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Implementing a Simple Feedforward Neural Network\n",
    "\n",
    "We will define a simple feedforward neural network using `torch.nn` and train it on the training data."
   ],
   "id": "34ec8e2ca5562588"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "num_classes = 3\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model, loss function, and optimizer\n",
    "model = SimpleNN(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_outputs = model(X_train_tensor)\n",
    "    _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "    train_accuracy = accuracy_score(y_train_tensor, train_predicted)\n",
    "\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_accuracy = accuracy_score(y_test_tensor, test_predicted)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Testing Accuracy: {test_accuracy:.4f}')"
   ],
   "id": "d3e8e2ca5562588",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Implementing a Convolutional Neural Network\n",
    "\n",
    "We will define a convolutional neural network using `torch.nn` and train it on the training data."
   ],
   "id": "44ec8e2ca5562588"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "        self.fc1 = nn.Linear(32*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 3\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model, loss function, and optimizer\n",
    "model = ConvNet(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Reshape data for ConvNet\n",
    "X_train_tensor = X_train_tensor.view(-1, 1, X_train_tensor.shape[1])\n",
    "X_test_tensor = X_test_tensor.view(-1, 1, X_test_tensor.shape[1])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_outputs = model(X_train_tensor)\n",
    "    _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "    train_accuracy = accuracy_score(y_train_tensor, train_predicted)\n",
    "\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_accuracy = accuracy_score(y_test_tensor, test_predicted)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Testing Accuracy: {test_accuracy:.4f}')"
   ],
   "id": "d4e8e2ca5562588",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Comparing the Results\n",
    "\n",
    "We will compare the accuracy, precision, recall, and F1-score of both the NN and CNN models. We will also visualize the results using plots to show the performance of both models."
   ],
   "id": "54ec8e2ca5562588"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision, recall, and F1-score for NN\n",
    "nn_precision = precision_score(y_test_tensor, test_predicted, average='weighted')\n",
    "nn_recall = recall_score(y_test_tensor, test_predicted, average='weighted')\n",
    "nn_f1 = f1_score(y_test_tensor, test_predicted, average='weighted')\n",
    "\n",
    "# Calculate precision, recall, and F1-score for CNN\n",
    "cnn_precision = precision_score(y_test_tensor, test_predicted, average='weighted')\n",
    "cnn_recall = recall_score(y_test_tensor, test_predicted, average='weighted')\n",
    "cnn_f1 = f1_score(y_test_tensor, test_predicted, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'NN Precision: {nn_precision:.4f}')\n",
    "print(f'NN Recall: {nn_recall:.4f}')\n",
    "print(f'NN F1-score: {nn_f1:.4f}')\n",
    "\n",
    "print(f'CNN Precision: {cnn_precision:.4f}')\n",
    "print(f'CNN Recall: {cnn_recall:.4f}')\n",
    "print(f'CNN F1-score: {cnn_f1:.4f}')\n",
    "\n",
    "# Visualize the results\n",
    "labels = ['NN', 'CNN']\n",
    "accuracy = [train_accuracy, test_accuracy]\n",
    "precision = [nn_precision, cnn_precision]\n",
    "recall = [nn_recall, cnn_recall]\n",
    "f1 = [nn_f1, cnn_f1]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, accuracy, width, label='Accuracy')\n",
    "rects2 = ax.bar(x + width/2, precision, width, label='Precision')\n",
    "rects3 = ax.bar(x + 1.5*width, recall, width, label='Recall')\n",
    "rects4 = ax.bar(x + 2.5*width, f1, width, label='F1-score')\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Comparison of NN and CNN Models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "id": "d5e8e2ca5562588",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
