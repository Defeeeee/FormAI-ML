{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-16T19:57:06.044910Z",
     "start_time": "2024-11-16T19:57:06.041601Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T19:57:06.059857Z",
     "start_time": "2024-11-16T19:57:06.056301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plank dataset class\n",
    "class PlankDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.data.iloc[idx].values, dtype=torch.float32)\n",
    "        return features"
   ],
   "id": "14d0c5fb4d74f8fd",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T19:57:06.076986Z",
     "start_time": "2024-11-16T19:57:06.072058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plank CNN model\n",
    "\n",
    "class PlankCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlankCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(16, 7)  # Corrected input size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16)  # Corrected flattening\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ],
   "id": "5e0507532300dd70",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T19:57:06.093163Z",
     "start_time": "2024-11-16T19:57:06.083833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data split and loader\n",
    "dataset = PlankDataset('/Users/defeee/Documents/GitHub/FormAI-ML/Computer_Vision/plank_features.csv')\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "58d02123328aa38e",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T19:57:06.105338Z",
     "start_time": "2024-11-16T19:57:06.101260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = PlankCNN()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()"
   ],
   "id": "44f257104696e721",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T19:57:21.030589Z",
     "start_time": "2024-11-16T19:57:06.112659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_epoch_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_epoch_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            inputs = data\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            val_epoch_loss += loss.item()\n",
    "\n",
    "    # Print training and validation losses\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_epoch_loss / len(train_dataloader):.4f}, '\n",
    "          f'Val Loss: {val_epoch_loss / len(val_dataloader):.4f}')"
   ],
   "id": "1267f5fa26e1cd9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Train Loss: 13198.8828, Val Loss: 13610.7012\n",
      "Epoch [2/10000], Train Loss: 12924.6689, Val Loss: 13333.2822\n",
      "Epoch [3/10000], Train Loss: 12661.4102, Val Loss: 13066.5322\n",
      "Epoch [4/10000], Train Loss: 12415.3623, Val Loss: 12815.6367\n",
      "Epoch [5/10000], Train Loss: 12180.1143, Val Loss: 12571.1748\n",
      "Epoch [6/10000], Train Loss: 11950.7373, Val Loss: 12330.8604\n",
      "Epoch [7/10000], Train Loss: 11725.8008, Val Loss: 12095.0527\n",
      "Epoch [8/10000], Train Loss: 11504.6445, Val Loss: 11863.8438\n",
      "Epoch [9/10000], Train Loss: 11288.6406, Val Loss: 11640.3818\n",
      "Epoch [10/10000], Train Loss: 11080.3594, Val Loss: 11420.7773\n",
      "Epoch [11/10000], Train Loss: 10878.0264, Val Loss: 11206.6562\n",
      "Epoch [12/10000], Train Loss: 10679.6572, Val Loss: 10995.3750\n",
      "Epoch [13/10000], Train Loss: 10484.4736, Val Loss: 10786.7822\n",
      "Epoch [14/10000], Train Loss: 10292.3252, Val Loss: 10580.7070\n",
      "Epoch [15/10000], Train Loss: 10103.0352, Val Loss: 10376.9932\n",
      "Epoch [16/10000], Train Loss: 9915.8291, Val Loss: 10175.4141\n",
      "Epoch [17/10000], Train Loss: 9730.3838, Val Loss: 9976.7100\n",
      "Epoch [18/10000], Train Loss: 9547.0625, Val Loss: 9780.6074\n",
      "Epoch [19/10000], Train Loss: 9365.6875, Val Loss: 9586.4297\n",
      "Epoch [20/10000], Train Loss: 9185.7734, Val Loss: 9393.8672\n",
      "Epoch [21/10000], Train Loss: 9007.3027, Val Loss: 9202.1143\n",
      "Epoch [22/10000], Train Loss: 8830.1309, Val Loss: 9011.0137\n",
      "Epoch [23/10000], Train Loss: 8653.7695, Val Loss: 8820.4541\n",
      "Epoch [24/10000], Train Loss: 8478.0586, Val Loss: 8630.3252\n",
      "Epoch [25/10000], Train Loss: 8302.9092, Val Loss: 8441.0723\n",
      "Epoch [26/10000], Train Loss: 8128.2300, Val Loss: 8253.5410\n",
      "Epoch [27/10000], Train Loss: 7954.0962, Val Loss: 8066.6079\n",
      "Epoch [28/10000], Train Loss: 7780.7739, Val Loss: 7880.8525\n",
      "Epoch [29/10000], Train Loss: 7608.1494, Val Loss: 7695.7681\n",
      "Epoch [30/10000], Train Loss: 7436.1270, Val Loss: 7511.2983\n",
      "Epoch [31/10000], Train Loss: 7264.8452, Val Loss: 7328.1685\n",
      "Epoch [32/10000], Train Loss: 7096.0757, Val Loss: 7149.0425\n",
      "Epoch [33/10000], Train Loss: 6933.0815, Val Loss: 6974.7617\n",
      "Epoch [34/10000], Train Loss: 6772.8242, Val Loss: 6802.3477\n",
      "Epoch [35/10000], Train Loss: 6613.1753, Val Loss: 6629.6201\n",
      "Epoch [36/10000], Train Loss: 6453.7695, Val Loss: 6456.6655\n",
      "Epoch [37/10000], Train Loss: 6294.2983, Val Loss: 6283.6064\n",
      "Epoch [38/10000], Train Loss: 6134.7612, Val Loss: 6110.5801\n",
      "Epoch [39/10000], Train Loss: 5975.2690, Val Loss: 5937.7446\n",
      "Epoch [40/10000], Train Loss: 5815.9448, Val Loss: 5765.2686\n",
      "Epoch [41/10000], Train Loss: 5656.9214, Val Loss: 5593.3228\n",
      "Epoch [42/10000], Train Loss: 5498.3384, Val Loss: 5422.0840\n",
      "Epoch [43/10000], Train Loss: 5340.3345, Val Loss: 5251.7222\n",
      "Epoch [44/10000], Train Loss: 5183.0454, Val Loss: 5082.4053\n",
      "Epoch [45/10000], Train Loss: 5026.6055, Val Loss: 4914.2939\n",
      "Epoch [46/10000], Train Loss: 4871.1387, Val Loss: 4747.5488\n",
      "Epoch [47/10000], Train Loss: 4716.7744, Val Loss: 4582.3354\n",
      "Epoch [48/10000], Train Loss: 4563.6421, Val Loss: 4418.8296\n",
      "Epoch [49/10000], Train Loss: 4411.8833, Val Loss: 4257.2183\n",
      "Epoch [50/10000], Train Loss: 4261.6484, Val Loss: 4097.6909\n",
      "Epoch [51/10000], Train Loss: 4113.0918, Val Loss: 3940.4375\n",
      "Epoch [52/10000], Train Loss: 3966.3838, Val Loss: 3785.6353\n",
      "Epoch [53/10000], Train Loss: 3821.6787, Val Loss: 3633.4478\n",
      "Epoch [54/10000], Train Loss: 3679.0725, Val Loss: 3484.0254\n",
      "Epoch [55/10000], Train Loss: 3538.6804, Val Loss: 3337.5068\n",
      "Epoch [56/10000], Train Loss: 3400.6108, Val Loss: 3194.0273\n",
      "Epoch [57/10000], Train Loss: 3264.9626, Val Loss: 3053.7197\n",
      "Epoch [58/10000], Train Loss: 3131.8364, Val Loss: 2916.7175\n",
      "Epoch [59/10000], Train Loss: 3001.3462, Val Loss: 2783.1455\n",
      "Epoch [60/10000], Train Loss: 2873.5933, Val Loss: 2653.1157\n",
      "Epoch [61/10000], Train Loss: 2748.6594, Val Loss: 2526.7271\n",
      "Epoch [62/10000], Train Loss: 2626.6248, Val Loss: 2404.0588\n",
      "Epoch [63/10000], Train Loss: 2507.5786, Val Loss: 2285.3423\n",
      "Epoch [64/10000], Train Loss: 2391.9102, Val Loss: 2170.9426\n",
      "Epoch [65/10000], Train Loss: 2279.7925, Val Loss: 2060.6482\n",
      "Epoch [66/10000], Train Loss: 2172.1729, Val Loss: 1954.4381\n",
      "Epoch [67/10000], Train Loss: 2068.6245, Val Loss: 1852.3717\n",
      "Epoch [68/10000], Train Loss: 1968.6113, Val Loss: 1754.4840\n",
      "Epoch [69/10000], Train Loss: 1872.0364, Val Loss: 1660.7885\n",
      "Epoch [70/10000], Train Loss: 1778.9147, Val Loss: 1571.2880\n",
      "Epoch [71/10000], Train Loss: 1689.2404, Val Loss: 1485.9576\n",
      "Epoch [72/10000], Train Loss: 1603.0002, Val Loss: 1404.7565\n",
      "Epoch [73/10000], Train Loss: 1520.1635, Val Loss: 1327.6328\n",
      "Epoch [74/10000], Train Loss: 1440.7046, Val Loss: 1254.5295\n",
      "Epoch [75/10000], Train Loss: 1364.5789, Val Loss: 1185.3795\n",
      "Epoch [76/10000], Train Loss: 1291.7554, Val Loss: 1120.1038\n",
      "Epoch [77/10000], Train Loss: 1222.1768, Val Loss: 1058.6058\n",
      "Epoch [78/10000], Train Loss: 1155.7889, Val Loss: 1000.7762\n",
      "Epoch [79/10000], Train Loss: 1092.5203, Val Loss: 946.4977\n",
      "Epoch [80/10000], Train Loss: 1032.2866, Val Loss: 895.6498\n",
      "Epoch [81/10000], Train Loss: 975.0026, Val Loss: 848.0972\n",
      "Epoch [82/10000], Train Loss: 920.5776, Val Loss: 803.7135\n",
      "Epoch [83/10000], Train Loss: 868.9281, Val Loss: 762.3723\n",
      "Epoch [84/10000], Train Loss: 819.9312, Val Loss: 723.9292\n",
      "Epoch [85/10000], Train Loss: 773.4989, Val Loss: 688.2385\n",
      "Epoch [86/10000], Train Loss: 729.5266, Val Loss: 655.1541\n",
      "Epoch [87/10000], Train Loss: 687.9183, Val Loss: 624.5316\n",
      "Epoch [88/10000], Train Loss: 648.5751, Val Loss: 596.1907\n",
      "Epoch [89/10000], Train Loss: 611.3907, Val Loss: 570.0158\n",
      "Epoch [90/10000], Train Loss: 576.2629, Val Loss: 545.8663\n",
      "Epoch [91/10000], Train Loss: 543.0944, Val Loss: 523.6058\n",
      "Epoch [92/10000], Train Loss: 511.7896, Val Loss: 503.1050\n",
      "Epoch [93/10000], Train Loss: 482.2580, Val Loss: 484.2132\n",
      "Epoch [94/10000], Train Loss: 454.4135, Val Loss: 466.8501\n",
      "Epoch [95/10000], Train Loss: 428.1721, Val Loss: 450.9041\n",
      "Epoch [96/10000], Train Loss: 403.4509, Val Loss: 436.2679\n",
      "Epoch [97/10000], Train Loss: 380.1696, Val Loss: 422.8419\n",
      "Epoch [98/10000], Train Loss: 358.2657, Val Loss: 410.5299\n",
      "Epoch [99/10000], Train Loss: 337.6725, Val Loss: 399.2401\n",
      "Epoch [100/10000], Train Loss: 318.3191, Val Loss: 388.8830\n",
      "Epoch [101/10000], Train Loss: 300.1516, Val Loss: 379.3888\n",
      "Epoch [102/10000], Train Loss: 283.1149, Val Loss: 370.6855\n",
      "Epoch [103/10000], Train Loss: 267.1535, Val Loss: 362.6967\n",
      "Epoch [104/10000], Train Loss: 252.2154, Val Loss: 355.3595\n",
      "Epoch [105/10000], Train Loss: 238.2497, Val Loss: 348.6135\n",
      "Epoch [106/10000], Train Loss: 225.2106, Val Loss: 342.4016\n",
      "Epoch [107/10000], Train Loss: 213.0484, Val Loss: 336.6687\n",
      "Epoch [108/10000], Train Loss: 201.7139, Val Loss: 331.3636\n",
      "Epoch [109/10000], Train Loss: 191.1615, Val Loss: 326.4368\n",
      "Epoch [110/10000], Train Loss: 181.3467, Val Loss: 321.8432\n",
      "Epoch [111/10000], Train Loss: 172.2268, Val Loss: 317.5423\n",
      "Epoch [112/10000], Train Loss: 163.7608, Val Loss: 313.4995\n",
      "Epoch [113/10000], Train Loss: 155.9094, Val Loss: 309.6856\n",
      "Epoch [114/10000], Train Loss: 148.6348, Val Loss: 306.0735\n",
      "Epoch [115/10000], Train Loss: 141.9008, Val Loss: 302.6388\n",
      "Epoch [116/10000], Train Loss: 135.6726, Val Loss: 299.3595\n",
      "Epoch [117/10000], Train Loss: 129.9206, Val Loss: 296.2151\n",
      "Epoch [118/10000], Train Loss: 124.6115, Val Loss: 293.1881\n",
      "Epoch [119/10000], Train Loss: 119.7160, Val Loss: 290.2633\n",
      "Epoch [120/10000], Train Loss: 115.2066, Val Loss: 287.4294\n",
      "Epoch [121/10000], Train Loss: 111.0574, Val Loss: 284.6787\n",
      "Epoch [122/10000], Train Loss: 107.2442, Val Loss: 282.0067\n",
      "Epoch [123/10000], Train Loss: 103.7445, Val Loss: 279.4111\n",
      "Epoch [124/10000], Train Loss: 100.5372, Val Loss: 276.8903\n",
      "Epoch [125/10000], Train Loss: 97.6023, Val Loss: 274.4432\n",
      "Epoch [126/10000], Train Loss: 94.9211, Val Loss: 272.0688\n",
      "Epoch [127/10000], Train Loss: 92.4765, Val Loss: 269.7664\n",
      "Epoch [128/10000], Train Loss: 90.2522, Val Loss: 267.5356\n",
      "Epoch [129/10000], Train Loss: 88.2327, Val Loss: 265.3779\n",
      "Epoch [130/10000], Train Loss: 86.4037, Val Loss: 263.2950\n",
      "Epoch [131/10000], Train Loss: 84.7506, Val Loss: 261.2904\n",
      "Epoch [132/10000], Train Loss: 83.2626, Val Loss: 259.3673\n",
      "Epoch [133/10000], Train Loss: 81.9267, Val Loss: 257.5286\n",
      "Epoch [134/10000], Train Loss: 80.7331, Val Loss: 255.7759\n",
      "Epoch [135/10000], Train Loss: 79.6688, Val Loss: 254.1098\n",
      "Epoch [136/10000], Train Loss: 78.7232, Val Loss: 252.5300\n",
      "Epoch [137/10000], Train Loss: 77.8865, Val Loss: 251.0363\n",
      "Epoch [138/10000], Train Loss: 77.1490, Val Loss: 249.6280\n",
      "Epoch [139/10000], Train Loss: 76.5009, Val Loss: 248.3055\n",
      "Epoch [140/10000], Train Loss: 75.9347, Val Loss: 247.0689\n",
      "Epoch [141/10000], Train Loss: 75.4417, Val Loss: 245.9176\n",
      "Epoch [142/10000], Train Loss: 75.0146, Val Loss: 244.8508\n",
      "Epoch [143/10000], Train Loss: 74.6468, Val Loss: 243.8638\n",
      "Epoch [144/10000], Train Loss: 74.3317, Val Loss: 242.9550\n",
      "Epoch [145/10000], Train Loss: 74.0634, Val Loss: 242.1226\n",
      "Epoch [146/10000], Train Loss: 73.8360, Val Loss: 241.3631\n",
      "Epoch [147/10000], Train Loss: 73.6445, Val Loss: 240.6710\n",
      "Epoch [148/10000], Train Loss: 73.4841, Val Loss: 240.0465\n",
      "Epoch [149/10000], Train Loss: 73.3504, Val Loss: 239.4870\n",
      "Epoch [150/10000], Train Loss: 73.2396, Val Loss: 238.9897\n",
      "Epoch [151/10000], Train Loss: 73.1482, Val Loss: 238.5515\n",
      "Epoch [152/10000], Train Loss: 73.0729, Val Loss: 238.1687\n",
      "Epoch [153/10000], Train Loss: 73.0112, Val Loss: 237.8375\n",
      "Epoch [154/10000], Train Loss: 72.9604, Val Loss: 237.5540\n",
      "Epoch [155/10000], Train Loss: 72.9187, Val Loss: 237.3095\n",
      "Epoch [156/10000], Train Loss: 72.8840, Val Loss: 237.1044\n",
      "Epoch [157/10000], Train Loss: 72.8549, Val Loss: 236.9376\n",
      "Epoch [158/10000], Train Loss: 72.8302, Val Loss: 236.8065\n",
      "Epoch [159/10000], Train Loss: 72.8079, Val Loss: 236.7005\n",
      "Epoch [160/10000], Train Loss: 72.7878, Val Loss: 236.6233\n",
      "Epoch [161/10000], Train Loss: 72.7694, Val Loss: 236.5726\n",
      "Epoch [162/10000], Train Loss: 72.7523, Val Loss: 236.5454\n",
      "Epoch [163/10000], Train Loss: 72.7358, Val Loss: 236.5381\n",
      "Epoch [164/10000], Train Loss: 72.7183, Val Loss: 236.5485\n",
      "Epoch [165/10000], Train Loss: 72.7009, Val Loss: 236.5742\n",
      "Epoch [166/10000], Train Loss: 72.6831, Val Loss: 236.6131\n",
      "Epoch [167/10000], Train Loss: 72.6641, Val Loss: 236.6635\n",
      "Epoch [168/10000], Train Loss: 72.6446, Val Loss: 236.7232\n",
      "Epoch [169/10000], Train Loss: 72.6246, Val Loss: 236.7901\n",
      "Epoch [170/10000], Train Loss: 72.6042, Val Loss: 236.8627\n",
      "Epoch [171/10000], Train Loss: 72.5832, Val Loss: 236.9387\n",
      "Epoch [172/10000], Train Loss: 72.5619, Val Loss: 237.0170\n",
      "Epoch [173/10000], Train Loss: 72.5403, Val Loss: 237.0964\n",
      "Epoch [174/10000], Train Loss: 72.5183, Val Loss: 237.1757\n",
      "Epoch [175/10000], Train Loss: 72.4960, Val Loss: 237.2538\n",
      "Epoch [176/10000], Train Loss: 72.4733, Val Loss: 237.3297\n",
      "Epoch [177/10000], Train Loss: 72.4505, Val Loss: 237.4024\n",
      "Epoch [178/10000], Train Loss: 72.4274, Val Loss: 237.4708\n",
      "Epoch [179/10000], Train Loss: 72.4040, Val Loss: 237.5340\n",
      "Epoch [180/10000], Train Loss: 72.3806, Val Loss: 237.5913\n",
      "Epoch [181/10000], Train Loss: 72.3570, Val Loss: 237.6425\n",
      "Epoch [182/10000], Train Loss: 72.3350, Val Loss: 237.6888\n",
      "Epoch [183/10000], Train Loss: 72.3147, Val Loss: 237.7301\n",
      "Epoch [184/10000], Train Loss: 72.2945, Val Loss: 237.7659\n",
      "Epoch [185/10000], Train Loss: 72.2742, Val Loss: 237.7957\n",
      "Epoch [186/10000], Train Loss: 72.2541, Val Loss: 237.8193\n",
      "Epoch [187/10000], Train Loss: 72.2341, Val Loss: 237.8365\n",
      "Epoch [188/10000], Train Loss: 72.2142, Val Loss: 237.8472\n",
      "Epoch [189/10000], Train Loss: 72.1944, Val Loss: 237.8516\n",
      "Epoch [190/10000], Train Loss: 72.1748, Val Loss: 237.8498\n",
      "Epoch [191/10000], Train Loss: 72.1553, Val Loss: 237.8421\n",
      "Epoch [192/10000], Train Loss: 72.1359, Val Loss: 237.8289\n",
      "Epoch [193/10000], Train Loss: 72.1168, Val Loss: 237.8101\n",
      "Epoch [194/10000], Train Loss: 72.0977, Val Loss: 237.7863\n",
      "Epoch [195/10000], Train Loss: 72.0788, Val Loss: 237.7576\n",
      "Epoch [196/10000], Train Loss: 72.0601, Val Loss: 237.7246\n",
      "Epoch [197/10000], Train Loss: 72.0415, Val Loss: 237.6878\n",
      "Epoch [198/10000], Train Loss: 72.0224, Val Loss: 237.6466\n",
      "Epoch [199/10000], Train Loss: 72.0026, Val Loss: 237.6013\n",
      "Epoch [200/10000], Train Loss: 71.9826, Val Loss: 237.5533\n",
      "Epoch [201/10000], Train Loss: 71.9626, Val Loss: 237.5027\n",
      "Epoch [202/10000], Train Loss: 71.9426, Val Loss: 237.4501\n",
      "Epoch [203/10000], Train Loss: 71.9225, Val Loss: 237.3963\n",
      "Epoch [204/10000], Train Loss: 71.9024, Val Loss: 237.3419\n",
      "Epoch [205/10000], Train Loss: 71.8823, Val Loss: 237.2873\n",
      "Epoch [206/10000], Train Loss: 71.8623, Val Loss: 237.2330\n",
      "Epoch [207/10000], Train Loss: 71.8422, Val Loss: 237.1797\n",
      "Epoch [208/10000], Train Loss: 71.8221, Val Loss: 237.1276\n",
      "Epoch [209/10000], Train Loss: 71.8020, Val Loss: 237.0769\n",
      "Epoch [210/10000], Train Loss: 71.7819, Val Loss: 237.0277\n",
      "Epoch [211/10000], Train Loss: 71.7619, Val Loss: 236.9802\n",
      "Epoch [212/10000], Train Loss: 71.7418, Val Loss: 236.9345\n",
      "Epoch [213/10000], Train Loss: 71.7218, Val Loss: 236.8907\n",
      "Epoch [214/10000], Train Loss: 71.7017, Val Loss: 236.8487\n",
      "Epoch [215/10000], Train Loss: 71.6816, Val Loss: 236.8084\n",
      "Epoch [216/10000], Train Loss: 71.6616, Val Loss: 236.7698\n",
      "Epoch [217/10000], Train Loss: 71.6415, Val Loss: 236.7327\n",
      "Epoch [218/10000], Train Loss: 71.6214, Val Loss: 236.6970\n",
      "Epoch [219/10000], Train Loss: 71.6013, Val Loss: 236.6625\n",
      "Epoch [220/10000], Train Loss: 71.5812, Val Loss: 236.6289\n",
      "Epoch [221/10000], Train Loss: 71.5611, Val Loss: 236.5962\n",
      "Epoch [222/10000], Train Loss: 71.5412, Val Loss: 236.5645\n",
      "Epoch [223/10000], Train Loss: 71.5213, Val Loss: 236.5335\n",
      "Epoch [224/10000], Train Loss: 71.5014, Val Loss: 236.5031\n",
      "Epoch [225/10000], Train Loss: 71.4815, Val Loss: 236.4730\n",
      "Epoch [226/10000], Train Loss: 71.4616, Val Loss: 236.4433\n",
      "Epoch [227/10000], Train Loss: 71.4418, Val Loss: 236.4139\n",
      "Epoch [228/10000], Train Loss: 71.4219, Val Loss: 236.3846\n",
      "Epoch [229/10000], Train Loss: 71.4020, Val Loss: 236.3556\n",
      "Epoch [230/10000], Train Loss: 71.3821, Val Loss: 236.3268\n",
      "Epoch [231/10000], Train Loss: 71.3623, Val Loss: 236.2980\n",
      "Epoch [232/10000], Train Loss: 71.3424, Val Loss: 236.2697\n",
      "Epoch [233/10000], Train Loss: 71.3225, Val Loss: 236.2413\n",
      "Epoch [234/10000], Train Loss: 71.3026, Val Loss: 236.2132\n",
      "Epoch [235/10000], Train Loss: 71.2828, Val Loss: 236.1852\n",
      "Epoch [236/10000], Train Loss: 71.2629, Val Loss: 236.1576\n",
      "Epoch [237/10000], Train Loss: 71.2431, Val Loss: 236.1304\n",
      "Epoch [238/10000], Train Loss: 71.2232, Val Loss: 236.1033\n",
      "Epoch [239/10000], Train Loss: 71.2033, Val Loss: 236.0767\n",
      "Epoch [240/10000], Train Loss: 71.1837, Val Loss: 236.0505\n",
      "Epoch [241/10000], Train Loss: 71.1640, Val Loss: 236.0246\n",
      "Epoch [242/10000], Train Loss: 71.1444, Val Loss: 235.9992\n",
      "Epoch [243/10000], Train Loss: 71.1248, Val Loss: 235.9742\n",
      "Epoch [244/10000], Train Loss: 71.1052, Val Loss: 235.9495\n",
      "Epoch [245/10000], Train Loss: 71.0856, Val Loss: 235.9252\n",
      "Epoch [246/10000], Train Loss: 71.0672, Val Loss: 235.9043\n",
      "Epoch [247/10000], Train Loss: 71.0521, Val Loss: 235.8866\n",
      "Epoch [248/10000], Train Loss: 71.0365, Val Loss: 235.8713\n",
      "Epoch [249/10000], Train Loss: 71.0205, Val Loss: 235.8580\n",
      "Epoch [250/10000], Train Loss: 71.0042, Val Loss: 235.8462\n",
      "Epoch [251/10000], Train Loss: 70.9877, Val Loss: 235.8354\n",
      "Epoch [252/10000], Train Loss: 70.9710, Val Loss: 235.8250\n",
      "Epoch [253/10000], Train Loss: 70.9542, Val Loss: 235.8146\n",
      "Epoch [254/10000], Train Loss: 70.9372, Val Loss: 235.8041\n",
      "Epoch [255/10000], Train Loss: 70.9202, Val Loss: 235.7925\n",
      "Epoch [256/10000], Train Loss: 70.9030, Val Loss: 235.7799\n",
      "Epoch [257/10000], Train Loss: 70.8858, Val Loss: 235.7660\n",
      "Epoch [258/10000], Train Loss: 70.8685, Val Loss: 235.7507\n",
      "Epoch [259/10000], Train Loss: 70.8512, Val Loss: 235.7340\n",
      "Epoch [260/10000], Train Loss: 70.8337, Val Loss: 235.7157\n",
      "Epoch [261/10000], Train Loss: 70.8163, Val Loss: 235.6962\n",
      "Epoch [262/10000], Train Loss: 70.7987, Val Loss: 235.6753\n",
      "Epoch [263/10000], Train Loss: 70.7832, Val Loss: 235.6500\n",
      "Epoch [264/10000], Train Loss: 70.7672, Val Loss: 235.6210\n",
      "Epoch [265/10000], Train Loss: 70.7507, Val Loss: 235.5889\n",
      "Epoch [266/10000], Train Loss: 70.7338, Val Loss: 235.5547\n",
      "Epoch [267/10000], Train Loss: 70.7164, Val Loss: 235.5188\n",
      "Epoch [268/10000], Train Loss: 70.6988, Val Loss: 235.4821\n",
      "Epoch [269/10000], Train Loss: 70.6809, Val Loss: 235.4451\n",
      "Epoch [270/10000], Train Loss: 70.6645, Val Loss: 235.4118\n",
      "Epoch [271/10000], Train Loss: 70.6484, Val Loss: 235.3820\n",
      "Epoch [272/10000], Train Loss: 70.6320, Val Loss: 235.3555\n",
      "Epoch [273/10000], Train Loss: 70.6154, Val Loss: 235.3323\n",
      "Epoch [274/10000], Train Loss: 70.5986, Val Loss: 235.3116\n",
      "Epoch [275/10000], Train Loss: 70.5816, Val Loss: 235.2934\n",
      "Epoch [276/10000], Train Loss: 70.5644, Val Loss: 235.2768\n",
      "Epoch [277/10000], Train Loss: 70.5471, Val Loss: 235.2614\n",
      "Epoch [278/10000], Train Loss: 70.5297, Val Loss: 235.2465\n",
      "Epoch [279/10000], Train Loss: 70.5126, Val Loss: 235.2285\n",
      "Epoch [280/10000], Train Loss: 70.4962, Val Loss: 235.2072\n",
      "Epoch [281/10000], Train Loss: 70.4795, Val Loss: 235.1828\n",
      "Epoch [282/10000], Train Loss: 70.4624, Val Loss: 235.1552\n",
      "Epoch [283/10000], Train Loss: 70.4451, Val Loss: 235.1248\n",
      "Epoch [284/10000], Train Loss: 70.4285, Val Loss: 235.0949\n",
      "Epoch [285/10000], Train Loss: 70.4120, Val Loss: 235.0658\n",
      "Epoch [286/10000], Train Loss: 70.3953, Val Loss: 235.0372\n",
      "Epoch [287/10000], Train Loss: 70.3784, Val Loss: 235.0091\n",
      "Epoch [288/10000], Train Loss: 70.3614, Val Loss: 234.9814\n",
      "Epoch [289/10000], Train Loss: 70.3443, Val Loss: 234.9540\n",
      "Epoch [290/10000], Train Loss: 70.3271, Val Loss: 234.9268\n",
      "Epoch [291/10000], Train Loss: 70.3109, Val Loss: 234.8965\n",
      "Epoch [292/10000], Train Loss: 70.2945, Val Loss: 234.8634\n",
      "Epoch [293/10000], Train Loss: 70.2776, Val Loss: 234.8279\n",
      "Epoch [294/10000], Train Loss: 70.2605, Val Loss: 234.7903\n",
      "Epoch [295/10000], Train Loss: 70.2432, Val Loss: 234.7549\n",
      "Epoch [296/10000], Train Loss: 70.2267, Val Loss: 234.7216\n",
      "Epoch [297/10000], Train Loss: 70.2100, Val Loss: 234.6903\n",
      "Epoch [298/10000], Train Loss: 70.1931, Val Loss: 234.6609\n",
      "Epoch [299/10000], Train Loss: 70.1761, Val Loss: 234.6332\n",
      "Epoch [300/10000], Train Loss: 70.1594, Val Loss: 234.6041\n",
      "Epoch [301/10000], Train Loss: 70.1428, Val Loss: 234.5734\n",
      "Epoch [302/10000], Train Loss: 70.1257, Val Loss: 234.5415\n",
      "Epoch [303/10000], Train Loss: 70.1090, Val Loss: 234.5121\n",
      "Epoch [304/10000], Train Loss: 70.0924, Val Loss: 234.4851\n",
      "Epoch [305/10000], Train Loss: 70.0756, Val Loss: 234.4601\n",
      "Epoch [306/10000], Train Loss: 70.0587, Val Loss: 234.4368\n",
      "Epoch [307/10000], Train Loss: 70.0416, Val Loss: 234.4150\n",
      "Epoch [308/10000], Train Loss: 70.0252, Val Loss: 234.3910\n",
      "Epoch [309/10000], Train Loss: 70.0085, Val Loss: 234.3650\n",
      "Epoch [310/10000], Train Loss: 69.9915, Val Loss: 234.3371\n",
      "Epoch [311/10000], Train Loss: 69.9746, Val Loss: 234.3111\n",
      "Epoch [312/10000], Train Loss: 69.9582, Val Loss: 234.2866\n",
      "Epoch [313/10000], Train Loss: 69.9416, Val Loss: 234.2634\n",
      "Epoch [314/10000], Train Loss: 69.9250, Val Loss: 234.2415\n",
      "Epoch [315/10000], Train Loss: 69.9083, Val Loss: 234.2170\n",
      "Epoch [316/10000], Train Loss: 69.8917, Val Loss: 234.1902\n",
      "Epoch [317/10000], Train Loss: 69.8754, Val Loss: 234.1649\n",
      "Epoch [318/10000], Train Loss: 69.8589, Val Loss: 234.1406\n",
      "Epoch [319/10000], Train Loss: 69.8423, Val Loss: 234.1175\n",
      "Epoch [320/10000], Train Loss: 69.8256, Val Loss: 234.0951\n",
      "Epoch [321/10000], Train Loss: 69.8094, Val Loss: 234.0702\n",
      "Epoch [322/10000], Train Loss: 69.7929, Val Loss: 234.0427\n",
      "Epoch [323/10000], Train Loss: 69.7761, Val Loss: 234.0131\n",
      "Epoch [324/10000], Train Loss: 69.7597, Val Loss: 233.9850\n",
      "Epoch [325/10000], Train Loss: 69.7434, Val Loss: 233.9586\n",
      "Epoch [326/10000], Train Loss: 69.7269, Val Loss: 233.9336\n",
      "Epoch [327/10000], Train Loss: 69.7103, Val Loss: 233.9099\n",
      "Epoch [328/10000], Train Loss: 69.6935, Val Loss: 233.8874\n",
      "Epoch [329/10000], Train Loss: 69.6767, Val Loss: 233.8656\n",
      "Epoch [330/10000], Train Loss: 69.6607, Val Loss: 233.8412\n",
      "Epoch [331/10000], Train Loss: 69.6443, Val Loss: 233.8141\n",
      "Epoch [332/10000], Train Loss: 69.6276, Val Loss: 233.7847\n",
      "Epoch [333/10000], Train Loss: 69.6105, Val Loss: 233.7535\n",
      "Epoch [334/10000], Train Loss: 69.5942, Val Loss: 233.7242\n",
      "Epoch [335/10000], Train Loss: 69.5779, Val Loss: 233.6969\n",
      "Epoch [336/10000], Train Loss: 69.5615, Val Loss: 233.6713\n",
      "Epoch [337/10000], Train Loss: 69.5449, Val Loss: 233.6472\n",
      "Epoch [338/10000], Train Loss: 69.5282, Val Loss: 233.6245\n",
      "Epoch [339/10000], Train Loss: 69.5113, Val Loss: 233.6027\n",
      "Epoch [340/10000], Train Loss: 69.4943, Val Loss: 233.5818\n",
      "Epoch [341/10000], Train Loss: 69.4778, Val Loss: 233.5579\n",
      "Epoch [342/10000], Train Loss: 69.4614, Val Loss: 233.5311\n",
      "Epoch [343/10000], Train Loss: 69.4447, Val Loss: 233.5020\n",
      "Epoch [344/10000], Train Loss: 69.4276, Val Loss: 233.4742\n",
      "Epoch [345/10000], Train Loss: 69.4110, Val Loss: 233.4477\n",
      "Epoch [346/10000], Train Loss: 69.3943, Val Loss: 233.4223\n",
      "Epoch [347/10000], Train Loss: 69.3776, Val Loss: 233.3981\n",
      "Epoch [348/10000], Train Loss: 69.3612, Val Loss: 233.3711\n",
      "Epoch [349/10000], Train Loss: 69.3445, Val Loss: 233.3420\n",
      "Epoch [350/10000], Train Loss: 69.3275, Val Loss: 233.3144\n",
      "Epoch [351/10000], Train Loss: 69.3109, Val Loss: 233.2881\n",
      "Epoch [352/10000], Train Loss: 69.2942, Val Loss: 233.2632\n",
      "Epoch [353/10000], Train Loss: 69.2774, Val Loss: 233.2360\n",
      "Epoch [354/10000], Train Loss: 69.2607, Val Loss: 233.2102\n",
      "Epoch [355/10000], Train Loss: 69.2439, Val Loss: 233.1823\n",
      "Epoch [356/10000], Train Loss: 69.2273, Val Loss: 233.1561\n",
      "Epoch [357/10000], Train Loss: 69.2106, Val Loss: 233.1310\n",
      "Epoch [358/10000], Train Loss: 69.1937, Val Loss: 233.1074\n",
      "Epoch [359/10000], Train Loss: 69.1770, Val Loss: 233.0813\n",
      "Epoch [360/10000], Train Loss: 69.1602, Val Loss: 233.0530\n",
      "Epoch [361/10000], Train Loss: 69.1435, Val Loss: 233.0264\n",
      "Epoch [362/10000], Train Loss: 69.1268, Val Loss: 233.0011\n",
      "Epoch [363/10000], Train Loss: 69.1100, Val Loss: 232.9772\n",
      "Epoch [364/10000], Train Loss: 69.0931, Val Loss: 232.9544\n",
      "Epoch [365/10000], Train Loss: 69.0763, Val Loss: 232.9290\n",
      "Epoch [366/10000], Train Loss: 69.0595, Val Loss: 232.9011\n",
      "Epoch [367/10000], Train Loss: 69.0426, Val Loss: 232.8746\n",
      "Epoch [368/10000], Train Loss: 69.0258, Val Loss: 232.8495\n",
      "Epoch [369/10000], Train Loss: 69.0090, Val Loss: 232.8254\n",
      "Epoch [370/10000], Train Loss: 68.9920, Val Loss: 232.8023\n",
      "Epoch [371/10000], Train Loss: 68.9755, Val Loss: 232.7764\n",
      "Epoch [372/10000], Train Loss: 68.9587, Val Loss: 232.7481\n",
      "Epoch [373/10000], Train Loss: 68.9414, Val Loss: 232.7176\n",
      "Epoch [374/10000], Train Loss: 68.9248, Val Loss: 232.6887\n",
      "Epoch [375/10000], Train Loss: 68.9082, Val Loss: 232.6617\n",
      "Epoch [376/10000], Train Loss: 68.8916, Val Loss: 232.6397\n",
      "Epoch [377/10000], Train Loss: 68.8760, Val Loss: 232.6226\n",
      "Epoch [378/10000], Train Loss: 68.8602, Val Loss: 232.6096\n",
      "Epoch [379/10000], Train Loss: 68.8442, Val Loss: 232.6001\n",
      "Epoch [380/10000], Train Loss: 68.8284, Val Loss: 232.5894\n",
      "Epoch [381/10000], Train Loss: 68.8129, Val Loss: 232.5770\n",
      "Epoch [382/10000], Train Loss: 68.7970, Val Loss: 232.5629\n",
      "Epoch [383/10000], Train Loss: 68.7810, Val Loss: 232.5509\n",
      "Epoch [384/10000], Train Loss: 68.7653, Val Loss: 232.5408\n",
      "Epoch [385/10000], Train Loss: 68.7495, Val Loss: 232.5318\n",
      "Epoch [386/10000], Train Loss: 68.7336, Val Loss: 232.5237\n",
      "Epoch [387/10000], Train Loss: 68.7178, Val Loss: 232.5122\n",
      "Epoch [388/10000], Train Loss: 68.7020, Val Loss: 232.4971\n",
      "Epoch [389/10000], Train Loss: 68.6862, Val Loss: 232.4826\n",
      "Epoch [390/10000], Train Loss: 68.6705, Val Loss: 232.4686\n",
      "Epoch [391/10000], Train Loss: 68.6547, Val Loss: 232.4551\n",
      "Epoch [392/10000], Train Loss: 68.6388, Val Loss: 232.4417\n",
      "Epoch [393/10000], Train Loss: 68.6231, Val Loss: 232.4244\n",
      "Epoch [394/10000], Train Loss: 68.6074, Val Loss: 232.4034\n",
      "Epoch [395/10000], Train Loss: 68.5915, Val Loss: 232.3829\n",
      "Epoch [396/10000], Train Loss: 68.5759, Val Loss: 232.3629\n",
      "Epoch [397/10000], Train Loss: 68.5601, Val Loss: 232.3433\n",
      "Epoch [398/10000], Train Loss: 68.5443, Val Loss: 232.3243\n",
      "Epoch [399/10000], Train Loss: 68.5286, Val Loss: 232.3018\n",
      "Epoch [400/10000], Train Loss: 68.5128, Val Loss: 232.2760\n",
      "Epoch [401/10000], Train Loss: 68.4971, Val Loss: 232.2510\n",
      "Epoch [402/10000], Train Loss: 68.4814, Val Loss: 232.2269\n",
      "Epoch [403/10000], Train Loss: 68.4657, Val Loss: 232.2036\n",
      "Epoch [404/10000], Train Loss: 68.4498, Val Loss: 232.1812\n",
      "Epoch [405/10000], Train Loss: 68.4341, Val Loss: 232.1557\n",
      "Epoch [406/10000], Train Loss: 68.4183, Val Loss: 232.1271\n",
      "Epoch [407/10000], Train Loss: 68.4028, Val Loss: 232.0997\n",
      "Epoch [408/10000], Train Loss: 68.3872, Val Loss: 232.0732\n",
      "Epoch [409/10000], Train Loss: 68.3714, Val Loss: 232.0480\n",
      "Epoch [410/10000], Train Loss: 68.3556, Val Loss: 232.0237\n",
      "Epoch [411/10000], Train Loss: 68.3398, Val Loss: 232.0002\n",
      "Epoch [412/10000], Train Loss: 68.3245, Val Loss: 231.9732\n",
      "Epoch [413/10000], Train Loss: 68.3088, Val Loss: 231.9432\n",
      "Epoch [414/10000], Train Loss: 68.2928, Val Loss: 231.9103\n",
      "Epoch [415/10000], Train Loss: 68.2772, Val Loss: 231.8792\n",
      "Epoch [416/10000], Train Loss: 68.2618, Val Loss: 231.8499\n",
      "Epoch [417/10000], Train Loss: 68.2462, Val Loss: 231.8223\n",
      "Epoch [418/10000], Train Loss: 68.2305, Val Loss: 231.7961\n",
      "Epoch [419/10000], Train Loss: 68.2148, Val Loss: 231.7712\n",
      "Epoch [420/10000], Train Loss: 68.1989, Val Loss: 231.7471\n",
      "Epoch [421/10000], Train Loss: 68.1830, Val Loss: 231.7238\n",
      "Epoch [422/10000], Train Loss: 68.1679, Val Loss: 231.6971\n",
      "Epoch [423/10000], Train Loss: 68.1525, Val Loss: 231.6674\n",
      "Epoch [424/10000], Train Loss: 68.1366, Val Loss: 231.6309\n",
      "Epoch [425/10000], Train Loss: 68.1205, Val Loss: 231.5964\n",
      "Epoch [426/10000], Train Loss: 68.1051, Val Loss: 231.5637\n",
      "Epoch [427/10000], Train Loss: 68.0895, Val Loss: 231.5333\n",
      "Epoch [428/10000], Train Loss: 68.0739, Val Loss: 231.5054\n",
      "Epoch [429/10000], Train Loss: 68.0582, Val Loss: 231.4794\n",
      "Epoch [430/10000], Train Loss: 68.0424, Val Loss: 231.4552\n",
      "Epoch [431/10000], Train Loss: 68.0274, Val Loss: 231.4240\n",
      "Epoch [432/10000], Train Loss: 68.0119, Val Loss: 231.3905\n",
      "Epoch [433/10000], Train Loss: 67.9959, Val Loss: 231.3552\n",
      "Epoch [434/10000], Train Loss: 67.9803, Val Loss: 231.3231\n",
      "Epoch [435/10000], Train Loss: 67.9650, Val Loss: 231.2942\n",
      "Epoch [436/10000], Train Loss: 67.9495, Val Loss: 231.2681\n",
      "Epoch [437/10000], Train Loss: 67.9340, Val Loss: 231.2442\n",
      "Epoch [438/10000], Train Loss: 67.9183, Val Loss: 231.2219\n",
      "Epoch [439/10000], Train Loss: 67.9025, Val Loss: 231.2009\n",
      "Epoch [440/10000], Train Loss: 67.8868, Val Loss: 231.1771\n",
      "Epoch [441/10000], Train Loss: 67.8714, Val Loss: 231.1509\n",
      "Epoch [442/10000], Train Loss: 67.8557, Val Loss: 231.1262\n",
      "Epoch [443/10000], Train Loss: 67.8402, Val Loss: 231.1030\n",
      "Epoch [444/10000], Train Loss: 67.8246, Val Loss: 231.0806\n",
      "Epoch [445/10000], Train Loss: 67.8092, Val Loss: 231.0549\n",
      "Epoch [446/10000], Train Loss: 67.7935, Val Loss: 231.0265\n",
      "Epoch [447/10000], Train Loss: 67.7782, Val Loss: 230.9998\n",
      "Epoch [448/10000], Train Loss: 67.7628, Val Loss: 230.9747\n",
      "Epoch [449/10000], Train Loss: 67.7473, Val Loss: 230.9464\n",
      "Epoch [450/10000], Train Loss: 67.7318, Val Loss: 230.9197\n",
      "Epoch [451/10000], Train Loss: 67.7161, Val Loss: 230.8943\n",
      "Epoch [452/10000], Train Loss: 67.7004, Val Loss: 230.8702\n",
      "Epoch [453/10000], Train Loss: 67.6853, Val Loss: 230.8435\n",
      "Epoch [454/10000], Train Loss: 67.6700, Val Loss: 230.8143\n",
      "Epoch [455/10000], Train Loss: 67.6541, Val Loss: 230.7830\n",
      "Epoch [456/10000], Train Loss: 67.6386, Val Loss: 230.7537\n",
      "Epoch [457/10000], Train Loss: 67.6233, Val Loss: 230.7264\n",
      "Epoch [458/10000], Train Loss: 67.6079, Val Loss: 230.7012\n",
      "Epoch [459/10000], Train Loss: 67.5924, Val Loss: 230.6782\n",
      "Epoch [460/10000], Train Loss: 67.5768, Val Loss: 230.6569\n",
      "Epoch [461/10000], Train Loss: 67.5611, Val Loss: 230.6367\n",
      "Epoch [462/10000], Train Loss: 67.5455, Val Loss: 230.6128\n",
      "Epoch [463/10000], Train Loss: 67.5301, Val Loss: 230.5856\n",
      "Epoch [464/10000], Train Loss: 67.5146, Val Loss: 230.5600\n",
      "Epoch [465/10000], Train Loss: 67.4992, Val Loss: 230.5356\n",
      "Epoch [466/10000], Train Loss: 67.4837, Val Loss: 230.5124\n",
      "Epoch [467/10000], Train Loss: 67.4681, Val Loss: 230.4858\n",
      "Epoch [468/10000], Train Loss: 67.4527, Val Loss: 230.4604\n",
      "Epoch [469/10000], Train Loss: 67.4373, Val Loss: 230.4357\n",
      "Epoch [470/10000], Train Loss: 67.4218, Val Loss: 230.4079\n",
      "Epoch [471/10000], Train Loss: 67.4064, Val Loss: 230.3813\n",
      "Epoch [472/10000], Train Loss: 67.3910, Val Loss: 230.3560\n",
      "Epoch [473/10000], Train Loss: 67.3755, Val Loss: 230.3318\n",
      "Epoch [474/10000], Train Loss: 67.3602, Val Loss: 230.3041\n",
      "Epoch [475/10000], Train Loss: 67.3446, Val Loss: 230.2734\n",
      "Epoch [476/10000], Train Loss: 67.3293, Val Loss: 230.2443\n",
      "Epoch [477/10000], Train Loss: 67.3140, Val Loss: 230.2170\n",
      "Epoch [478/10000], Train Loss: 67.2987, Val Loss: 230.1914\n",
      "Epoch [479/10000], Train Loss: 67.2831, Val Loss: 230.1672\n",
      "Epoch [480/10000], Train Loss: 67.2676, Val Loss: 230.1441\n",
      "Epoch [481/10000], Train Loss: 67.2520, Val Loss: 230.1174\n",
      "Epoch [482/10000], Train Loss: 67.2366, Val Loss: 230.0877\n",
      "Epoch [483/10000], Train Loss: 67.2213, Val Loss: 230.0594\n",
      "Epoch [484/10000], Train Loss: 67.2061, Val Loss: 230.0327\n",
      "Epoch [485/10000], Train Loss: 67.1907, Val Loss: 230.0073\n",
      "Epoch [486/10000], Train Loss: 67.1753, Val Loss: 229.9832\n",
      "Epoch [487/10000], Train Loss: 67.1598, Val Loss: 229.9598\n",
      "Epoch [488/10000], Train Loss: 67.1449, Val Loss: 229.9327\n",
      "Epoch [489/10000], Train Loss: 67.1295, Val Loss: 229.9023\n",
      "Epoch [490/10000], Train Loss: 67.1138, Val Loss: 229.8690\n",
      "Epoch [491/10000], Train Loss: 67.0987, Val Loss: 229.8378\n",
      "Epoch [492/10000], Train Loss: 67.0836, Val Loss: 229.8086\n",
      "Epoch [493/10000], Train Loss: 67.0685, Val Loss: 229.7816\n",
      "Epoch [494/10000], Train Loss: 67.0532, Val Loss: 229.7563\n",
      "Epoch [495/10000], Train Loss: 67.0378, Val Loss: 229.7324\n",
      "Epoch [496/10000], Train Loss: 67.0223, Val Loss: 229.7097\n",
      "Epoch [497/10000], Train Loss: 67.0068, Val Loss: 229.6877\n",
      "Epoch [498/10000], Train Loss: 66.9912, Val Loss: 229.6664\n",
      "Epoch [499/10000], Train Loss: 66.9765, Val Loss: 229.6408\n",
      "Epoch [500/10000], Train Loss: 66.9615, Val Loss: 229.6113\n",
      "Epoch [501/10000], Train Loss: 66.9459, Val Loss: 229.5784\n",
      "Epoch [502/10000], Train Loss: 66.9300, Val Loss: 229.5470\n",
      "Epoch [503/10000], Train Loss: 66.9149, Val Loss: 229.5174\n",
      "Epoch [504/10000], Train Loss: 66.8997, Val Loss: 229.4896\n",
      "Epoch [505/10000], Train Loss: 66.8844, Val Loss: 229.4633\n",
      "Epoch [506/10000], Train Loss: 66.8690, Val Loss: 229.4386\n",
      "Epoch [507/10000], Train Loss: 66.8536, Val Loss: 229.4147\n",
      "Epoch [508/10000], Train Loss: 66.8386, Val Loss: 229.3874\n",
      "Epoch [509/10000], Train Loss: 66.8234, Val Loss: 229.3567\n",
      "Epoch [510/10000], Train Loss: 66.8077, Val Loss: 229.3281\n",
      "Epoch [511/10000], Train Loss: 66.7925, Val Loss: 229.3010\n",
      "Epoch [512/10000], Train Loss: 66.7772, Val Loss: 229.2754\n",
      "Epoch [513/10000], Train Loss: 66.7618, Val Loss: 229.2465\n",
      "Epoch [514/10000], Train Loss: 66.7467, Val Loss: 229.2194\n",
      "Epoch [515/10000], Train Loss: 66.7314, Val Loss: 229.1937\n",
      "Epoch [516/10000], Train Loss: 66.7161, Val Loss: 229.1693\n",
      "Epoch [517/10000], Train Loss: 66.7009, Val Loss: 229.1414\n",
      "Epoch [518/10000], Train Loss: 66.6855, Val Loss: 229.1106\n",
      "Epoch [519/10000], Train Loss: 66.6705, Val Loss: 229.0814\n",
      "Epoch [520/10000], Train Loss: 66.6553, Val Loss: 229.0540\n",
      "Epoch [521/10000], Train Loss: 66.6401, Val Loss: 229.0281\n",
      "Epoch [522/10000], Train Loss: 66.6248, Val Loss: 229.0036\n",
      "Epoch [523/10000], Train Loss: 66.6094, Val Loss: 228.9803\n",
      "Epoch [524/10000], Train Loss: 66.5940, Val Loss: 228.9579\n",
      "Epoch [525/10000], Train Loss: 66.5790, Val Loss: 228.9310\n",
      "Epoch [526/10000], Train Loss: 66.5638, Val Loss: 228.9004\n",
      "Epoch [527/10000], Train Loss: 66.5482, Val Loss: 228.8666\n",
      "Epoch [528/10000], Train Loss: 66.5332, Val Loss: 228.8348\n",
      "Epoch [529/10000], Train Loss: 66.5182, Val Loss: 228.8051\n",
      "Epoch [530/10000], Train Loss: 66.5031, Val Loss: 228.7774\n",
      "Epoch [531/10000], Train Loss: 66.4879, Val Loss: 228.7514\n",
      "Epoch [532/10000], Train Loss: 66.4725, Val Loss: 228.7270\n",
      "Epoch [533/10000], Train Loss: 66.4572, Val Loss: 228.7039\n",
      "Epoch [534/10000], Train Loss: 66.4417, Val Loss: 228.6815\n",
      "Epoch [535/10000], Train Loss: 66.4262, Val Loss: 228.6597\n",
      "Epoch [536/10000], Train Loss: 66.4115, Val Loss: 228.6336\n",
      "Epoch [537/10000], Train Loss: 66.3964, Val Loss: 228.6035\n",
      "Epoch [538/10000], Train Loss: 66.3808, Val Loss: 228.5697\n",
      "Epoch [539/10000], Train Loss: 66.3653, Val Loss: 228.5377\n",
      "Epoch [540/10000], Train Loss: 66.3502, Val Loss: 228.5077\n",
      "Epoch [541/10000], Train Loss: 66.3351, Val Loss: 228.4798\n",
      "Epoch [542/10000], Train Loss: 66.3199, Val Loss: 228.4536\n",
      "Epoch [543/10000], Train Loss: 66.3046, Val Loss: 228.4290\n",
      "Epoch [544/10000], Train Loss: 66.2891, Val Loss: 228.4055\n",
      "Epoch [545/10000], Train Loss: 66.2737, Val Loss: 228.3830\n",
      "Epoch [546/10000], Train Loss: 66.2590, Val Loss: 228.3565\n",
      "Epoch [547/10000], Train Loss: 66.2439, Val Loss: 228.3262\n",
      "Epoch [548/10000], Train Loss: 66.2283, Val Loss: 228.2930\n",
      "Epoch [549/10000], Train Loss: 66.2132, Val Loss: 228.2617\n",
      "Epoch [550/10000], Train Loss: 66.1984, Val Loss: 228.2327\n",
      "Epoch [551/10000], Train Loss: 66.1835, Val Loss: 228.2058\n",
      "Epoch [552/10000], Train Loss: 66.1684, Val Loss: 228.1810\n",
      "Epoch [553/10000], Train Loss: 66.1533, Val Loss: 228.1579\n",
      "Epoch [554/10000], Train Loss: 66.1380, Val Loss: 228.1355\n",
      "Epoch [555/10000], Train Loss: 66.1228, Val Loss: 228.1138\n",
      "Epoch [556/10000], Train Loss: 66.1076, Val Loss: 228.0879\n",
      "Epoch [557/10000], Train Loss: 66.0926, Val Loss: 228.0580\n",
      "Epoch [558/10000], Train Loss: 66.0774, Val Loss: 228.0294\n",
      "Epoch [559/10000], Train Loss: 66.0624, Val Loss: 228.0018\n",
      "Epoch [560/10000], Train Loss: 66.0473, Val Loss: 227.9752\n",
      "Epoch [561/10000], Train Loss: 66.0322, Val Loss: 227.9498\n",
      "Epoch [562/10000], Train Loss: 66.0172, Val Loss: 227.9205\n",
      "Epoch [563/10000], Train Loss: 66.0020, Val Loss: 227.8876\n",
      "Epoch [564/10000], Train Loss: 65.9871, Val Loss: 227.8566\n",
      "Epoch [565/10000], Train Loss: 65.9722, Val Loss: 227.8275\n",
      "Epoch [566/10000], Train Loss: 65.9572, Val Loss: 227.8005\n",
      "Epoch [567/10000], Train Loss: 65.9421, Val Loss: 227.7751\n",
      "Epoch [568/10000], Train Loss: 65.9269, Val Loss: 227.7513\n",
      "Epoch [569/10000], Train Loss: 65.9116, Val Loss: 227.7284\n",
      "Epoch [570/10000], Train Loss: 65.8967, Val Loss: 227.7014\n",
      "Epoch [571/10000], Train Loss: 65.8817, Val Loss: 227.6706\n",
      "Epoch [572/10000], Train Loss: 65.8663, Val Loss: 227.6414\n",
      "Epoch [573/10000], Train Loss: 65.8514, Val Loss: 227.6139\n",
      "Epoch [574/10000], Train Loss: 65.8363, Val Loss: 227.5878\n",
      "Epoch [575/10000], Train Loss: 65.8211, Val Loss: 227.5630\n",
      "Epoch [576/10000], Train Loss: 65.8061, Val Loss: 227.5342\n",
      "Epoch [577/10000], Train Loss: 65.7909, Val Loss: 227.5067\n",
      "Epoch [578/10000], Train Loss: 65.7758, Val Loss: 227.4806\n",
      "Epoch [579/10000], Train Loss: 65.7610, Val Loss: 227.4507\n",
      "Epoch [580/10000], Train Loss: 65.7457, Val Loss: 227.4223\n",
      "Epoch [581/10000], Train Loss: 65.7307, Val Loss: 227.3956\n",
      "Epoch [582/10000], Train Loss: 65.7155, Val Loss: 227.3699\n",
      "Epoch [583/10000], Train Loss: 65.7007, Val Loss: 227.3407\n",
      "Epoch [584/10000], Train Loss: 65.6854, Val Loss: 227.3080\n",
      "Epoch [585/10000], Train Loss: 65.6706, Val Loss: 227.2776\n",
      "Epoch [586/10000], Train Loss: 65.6556, Val Loss: 227.2494\n",
      "Epoch [587/10000], Train Loss: 65.6407, Val Loss: 227.2231\n",
      "Epoch [588/10000], Train Loss: 65.6255, Val Loss: 227.1985\n",
      "Epoch [589/10000], Train Loss: 65.6104, Val Loss: 227.1754\n",
      "Epoch [590/10000], Train Loss: 65.5951, Val Loss: 227.1532\n",
      "Epoch [591/10000], Train Loss: 65.5798, Val Loss: 227.1313\n",
      "Epoch [592/10000], Train Loss: 65.5653, Val Loss: 227.1047\n",
      "Epoch [593/10000], Train Loss: 65.5504, Val Loss: 227.0739\n",
      "Epoch [594/10000], Train Loss: 65.5349, Val Loss: 227.0392\n",
      "Epoch [595/10000], Train Loss: 65.5196, Val Loss: 227.0065\n",
      "Epoch [596/10000], Train Loss: 65.5048, Val Loss: 226.9759\n",
      "Epoch [597/10000], Train Loss: 65.4898, Val Loss: 226.9475\n",
      "Epoch [598/10000], Train Loss: 65.4747, Val Loss: 226.9213\n",
      "Epoch [599/10000], Train Loss: 65.4596, Val Loss: 226.8966\n",
      "Epoch [600/10000], Train Loss: 65.4444, Val Loss: 226.8732\n",
      "Epoch [601/10000], Train Loss: 65.4291, Val Loss: 226.8508\n",
      "Epoch [602/10000], Train Loss: 65.4138, Val Loss: 226.8292\n",
      "Epoch [603/10000], Train Loss: 65.3993, Val Loss: 226.8026\n",
      "Epoch [604/10000], Train Loss: 65.3843, Val Loss: 226.7717\n",
      "Epoch [605/10000], Train Loss: 65.3688, Val Loss: 226.7370\n",
      "Epoch [606/10000], Train Loss: 65.3535, Val Loss: 226.7043\n",
      "Epoch [607/10000], Train Loss: 65.3386, Val Loss: 226.6739\n",
      "Epoch [608/10000], Train Loss: 65.3237, Val Loss: 226.6458\n",
      "Epoch [609/10000], Train Loss: 65.3086, Val Loss: 226.6198\n",
      "Epoch [610/10000], Train Loss: 65.2934, Val Loss: 226.5956\n",
      "Epoch [611/10000], Train Loss: 65.2782, Val Loss: 226.5726\n",
      "Epoch [612/10000], Train Loss: 65.2629, Val Loss: 226.5505\n",
      "Epoch [613/10000], Train Loss: 65.2476, Val Loss: 226.5290\n",
      "Epoch [614/10000], Train Loss: 65.2331, Val Loss: 226.5027\n",
      "Epoch [615/10000], Train Loss: 65.2182, Val Loss: 226.4720\n",
      "Epoch [616/10000], Train Loss: 65.2026, Val Loss: 226.4372\n",
      "Epoch [617/10000], Train Loss: 65.1872, Val Loss: 226.4042\n",
      "Epoch [618/10000], Train Loss: 65.1723, Val Loss: 226.3738\n",
      "Epoch [619/10000], Train Loss: 65.1574, Val Loss: 226.3456\n",
      "Epoch [620/10000], Train Loss: 65.1423, Val Loss: 226.3195\n",
      "Epoch [621/10000], Train Loss: 65.1271, Val Loss: 226.2950\n",
      "Epoch [622/10000], Train Loss: 65.1119, Val Loss: 226.2718\n",
      "Epoch [623/10000], Train Loss: 65.0966, Val Loss: 226.2495\n",
      "Epoch [624/10000], Train Loss: 65.0812, Val Loss: 226.2278\n",
      "Epoch [625/10000], Train Loss: 65.0668, Val Loss: 226.2012\n",
      "Epoch [626/10000], Train Loss: 65.0518, Val Loss: 226.1701\n",
      "Epoch [627/10000], Train Loss: 65.0362, Val Loss: 226.1348\n",
      "Epoch [628/10000], Train Loss: 65.0208, Val Loss: 226.1015\n",
      "Epoch [629/10000], Train Loss: 65.0059, Val Loss: 226.0708\n",
      "Epoch [630/10000], Train Loss: 64.9909, Val Loss: 226.0424\n",
      "Epoch [631/10000], Train Loss: 64.9758, Val Loss: 226.0162\n",
      "Epoch [632/10000], Train Loss: 64.9606, Val Loss: 225.9916\n",
      "Epoch [633/10000], Train Loss: 64.9454, Val Loss: 225.9684\n",
      "Epoch [634/10000], Train Loss: 64.9301, Val Loss: 225.9462\n",
      "Epoch [635/10000], Train Loss: 64.9147, Val Loss: 225.9245\n",
      "Epoch [636/10000], Train Loss: 64.9002, Val Loss: 225.8981\n",
      "Epoch [637/10000], Train Loss: 64.8852, Val Loss: 225.8668\n",
      "Epoch [638/10000], Train Loss: 64.8696, Val Loss: 225.8315\n",
      "Epoch [639/10000], Train Loss: 64.8542, Val Loss: 225.7982\n",
      "Epoch [640/10000], Train Loss: 64.8393, Val Loss: 225.7675\n",
      "Epoch [641/10000], Train Loss: 64.8243, Val Loss: 225.7393\n",
      "Epoch [642/10000], Train Loss: 64.8092, Val Loss: 225.7132\n",
      "Epoch [643/10000], Train Loss: 64.7940, Val Loss: 225.6888\n",
      "Epoch [644/10000], Train Loss: 64.7787, Val Loss: 225.6657\n",
      "Epoch [645/10000], Train Loss: 64.7634, Val Loss: 225.6436\n",
      "Epoch [646/10000], Train Loss: 64.7480, Val Loss: 225.6222\n",
      "Epoch [647/10000], Train Loss: 64.7333, Val Loss: 225.5958\n",
      "Epoch [648/10000], Train Loss: 64.7182, Val Loss: 225.5646\n",
      "Epoch [649/10000], Train Loss: 64.7026, Val Loss: 225.5293\n",
      "Epoch [650/10000], Train Loss: 64.6875, Val Loss: 225.4960\n",
      "Epoch [651/10000], Train Loss: 64.6726, Val Loss: 225.4655\n",
      "Epoch [652/10000], Train Loss: 64.6576, Val Loss: 225.4373\n",
      "Epoch [653/10000], Train Loss: 64.6424, Val Loss: 225.4113\n",
      "Epoch [654/10000], Train Loss: 64.6272, Val Loss: 225.3870\n",
      "Epoch [655/10000], Train Loss: 64.6119, Val Loss: 225.3641\n",
      "Epoch [656/10000], Train Loss: 64.5966, Val Loss: 225.3422\n",
      "Epoch [657/10000], Train Loss: 64.5812, Val Loss: 225.3210\n",
      "Epoch [658/10000], Train Loss: 64.5661, Val Loss: 225.2946\n",
      "Epoch [659/10000], Train Loss: 64.5510, Val Loss: 225.2634\n",
      "Epoch [660/10000], Train Loss: 64.5355, Val Loss: 225.2331\n",
      "Epoch [661/10000], Train Loss: 64.5204, Val Loss: 225.2042\n",
      "Epoch [662/10000], Train Loss: 64.5052, Val Loss: 225.1768\n",
      "Epoch [663/10000], Train Loss: 64.4900, Val Loss: 225.1507\n",
      "Epoch [664/10000], Train Loss: 64.4748, Val Loss: 225.1202\n",
      "Epoch [665/10000], Train Loss: 64.4595, Val Loss: 225.0914\n",
      "Epoch [666/10000], Train Loss: 64.4443, Val Loss: 225.0640\n",
      "Epoch [667/10000], Train Loss: 64.4291, Val Loss: 225.0330\n",
      "Epoch [668/10000], Train Loss: 64.4140, Val Loss: 225.0042\n",
      "Epoch [669/10000], Train Loss: 64.3988, Val Loss: 224.9776\n",
      "Epoch [670/10000], Train Loss: 64.3836, Val Loss: 224.9524\n",
      "Epoch [671/10000], Train Loss: 64.3683, Val Loss: 224.9287\n",
      "Epoch [672/10000], Train Loss: 64.3534, Val Loss: 224.9009\n",
      "Epoch [673/10000], Train Loss: 64.3380, Val Loss: 224.8694\n",
      "Epoch [674/10000], Train Loss: 64.3228, Val Loss: 224.8399\n",
      "Epoch [675/10000], Train Loss: 64.3078, Val Loss: 224.8125\n",
      "Epoch [676/10000], Train Loss: 64.2926, Val Loss: 224.7870\n",
      "Epoch [677/10000], Train Loss: 64.2774, Val Loss: 224.7630\n",
      "Epoch [678/10000], Train Loss: 64.2621, Val Loss: 224.7402\n",
      "Epoch [679/10000], Train Loss: 64.2467, Val Loss: 224.7181\n",
      "Epoch [680/10000], Train Loss: 64.2316, Val Loss: 224.6907\n",
      "Epoch [681/10000], Train Loss: 64.2163, Val Loss: 224.6587\n",
      "Epoch [682/10000], Train Loss: 64.2011, Val Loss: 224.6281\n",
      "Epoch [683/10000], Train Loss: 64.1860, Val Loss: 224.5992\n",
      "Epoch [684/10000], Train Loss: 64.1708, Val Loss: 224.5718\n",
      "Epoch [685/10000], Train Loss: 64.1555, Val Loss: 224.5458\n",
      "Epoch [686/10000], Train Loss: 64.1402, Val Loss: 224.5209\n",
      "Epoch [687/10000], Train Loss: 64.1248, Val Loss: 224.4967\n",
      "Epoch [688/10000], Train Loss: 64.1101, Val Loss: 224.4678\n",
      "Epoch [689/10000], Train Loss: 64.0948, Val Loss: 224.4347\n",
      "Epoch [690/10000], Train Loss: 64.0791, Val Loss: 224.4035\n",
      "Epoch [691/10000], Train Loss: 64.0640, Val Loss: 224.3745\n",
      "Epoch [692/10000], Train Loss: 64.0488, Val Loss: 224.3475\n",
      "Epoch [693/10000], Train Loss: 64.0335, Val Loss: 224.3225\n",
      "Epoch [694/10000], Train Loss: 64.0182, Val Loss: 224.2988\n",
      "Epoch [695/10000], Train Loss: 64.0032, Val Loss: 224.2708\n",
      "Epoch [696/10000], Train Loss: 63.9879, Val Loss: 224.2390\n",
      "Epoch [697/10000], Train Loss: 63.9726, Val Loss: 224.2095\n",
      "Epoch [698/10000], Train Loss: 63.9575, Val Loss: 224.1825\n",
      "Epoch [699/10000], Train Loss: 63.9423, Val Loss: 224.1574\n",
      "Epoch [700/10000], Train Loss: 63.9270, Val Loss: 224.1340\n",
      "Epoch [701/10000], Train Loss: 63.9116, Val Loss: 224.1117\n",
      "Epoch [702/10000], Train Loss: 63.8962, Val Loss: 224.0902\n",
      "Epoch [703/10000], Train Loss: 63.8812, Val Loss: 224.0635\n",
      "Epoch [704/10000], Train Loss: 63.8659, Val Loss: 224.0322\n",
      "Epoch [705/10000], Train Loss: 63.8505, Val Loss: 224.0022\n",
      "Epoch [706/10000], Train Loss: 63.8353, Val Loss: 223.9739\n",
      "Epoch [707/10000], Train Loss: 63.8201, Val Loss: 223.9469\n",
      "Epoch [708/10000], Train Loss: 63.8048, Val Loss: 223.9215\n",
      "Epoch [709/10000], Train Loss: 63.7895, Val Loss: 223.8972\n",
      "Epoch [710/10000], Train Loss: 63.7741, Val Loss: 223.8733\n",
      "Epoch [711/10000], Train Loss: 63.7593, Val Loss: 223.8448\n",
      "Epoch [712/10000], Train Loss: 63.7440, Val Loss: 223.8116\n",
      "Epoch [713/10000], Train Loss: 63.7283, Val Loss: 223.7805\n",
      "Epoch [714/10000], Train Loss: 63.7131, Val Loss: 223.7515\n",
      "Epoch [715/10000], Train Loss: 63.6979, Val Loss: 223.7246\n",
      "Epoch [716/10000], Train Loss: 63.6826, Val Loss: 223.6995\n",
      "Epoch [717/10000], Train Loss: 63.6672, Val Loss: 223.6759\n",
      "Epoch [718/10000], Train Loss: 63.6521, Val Loss: 223.6479\n",
      "Epoch [719/10000], Train Loss: 63.6367, Val Loss: 223.6160\n",
      "Epoch [720/10000], Train Loss: 63.6215, Val Loss: 223.5865\n",
      "Epoch [721/10000], Train Loss: 63.6064, Val Loss: 223.5593\n",
      "Epoch [722/10000], Train Loss: 63.5912, Val Loss: 223.5343\n",
      "Epoch [723/10000], Train Loss: 63.5759, Val Loss: 223.5109\n",
      "Epoch [724/10000], Train Loss: 63.5605, Val Loss: 223.4888\n",
      "Epoch [725/10000], Train Loss: 63.5451, Val Loss: 223.4674\n",
      "Epoch [726/10000], Train Loss: 63.5297, Val Loss: 223.4407\n",
      "Epoch [727/10000], Train Loss: 63.5144, Val Loss: 223.4093\n",
      "Epoch [728/10000], Train Loss: 63.4992, Val Loss: 223.3793\n",
      "Epoch [729/10000], Train Loss: 63.4841, Val Loss: 223.3510\n",
      "Epoch [730/10000], Train Loss: 63.4688, Val Loss: 223.3242\n",
      "Epoch [731/10000], Train Loss: 63.4535, Val Loss: 223.2989\n",
      "Epoch [732/10000], Train Loss: 63.4381, Val Loss: 223.2747\n",
      "Epoch [733/10000], Train Loss: 63.4227, Val Loss: 223.2512\n",
      "Epoch [734/10000], Train Loss: 63.4075, Val Loss: 223.2227\n",
      "Epoch [735/10000], Train Loss: 63.3922, Val Loss: 223.1899\n",
      "Epoch [736/10000], Train Loss: 63.3768, Val Loss: 223.1590\n",
      "Epoch [737/10000], Train Loss: 63.3617, Val Loss: 223.1304\n",
      "Epoch [738/10000], Train Loss: 63.3464, Val Loss: 223.1038\n",
      "Epoch [739/10000], Train Loss: 63.3311, Val Loss: 223.0791\n",
      "Epoch [740/10000], Train Loss: 63.3157, Val Loss: 223.0559\n",
      "Epoch [741/10000], Train Loss: 63.3002, Val Loss: 223.0339\n",
      "Epoch [742/10000], Train Loss: 63.2853, Val Loss: 223.0070\n",
      "Epoch [743/10000], Train Loss: 63.2700, Val Loss: 222.9756\n",
      "Epoch [744/10000], Train Loss: 63.2543, Val Loss: 222.9462\n",
      "Epoch [745/10000], Train Loss: 63.2391, Val Loss: 222.9188\n",
      "Epoch [746/10000], Train Loss: 63.2239, Val Loss: 222.8932\n",
      "Epoch [747/10000], Train Loss: 63.2085, Val Loss: 222.8692\n",
      "Epoch [748/10000], Train Loss: 63.1931, Val Loss: 222.8464\n",
      "Epoch [749/10000], Train Loss: 63.1778, Val Loss: 222.8189\n",
      "Epoch [750/10000], Train Loss: 63.1624, Val Loss: 222.7926\n",
      "Epoch [751/10000], Train Loss: 63.1471, Val Loss: 222.7675\n",
      "Epoch [752/10000], Train Loss: 63.1319, Val Loss: 222.7377\n",
      "Epoch [753/10000], Train Loss: 63.1165, Val Loss: 222.7096\n",
      "Epoch [754/10000], Train Loss: 63.1012, Val Loss: 222.6832\n",
      "Epoch [755/10000], Train Loss: 63.0859, Val Loss: 222.6593\n",
      "Epoch [756/10000], Train Loss: 63.0705, Val Loss: 222.6368\n",
      "Epoch [757/10000], Train Loss: 63.0556, Val Loss: 222.6103\n",
      "Epoch [758/10000], Train Loss: 63.0400, Val Loss: 222.5802\n",
      "Epoch [759/10000], Train Loss: 63.0247, Val Loss: 222.5520\n",
      "Epoch [760/10000], Train Loss: 63.0095, Val Loss: 222.5261\n",
      "Epoch [761/10000], Train Loss: 62.9943, Val Loss: 222.5024\n",
      "Epoch [762/10000], Train Loss: 62.9790, Val Loss: 222.4803\n",
      "Epoch [763/10000], Train Loss: 62.9635, Val Loss: 222.4596\n",
      "Epoch [764/10000], Train Loss: 62.9481, Val Loss: 222.4398\n",
      "Epoch [765/10000], Train Loss: 62.9326, Val Loss: 222.4202\n",
      "Epoch [766/10000], Train Loss: 62.9179, Val Loss: 222.3956\n",
      "Epoch [767/10000], Train Loss: 62.9026, Val Loss: 222.3663\n",
      "Epoch [768/10000], Train Loss: 62.8867, Val Loss: 222.3332\n",
      "Epoch [769/10000], Train Loss: 62.8716, Val Loss: 222.3026\n",
      "Epoch [770/10000], Train Loss: 62.8565, Val Loss: 222.2745\n",
      "Epoch [771/10000], Train Loss: 62.8414, Val Loss: 222.2492\n",
      "Epoch [772/10000], Train Loss: 62.8261, Val Loss: 222.2263\n",
      "Epoch [773/10000], Train Loss: 62.8108, Val Loss: 222.2054\n",
      "Epoch [774/10000], Train Loss: 62.7953, Val Loss: 222.1860\n",
      "Epoch [775/10000], Train Loss: 62.7798, Val Loss: 222.1674\n",
      "Epoch [776/10000], Train Loss: 62.7643, Val Loss: 222.1493\n",
      "Epoch [777/10000], Train Loss: 62.7487, Val Loss: 222.1306\n",
      "Epoch [778/10000], Train Loss: 62.7336, Val Loss: 222.1062\n",
      "Epoch [779/10000], Train Loss: 62.7184, Val Loss: 222.0762\n",
      "Epoch [780/10000], Train Loss: 62.7026, Val Loss: 222.0471\n",
      "Epoch [781/10000], Train Loss: 62.6873, Val Loss: 222.0191\n",
      "Epoch [782/10000], Train Loss: 62.6720, Val Loss: 221.9925\n",
      "Epoch [783/10000], Train Loss: 62.6566, Val Loss: 221.9672\n",
      "Epoch [784/10000], Train Loss: 62.6412, Val Loss: 221.9433\n",
      "Epoch [785/10000], Train Loss: 62.6263, Val Loss: 221.9157\n",
      "Epoch [786/10000], Train Loss: 62.6107, Val Loss: 221.8850\n",
      "Epoch [787/10000], Train Loss: 62.5953, Val Loss: 221.8574\n",
      "Epoch [788/10000], Train Loss: 62.5802, Val Loss: 221.8324\n",
      "Epoch [789/10000], Train Loss: 62.5649, Val Loss: 221.8104\n",
      "Epoch [790/10000], Train Loss: 62.5495, Val Loss: 221.7906\n",
      "Epoch [791/10000], Train Loss: 62.5341, Val Loss: 221.7724\n",
      "Epoch [792/10000], Train Loss: 62.5186, Val Loss: 221.7551\n",
      "Epoch [793/10000], Train Loss: 62.5032, Val Loss: 221.7331\n",
      "Epoch [794/10000], Train Loss: 62.4878, Val Loss: 221.7064\n",
      "Epoch [795/10000], Train Loss: 62.4726, Val Loss: 221.6809\n",
      "Epoch [796/10000], Train Loss: 62.4573, Val Loss: 221.6565\n",
      "Epoch [797/10000], Train Loss: 62.4420, Val Loss: 221.6332\n",
      "Epoch [798/10000], Train Loss: 62.4267, Val Loss: 221.6105\n",
      "Epoch [799/10000], Train Loss: 62.4112, Val Loss: 221.5883\n",
      "Epoch [800/10000], Train Loss: 62.3958, Val Loss: 221.5663\n",
      "Epoch [801/10000], Train Loss: 62.3806, Val Loss: 221.5393\n",
      "Epoch [802/10000], Train Loss: 62.3652, Val Loss: 221.5079\n",
      "Epoch [803/10000], Train Loss: 62.3498, Val Loss: 221.4783\n",
      "Epoch [804/10000], Train Loss: 62.3346, Val Loss: 221.4507\n",
      "Epoch [805/10000], Train Loss: 62.3193, Val Loss: 221.4252\n",
      "Epoch [806/10000], Train Loss: 62.3039, Val Loss: 221.4016\n",
      "Epoch [807/10000], Train Loss: 62.2885, Val Loss: 221.3797\n",
      "Epoch [808/10000], Train Loss: 62.2730, Val Loss: 221.3591\n",
      "Epoch [809/10000], Train Loss: 62.2577, Val Loss: 221.3342\n",
      "Epoch [810/10000], Train Loss: 62.2423, Val Loss: 221.3055\n",
      "Epoch [811/10000], Train Loss: 62.2270, Val Loss: 221.2789\n",
      "Epoch [812/10000], Train Loss: 62.2118, Val Loss: 221.2543\n",
      "Epoch [813/10000], Train Loss: 62.1965, Val Loss: 221.2318\n",
      "Epoch [814/10000], Train Loss: 62.1811, Val Loss: 221.2108\n",
      "Epoch [815/10000], Train Loss: 62.1656, Val Loss: 221.1909\n",
      "Epoch [816/10000], Train Loss: 62.1502, Val Loss: 221.1717\n",
      "Epoch [817/10000], Train Loss: 62.1350, Val Loss: 221.1474\n",
      "Epoch [818/10000], Train Loss: 62.1196, Val Loss: 221.1187\n",
      "Epoch [819/10000], Train Loss: 62.1042, Val Loss: 221.0916\n",
      "Epoch [820/10000], Train Loss: 62.0890, Val Loss: 221.0662\n",
      "Epoch [821/10000], Train Loss: 62.0737, Val Loss: 221.0425\n",
      "Epoch [822/10000], Train Loss: 62.0583, Val Loss: 221.0204\n",
      "Epoch [823/10000], Train Loss: 62.0429, Val Loss: 220.9994\n",
      "Epoch [824/10000], Train Loss: 62.0274, Val Loss: 220.9791\n",
      "Epoch [825/10000], Train Loss: 62.0121, Val Loss: 220.9543\n",
      "Epoch [826/10000], Train Loss: 61.9967, Val Loss: 220.9251\n",
      "Epoch [827/10000], Train Loss: 61.9814, Val Loss: 220.8978\n",
      "Epoch [828/10000], Train Loss: 61.9662, Val Loss: 220.8725\n",
      "Epoch [829/10000], Train Loss: 61.9509, Val Loss: 220.8493\n",
      "Epoch [830/10000], Train Loss: 61.9355, Val Loss: 220.8275\n",
      "Epoch [831/10000], Train Loss: 61.9201, Val Loss: 220.8071\n",
      "Epoch [832/10000], Train Loss: 61.9046, Val Loss: 220.7875\n",
      "Epoch [833/10000], Train Loss: 61.8893, Val Loss: 220.7630\n",
      "Epoch [834/10000], Train Loss: 61.8739, Val Loss: 220.7341\n",
      "Epoch [835/10000], Train Loss: 61.8586, Val Loss: 220.7070\n",
      "Epoch [836/10000], Train Loss: 61.8434, Val Loss: 220.6818\n",
      "Epoch [837/10000], Train Loss: 61.8281, Val Loss: 220.6582\n",
      "Epoch [838/10000], Train Loss: 61.8127, Val Loss: 220.6362\n",
      "Epoch [839/10000], Train Loss: 61.7973, Val Loss: 220.6154\n",
      "Epoch [840/10000], Train Loss: 61.7818, Val Loss: 220.5952\n",
      "Epoch [841/10000], Train Loss: 61.7665, Val Loss: 220.5702\n",
      "Epoch [842/10000], Train Loss: 61.7510, Val Loss: 220.5410\n",
      "Epoch [843/10000], Train Loss: 61.7358, Val Loss: 220.5135\n",
      "Epoch [844/10000], Train Loss: 61.7206, Val Loss: 220.4882\n",
      "Epoch [845/10000], Train Loss: 61.7053, Val Loss: 220.4646\n",
      "Epoch [846/10000], Train Loss: 61.6900, Val Loss: 220.4427\n",
      "Epoch [847/10000], Train Loss: 61.6746, Val Loss: 220.4222\n",
      "Epoch [848/10000], Train Loss: 61.6591, Val Loss: 220.4025\n",
      "Epoch [849/10000], Train Loss: 61.6436, Val Loss: 220.3780\n",
      "Epoch [850/10000], Train Loss: 61.6282, Val Loss: 220.3544\n",
      "Epoch [851/10000], Train Loss: 61.6130, Val Loss: 220.3265\n",
      "Epoch [852/10000], Train Loss: 61.5977, Val Loss: 220.3002\n",
      "Epoch [853/10000], Train Loss: 61.5824, Val Loss: 220.2756\n",
      "Epoch [854/10000], Train Loss: 61.5671, Val Loss: 220.2527\n",
      "Epoch [855/10000], Train Loss: 61.5517, Val Loss: 220.2312\n",
      "Epoch [856/10000], Train Loss: 61.5363, Val Loss: 220.2107\n",
      "Epoch [857/10000], Train Loss: 61.5211, Val Loss: 220.1858\n",
      "Epoch [858/10000], Train Loss: 61.5056, Val Loss: 220.1569\n",
      "Epoch [859/10000], Train Loss: 61.4904, Val Loss: 220.1302\n",
      "Epoch [860/10000], Train Loss: 61.4752, Val Loss: 220.1058\n",
      "Epoch [861/10000], Train Loss: 61.4600, Val Loss: 220.0835\n",
      "Epoch [862/10000], Train Loss: 61.4446, Val Loss: 220.0630\n",
      "Epoch [863/10000], Train Loss: 61.4292, Val Loss: 220.0439\n",
      "Epoch [864/10000], Train Loss: 61.4137, Val Loss: 220.0253\n",
      "Epoch [865/10000], Train Loss: 61.3982, Val Loss: 220.0066\n",
      "Epoch [866/10000], Train Loss: 61.3835, Val Loss: 219.9823\n",
      "Epoch [867/10000], Train Loss: 61.3682, Val Loss: 219.9531\n",
      "Epoch [868/10000], Train Loss: 61.3522, Val Loss: 219.9198\n",
      "Epoch [869/10000], Train Loss: 61.3372, Val Loss: 219.8894\n",
      "Epoch [870/10000], Train Loss: 61.3222, Val Loss: 219.8621\n",
      "Epoch [871/10000], Train Loss: 61.3071, Val Loss: 219.8380\n",
      "Epoch [872/10000], Train Loss: 61.2918, Val Loss: 219.8167\n",
      "Epoch [873/10000], Train Loss: 61.2765, Val Loss: 219.7978\n",
      "Epoch [874/10000], Train Loss: 61.2611, Val Loss: 219.7807\n",
      "Epoch [875/10000], Train Loss: 61.2456, Val Loss: 219.7642\n",
      "Epoch [876/10000], Train Loss: 61.2301, Val Loss: 219.7474\n",
      "Epoch [877/10000], Train Loss: 61.2146, Val Loss: 219.7298\n",
      "Epoch [878/10000], Train Loss: 61.1992, Val Loss: 219.7054\n",
      "Epoch [879/10000], Train Loss: 61.1840, Val Loss: 219.6750\n",
      "Epoch [880/10000], Train Loss: 61.1685, Val Loss: 219.6451\n",
      "Epoch [881/10000], Train Loss: 61.1533, Val Loss: 219.6163\n",
      "Epoch [882/10000], Train Loss: 61.1380, Val Loss: 219.5892\n",
      "Epoch [883/10000], Train Loss: 61.1227, Val Loss: 219.5639\n",
      "Epoch [884/10000], Train Loss: 61.1073, Val Loss: 219.5404\n",
      "Epoch [885/10000], Train Loss: 61.0919, Val Loss: 219.5186\n",
      "Epoch [886/10000], Train Loss: 61.0768, Val Loss: 219.4930\n",
      "Epoch [887/10000], Train Loss: 61.0614, Val Loss: 219.4644\n",
      "Epoch [888/10000], Train Loss: 61.0460, Val Loss: 219.4388\n",
      "Epoch [889/10000], Train Loss: 61.0309, Val Loss: 219.4163\n",
      "Epoch [890/10000], Train Loss: 61.0156, Val Loss: 219.3964\n",
      "Epoch [891/10000], Train Loss: 61.0003, Val Loss: 219.3787\n",
      "Epoch [892/10000], Train Loss: 60.9849, Val Loss: 219.3622\n",
      "Epoch [893/10000], Train Loss: 60.9694, Val Loss: 219.3463\n",
      "Epoch [894/10000], Train Loss: 60.9545, Val Loss: 219.3249\n",
      "Epoch [895/10000], Train Loss: 60.9392, Val Loss: 219.2984\n",
      "Epoch [896/10000], Train Loss: 60.9236, Val Loss: 219.2728\n",
      "Epoch [897/10000], Train Loss: 60.9084, Val Loss: 219.2483\n",
      "Epoch [898/10000], Train Loss: 60.8932, Val Loss: 219.2249\n",
      "Epoch [899/10000], Train Loss: 60.8779, Val Loss: 219.2024\n",
      "Epoch [900/10000], Train Loss: 60.8625, Val Loss: 219.1807\n",
      "Epoch [901/10000], Train Loss: 60.8471, Val Loss: 219.1594\n",
      "Epoch [902/10000], Train Loss: 60.8321, Val Loss: 219.1329\n",
      "Epoch [903/10000], Train Loss: 60.8167, Val Loss: 219.1023\n",
      "Epoch [904/10000], Train Loss: 60.8013, Val Loss: 219.0737\n",
      "Epoch [905/10000], Train Loss: 60.7862, Val Loss: 219.0476\n",
      "Epoch [906/10000], Train Loss: 60.7710, Val Loss: 219.0239\n",
      "Epoch [907/10000], Train Loss: 60.7557, Val Loss: 219.0023\n",
      "Epoch [908/10000], Train Loss: 60.7403, Val Loss: 218.9824\n",
      "Epoch [909/10000], Train Loss: 60.7250, Val Loss: 218.9637\n",
      "Epoch [910/10000], Train Loss: 60.7098, Val Loss: 218.9401\n",
      "Epoch [911/10000], Train Loss: 60.6944, Val Loss: 218.9124\n",
      "Epoch [912/10000], Train Loss: 60.6792, Val Loss: 218.8865\n",
      "Epoch [913/10000], Train Loss: 60.6641, Val Loss: 218.8626\n",
      "Epoch [914/10000], Train Loss: 60.6488, Val Loss: 218.8406\n",
      "Epoch [915/10000], Train Loss: 60.6336, Val Loss: 218.8201\n",
      "Epoch [916/10000], Train Loss: 60.6182, Val Loss: 218.8006\n",
      "Epoch [917/10000], Train Loss: 60.6029, Val Loss: 218.7819\n",
      "Epoch [918/10000], Train Loss: 60.5875, Val Loss: 218.7579\n",
      "Epoch [919/10000], Train Loss: 60.5723, Val Loss: 218.7345\n",
      "Epoch [920/10000], Train Loss: 60.5570, Val Loss: 218.7068\n",
      "Epoch [921/10000], Train Loss: 60.5419, Val Loss: 218.6809\n",
      "Epoch [922/10000], Train Loss: 60.5267, Val Loss: 218.6582\n",
      "Epoch [923/10000], Train Loss: 60.5115, Val Loss: 218.6372\n",
      "Epoch [924/10000], Train Loss: 60.4962, Val Loss: 218.6177\n",
      "Epoch [925/10000], Train Loss: 60.4809, Val Loss: 218.5993\n",
      "Epoch [926/10000], Train Loss: 60.4655, Val Loss: 218.5816\n",
      "Epoch [927/10000], Train Loss: 60.4509, Val Loss: 218.5593\n",
      "Epoch [928/10000], Train Loss: 60.4356, Val Loss: 218.5332\n",
      "Epoch [929/10000], Train Loss: 60.4199, Val Loss: 218.5089\n",
      "Epoch [930/10000], Train Loss: 60.4048, Val Loss: 218.4863\n",
      "Epoch [931/10000], Train Loss: 60.3896, Val Loss: 218.4656\n",
      "Epoch [932/10000], Train Loss: 60.3743, Val Loss: 218.4463\n",
      "Epoch [933/10000], Train Loss: 60.3591, Val Loss: 218.4281\n",
      "Epoch [934/10000], Train Loss: 60.3437, Val Loss: 218.4061\n",
      "Epoch [935/10000], Train Loss: 60.3285, Val Loss: 218.3851\n",
      "Epoch [936/10000], Train Loss: 60.3133, Val Loss: 218.3648\n",
      "Epoch [937/10000], Train Loss: 60.2981, Val Loss: 218.3408\n",
      "Epoch [938/10000], Train Loss: 60.2830, Val Loss: 218.3178\n",
      "Epoch [939/10000], Train Loss: 60.2678, Val Loss: 218.2964\n",
      "Epoch [940/10000], Train Loss: 60.2526, Val Loss: 218.2759\n",
      "Epoch [941/10000], Train Loss: 60.2374, Val Loss: 218.2561\n",
      "Epoch [942/10000], Train Loss: 60.2221, Val Loss: 218.2323\n",
      "Epoch [943/10000], Train Loss: 60.2069, Val Loss: 218.2097\n",
      "Epoch [944/10000], Train Loss: 60.1917, Val Loss: 218.1881\n",
      "Epoch [945/10000], Train Loss: 60.1765, Val Loss: 218.1673\n",
      "Epoch [946/10000], Train Loss: 60.1614, Val Loss: 218.1427\n",
      "Epoch [947/10000], Train Loss: 60.1461, Val Loss: 218.1195\n",
      "Epoch [948/10000], Train Loss: 60.1310, Val Loss: 218.0977\n",
      "Epoch [949/10000], Train Loss: 60.1158, Val Loss: 218.0773\n",
      "Epoch [950/10000], Train Loss: 60.1007, Val Loss: 218.0531\n",
      "Epoch [951/10000], Train Loss: 60.0854, Val Loss: 218.0309\n",
      "Epoch [952/10000], Train Loss: 60.0703, Val Loss: 218.0102\n",
      "Epoch [953/10000], Train Loss: 60.0551, Val Loss: 217.9909\n",
      "Epoch [954/10000], Train Loss: 60.0399, Val Loss: 217.9680\n",
      "Epoch [955/10000], Train Loss: 60.0248, Val Loss: 217.9467\n",
      "Epoch [956/10000], Train Loss: 60.0097, Val Loss: 217.9267\n",
      "Epoch [957/10000], Train Loss: 59.9945, Val Loss: 217.9079\n",
      "Epoch [958/10000], Train Loss: 59.9792, Val Loss: 217.8896\n",
      "Epoch [959/10000], Train Loss: 59.9645, Val Loss: 217.8669\n",
      "Epoch [960/10000], Train Loss: 59.9492, Val Loss: 217.8406\n",
      "Epoch [961/10000], Train Loss: 59.9340, Val Loss: 217.8164\n",
      "Epoch [962/10000], Train Loss: 59.9190, Val Loss: 217.7942\n",
      "Epoch [963/10000], Train Loss: 59.9040, Val Loss: 217.7737\n",
      "Epoch [964/10000], Train Loss: 59.8888, Val Loss: 217.7551\n",
      "Epoch [965/10000], Train Loss: 59.8736, Val Loss: 217.7377\n",
      "Epoch [966/10000], Train Loss: 59.8583, Val Loss: 217.7209\n",
      "Epoch [967/10000], Train Loss: 59.8431, Val Loss: 217.7036\n",
      "Epoch [968/10000], Train Loss: 59.8283, Val Loss: 217.6807\n",
      "Epoch [969/10000], Train Loss: 59.8132, Val Loss: 217.6534\n",
      "Epoch [970/10000], Train Loss: 59.7977, Val Loss: 217.6272\n",
      "Epoch [971/10000], Train Loss: 59.7827, Val Loss: 217.6024\n",
      "Epoch [972/10000], Train Loss: 59.7677, Val Loss: 217.5794\n",
      "Epoch [973/10000], Train Loss: 59.7526, Val Loss: 217.5582\n",
      "Epoch [974/10000], Train Loss: 59.7374, Val Loss: 217.5386\n",
      "Epoch [975/10000], Train Loss: 59.7222, Val Loss: 217.5201\n",
      "Epoch [976/10000], Train Loss: 59.7073, Val Loss: 217.4975\n",
      "Epoch [977/10000], Train Loss: 59.6921, Val Loss: 217.4715\n",
      "Epoch [978/10000], Train Loss: 59.6770, Val Loss: 217.4478\n",
      "Epoch [979/10000], Train Loss: 59.6621, Val Loss: 217.4263\n",
      "Epoch [980/10000], Train Loss: 59.6470, Val Loss: 217.4070\n",
      "Epoch [981/10000], Train Loss: 59.6319, Val Loss: 217.3893\n",
      "Epoch [982/10000], Train Loss: 59.6168, Val Loss: 217.3728\n",
      "Epoch [983/10000], Train Loss: 59.6016, Val Loss: 217.3566\n",
      "Epoch [984/10000], Train Loss: 59.5865, Val Loss: 217.3353\n",
      "Epoch [985/10000], Train Loss: 59.5713, Val Loss: 217.3095\n",
      "Epoch [986/10000], Train Loss: 59.5564, Val Loss: 217.2850\n",
      "Epoch [987/10000], Train Loss: 59.5415, Val Loss: 217.2621\n",
      "Epoch [988/10000], Train Loss: 59.5265, Val Loss: 217.2407\n",
      "Epoch [989/10000], Train Loss: 59.5115, Val Loss: 217.2207\n",
      "Epoch [990/10000], Train Loss: 59.4964, Val Loss: 217.2019\n",
      "Epoch [991/10000], Train Loss: 59.4812, Val Loss: 217.1835\n",
      "Epoch [992/10000], Train Loss: 59.4660, Val Loss: 217.1651\n",
      "Epoch [993/10000], Train Loss: 59.4513, Val Loss: 217.1416\n",
      "Epoch [994/10000], Train Loss: 59.4362, Val Loss: 217.1137\n",
      "Epoch [995/10000], Train Loss: 59.4209, Val Loss: 217.0874\n",
      "Epoch [996/10000], Train Loss: 59.4060, Val Loss: 217.0634\n",
      "Epoch [997/10000], Train Loss: 59.3911, Val Loss: 217.0413\n",
      "Epoch [998/10000], Train Loss: 59.3761, Val Loss: 217.0213\n",
      "Epoch [999/10000], Train Loss: 59.3610, Val Loss: 217.0032\n",
      "Epoch [1000/10000], Train Loss: 59.3458, Val Loss: 216.9903\n",
      "Epoch [1001/10000], Train Loss: 59.3313, Val Loss: 216.9765\n",
      "Epoch [1002/10000], Train Loss: 59.3166, Val Loss: 216.9613\n",
      "Epoch [1003/10000], Train Loss: 59.3014, Val Loss: 216.9441\n",
      "Epoch [1004/10000], Train Loss: 59.2865, Val Loss: 216.9299\n",
      "Epoch [1005/10000], Train Loss: 59.2718, Val Loss: 216.9174\n",
      "Epoch [1006/10000], Train Loss: 59.2569, Val Loss: 216.9059\n",
      "Epoch [1007/10000], Train Loss: 59.2421, Val Loss: 216.8897\n",
      "Epoch [1008/10000], Train Loss: 59.2273, Val Loss: 216.8687\n",
      "Epoch [1009/10000], Train Loss: 59.2125, Val Loss: 216.8430\n",
      "Epoch [1010/10000], Train Loss: 59.1976, Val Loss: 216.8083\n",
      "Epoch [1011/10000], Train Loss: 59.1826, Val Loss: 216.7720\n",
      "Epoch [1012/10000], Train Loss: 59.1679, Val Loss: 216.7396\n",
      "Epoch [1013/10000], Train Loss: 59.1531, Val Loss: 216.7115\n",
      "Epoch [1014/10000], Train Loss: 59.1383, Val Loss: 216.6874\n",
      "Epoch [1015/10000], Train Loss: 59.1235, Val Loss: 216.6624\n",
      "Epoch [1016/10000], Train Loss: 59.1086, Val Loss: 216.6368\n",
      "Epoch [1017/10000], Train Loss: 59.0940, Val Loss: 216.6153\n",
      "Epoch [1018/10000], Train Loss: 59.0793, Val Loss: 216.5973\n",
      "Epoch [1019/10000], Train Loss: 59.0644, Val Loss: 216.5817\n",
      "Epoch [1020/10000], Train Loss: 59.0495, Val Loss: 216.5636\n",
      "Epoch [1021/10000], Train Loss: 59.0349, Val Loss: 216.5376\n",
      "Epoch [1022/10000], Train Loss: 59.0200, Val Loss: 216.5094\n",
      "Epoch [1023/10000], Train Loss: 59.0053, Val Loss: 216.4837\n",
      "Epoch [1024/10000], Train Loss: 58.9906, Val Loss: 216.4606\n",
      "Epoch [1025/10000], Train Loss: 58.9758, Val Loss: 216.4397\n",
      "Epoch [1026/10000], Train Loss: 58.9613, Val Loss: 216.4117\n",
      "Epoch [1027/10000], Train Loss: 58.9463, Val Loss: 216.3862\n",
      "Epoch [1028/10000], Train Loss: 58.9316, Val Loss: 216.3633\n",
      "Epoch [1029/10000], Train Loss: 58.9171, Val Loss: 216.3381\n",
      "Epoch [1030/10000], Train Loss: 58.9023, Val Loss: 216.3157\n",
      "Epoch [1031/10000], Train Loss: 58.8876, Val Loss: 216.2953\n",
      "Epoch [1032/10000], Train Loss: 58.8730, Val Loss: 216.2682\n",
      "Epoch [1033/10000], Train Loss: 58.8584, Val Loss: 216.2401\n",
      "Epoch [1034/10000], Train Loss: 58.8439, Val Loss: 216.2153\n",
      "Epoch [1035/10000], Train Loss: 58.8292, Val Loss: 216.1933\n",
      "Epoch [1036/10000], Train Loss: 58.8145, Val Loss: 216.1737\n",
      "Epoch [1037/10000], Train Loss: 58.7997, Val Loss: 216.1516\n",
      "Epoch [1038/10000], Train Loss: 58.7855, Val Loss: 216.1221\n",
      "Epoch [1039/10000], Train Loss: 58.7706, Val Loss: 216.0904\n",
      "Epoch [1040/10000], Train Loss: 58.7561, Val Loss: 216.0621\n",
      "Epoch [1041/10000], Train Loss: 58.7417, Val Loss: 216.0374\n",
      "Epoch [1042/10000], Train Loss: 58.7271, Val Loss: 216.0159\n",
      "Epoch [1043/10000], Train Loss: 58.7124, Val Loss: 215.9968\n",
      "Epoch [1044/10000], Train Loss: 58.6977, Val Loss: 215.9794\n",
      "Epoch [1045/10000], Train Loss: 58.6829, Val Loss: 215.9625\n",
      "Epoch [1046/10000], Train Loss: 58.6690, Val Loss: 215.9367\n",
      "Epoch [1047/10000], Train Loss: 58.6543, Val Loss: 215.9035\n",
      "Epoch [1048/10000], Train Loss: 58.6393, Val Loss: 215.8727\n",
      "Epoch [1049/10000], Train Loss: 58.6249, Val Loss: 215.8455\n",
      "Epoch [1050/10000], Train Loss: 58.6105, Val Loss: 215.8217\n",
      "Epoch [1051/10000], Train Loss: 58.5960, Val Loss: 215.8011\n",
      "Epoch [1052/10000], Train Loss: 58.5813, Val Loss: 215.7829\n",
      "Epoch [1053/10000], Train Loss: 58.5666, Val Loss: 215.7664\n",
      "Epoch [1054/10000], Train Loss: 58.5524, Val Loss: 215.7458\n",
      "Epoch [1055/10000], Train Loss: 58.5379, Val Loss: 215.7213\n",
      "Epoch [1056/10000], Train Loss: 58.5231, Val Loss: 215.6984\n",
      "Epoch [1057/10000], Train Loss: 58.5087, Val Loss: 215.6767\n",
      "Epoch [1058/10000], Train Loss: 58.4942, Val Loss: 215.6564\n",
      "Epoch [1059/10000], Train Loss: 58.4797, Val Loss: 215.6367\n",
      "Epoch [1060/10000], Train Loss: 58.4652, Val Loss: 215.6172\n",
      "Epoch [1061/10000], Train Loss: 58.4508, Val Loss: 215.5929\n",
      "Epoch [1062/10000], Train Loss: 58.4362, Val Loss: 215.5646\n",
      "Epoch [1063/10000], Train Loss: 58.4219, Val Loss: 215.5378\n",
      "Epoch [1064/10000], Train Loss: 58.4077, Val Loss: 215.5130\n",
      "Epoch [1065/10000], Train Loss: 58.3933, Val Loss: 215.4901\n",
      "Epoch [1066/10000], Train Loss: 58.3789, Val Loss: 215.4688\n",
      "Epoch [1067/10000], Train Loss: 58.3643, Val Loss: 215.4486\n",
      "Epoch [1068/10000], Train Loss: 58.3498, Val Loss: 215.4286\n",
      "Epoch [1069/10000], Train Loss: 58.3353, Val Loss: 215.4081\n",
      "Epoch [1070/10000], Train Loss: 58.3210, Val Loss: 215.3819\n",
      "Epoch [1071/10000], Train Loss: 58.3066, Val Loss: 215.3510\n",
      "Epoch [1072/10000], Train Loss: 58.2921, Val Loss: 215.3214\n",
      "Epoch [1073/10000], Train Loss: 58.2778, Val Loss: 215.2936\n",
      "Epoch [1074/10000], Train Loss: 58.2634, Val Loss: 215.2680\n",
      "Epoch [1075/10000], Train Loss: 58.2491, Val Loss: 215.2447\n",
      "Epoch [1076/10000], Train Loss: 58.2346, Val Loss: 215.2232\n",
      "Epoch [1077/10000], Train Loss: 58.2201, Val Loss: 215.2030\n",
      "Epoch [1078/10000], Train Loss: 58.2056, Val Loss: 215.1790\n",
      "Epoch [1079/10000], Train Loss: 58.1913, Val Loss: 215.1559\n",
      "Epoch [1080/10000], Train Loss: 58.1769, Val Loss: 215.1338\n",
      "Epoch [1081/10000], Train Loss: 58.1627, Val Loss: 215.1079\n",
      "Epoch [1082/10000], Train Loss: 58.1483, Val Loss: 215.0835\n",
      "Epoch [1083/10000], Train Loss: 58.1339, Val Loss: 215.0607\n",
      "Epoch [1084/10000], Train Loss: 58.1196, Val Loss: 215.0394\n",
      "Epoch [1085/10000], Train Loss: 58.1052, Val Loss: 215.0190\n",
      "Epoch [1086/10000], Train Loss: 58.0910, Val Loss: 214.9947\n",
      "Epoch [1087/10000], Train Loss: 58.0765, Val Loss: 214.9715\n",
      "Epoch [1088/10000], Train Loss: 58.0622, Val Loss: 214.9497\n",
      "Epoch [1089/10000], Train Loss: 58.0478, Val Loss: 214.9283\n",
      "Epoch [1090/10000], Train Loss: 58.0337, Val Loss: 214.9031\n",
      "Epoch [1091/10000], Train Loss: 58.0192, Val Loss: 214.8790\n",
      "Epoch [1092/10000], Train Loss: 58.0049, Val Loss: 214.8564\n",
      "Epoch [1093/10000], Train Loss: 57.9906, Val Loss: 214.8346\n",
      "Epoch [1094/10000], Train Loss: 57.9763, Val Loss: 214.8091\n",
      "Epoch [1095/10000], Train Loss: 57.9620, Val Loss: 214.7852\n",
      "Epoch [1096/10000], Train Loss: 57.9477, Val Loss: 214.7629\n",
      "Epoch [1097/10000], Train Loss: 57.9334, Val Loss: 214.7415\n",
      "Epoch [1098/10000], Train Loss: 57.9190, Val Loss: 214.7207\n",
      "Epoch [1099/10000], Train Loss: 57.9050, Val Loss: 214.6959\n",
      "Epoch [1100/10000], Train Loss: 57.8908, Val Loss: 214.6738\n",
      "Epoch [1101/10000], Train Loss: 57.8769, Val Loss: 214.6586\n",
      "Epoch [1102/10000], Train Loss: 57.8626, Val Loss: 214.6487\n",
      "Epoch [1103/10000], Train Loss: 57.8480, Val Loss: 214.6424\n",
      "Epoch [1104/10000], Train Loss: 57.8338, Val Loss: 214.6270\n",
      "Epoch [1105/10000], Train Loss: 57.8197, Val Loss: 214.6071\n",
      "Epoch [1106/10000], Train Loss: 57.8056, Val Loss: 214.5828\n",
      "Epoch [1107/10000], Train Loss: 57.7915, Val Loss: 214.5546\n",
      "Epoch [1108/10000], Train Loss: 57.7773, Val Loss: 214.5237\n",
      "Epoch [1109/10000], Train Loss: 57.7630, Val Loss: 214.4912\n",
      "Epoch [1110/10000], Train Loss: 57.7487, Val Loss: 214.4579\n",
      "Epoch [1111/10000], Train Loss: 57.7345, Val Loss: 214.4207\n",
      "Epoch [1112/10000], Train Loss: 57.7205, Val Loss: 214.3917\n",
      "Epoch [1113/10000], Train Loss: 57.7065, Val Loss: 214.3709\n",
      "Epoch [1114/10000], Train Loss: 57.6922, Val Loss: 214.3566\n",
      "Epoch [1115/10000], Train Loss: 57.6782, Val Loss: 214.3428\n",
      "Epoch [1116/10000], Train Loss: 57.6643, Val Loss: 214.3226\n",
      "Epoch [1117/10000], Train Loss: 57.6496, Val Loss: 214.2968\n",
      "Epoch [1118/10000], Train Loss: 57.6359, Val Loss: 214.2767\n",
      "Epoch [1119/10000], Train Loss: 57.6222, Val Loss: 214.2615\n",
      "Epoch [1120/10000], Train Loss: 57.6081, Val Loss: 214.2502\n",
      "Epoch [1121/10000], Train Loss: 57.5939, Val Loss: 214.2358\n",
      "Epoch [1122/10000], Train Loss: 57.5799, Val Loss: 214.2169\n",
      "Epoch [1123/10000], Train Loss: 57.5659, Val Loss: 214.1930\n",
      "Epoch [1124/10000], Train Loss: 57.5518, Val Loss: 214.1649\n",
      "Epoch [1125/10000], Train Loss: 57.5377, Val Loss: 214.1331\n",
      "Epoch [1126/10000], Train Loss: 57.5235, Val Loss: 214.0983\n",
      "Epoch [1127/10000], Train Loss: 57.5092, Val Loss: 214.0618\n",
      "Epoch [1128/10000], Train Loss: 57.4950, Val Loss: 214.0305\n",
      "Epoch [1129/10000], Train Loss: 57.4809, Val Loss: 214.0005\n",
      "Epoch [1130/10000], Train Loss: 57.4669, Val Loss: 213.9722\n",
      "Epoch [1131/10000], Train Loss: 57.4532, Val Loss: 213.9503\n",
      "Epoch [1132/10000], Train Loss: 57.4392, Val Loss: 213.9341\n",
      "Epoch [1133/10000], Train Loss: 57.4251, Val Loss: 213.9223\n",
      "Epoch [1134/10000], Train Loss: 57.4109, Val Loss: 213.9038\n",
      "Epoch [1135/10000], Train Loss: 57.3969, Val Loss: 213.8832\n",
      "Epoch [1136/10000], Train Loss: 57.3830, Val Loss: 213.8654\n",
      "Epoch [1137/10000], Train Loss: 57.3690, Val Loss: 213.8500\n",
      "Epoch [1138/10000], Train Loss: 57.3551, Val Loss: 213.8262\n",
      "Epoch [1139/10000], Train Loss: 57.3412, Val Loss: 213.8047\n",
      "Epoch [1140/10000], Train Loss: 57.3273, Val Loss: 213.7850\n",
      "Epoch [1141/10000], Train Loss: 57.3133, Val Loss: 213.7613\n",
      "Epoch [1142/10000], Train Loss: 57.2994, Val Loss: 213.7393\n",
      "Epoch [1143/10000], Train Loss: 57.2855, Val Loss: 213.7091\n",
      "Epoch [1144/10000], Train Loss: 57.2716, Val Loss: 213.6818\n",
      "Epoch [1145/10000], Train Loss: 57.2578, Val Loss: 213.6575\n",
      "Epoch [1146/10000], Train Loss: 57.2439, Val Loss: 213.6359\n",
      "Epoch [1147/10000], Train Loss: 57.2299, Val Loss: 213.6165\n",
      "Epoch [1148/10000], Train Loss: 57.2164, Val Loss: 213.5940\n",
      "Epoch [1149/10000], Train Loss: 57.2024, Val Loss: 213.5688\n",
      "Epoch [1150/10000], Train Loss: 57.1884, Val Loss: 213.5460\n",
      "Epoch [1151/10000], Train Loss: 57.1746, Val Loss: 213.5253\n",
      "Epoch [1152/10000], Train Loss: 57.1608, Val Loss: 213.5061\n",
      "Epoch [1153/10000], Train Loss: 57.1469, Val Loss: 213.4832\n",
      "Epoch [1154/10000], Train Loss: 57.1331, Val Loss: 213.4565\n",
      "Epoch [1155/10000], Train Loss: 57.1192, Val Loss: 213.4314\n",
      "Epoch [1156/10000], Train Loss: 57.1053, Val Loss: 213.4078\n",
      "Epoch [1157/10000], Train Loss: 57.0919, Val Loss: 213.3811\n",
      "Epoch [1158/10000], Train Loss: 57.0780, Val Loss: 213.3522\n",
      "Epoch [1159/10000], Train Loss: 57.0641, Val Loss: 213.3263\n",
      "Epoch [1160/10000], Train Loss: 57.0505, Val Loss: 213.3036\n",
      "Epoch [1161/10000], Train Loss: 57.0368, Val Loss: 213.2838\n",
      "Epoch [1162/10000], Train Loss: 57.0230, Val Loss: 213.2661\n",
      "Epoch [1163/10000], Train Loss: 57.0091, Val Loss: 213.2496\n",
      "Epoch [1164/10000], Train Loss: 56.9952, Val Loss: 213.2332\n",
      "Epoch [1165/10000], Train Loss: 56.9817, Val Loss: 213.2118\n",
      "Epoch [1166/10000], Train Loss: 56.9678, Val Loss: 213.1857\n",
      "Epoch [1167/10000], Train Loss: 56.9541, Val Loss: 213.1604\n",
      "Epoch [1168/10000], Train Loss: 56.9405, Val Loss: 213.1360\n",
      "Epoch [1169/10000], Train Loss: 56.9269, Val Loss: 213.1129\n",
      "Epoch [1170/10000], Train Loss: 56.9132, Val Loss: 213.0909\n",
      "Epoch [1171/10000], Train Loss: 56.8994, Val Loss: 213.0699\n",
      "Epoch [1172/10000], Train Loss: 56.8856, Val Loss: 213.0490\n",
      "Epoch [1173/10000], Train Loss: 56.8718, Val Loss: 213.0276\n",
      "Epoch [1174/10000], Train Loss: 56.8581, Val Loss: 213.0013\n",
      "Epoch [1175/10000], Train Loss: 56.8443, Val Loss: 212.9750\n",
      "Epoch [1176/10000], Train Loss: 56.8307, Val Loss: 212.9491\n",
      "Epoch [1177/10000], Train Loss: 56.8169, Val Loss: 212.9235\n",
      "Epoch [1178/10000], Train Loss: 56.8035, Val Loss: 212.8946\n",
      "Epoch [1179/10000], Train Loss: 56.7896, Val Loss: 212.8678\n",
      "Epoch [1180/10000], Train Loss: 56.7760, Val Loss: 212.8433\n",
      "Epoch [1181/10000], Train Loss: 56.7624, Val Loss: 212.8208\n",
      "Epoch [1182/10000], Train Loss: 56.7486, Val Loss: 212.8002\n",
      "Epoch [1183/10000], Train Loss: 56.7350, Val Loss: 212.7770\n",
      "Epoch [1184/10000], Train Loss: 56.7213, Val Loss: 212.7555\n",
      "Epoch [1185/10000], Train Loss: 56.7077, Val Loss: 212.7354\n",
      "Epoch [1186/10000], Train Loss: 56.6940, Val Loss: 212.7160\n",
      "Epoch [1187/10000], Train Loss: 56.6803, Val Loss: 212.6932\n",
      "Epoch [1188/10000], Train Loss: 56.6667, Val Loss: 212.6715\n",
      "Epoch [1189/10000], Train Loss: 56.6531, Val Loss: 212.6503\n",
      "Epoch [1190/10000], Train Loss: 56.6394, Val Loss: 212.6293\n",
      "Epoch [1191/10000], Train Loss: 56.6257, Val Loss: 212.6087\n",
      "Epoch [1192/10000], Train Loss: 56.6120, Val Loss: 212.5839\n",
      "Epoch [1193/10000], Train Loss: 56.5984, Val Loss: 212.5596\n",
      "Epoch [1194/10000], Train Loss: 56.5848, Val Loss: 212.5358\n",
      "Epoch [1195/10000], Train Loss: 56.5712, Val Loss: 212.5127\n",
      "Epoch [1196/10000], Train Loss: 56.5575, Val Loss: 212.4903\n",
      "Epoch [1197/10000], Train Loss: 56.5438, Val Loss: 212.4640\n",
      "Epoch [1198/10000], Train Loss: 56.5302, Val Loss: 212.4389\n",
      "Epoch [1199/10000], Train Loss: 56.5166, Val Loss: 212.4150\n",
      "Epoch [1200/10000], Train Loss: 56.5029, Val Loss: 212.3923\n",
      "Epoch [1201/10000], Train Loss: 56.4892, Val Loss: 212.3705\n",
      "Epoch [1202/10000], Train Loss: 56.4757, Val Loss: 212.3452\n",
      "Epoch [1203/10000], Train Loss: 56.4619, Val Loss: 212.3214\n",
      "Epoch [1204/10000], Train Loss: 56.4483, Val Loss: 212.2988\n",
      "Epoch [1205/10000], Train Loss: 56.4347, Val Loss: 212.2773\n",
      "Epoch [1206/10000], Train Loss: 56.4210, Val Loss: 212.2565\n",
      "Epoch [1207/10000], Train Loss: 56.4076, Val Loss: 212.2324\n",
      "Epoch [1208/10000], Train Loss: 56.3937, Val Loss: 212.2094\n",
      "Epoch [1209/10000], Train Loss: 56.3801, Val Loss: 212.1876\n",
      "Epoch [1210/10000], Train Loss: 56.3668, Val Loss: 212.1671\n",
      "Epoch [1211/10000], Train Loss: 56.3534, Val Loss: 212.1480\n",
      "Epoch [1212/10000], Train Loss: 56.3404, Val Loss: 212.1258\n",
      "Epoch [1213/10000], Train Loss: 56.3269, Val Loss: 212.1050\n",
      "Epoch [1214/10000], Train Loss: 56.3136, Val Loss: 212.0855\n",
      "Epoch [1215/10000], Train Loss: 56.3004, Val Loss: 212.0673\n",
      "Epoch [1216/10000], Train Loss: 56.2871, Val Loss: 212.0460\n",
      "Epoch [1217/10000], Train Loss: 56.2739, Val Loss: 212.0263\n",
      "Epoch [1218/10000], Train Loss: 56.2607, Val Loss: 212.0081\n",
      "Epoch [1219/10000], Train Loss: 56.2474, Val Loss: 211.9911\n",
      "Epoch [1220/10000], Train Loss: 56.2341, Val Loss: 211.9745\n",
      "Epoch [1221/10000], Train Loss: 56.2208, Val Loss: 211.9580\n",
      "Epoch [1222/10000], Train Loss: 56.2079, Val Loss: 211.9371\n",
      "Epoch [1223/10000], Train Loss: 56.1944, Val Loss: 211.9123\n",
      "Epoch [1224/10000], Train Loss: 56.1812, Val Loss: 211.8894\n",
      "Epoch [1225/10000], Train Loss: 56.1681, Val Loss: 211.8684\n",
      "Epoch [1226/10000], Train Loss: 56.1550, Val Loss: 211.8495\n",
      "Epoch [1227/10000], Train Loss: 56.1418, Val Loss: 211.8324\n",
      "Epoch [1228/10000], Train Loss: 56.1285, Val Loss: 211.8165\n",
      "Epoch [1229/10000], Train Loss: 56.1151, Val Loss: 211.8009\n",
      "Epoch [1230/10000], Train Loss: 56.1018, Val Loss: 211.7843\n",
      "Epoch [1231/10000], Train Loss: 56.0884, Val Loss: 211.7664\n",
      "Epoch [1232/10000], Train Loss: 56.0754, Val Loss: 211.7427\n",
      "Epoch [1233/10000], Train Loss: 56.0619, Val Loss: 211.7150\n",
      "Epoch [1234/10000], Train Loss: 56.0485, Val Loss: 211.6886\n",
      "Epoch [1235/10000], Train Loss: 56.0354, Val Loss: 211.6645\n",
      "Epoch [1236/10000], Train Loss: 56.0222, Val Loss: 211.6438\n",
      "Epoch [1237/10000], Train Loss: 56.0089, Val Loss: 211.6259\n",
      "Epoch [1238/10000], Train Loss: 55.9955, Val Loss: 211.6106\n",
      "Epoch [1239/10000], Train Loss: 55.9821, Val Loss: 211.5968\n",
      "Epoch [1240/10000], Train Loss: 55.9686, Val Loss: 211.5833\n",
      "Epoch [1241/10000], Train Loss: 55.9552, Val Loss: 211.5692\n",
      "Epoch [1242/10000], Train Loss: 55.9422, Val Loss: 211.5497\n",
      "Epoch [1243/10000], Train Loss: 55.9288, Val Loss: 211.5259\n",
      "Epoch [1244/10000], Train Loss: 55.9152, Val Loss: 211.5029\n",
      "Epoch [1245/10000], Train Loss: 55.9020, Val Loss: 211.4814\n",
      "Epoch [1246/10000], Train Loss: 55.8888, Val Loss: 211.4619\n",
      "Epoch [1247/10000], Train Loss: 55.8755, Val Loss: 211.4446\n",
      "Epoch [1248/10000], Train Loss: 55.8622, Val Loss: 211.4288\n",
      "Epoch [1249/10000], Train Loss: 55.8487, Val Loss: 211.4140\n",
      "Epoch [1250/10000], Train Loss: 55.8353, Val Loss: 211.3989\n",
      "Epoch [1251/10000], Train Loss: 55.8219, Val Loss: 211.3831\n",
      "Epoch [1252/10000], Train Loss: 55.8092, Val Loss: 211.3620\n",
      "Epoch [1253/10000], Train Loss: 55.7957, Val Loss: 211.3369\n",
      "Epoch [1254/10000], Train Loss: 55.7819, Val Loss: 211.3128\n",
      "Epoch [1255/10000], Train Loss: 55.7688, Val Loss: 211.2908\n",
      "Epoch [1256/10000], Train Loss: 55.7555, Val Loss: 211.2710\n",
      "Epoch [1257/10000], Train Loss: 55.7422, Val Loss: 211.2533\n",
      "Epoch [1258/10000], Train Loss: 55.7289, Val Loss: 211.2375\n",
      "Epoch [1259/10000], Train Loss: 55.7154, Val Loss: 211.2223\n",
      "Epoch [1260/10000], Train Loss: 55.7020, Val Loss: 211.2069\n",
      "Epoch [1261/10000], Train Loss: 55.6890, Val Loss: 211.1871\n",
      "Epoch [1262/10000], Train Loss: 55.6756, Val Loss: 211.1633\n",
      "Epoch [1263/10000], Train Loss: 55.6621, Val Loss: 211.1407\n",
      "Epoch [1264/10000], Train Loss: 55.6489, Val Loss: 211.1196\n",
      "Epoch [1265/10000], Train Loss: 55.6357, Val Loss: 211.1004\n",
      "Epoch [1266/10000], Train Loss: 55.6224, Val Loss: 211.0831\n",
      "Epoch [1267/10000], Train Loss: 55.6091, Val Loss: 211.0669\n",
      "Epoch [1268/10000], Train Loss: 55.5956, Val Loss: 211.0511\n",
      "Epoch [1269/10000], Train Loss: 55.5822, Val Loss: 211.0350\n",
      "Epoch [1270/10000], Train Loss: 55.5689, Val Loss: 211.0144\n",
      "Epoch [1271/10000], Train Loss: 55.5555, Val Loss: 210.9935\n",
      "Epoch [1272/10000], Train Loss: 55.5422, Val Loss: 210.9726\n",
      "Epoch [1273/10000], Train Loss: 55.5289, Val Loss: 210.9519\n",
      "Epoch [1274/10000], Train Loss: 55.5158, Val Loss: 210.9285\n",
      "Epoch [1275/10000], Train Loss: 55.5024, Val Loss: 210.9070\n",
      "Epoch [1276/10000], Train Loss: 55.4892, Val Loss: 210.8877\n",
      "Epoch [1277/10000], Train Loss: 55.4759, Val Loss: 210.8702\n",
      "Epoch [1278/10000], Train Loss: 55.4625, Val Loss: 210.8546\n",
      "Epoch [1279/10000], Train Loss: 55.4491, Val Loss: 210.8398\n",
      "Epoch [1280/10000], Train Loss: 55.4363, Val Loss: 210.8218\n",
      "Epoch [1281/10000], Train Loss: 55.4228, Val Loss: 210.8011\n",
      "Epoch [1282/10000], Train Loss: 55.4094, Val Loss: 210.7821\n",
      "Epoch [1283/10000], Train Loss: 55.3962, Val Loss: 210.7646\n",
      "Epoch [1284/10000], Train Loss: 55.3831, Val Loss: 210.7486\n",
      "Epoch [1285/10000], Train Loss: 55.3697, Val Loss: 210.7336\n",
      "Epoch [1286/10000], Train Loss: 55.3564, Val Loss: 210.7190\n",
      "Epoch [1287/10000], Train Loss: 55.3430, Val Loss: 210.7035\n",
      "Epoch [1288/10000], Train Loss: 55.3297, Val Loss: 210.6864\n",
      "Epoch [1289/10000], Train Loss: 55.3166, Val Loss: 210.6641\n",
      "Epoch [1290/10000], Train Loss: 55.3031, Val Loss: 210.6378\n",
      "Epoch [1291/10000], Train Loss: 55.2900, Val Loss: 210.6127\n",
      "Epoch [1292/10000], Train Loss: 55.2769, Val Loss: 210.5896\n",
      "Epoch [1293/10000], Train Loss: 55.2637, Val Loss: 210.5691\n",
      "Epoch [1294/10000], Train Loss: 55.2505, Val Loss: 210.5513\n",
      "Epoch [1295/10000], Train Loss: 55.2372, Val Loss: 210.5353\n",
      "Epoch [1296/10000], Train Loss: 55.2238, Val Loss: 210.5200\n",
      "Epoch [1297/10000], Train Loss: 55.2104, Val Loss: 210.5048\n",
      "Epoch [1298/10000], Train Loss: 55.1970, Val Loss: 210.4885\n",
      "Epoch [1299/10000], Train Loss: 55.1841, Val Loss: 210.4673\n",
      "Epoch [1300/10000], Train Loss: 55.1707, Val Loss: 210.4420\n",
      "Epoch [1301/10000], Train Loss: 55.1573, Val Loss: 210.4182\n",
      "Epoch [1302/10000], Train Loss: 55.1442, Val Loss: 210.3966\n",
      "Epoch [1303/10000], Train Loss: 55.1311, Val Loss: 210.3776\n",
      "Epoch [1304/10000], Train Loss: 55.1179, Val Loss: 210.3613\n",
      "Epoch [1305/10000], Train Loss: 55.1046, Val Loss: 210.3472\n",
      "Epoch [1306/10000], Train Loss: 55.0912, Val Loss: 210.3341\n",
      "Epoch [1307/10000], Train Loss: 55.0779, Val Loss: 210.3209\n",
      "Epoch [1308/10000], Train Loss: 55.0645, Val Loss: 210.3067\n",
      "Epoch [1309/10000], Train Loss: 55.0518, Val Loss: 210.2877\n",
      "Epoch [1310/10000], Train Loss: 55.0384, Val Loss: 210.2645\n",
      "Epoch [1311/10000], Train Loss: 55.0249, Val Loss: 210.2420\n",
      "Epoch [1312/10000], Train Loss: 55.0118, Val Loss: 210.2213\n",
      "Epoch [1313/10000], Train Loss: 54.9987, Val Loss: 210.2026\n",
      "Epoch [1314/10000], Train Loss: 54.9855, Val Loss: 210.1859\n",
      "Epoch [1315/10000], Train Loss: 54.9722, Val Loss: 210.1706\n",
      "Epoch [1316/10000], Train Loss: 54.9588, Val Loss: 210.1559\n",
      "Epoch [1317/10000], Train Loss: 54.9455, Val Loss: 210.1407\n",
      "Epoch [1318/10000], Train Loss: 54.9325, Val Loss: 210.1212\n",
      "Epoch [1319/10000], Train Loss: 54.9192, Val Loss: 210.0982\n",
      "Epoch [1320/10000], Train Loss: 54.9059, Val Loss: 210.0761\n",
      "Epoch [1321/10000], Train Loss: 54.8929, Val Loss: 210.0552\n",
      "Epoch [1322/10000], Train Loss: 54.8798, Val Loss: 210.0360\n",
      "Epoch [1323/10000], Train Loss: 54.8666, Val Loss: 210.0184\n",
      "Epoch [1324/10000], Train Loss: 54.8533, Val Loss: 210.0020\n",
      "Epoch [1325/10000], Train Loss: 54.8400, Val Loss: 209.9857\n",
      "Epoch [1326/10000], Train Loss: 54.8267, Val Loss: 209.9689\n",
      "Epoch [1327/10000], Train Loss: 54.8135, Val Loss: 209.9480\n",
      "Epoch [1328/10000], Train Loss: 54.8003, Val Loss: 209.9270\n",
      "Epoch [1329/10000], Train Loss: 54.7871, Val Loss: 209.9061\n",
      "Epoch [1330/10000], Train Loss: 54.7739, Val Loss: 209.8855\n",
      "Epoch [1331/10000], Train Loss: 54.7607, Val Loss: 209.8629\n",
      "Epoch [1332/10000], Train Loss: 54.7476, Val Loss: 209.8425\n",
      "Epoch [1333/10000], Train Loss: 54.7345, Val Loss: 209.8242\n",
      "Epoch [1334/10000], Train Loss: 54.7213, Val Loss: 209.8081\n",
      "Epoch [1335/10000], Train Loss: 54.7081, Val Loss: 209.7935\n",
      "Epoch [1336/10000], Train Loss: 54.6948, Val Loss: 209.7801\n",
      "Epoch [1337/10000], Train Loss: 54.6821, Val Loss: 209.7636\n",
      "Epoch [1338/10000], Train Loss: 54.6687, Val Loss: 209.7445\n",
      "Epoch [1339/10000], Train Loss: 54.6554, Val Loss: 209.7267\n",
      "Epoch [1340/10000], Train Loss: 54.6425, Val Loss: 209.7102\n",
      "Epoch [1341/10000], Train Loss: 54.6294, Val Loss: 209.6950\n",
      "Epoch [1342/10000], Train Loss: 54.6162, Val Loss: 209.6804\n",
      "Epoch [1343/10000], Train Loss: 54.6030, Val Loss: 209.6658\n",
      "Epoch [1344/10000], Train Loss: 54.5898, Val Loss: 209.6501\n",
      "Epoch [1345/10000], Train Loss: 54.5765, Val Loss: 209.6328\n",
      "Epoch [1346/10000], Train Loss: 54.5636, Val Loss: 209.6108\n",
      "Epoch [1347/10000], Train Loss: 54.5501, Val Loss: 209.5856\n",
      "Epoch [1348/10000], Train Loss: 54.5370, Val Loss: 209.5613\n",
      "Epoch [1349/10000], Train Loss: 54.5241, Val Loss: 209.5391\n",
      "Epoch [1350/10000], Train Loss: 54.5111, Val Loss: 209.5195\n",
      "Epoch [1351/10000], Train Loss: 54.4979, Val Loss: 209.5023\n",
      "Epoch [1352/10000], Train Loss: 54.4846, Val Loss: 209.4867\n",
      "Epoch [1353/10000], Train Loss: 54.4713, Val Loss: 209.4716\n",
      "Epoch [1354/10000], Train Loss: 54.4580, Val Loss: 209.4562\n",
      "Epoch [1355/10000], Train Loss: 54.4447, Val Loss: 209.4394\n",
      "Epoch [1356/10000], Train Loss: 54.4322, Val Loss: 209.4180\n",
      "Epoch [1357/10000], Train Loss: 54.4188, Val Loss: 209.3933\n",
      "Epoch [1358/10000], Train Loss: 54.4054, Val Loss: 209.3700\n",
      "Epoch [1359/10000], Train Loss: 54.3925, Val Loss: 209.3490\n",
      "Epoch [1360/10000], Train Loss: 54.3796, Val Loss: 209.3329\n",
      "Epoch [1361/10000], Train Loss: 54.3666, Val Loss: 209.3211\n",
      "Epoch [1362/10000], Train Loss: 54.3534, Val Loss: 209.3125\n",
      "Epoch [1363/10000], Train Loss: 54.3401, Val Loss: 209.3050\n",
      "Epoch [1364/10000], Train Loss: 54.3270, Val Loss: 209.2922\n",
      "Epoch [1365/10000], Train Loss: 54.3139, Val Loss: 209.2768\n",
      "Epoch [1366/10000], Train Loss: 54.3009, Val Loss: 209.2560\n",
      "Epoch [1367/10000], Train Loss: 54.2880, Val Loss: 209.2361\n",
      "Epoch [1368/10000], Train Loss: 54.2752, Val Loss: 209.2174\n",
      "Epoch [1369/10000], Train Loss: 54.2623, Val Loss: 209.2002\n",
      "Epoch [1370/10000], Train Loss: 54.2492, Val Loss: 209.1838\n",
      "Epoch [1371/10000], Train Loss: 54.2361, Val Loss: 209.1679\n",
      "Epoch [1372/10000], Train Loss: 54.2230, Val Loss: 209.1517\n",
      "Epoch [1373/10000], Train Loss: 54.2102, Val Loss: 209.1322\n",
      "Epoch [1374/10000], Train Loss: 54.1971, Val Loss: 209.1099\n",
      "Epoch [1375/10000], Train Loss: 54.1842, Val Loss: 209.0885\n",
      "Epoch [1376/10000], Train Loss: 54.1714, Val Loss: 209.0685\n",
      "Epoch [1377/10000], Train Loss: 54.1586, Val Loss: 209.0495\n",
      "Epoch [1378/10000], Train Loss: 54.1456, Val Loss: 209.0319\n",
      "Epoch [1379/10000], Train Loss: 54.1326, Val Loss: 209.0148\n",
      "Epoch [1380/10000], Train Loss: 54.1196, Val Loss: 208.9977\n",
      "Epoch [1381/10000], Train Loss: 54.1065, Val Loss: 208.9798\n",
      "Epoch [1382/10000], Train Loss: 54.0938, Val Loss: 208.9584\n",
      "Epoch [1383/10000], Train Loss: 54.0806, Val Loss: 208.9369\n",
      "Epoch [1384/10000], Train Loss: 54.0677, Val Loss: 208.9153\n",
      "Epoch [1385/10000], Train Loss: 54.0548, Val Loss: 208.8941\n",
      "Epoch [1386/10000], Train Loss: 54.0419, Val Loss: 208.8718\n",
      "Epoch [1387/10000], Train Loss: 54.0291, Val Loss: 208.8516\n",
      "Epoch [1388/10000], Train Loss: 54.0163, Val Loss: 208.8334\n",
      "Epoch [1389/10000], Train Loss: 54.0034, Val Loss: 208.8171\n",
      "Epoch [1390/10000], Train Loss: 53.9904, Val Loss: 208.8022\n",
      "Epoch [1391/10000], Train Loss: 53.9774, Val Loss: 208.7879\n",
      "Epoch [1392/10000], Train Loss: 53.9649, Val Loss: 208.7710\n",
      "Epoch [1393/10000], Train Loss: 53.9518, Val Loss: 208.7520\n",
      "Epoch [1394/10000], Train Loss: 53.9388, Val Loss: 208.7337\n",
      "Epoch [1395/10000], Train Loss: 53.9261, Val Loss: 208.7162\n",
      "Epoch [1396/10000], Train Loss: 53.9133, Val Loss: 208.6990\n",
      "Epoch [1397/10000], Train Loss: 53.9004, Val Loss: 208.6824\n",
      "Epoch [1398/10000], Train Loss: 53.8875, Val Loss: 208.6657\n",
      "Epoch [1399/10000], Train Loss: 53.8745, Val Loss: 208.6479\n",
      "Epoch [1400/10000], Train Loss: 53.8615, Val Loss: 208.6285\n",
      "Epoch [1401/10000], Train Loss: 53.8487, Val Loss: 208.6059\n",
      "Epoch [1402/10000], Train Loss: 53.8357, Val Loss: 208.5827\n",
      "Epoch [1403/10000], Train Loss: 53.8229, Val Loss: 208.5593\n",
      "Epoch [1404/10000], Train Loss: 53.8100, Val Loss: 208.5365\n",
      "Epoch [1405/10000], Train Loss: 53.7971, Val Loss: 208.5149\n",
      "Epoch [1406/10000], Train Loss: 53.7842, Val Loss: 208.4927\n",
      "Epoch [1407/10000], Train Loss: 53.7714, Val Loss: 208.4725\n",
      "Epoch [1408/10000], Train Loss: 53.7585, Val Loss: 208.4544\n",
      "Epoch [1409/10000], Train Loss: 53.7456, Val Loss: 208.4382\n",
      "Epoch [1410/10000], Train Loss: 53.7327, Val Loss: 208.4232\n",
      "Epoch [1411/10000], Train Loss: 53.7199, Val Loss: 208.4071\n",
      "Epoch [1412/10000], Train Loss: 53.7069, Val Loss: 208.3917\n",
      "Epoch [1413/10000], Train Loss: 53.6940, Val Loss: 208.3764\n",
      "Epoch [1414/10000], Train Loss: 53.6811, Val Loss: 208.3611\n",
      "Epoch [1415/10000], Train Loss: 53.6684, Val Loss: 208.3438\n",
      "Epoch [1416/10000], Train Loss: 53.6555, Val Loss: 208.3267\n",
      "Epoch [1417/10000], Train Loss: 53.6427, Val Loss: 208.3100\n",
      "Epoch [1418/10000], Train Loss: 53.6298, Val Loss: 208.2930\n",
      "Epoch [1419/10000], Train Loss: 53.6170, Val Loss: 208.2764\n",
      "Epoch [1420/10000], Train Loss: 53.6040, Val Loss: 208.2593\n",
      "Epoch [1421/10000], Train Loss: 53.5913, Val Loss: 208.2397\n",
      "Epoch [1422/10000], Train Loss: 53.5783, Val Loss: 208.2201\n",
      "Epoch [1423/10000], Train Loss: 53.5655, Val Loss: 208.2004\n",
      "Epoch [1424/10000], Train Loss: 53.5526, Val Loss: 208.1806\n",
      "Epoch [1425/10000], Train Loss: 53.5398, Val Loss: 208.1594\n",
      "Epoch [1426/10000], Train Loss: 53.5270, Val Loss: 208.1391\n",
      "Epoch [1427/10000], Train Loss: 53.5142, Val Loss: 208.1197\n",
      "Epoch [1428/10000], Train Loss: 53.5014, Val Loss: 208.1007\n",
      "Epoch [1429/10000], Train Loss: 53.4885, Val Loss: 208.0823\n",
      "Epoch [1430/10000], Train Loss: 53.4756, Val Loss: 208.0640\n",
      "Epoch [1431/10000], Train Loss: 53.4631, Val Loss: 208.0439\n",
      "Epoch [1432/10000], Train Loss: 53.4500, Val Loss: 208.0225\n",
      "Epoch [1433/10000], Train Loss: 53.4372, Val Loss: 208.0026\n",
      "Epoch [1434/10000], Train Loss: 53.4246, Val Loss: 207.9842\n",
      "Epoch [1435/10000], Train Loss: 53.4119, Val Loss: 207.9674\n",
      "Epoch [1436/10000], Train Loss: 53.3991, Val Loss: 207.9519\n",
      "Epoch [1437/10000], Train Loss: 53.3861, Val Loss: 207.9369\n",
      "Epoch [1438/10000], Train Loss: 53.3732, Val Loss: 207.9213\n",
      "Epoch [1439/10000], Train Loss: 53.3603, Val Loss: 207.9044\n",
      "Epoch [1440/10000], Train Loss: 53.3474, Val Loss: 207.8858\n",
      "Epoch [1441/10000], Train Loss: 53.3350, Val Loss: 207.8642\n",
      "Epoch [1442/10000], Train Loss: 53.3218, Val Loss: 207.8404\n",
      "Epoch [1443/10000], Train Loss: 53.3090, Val Loss: 207.8180\n",
      "Epoch [1444/10000], Train Loss: 53.2964, Val Loss: 207.7975\n",
      "Epoch [1445/10000], Train Loss: 53.2838, Val Loss: 207.7792\n",
      "Epoch [1446/10000], Train Loss: 53.2710, Val Loss: 207.7632\n",
      "Epoch [1447/10000], Train Loss: 53.2581, Val Loss: 207.7486\n",
      "Epoch [1448/10000], Train Loss: 53.2451, Val Loss: 207.7344\n",
      "Epoch [1449/10000], Train Loss: 53.2321, Val Loss: 207.7192\n",
      "Epoch [1450/10000], Train Loss: 53.2192, Val Loss: 207.7024\n",
      "Epoch [1451/10000], Train Loss: 53.2071, Val Loss: 207.6822\n",
      "Epoch [1452/10000], Train Loss: 53.1940, Val Loss: 207.6595\n",
      "Epoch [1453/10000], Train Loss: 53.1808, Val Loss: 207.6374\n",
      "Epoch [1454/10000], Train Loss: 53.1682, Val Loss: 207.6164\n",
      "Epoch [1455/10000], Train Loss: 53.1556, Val Loss: 207.5975\n",
      "Epoch [1456/10000], Train Loss: 53.1428, Val Loss: 207.5805\n",
      "Epoch [1457/10000], Train Loss: 53.1299, Val Loss: 207.5649\n",
      "Epoch [1458/10000], Train Loss: 53.1170, Val Loss: 207.5497\n",
      "Epoch [1459/10000], Train Loss: 53.1040, Val Loss: 207.5342\n",
      "Epoch [1460/10000], Train Loss: 53.0911, Val Loss: 207.5173\n",
      "Epoch [1461/10000], Train Loss: 53.0790, Val Loss: 207.4976\n",
      "Epoch [1462/10000], Train Loss: 53.0660, Val Loss: 207.4757\n",
      "Epoch [1463/10000], Train Loss: 53.0527, Val Loss: 207.4540\n",
      "Epoch [1464/10000], Train Loss: 53.0401, Val Loss: 207.4333\n",
      "Epoch [1465/10000], Train Loss: 53.0274, Val Loss: 207.4141\n",
      "Epoch [1466/10000], Train Loss: 53.0147, Val Loss: 207.3964\n",
      "Epoch [1467/10000], Train Loss: 53.0018, Val Loss: 207.3797\n",
      "Epoch [1468/10000], Train Loss: 52.9889, Val Loss: 207.3632\n",
      "Epoch [1469/10000], Train Loss: 52.9760, Val Loss: 207.3463\n",
      "Epoch [1470/10000], Train Loss: 52.9635, Val Loss: 207.3275\n",
      "Epoch [1471/10000], Train Loss: 52.9505, Val Loss: 207.3073\n",
      "Epoch [1472/10000], Train Loss: 52.9377, Val Loss: 207.2872\n",
      "Epoch [1473/10000], Train Loss: 52.9251, Val Loss: 207.2678\n",
      "Epoch [1474/10000], Train Loss: 52.9124, Val Loss: 207.2494\n",
      "Epoch [1475/10000], Train Loss: 52.8996, Val Loss: 207.2319\n",
      "Epoch [1476/10000], Train Loss: 52.8867, Val Loss: 207.2148\n",
      "Epoch [1477/10000], Train Loss: 52.8739, Val Loss: 207.1975\n",
      "Epoch [1478/10000], Train Loss: 52.8610, Val Loss: 207.1796\n",
      "Epoch [1479/10000], Train Loss: 52.8482, Val Loss: 207.1604\n",
      "Epoch [1480/10000], Train Loss: 52.8360, Val Loss: 207.1391\n",
      "Epoch [1481/10000], Train Loss: 52.8229, Val Loss: 207.1170\n",
      "Epoch [1482/10000], Train Loss: 52.8099, Val Loss: 207.0959\n",
      "Epoch [1483/10000], Train Loss: 52.7974, Val Loss: 207.0764\n",
      "Epoch [1484/10000], Train Loss: 52.7847, Val Loss: 207.0588\n",
      "Epoch [1485/10000], Train Loss: 52.7720, Val Loss: 207.0429\n",
      "Epoch [1486/10000], Train Loss: 52.7591, Val Loss: 207.0279\n",
      "Epoch [1487/10000], Train Loss: 52.7461, Val Loss: 207.0128\n",
      "Epoch [1488/10000], Train Loss: 52.7333, Val Loss: 206.9966\n",
      "Epoch [1489/10000], Train Loss: 52.7209, Val Loss: 206.9784\n",
      "Epoch [1490/10000], Train Loss: 52.7079, Val Loss: 206.9585\n",
      "Epoch [1491/10000], Train Loss: 52.6951, Val Loss: 206.9384\n",
      "Epoch [1492/10000], Train Loss: 52.6825, Val Loss: 206.9187\n",
      "Epoch [1493/10000], Train Loss: 52.6699, Val Loss: 206.8999\n",
      "Epoch [1494/10000], Train Loss: 52.6571, Val Loss: 206.8819\n",
      "Epoch [1495/10000], Train Loss: 52.6443, Val Loss: 206.8645\n",
      "Epoch [1496/10000], Train Loss: 52.6314, Val Loss: 206.8468\n",
      "Epoch [1497/10000], Train Loss: 52.6186, Val Loss: 206.8285\n",
      "Epoch [1498/10000], Train Loss: 52.6058, Val Loss: 206.8089\n",
      "Epoch [1499/10000], Train Loss: 52.5935, Val Loss: 206.7877\n",
      "Epoch [1500/10000], Train Loss: 52.5805, Val Loss: 206.7656\n",
      "Epoch [1501/10000], Train Loss: 52.5676, Val Loss: 206.7443\n",
      "Epoch [1502/10000], Train Loss: 52.5550, Val Loss: 206.7243\n",
      "Epoch [1503/10000], Train Loss: 52.5425, Val Loss: 206.7058\n",
      "Epoch [1504/10000], Train Loss: 52.5298, Val Loss: 206.6889\n",
      "Epoch [1505/10000], Train Loss: 52.5169, Val Loss: 206.6729\n",
      "Epoch [1506/10000], Train Loss: 52.5040, Val Loss: 206.6566\n",
      "Epoch [1507/10000], Train Loss: 52.4912, Val Loss: 206.6398\n",
      "Epoch [1508/10000], Train Loss: 52.4787, Val Loss: 206.6216\n",
      "Epoch [1509/10000], Train Loss: 52.4658, Val Loss: 206.6022\n",
      "Epoch [1510/10000], Train Loss: 52.4530, Val Loss: 206.5828\n",
      "Epoch [1511/10000], Train Loss: 52.4405, Val Loss: 206.5639\n",
      "Epoch [1512/10000], Train Loss: 52.4279, Val Loss: 206.5456\n",
      "Epoch [1513/10000], Train Loss: 52.4152, Val Loss: 206.5281\n",
      "Epoch [1514/10000], Train Loss: 52.4024, Val Loss: 206.5109\n",
      "Epoch [1515/10000], Train Loss: 52.3896, Val Loss: 206.4933\n",
      "Epoch [1516/10000], Train Loss: 52.3768, Val Loss: 206.4750\n",
      "Epoch [1517/10000], Train Loss: 52.3640, Val Loss: 206.4552\n",
      "Epoch [1518/10000], Train Loss: 52.3518, Val Loss: 206.4340\n",
      "Epoch [1519/10000], Train Loss: 52.3388, Val Loss: 206.4124\n",
      "Epoch [1520/10000], Train Loss: 52.3259, Val Loss: 206.3912\n",
      "Epoch [1521/10000], Train Loss: 52.3134, Val Loss: 206.3714\n",
      "Epoch [1522/10000], Train Loss: 52.3009, Val Loss: 206.3529\n",
      "Epoch [1523/10000], Train Loss: 52.2882, Val Loss: 206.3357\n",
      "Epoch [1524/10000], Train Loss: 52.2754, Val Loss: 206.3192\n",
      "Epoch [1525/10000], Train Loss: 52.2625, Val Loss: 206.3027\n",
      "Epoch [1526/10000], Train Loss: 52.2497, Val Loss: 206.2852\n",
      "Epoch [1527/10000], Train Loss: 52.2374, Val Loss: 206.2667\n",
      "Epoch [1528/10000], Train Loss: 52.2245, Val Loss: 206.2475\n",
      "Epoch [1529/10000], Train Loss: 52.2117, Val Loss: 206.2281\n",
      "Epoch [1530/10000], Train Loss: 52.1992, Val Loss: 206.2091\n",
      "Epoch [1531/10000], Train Loss: 52.1866, Val Loss: 206.1906\n",
      "Epoch [1532/10000], Train Loss: 52.1740, Val Loss: 206.1727\n",
      "Epoch [1533/10000], Train Loss: 52.1612, Val Loss: 206.1551\n",
      "Epoch [1534/10000], Train Loss: 52.1484, Val Loss: 206.1371\n",
      "Epoch [1535/10000], Train Loss: 52.1356, Val Loss: 206.1183\n",
      "Epoch [1536/10000], Train Loss: 52.1229, Val Loss: 206.0982\n",
      "Epoch [1537/10000], Train Loss: 52.1108, Val Loss: 206.0772\n",
      "Epoch [1538/10000], Train Loss: 52.0979, Val Loss: 206.0561\n",
      "Epoch [1539/10000], Train Loss: 52.0849, Val Loss: 206.0355\n",
      "Epoch [1540/10000], Train Loss: 52.0725, Val Loss: 206.0158\n",
      "Epoch [1541/10000], Train Loss: 52.0600, Val Loss: 205.9972\n",
      "Epoch [1542/10000], Train Loss: 52.0473, Val Loss: 205.9799\n",
      "Epoch [1543/10000], Train Loss: 52.0345, Val Loss: 205.9631\n",
      "Epoch [1544/10000], Train Loss: 52.0217, Val Loss: 205.9460\n",
      "Epoch [1545/10000], Train Loss: 52.0090, Val Loss: 205.9281\n",
      "Epoch [1546/10000], Train Loss: 51.9968, Val Loss: 205.9096\n",
      "Epoch [1547/10000], Train Loss: 51.9840, Val Loss: 205.8907\n",
      "Epoch [1548/10000], Train Loss: 51.9711, Val Loss: 205.8716\n",
      "Epoch [1549/10000], Train Loss: 51.9586, Val Loss: 205.8527\n",
      "Epoch [1550/10000], Train Loss: 51.9461, Val Loss: 205.8342\n",
      "Epoch [1551/10000], Train Loss: 51.9335, Val Loss: 205.8161\n",
      "Epoch [1552/10000], Train Loss: 51.9208, Val Loss: 205.7982\n",
      "Epoch [1553/10000], Train Loss: 51.9080, Val Loss: 205.7799\n",
      "Epoch [1554/10000], Train Loss: 51.8952, Val Loss: 205.7605\n",
      "Epoch [1555/10000], Train Loss: 51.8828, Val Loss: 205.7410\n",
      "Epoch [1556/10000], Train Loss: 51.8700, Val Loss: 205.7215\n",
      "Epoch [1557/10000], Train Loss: 51.8574, Val Loss: 205.7018\n",
      "Epoch [1558/10000], Train Loss: 51.8450, Val Loss: 205.6821\n",
      "Epoch [1559/10000], Train Loss: 51.8325, Val Loss: 205.6629\n",
      "Epoch [1560/10000], Train Loss: 51.8199, Val Loss: 205.6441\n",
      "Epoch [1561/10000], Train Loss: 51.8071, Val Loss: 205.6252\n",
      "Epoch [1562/10000], Train Loss: 51.7944, Val Loss: 205.6059\n",
      "Epoch [1563/10000], Train Loss: 51.7817, Val Loss: 205.5859\n",
      "Epoch [1564/10000], Train Loss: 51.7691, Val Loss: 205.5659\n",
      "Epoch [1565/10000], Train Loss: 51.7565, Val Loss: 205.5452\n",
      "Epoch [1566/10000], Train Loss: 51.7439, Val Loss: 205.5243\n",
      "Epoch [1567/10000], Train Loss: 51.7313, Val Loss: 205.5034\n",
      "Epoch [1568/10000], Train Loss: 51.7186, Val Loss: 205.4829\n",
      "Epoch [1569/10000], Train Loss: 51.7060, Val Loss: 205.4629\n",
      "Epoch [1570/10000], Train Loss: 51.6937, Val Loss: 205.4448\n",
      "Epoch [1571/10000], Train Loss: 51.6809, Val Loss: 205.4289\n",
      "Epoch [1572/10000], Train Loss: 51.6685, Val Loss: 205.4138\n",
      "Epoch [1573/10000], Train Loss: 51.6561, Val Loss: 205.3991\n",
      "Epoch [1574/10000], Train Loss: 51.6435, Val Loss: 205.3844\n",
      "Epoch [1575/10000], Train Loss: 51.6307, Val Loss: 205.3694\n",
      "Epoch [1576/10000], Train Loss: 51.6180, Val Loss: 205.3530\n",
      "Epoch [1577/10000], Train Loss: 51.6054, Val Loss: 205.3345\n",
      "Epoch [1578/10000], Train Loss: 51.5933, Val Loss: 205.3153\n",
      "Epoch [1579/10000], Train Loss: 51.5804, Val Loss: 205.2957\n",
      "Epoch [1580/10000], Train Loss: 51.5678, Val Loss: 205.2751\n",
      "Epoch [1581/10000], Train Loss: 51.5554, Val Loss: 205.2539\n",
      "Epoch [1582/10000], Train Loss: 51.5430, Val Loss: 205.2327\n",
      "Epoch [1583/10000], Train Loss: 51.5305, Val Loss: 205.2114\n",
      "Epoch [1584/10000], Train Loss: 51.5178, Val Loss: 205.1902\n",
      "Epoch [1585/10000], Train Loss: 51.5051, Val Loss: 205.1684\n",
      "Epoch [1586/10000], Train Loss: 51.4924, Val Loss: 205.1461\n",
      "Epoch [1587/10000], Train Loss: 51.4798, Val Loss: 205.1227\n",
      "Epoch [1588/10000], Train Loss: 51.4679, Val Loss: 205.1001\n",
      "Epoch [1589/10000], Train Loss: 51.4550, Val Loss: 205.0792\n",
      "Epoch [1590/10000], Train Loss: 51.4422, Val Loss: 205.0589\n",
      "Epoch [1591/10000], Train Loss: 51.4299, Val Loss: 205.0397\n",
      "Epoch [1592/10000], Train Loss: 51.4175, Val Loss: 205.0218\n",
      "Epoch [1593/10000], Train Loss: 51.4050, Val Loss: 205.0051\n",
      "Epoch [1594/10000], Train Loss: 51.3923, Val Loss: 204.9889\n",
      "Epoch [1595/10000], Train Loss: 51.3796, Val Loss: 204.9727\n",
      "Epoch [1596/10000], Train Loss: 51.3669, Val Loss: 204.9559\n",
      "Epoch [1597/10000], Train Loss: 51.3547, Val Loss: 204.9396\n",
      "Epoch [1598/10000], Train Loss: 51.3420, Val Loss: 204.9239\n",
      "Epoch [1599/10000], Train Loss: 51.3294, Val Loss: 204.9074\n",
      "Epoch [1600/10000], Train Loss: 51.3170, Val Loss: 204.8902\n",
      "Epoch [1601/10000], Train Loss: 51.3046, Val Loss: 204.8725\n",
      "Epoch [1602/10000], Train Loss: 51.2922, Val Loss: 204.8542\n",
      "Epoch [1603/10000], Train Loss: 51.2795, Val Loss: 204.8345\n",
      "Epoch [1604/10000], Train Loss: 51.2669, Val Loss: 204.8134\n",
      "Epoch [1605/10000], Train Loss: 51.2543, Val Loss: 204.7914\n",
      "Epoch [1606/10000], Train Loss: 51.2417, Val Loss: 204.7706\n",
      "Epoch [1607/10000], Train Loss: 51.2292, Val Loss: 204.7486\n",
      "Epoch [1608/10000], Train Loss: 51.2167, Val Loss: 204.7258\n",
      "Epoch [1609/10000], Train Loss: 51.2042, Val Loss: 204.7025\n",
      "Epoch [1610/10000], Train Loss: 51.1916, Val Loss: 204.6793\n",
      "Epoch [1611/10000], Train Loss: 51.1792, Val Loss: 204.6594\n",
      "Epoch [1612/10000], Train Loss: 51.1667, Val Loss: 204.6399\n",
      "Epoch [1613/10000], Train Loss: 51.1543, Val Loss: 204.6208\n",
      "Epoch [1614/10000], Train Loss: 51.1417, Val Loss: 204.6021\n",
      "Epoch [1615/10000], Train Loss: 51.1292, Val Loss: 204.5867\n",
      "Epoch [1616/10000], Train Loss: 51.1167, Val Loss: 204.5712\n",
      "Epoch [1617/10000], Train Loss: 51.1042, Val Loss: 204.5550\n",
      "Epoch [1618/10000], Train Loss: 51.0917, Val Loss: 204.5381\n",
      "Epoch [1619/10000], Train Loss: 51.0794, Val Loss: 204.5233\n",
      "Epoch [1620/10000], Train Loss: 51.0668, Val Loss: 204.5071\n",
      "Epoch [1621/10000], Train Loss: 51.0543, Val Loss: 204.4895\n",
      "Epoch [1622/10000], Train Loss: 51.0419, Val Loss: 204.4703\n",
      "Epoch [1623/10000], Train Loss: 51.0294, Val Loss: 204.4500\n",
      "Epoch [1624/10000], Train Loss: 51.0169, Val Loss: 204.4313\n",
      "Epoch [1625/10000], Train Loss: 51.0044, Val Loss: 204.4115\n",
      "Epoch [1626/10000], Train Loss: 50.9920, Val Loss: 204.3904\n",
      "Epoch [1627/10000], Train Loss: 50.9795, Val Loss: 204.3681\n",
      "Epoch [1628/10000], Train Loss: 50.9670, Val Loss: 204.3450\n",
      "Epoch [1629/10000], Train Loss: 50.9548, Val Loss: 204.3247\n",
      "Epoch [1630/10000], Train Loss: 50.9422, Val Loss: 204.3069\n",
      "Epoch [1631/10000], Train Loss: 50.9299, Val Loss: 204.2884\n",
      "Epoch [1632/10000], Train Loss: 50.9176, Val Loss: 204.2693\n",
      "Epoch [1633/10000], Train Loss: 50.9052, Val Loss: 204.2495\n",
      "Epoch [1634/10000], Train Loss: 50.8927, Val Loss: 204.2292\n",
      "Epoch [1635/10000], Train Loss: 50.8801, Val Loss: 204.2082\n",
      "Epoch [1636/10000], Train Loss: 50.8677, Val Loss: 204.1864\n",
      "Epoch [1637/10000], Train Loss: 50.8552, Val Loss: 204.1640\n",
      "Epoch [1638/10000], Train Loss: 50.8430, Val Loss: 204.1441\n",
      "Epoch [1639/10000], Train Loss: 50.8303, Val Loss: 204.1238\n",
      "Epoch [1640/10000], Train Loss: 50.8178, Val Loss: 204.1032\n",
      "Epoch [1641/10000], Train Loss: 50.8054, Val Loss: 204.0826\n",
      "Epoch [1642/10000], Train Loss: 50.7930, Val Loss: 204.0621\n",
      "Epoch [1643/10000], Train Loss: 50.7805, Val Loss: 204.0417\n",
      "Epoch [1644/10000], Train Loss: 50.7683, Val Loss: 204.0249\n",
      "Epoch [1645/10000], Train Loss: 50.7557, Val Loss: 204.0114\n",
      "Epoch [1646/10000], Train Loss: 50.7434, Val Loss: 203.9972\n",
      "Epoch [1647/10000], Train Loss: 50.7311, Val Loss: 203.9818\n",
      "Epoch [1648/10000], Train Loss: 50.7186, Val Loss: 203.9651\n",
      "Epoch [1649/10000], Train Loss: 50.7061, Val Loss: 203.9471\n",
      "Epoch [1650/10000], Train Loss: 50.6937, Val Loss: 203.9273\n",
      "Epoch [1651/10000], Train Loss: 50.6813, Val Loss: 203.9057\n",
      "Epoch [1652/10000], Train Loss: 50.6693, Val Loss: 203.8861\n",
      "Epoch [1653/10000], Train Loss: 50.6565, Val Loss: 203.8685\n",
      "Epoch [1654/10000], Train Loss: 50.6441, Val Loss: 203.8494\n",
      "Epoch [1655/10000], Train Loss: 50.6321, Val Loss: 203.8289\n",
      "Epoch [1656/10000], Train Loss: 50.6198, Val Loss: 203.8071\n",
      "Epoch [1657/10000], Train Loss: 50.6074, Val Loss: 203.7843\n",
      "Epoch [1658/10000], Train Loss: 50.5947, Val Loss: 203.7606\n",
      "Epoch [1659/10000], Train Loss: 50.5822, Val Loss: 203.7359\n",
      "Epoch [1660/10000], Train Loss: 50.5698, Val Loss: 203.7105\n",
      "Epoch [1661/10000], Train Loss: 50.5577, Val Loss: 203.6882\n",
      "Epoch [1662/10000], Train Loss: 50.5451, Val Loss: 203.6690\n",
      "Epoch [1663/10000], Train Loss: 50.5326, Val Loss: 203.6495\n",
      "Epoch [1664/10000], Train Loss: 50.5205, Val Loss: 203.6297\n",
      "Epoch [1665/10000], Train Loss: 50.5083, Val Loss: 203.6098\n",
      "Epoch [1666/10000], Train Loss: 50.4959, Val Loss: 203.5899\n",
      "Epoch [1667/10000], Train Loss: 50.4834, Val Loss: 203.5697\n",
      "Epoch [1668/10000], Train Loss: 50.4708, Val Loss: 203.5495\n",
      "Epoch [1669/10000], Train Loss: 50.4584, Val Loss: 203.5290\n",
      "Epoch [1670/10000], Train Loss: 50.4460, Val Loss: 203.5078\n",
      "Epoch [1671/10000], Train Loss: 50.4341, Val Loss: 203.4899\n",
      "Epoch [1672/10000], Train Loss: 50.4214, Val Loss: 203.4752\n",
      "Epoch [1673/10000], Train Loss: 50.4089, Val Loss: 203.4598\n",
      "Epoch [1674/10000], Train Loss: 50.3968, Val Loss: 203.4431\n",
      "Epoch [1675/10000], Train Loss: 50.3847, Val Loss: 203.4252\n",
      "Epoch [1676/10000], Train Loss: 50.3723, Val Loss: 203.4062\n",
      "Epoch [1677/10000], Train Loss: 50.3597, Val Loss: 203.3858\n",
      "Epoch [1678/10000], Train Loss: 50.3471, Val Loss: 203.3640\n",
      "Epoch [1679/10000], Train Loss: 50.3347, Val Loss: 203.3410\n",
      "Epoch [1680/10000], Train Loss: 50.3230, Val Loss: 203.3203\n",
      "Epoch [1681/10000], Train Loss: 50.3104, Val Loss: 203.3022\n",
      "Epoch [1682/10000], Train Loss: 50.2977, Val Loss: 203.2827\n",
      "Epoch [1683/10000], Train Loss: 50.2855, Val Loss: 203.2618\n",
      "Epoch [1684/10000], Train Loss: 50.2734, Val Loss: 203.2398\n",
      "Epoch [1685/10000], Train Loss: 50.2611, Val Loss: 203.2169\n",
      "Epoch [1686/10000], Train Loss: 50.2486, Val Loss: 203.1931\n",
      "Epoch [1687/10000], Train Loss: 50.2361, Val Loss: 203.1687\n",
      "Epoch [1688/10000], Train Loss: 50.2236, Val Loss: 203.1440\n",
      "Epoch [1689/10000], Train Loss: 50.2117, Val Loss: 203.1231\n",
      "Epoch [1690/10000], Train Loss: 50.1992, Val Loss: 203.1055\n",
      "Epoch [1691/10000], Train Loss: 50.1867, Val Loss: 203.0874\n",
      "Epoch [1692/10000], Train Loss: 50.1745, Val Loss: 203.0684\n",
      "Epoch [1693/10000], Train Loss: 50.1623, Val Loss: 203.0485\n",
      "Epoch [1694/10000], Train Loss: 50.1500, Val Loss: 203.0280\n",
      "Epoch [1695/10000], Train Loss: 50.1375, Val Loss: 203.0066\n",
      "Epoch [1696/10000], Train Loss: 50.1251, Val Loss: 202.9845\n",
      "Epoch [1697/10000], Train Loss: 50.1127, Val Loss: 202.9619\n",
      "Epoch [1698/10000], Train Loss: 50.1008, Val Loss: 202.9426\n",
      "Epoch [1699/10000], Train Loss: 50.0882, Val Loss: 202.9269\n",
      "Epoch [1700/10000], Train Loss: 50.0758, Val Loss: 202.9099\n",
      "Epoch [1701/10000], Train Loss: 50.0637, Val Loss: 202.8913\n",
      "Epoch [1702/10000], Train Loss: 50.0515, Val Loss: 202.8713\n",
      "Epoch [1703/10000], Train Loss: 50.0392, Val Loss: 202.8500\n",
      "Epoch [1704/10000], Train Loss: 50.0267, Val Loss: 202.8274\n",
      "Epoch [1705/10000], Train Loss: 50.0143, Val Loss: 202.8037\n",
      "Epoch [1706/10000], Train Loss: 50.0019, Val Loss: 202.7792\n",
      "Epoch [1707/10000], Train Loss: 49.9900, Val Loss: 202.7581\n",
      "Epoch [1708/10000], Train Loss: 49.9774, Val Loss: 202.7405\n",
      "Epoch [1709/10000], Train Loss: 49.9650, Val Loss: 202.7218\n",
      "Epoch [1710/10000], Train Loss: 49.9530, Val Loss: 202.7017\n",
      "Epoch [1711/10000], Train Loss: 49.9408, Val Loss: 202.6803\n",
      "Epoch [1712/10000], Train Loss: 49.9285, Val Loss: 202.6578\n",
      "Epoch [1713/10000], Train Loss: 49.9160, Val Loss: 202.6343\n",
      "Epoch [1714/10000], Train Loss: 49.9036, Val Loss: 202.6099\n",
      "Epoch [1715/10000], Train Loss: 49.8912, Val Loss: 202.5852\n",
      "Epoch [1716/10000], Train Loss: 49.8793, Val Loss: 202.5644\n",
      "Epoch [1717/10000], Train Loss: 49.8668, Val Loss: 202.5474\n",
      "Epoch [1718/10000], Train Loss: 49.8544, Val Loss: 202.5294\n",
      "Epoch [1719/10000], Train Loss: 49.8423, Val Loss: 202.5100\n",
      "Epoch [1720/10000], Train Loss: 49.8302, Val Loss: 202.4893\n",
      "Epoch [1721/10000], Train Loss: 49.8179, Val Loss: 202.4673\n",
      "Epoch [1722/10000], Train Loss: 49.8054, Val Loss: 202.4442\n",
      "Epoch [1723/10000], Train Loss: 49.7930, Val Loss: 202.4203\n",
      "Epoch [1724/10000], Train Loss: 49.7807, Val Loss: 202.3957\n",
      "Epoch [1725/10000], Train Loss: 49.7687, Val Loss: 202.3752\n",
      "Epoch [1726/10000], Train Loss: 49.7562, Val Loss: 202.3584\n",
      "Epoch [1727/10000], Train Loss: 49.7438, Val Loss: 202.3404\n",
      "Epoch [1728/10000], Train Loss: 49.7318, Val Loss: 202.3207\n",
      "Epoch [1729/10000], Train Loss: 49.7197, Val Loss: 202.2994\n",
      "Epoch [1730/10000], Train Loss: 49.7074, Val Loss: 202.2769\n",
      "Epoch [1731/10000], Train Loss: 49.6949, Val Loss: 202.2530\n",
      "Epoch [1732/10000], Train Loss: 49.6825, Val Loss: 202.2283\n",
      "Epoch [1733/10000], Train Loss: 49.6701, Val Loss: 202.2029\n",
      "Epoch [1734/10000], Train Loss: 49.6582, Val Loss: 202.1817\n",
      "Epoch [1735/10000], Train Loss: 49.6460, Val Loss: 202.1677\n",
      "Epoch [1736/10000], Train Loss: 49.6334, Val Loss: 202.1519\n",
      "Epoch [1737/10000], Train Loss: 49.6213, Val Loss: 202.1337\n",
      "Epoch [1738/10000], Train Loss: 49.6091, Val Loss: 202.1131\n",
      "Epoch [1739/10000], Train Loss: 49.5969, Val Loss: 202.0906\n",
      "Epoch [1740/10000], Train Loss: 49.5846, Val Loss: 202.0660\n",
      "Epoch [1741/10000], Train Loss: 49.5723, Val Loss: 202.0400\n",
      "Epoch [1742/10000], Train Loss: 49.5600, Val Loss: 202.0131\n",
      "Epoch [1743/10000], Train Loss: 49.5480, Val Loss: 201.9905\n",
      "Epoch [1744/10000], Train Loss: 49.5355, Val Loss: 201.9672\n",
      "Epoch [1745/10000], Train Loss: 49.5232, Val Loss: 201.9434\n",
      "Epoch [1746/10000], Train Loss: 49.5110, Val Loss: 201.9191\n",
      "Epoch [1747/10000], Train Loss: 49.4987, Val Loss: 201.8947\n",
      "Epoch [1748/10000], Train Loss: 49.4865, Val Loss: 201.8756\n",
      "Epoch [1749/10000], Train Loss: 49.4742, Val Loss: 201.8557\n",
      "Epoch [1750/10000], Train Loss: 49.4620, Val Loss: 201.8350\n",
      "Epoch [1751/10000], Train Loss: 49.4497, Val Loss: 201.8136\n",
      "Epoch [1752/10000], Train Loss: 49.4376, Val Loss: 201.7966\n",
      "Epoch [1753/10000], Train Loss: 49.4252, Val Loss: 201.7831\n",
      "Epoch [1754/10000], Train Loss: 49.4131, Val Loss: 201.7673\n",
      "Epoch [1755/10000], Train Loss: 49.4010, Val Loss: 201.7484\n",
      "Epoch [1756/10000], Train Loss: 49.3887, Val Loss: 201.7266\n",
      "Epoch [1757/10000], Train Loss: 49.3764, Val Loss: 201.7024\n",
      "Epoch [1758/10000], Train Loss: 49.3641, Val Loss: 201.6757\n",
      "Epoch [1759/10000], Train Loss: 49.3518, Val Loss: 201.6472\n",
      "Epoch [1760/10000], Train Loss: 49.3395, Val Loss: 201.6174\n",
      "Epoch [1761/10000], Train Loss: 49.3275, Val Loss: 201.5920\n",
      "Epoch [1762/10000], Train Loss: 49.3149, Val Loss: 201.5659\n",
      "Epoch [1763/10000], Train Loss: 49.3027, Val Loss: 201.5391\n",
      "Epoch [1764/10000], Train Loss: 49.2905, Val Loss: 201.5118\n",
      "Epoch [1765/10000], Train Loss: 49.2782, Val Loss: 201.4848\n",
      "Epoch [1766/10000], Train Loss: 49.2659, Val Loss: 201.4637\n",
      "Epoch [1767/10000], Train Loss: 49.2536, Val Loss: 201.4426\n",
      "Epoch [1768/10000], Train Loss: 49.2413, Val Loss: 201.4217\n",
      "Epoch [1769/10000], Train Loss: 49.2291, Val Loss: 201.4062\n",
      "Epoch [1770/10000], Train Loss: 49.2168, Val Loss: 201.3902\n",
      "Epoch [1771/10000], Train Loss: 49.2046, Val Loss: 201.3729\n",
      "Epoch [1772/10000], Train Loss: 49.1923, Val Loss: 201.3542\n",
      "Epoch [1773/10000], Train Loss: 49.1800, Val Loss: 201.3342\n",
      "Epoch [1774/10000], Train Loss: 49.1678, Val Loss: 201.3179\n",
      "Epoch [1775/10000], Train Loss: 49.1555, Val Loss: 201.2992\n",
      "Epoch [1776/10000], Train Loss: 49.1433, Val Loss: 201.2778\n",
      "Epoch [1777/10000], Train Loss: 49.1310, Val Loss: 201.2536\n",
      "Epoch [1778/10000], Train Loss: 49.1187, Val Loss: 201.2269\n",
      "Epoch [1779/10000], Train Loss: 49.1064, Val Loss: 201.2039\n",
      "Epoch [1780/10000], Train Loss: 49.0941, Val Loss: 201.1785\n",
      "Epoch [1781/10000], Train Loss: 49.0819, Val Loss: 201.1507\n",
      "Epoch [1782/10000], Train Loss: 49.0696, Val Loss: 201.1215\n",
      "Epoch [1783/10000], Train Loss: 49.0575, Val Loss: 201.0969\n",
      "Epoch [1784/10000], Train Loss: 49.0451, Val Loss: 201.0713\n",
      "Epoch [1785/10000], Train Loss: 49.0328, Val Loss: 201.0445\n",
      "Epoch [1786/10000], Train Loss: 49.0206, Val Loss: 201.0173\n",
      "Epoch [1787/10000], Train Loss: 49.0083, Val Loss: 200.9956\n",
      "Epoch [1788/10000], Train Loss: 48.9961, Val Loss: 200.9732\n",
      "Epoch [1789/10000], Train Loss: 48.9838, Val Loss: 200.9500\n",
      "Epoch [1790/10000], Train Loss: 48.9716, Val Loss: 200.9263\n",
      "Epoch [1791/10000], Train Loss: 48.9592, Val Loss: 200.9022\n",
      "Epoch [1792/10000], Train Loss: 48.9470, Val Loss: 200.8832\n",
      "Epoch [1793/10000], Train Loss: 48.9347, Val Loss: 200.8634\n",
      "Epoch [1794/10000], Train Loss: 48.9224, Val Loss: 200.8418\n",
      "Epoch [1795/10000], Train Loss: 48.9102, Val Loss: 200.8189\n",
      "Epoch [1796/10000], Train Loss: 48.8979, Val Loss: 200.7947\n",
      "Epoch [1797/10000], Train Loss: 48.8857, Val Loss: 200.7749\n",
      "Epoch [1798/10000], Train Loss: 48.8733, Val Loss: 200.7531\n",
      "Epoch [1799/10000], Train Loss: 48.8610, Val Loss: 200.7294\n",
      "Epoch [1800/10000], Train Loss: 48.8487, Val Loss: 200.7041\n",
      "Epoch [1801/10000], Train Loss: 48.8366, Val Loss: 200.6832\n",
      "Epoch [1802/10000], Train Loss: 48.8242, Val Loss: 200.6604\n",
      "Epoch [1803/10000], Train Loss: 48.8120, Val Loss: 200.6355\n",
      "Epoch [1804/10000], Train Loss: 48.7996, Val Loss: 200.6091\n",
      "Epoch [1805/10000], Train Loss: 48.7874, Val Loss: 200.5876\n",
      "Epoch [1806/10000], Train Loss: 48.7751, Val Loss: 200.5641\n",
      "Epoch [1807/10000], Train Loss: 48.7629, Val Loss: 200.5391\n",
      "Epoch [1808/10000], Train Loss: 48.7506, Val Loss: 200.5126\n",
      "Epoch [1809/10000], Train Loss: 48.7382, Val Loss: 200.4851\n",
      "Epoch [1810/10000], Train Loss: 48.7260, Val Loss: 200.4628\n",
      "Epoch [1811/10000], Train Loss: 48.7137, Val Loss: 200.4392\n",
      "Epoch [1812/10000], Train Loss: 48.7014, Val Loss: 200.4141\n",
      "Epoch [1813/10000], Train Loss: 48.6891, Val Loss: 200.3877\n",
      "Epoch [1814/10000], Train Loss: 48.6768, Val Loss: 200.3605\n",
      "Epoch [1815/10000], Train Loss: 48.6647, Val Loss: 200.3386\n",
      "Epoch [1816/10000], Train Loss: 48.6522, Val Loss: 200.3216\n",
      "Epoch [1817/10000], Train Loss: 48.6401, Val Loss: 200.3023\n",
      "Epoch [1818/10000], Train Loss: 48.6280, Val Loss: 200.2800\n",
      "Epoch [1819/10000], Train Loss: 48.6157, Val Loss: 200.2554\n",
      "Epoch [1820/10000], Train Loss: 48.6032, Val Loss: 200.2289\n",
      "Epoch [1821/10000], Train Loss: 48.5909, Val Loss: 200.2009\n",
      "Epoch [1822/10000], Train Loss: 48.5786, Val Loss: 200.1720\n",
      "Epoch [1823/10000], Train Loss: 48.5664, Val Loss: 200.1490\n",
      "Epoch [1824/10000], Train Loss: 48.5539, Val Loss: 200.1248\n",
      "Epoch [1825/10000], Train Loss: 48.5416, Val Loss: 200.0993\n",
      "Epoch [1826/10000], Train Loss: 48.5293, Val Loss: 200.0725\n",
      "Epoch [1827/10000], Train Loss: 48.5170, Val Loss: 200.0445\n",
      "Epoch [1828/10000], Train Loss: 48.5047, Val Loss: 200.0156\n",
      "Epoch [1829/10000], Train Loss: 48.4923, Val Loss: 199.9928\n",
      "Epoch [1830/10000], Train Loss: 48.4800, Val Loss: 199.9691\n",
      "Epoch [1831/10000], Train Loss: 48.4676, Val Loss: 199.9444\n",
      "Epoch [1832/10000], Train Loss: 48.4554, Val Loss: 199.9255\n",
      "Epoch [1833/10000], Train Loss: 48.4430, Val Loss: 199.9051\n",
      "Epoch [1834/10000], Train Loss: 48.4307, Val Loss: 199.8828\n",
      "Epoch [1835/10000], Train Loss: 48.4184, Val Loss: 199.8588\n",
      "Epoch [1836/10000], Train Loss: 48.4060, Val Loss: 199.8335\n",
      "Epoch [1837/10000], Train Loss: 48.3938, Val Loss: 199.8130\n",
      "Epoch [1838/10000], Train Loss: 48.3814, Val Loss: 199.7906\n",
      "Epoch [1839/10000], Train Loss: 48.3691, Val Loss: 199.7657\n",
      "Epoch [1840/10000], Train Loss: 48.3567, Val Loss: 199.7384\n",
      "Epoch [1841/10000], Train Loss: 48.3444, Val Loss: 199.7094\n",
      "Epoch [1842/10000], Train Loss: 48.3322, Val Loss: 199.6854\n",
      "Epoch [1843/10000], Train Loss: 48.3197, Val Loss: 199.6657\n",
      "Epoch [1844/10000], Train Loss: 48.3075, Val Loss: 199.6430\n",
      "Epoch [1845/10000], Train Loss: 48.2953, Val Loss: 199.6167\n",
      "Epoch [1846/10000], Train Loss: 48.2830, Val Loss: 199.5876\n",
      "Epoch [1847/10000], Train Loss: 48.2705, Val Loss: 199.5569\n",
      "Epoch [1848/10000], Train Loss: 48.2581, Val Loss: 199.5249\n",
      "Epoch [1849/10000], Train Loss: 48.2457, Val Loss: 199.4929\n",
      "Epoch [1850/10000], Train Loss: 48.2337, Val Loss: 199.4678\n",
      "Epoch [1851/10000], Train Loss: 48.2210, Val Loss: 199.4423\n",
      "Epoch [1852/10000], Train Loss: 48.2086, Val Loss: 199.4161\n",
      "Epoch [1853/10000], Train Loss: 48.1963, Val Loss: 199.3891\n",
      "Epoch [1854/10000], Train Loss: 48.1839, Val Loss: 199.3612\n",
      "Epoch [1855/10000], Train Loss: 48.1715, Val Loss: 199.3329\n",
      "Epoch [1856/10000], Train Loss: 48.1591, Val Loss: 199.3112\n",
      "Epoch [1857/10000], Train Loss: 48.1467, Val Loss: 199.2955\n",
      "Epoch [1858/10000], Train Loss: 48.1344, Val Loss: 199.2773\n",
      "Epoch [1859/10000], Train Loss: 48.1221, Val Loss: 199.2565\n",
      "Epoch [1860/10000], Train Loss: 48.1097, Val Loss: 199.2332\n",
      "Epoch [1861/10000], Train Loss: 48.0973, Val Loss: 199.2077\n",
      "Epoch [1862/10000], Train Loss: 48.0848, Val Loss: 199.1802\n",
      "Epoch [1863/10000], Train Loss: 48.0725, Val Loss: 199.1582\n",
      "Epoch [1864/10000], Train Loss: 48.0600, Val Loss: 199.1339\n",
      "Epoch [1865/10000], Train Loss: 48.0476, Val Loss: 199.1068\n",
      "Epoch [1866/10000], Train Loss: 48.0352, Val Loss: 199.0772\n",
      "Epoch [1867/10000], Train Loss: 48.0228, Val Loss: 199.0453\n",
      "Epoch [1868/10000], Train Loss: 48.0104, Val Loss: 199.0116\n",
      "Epoch [1869/10000], Train Loss: 47.9980, Val Loss: 198.9841\n",
      "Epoch [1870/10000], Train Loss: 47.9855, Val Loss: 198.9552\n",
      "Epoch [1871/10000], Train Loss: 47.9731, Val Loss: 198.9250\n",
      "Epoch [1872/10000], Train Loss: 47.9607, Val Loss: 198.9013\n",
      "Epoch [1873/10000], Train Loss: 47.9483, Val Loss: 198.8763\n",
      "Epoch [1874/10000], Train Loss: 47.9359, Val Loss: 198.8497\n",
      "Epoch [1875/10000], Train Loss: 47.9234, Val Loss: 198.8221\n",
      "Epoch [1876/10000], Train Loss: 47.9109, Val Loss: 198.7942\n",
      "Epoch [1877/10000], Train Loss: 47.8987, Val Loss: 198.7726\n",
      "Epoch [1878/10000], Train Loss: 47.8861, Val Loss: 198.7500\n",
      "Epoch [1879/10000], Train Loss: 47.8736, Val Loss: 198.7256\n",
      "Epoch [1880/10000], Train Loss: 47.8612, Val Loss: 198.6992\n",
      "Epoch [1881/10000], Train Loss: 47.8487, Val Loss: 198.6712\n",
      "Epoch [1882/10000], Train Loss: 47.8364, Val Loss: 198.6488\n",
      "Epoch [1883/10000], Train Loss: 47.8238, Val Loss: 198.6238\n",
      "Epoch [1884/10000], Train Loss: 47.8113, Val Loss: 198.5965\n",
      "Epoch [1885/10000], Train Loss: 47.7988, Val Loss: 198.5666\n",
      "Epoch [1886/10000], Train Loss: 47.7865, Val Loss: 198.5423\n",
      "Epoch [1887/10000], Train Loss: 47.7739, Val Loss: 198.5156\n",
      "Epoch [1888/10000], Train Loss: 47.7614, Val Loss: 198.4863\n",
      "Epoch [1889/10000], Train Loss: 47.7489, Val Loss: 198.4555\n",
      "Epoch [1890/10000], Train Loss: 47.7366, Val Loss: 198.4307\n",
      "Epoch [1891/10000], Train Loss: 47.7240, Val Loss: 198.4038\n",
      "Epoch [1892/10000], Train Loss: 47.7115, Val Loss: 198.3748\n",
      "Epoch [1893/10000], Train Loss: 47.6990, Val Loss: 198.3443\n",
      "Epoch [1894/10000], Train Loss: 47.6864, Val Loss: 198.3127\n",
      "Epoch [1895/10000], Train Loss: 47.6741, Val Loss: 198.2877\n",
      "Epoch [1896/10000], Train Loss: 47.6614, Val Loss: 198.2613\n",
      "Epoch [1897/10000], Train Loss: 47.6489, Val Loss: 198.2330\n",
      "Epoch [1898/10000], Train Loss: 47.6364, Val Loss: 198.2033\n",
      "Epoch [1899/10000], Train Loss: 47.6239, Val Loss: 198.1799\n",
      "Epoch [1900/10000], Train Loss: 47.6114, Val Loss: 198.1542\n",
      "Epoch [1901/10000], Train Loss: 47.5989, Val Loss: 198.1263\n",
      "Epoch [1902/10000], Train Loss: 47.5863, Val Loss: 198.0965\n",
      "Epoch [1903/10000], Train Loss: 47.5737, Val Loss: 198.0727\n",
      "Epoch [1904/10000], Train Loss: 47.5612, Val Loss: 198.0465\n",
      "Epoch [1905/10000], Train Loss: 47.5487, Val Loss: 198.0180\n",
      "Epoch [1906/10000], Train Loss: 47.5361, Val Loss: 197.9875\n",
      "Epoch [1907/10000], Train Loss: 47.5235, Val Loss: 197.9557\n",
      "Epoch [1908/10000], Train Loss: 47.5111, Val Loss: 197.9302\n",
      "Epoch [1909/10000], Train Loss: 47.4984, Val Loss: 197.9029\n",
      "Epoch [1910/10000], Train Loss: 47.4858, Val Loss: 197.8734\n",
      "Epoch [1911/10000], Train Loss: 47.4733, Val Loss: 197.8419\n",
      "Epoch [1912/10000], Train Loss: 47.4606, Val Loss: 197.8093\n",
      "Epoch [1913/10000], Train Loss: 47.4482, Val Loss: 197.7834\n",
      "Epoch [1914/10000], Train Loss: 47.4354, Val Loss: 197.7558\n",
      "Epoch [1915/10000], Train Loss: 47.4228, Val Loss: 197.7266\n",
      "Epoch [1916/10000], Train Loss: 47.4102, Val Loss: 197.6958\n",
      "Epoch [1917/10000], Train Loss: 47.3977, Val Loss: 197.6718\n",
      "Epoch [1918/10000], Train Loss: 47.3850, Val Loss: 197.6458\n",
      "Epoch [1919/10000], Train Loss: 47.3724, Val Loss: 197.6172\n",
      "Epoch [1920/10000], Train Loss: 47.3597, Val Loss: 197.5871\n",
      "Epoch [1921/10000], Train Loss: 47.3472, Val Loss: 197.5628\n",
      "Epoch [1922/10000], Train Loss: 47.3345, Val Loss: 197.5357\n",
      "Epoch [1923/10000], Train Loss: 47.3220, Val Loss: 197.5056\n",
      "Epoch [1924/10000], Train Loss: 47.3094, Val Loss: 197.4729\n",
      "Epoch [1925/10000], Train Loss: 47.2967, Val Loss: 197.4381\n",
      "Epoch [1926/10000], Train Loss: 47.2843, Val Loss: 197.4095\n",
      "Epoch [1927/10000], Train Loss: 47.2714, Val Loss: 197.3786\n",
      "Epoch [1928/10000], Train Loss: 47.2588, Val Loss: 197.3452\n",
      "Epoch [1929/10000], Train Loss: 47.2461, Val Loss: 197.3098\n",
      "Epoch [1930/10000], Train Loss: 47.2334, Val Loss: 197.2810\n",
      "Epoch [1931/10000], Train Loss: 47.2208, Val Loss: 197.2498\n",
      "Epoch [1932/10000], Train Loss: 47.2082, Val Loss: 197.2166\n",
      "Epoch [1933/10000], Train Loss: 47.1955, Val Loss: 197.1819\n",
      "Epoch [1934/10000], Train Loss: 47.1828, Val Loss: 197.1465\n",
      "Epoch [1935/10000], Train Loss: 47.1703, Val Loss: 197.1189\n",
      "Epoch [1936/10000], Train Loss: 47.1574, Val Loss: 197.0982\n",
      "Epoch [1937/10000], Train Loss: 47.1449, Val Loss: 197.0746\n",
      "Epoch [1938/10000], Train Loss: 47.1323, Val Loss: 197.0472\n",
      "Epoch [1939/10000], Train Loss: 47.1197, Val Loss: 197.0160\n",
      "Epoch [1940/10000], Train Loss: 47.1069, Val Loss: 196.9817\n",
      "Epoch [1941/10000], Train Loss: 47.0941, Val Loss: 196.9454\n",
      "Epoch [1942/10000], Train Loss: 47.0813, Val Loss: 196.9082\n",
      "Epoch [1943/10000], Train Loss: 47.0687, Val Loss: 196.8787\n",
      "Epoch [1944/10000], Train Loss: 47.0559, Val Loss: 196.8479\n",
      "Epoch [1945/10000], Train Loss: 47.0431, Val Loss: 196.8153\n",
      "Epoch [1946/10000], Train Loss: 47.0304, Val Loss: 196.7803\n",
      "Epoch [1947/10000], Train Loss: 47.0177, Val Loss: 196.7438\n",
      "Epoch [1948/10000], Train Loss: 47.0049, Val Loss: 196.7059\n",
      "Epoch [1949/10000], Train Loss: 46.9920, Val Loss: 196.6678\n",
      "Epoch [1950/10000], Train Loss: 46.9796, Val Loss: 196.6382\n",
      "Epoch [1951/10000], Train Loss: 46.9667, Val Loss: 196.6160\n",
      "Epoch [1952/10000], Train Loss: 46.9537, Val Loss: 196.5913\n",
      "Epoch [1953/10000], Train Loss: 46.9411, Val Loss: 196.5638\n",
      "Epoch [1954/10000], Train Loss: 46.9283, Val Loss: 196.5334\n",
      "Epoch [1955/10000], Train Loss: 46.9154, Val Loss: 196.5009\n",
      "Epoch [1956/10000], Train Loss: 46.9026, Val Loss: 196.4667\n",
      "Epoch [1957/10000], Train Loss: 46.8899, Val Loss: 196.4397\n",
      "Epoch [1958/10000], Train Loss: 46.8769, Val Loss: 196.4103\n",
      "Epoch [1959/10000], Train Loss: 46.8641, Val Loss: 196.3777\n",
      "Epoch [1960/10000], Train Loss: 46.8512, Val Loss: 196.3421\n",
      "Epoch [1961/10000], Train Loss: 46.8384, Val Loss: 196.3041\n",
      "Epoch [1962/10000], Train Loss: 46.8256, Val Loss: 196.2721\n",
      "Epoch [1963/10000], Train Loss: 46.8127, Val Loss: 196.2375\n",
      "Epoch [1964/10000], Train Loss: 46.7999, Val Loss: 196.1999\n",
      "Epoch [1965/10000], Train Loss: 46.7870, Val Loss: 196.1605\n",
      "Epoch [1966/10000], Train Loss: 46.7743, Val Loss: 196.1292\n",
      "Epoch [1967/10000], Train Loss: 46.7612, Val Loss: 196.1039\n",
      "Epoch [1968/10000], Train Loss: 46.7485, Val Loss: 196.0756\n",
      "Epoch [1969/10000], Train Loss: 46.7357, Val Loss: 196.0435\n",
      "Epoch [1970/10000], Train Loss: 46.7228, Val Loss: 196.0087\n",
      "Epoch [1971/10000], Train Loss: 46.7098, Val Loss: 195.9722\n",
      "Epoch [1972/10000], Train Loss: 46.6969, Val Loss: 195.9345\n",
      "Epoch [1973/10000], Train Loss: 46.6839, Val Loss: 195.8967\n",
      "Epoch [1974/10000], Train Loss: 46.6710, Val Loss: 195.8592\n",
      "Epoch [1975/10000], Train Loss: 46.6582, Val Loss: 195.8298\n",
      "Epoch [1976/10000], Train Loss: 46.6450, Val Loss: 195.7987\n",
      "Epoch [1977/10000], Train Loss: 46.6322, Val Loss: 195.7645\n",
      "Epoch [1978/10000], Train Loss: 46.6193, Val Loss: 195.7276\n",
      "Epoch [1979/10000], Train Loss: 46.6063, Val Loss: 195.6887\n",
      "Epoch [1980/10000], Train Loss: 46.5932, Val Loss: 195.6572\n",
      "Epoch [1981/10000], Train Loss: 46.5801, Val Loss: 195.6244\n",
      "Epoch [1982/10000], Train Loss: 46.5672, Val Loss: 195.5987\n",
      "Epoch [1983/10000], Train Loss: 46.5542, Val Loss: 195.5700\n",
      "Epoch [1984/10000], Train Loss: 46.5413, Val Loss: 195.5383\n",
      "Epoch [1985/10000], Train Loss: 46.5283, Val Loss: 195.5037\n",
      "Epoch [1986/10000], Train Loss: 46.5152, Val Loss: 195.4671\n",
      "Epoch [1987/10000], Train Loss: 46.5022, Val Loss: 195.4289\n",
      "Epoch [1988/10000], Train Loss: 46.4891, Val Loss: 195.3897\n",
      "Epoch [1989/10000], Train Loss: 46.4762, Val Loss: 195.3586\n",
      "Epoch [1990/10000], Train Loss: 46.4630, Val Loss: 195.3250\n",
      "Epoch [1991/10000], Train Loss: 46.4500, Val Loss: 195.2882\n",
      "Epoch [1992/10000], Train Loss: 46.4369, Val Loss: 195.2485\n",
      "Epoch [1993/10000], Train Loss: 46.4238, Val Loss: 195.2151\n",
      "Epoch [1994/10000], Train Loss: 46.4107, Val Loss: 195.1792\n",
      "Epoch [1995/10000], Train Loss: 46.3976, Val Loss: 195.1409\n",
      "Epoch [1996/10000], Train Loss: 46.3846, Val Loss: 195.1098\n",
      "Epoch [1997/10000], Train Loss: 46.3714, Val Loss: 195.0768\n",
      "Epoch [1998/10000], Train Loss: 46.3583, Val Loss: 195.0411\n",
      "Epoch [1999/10000], Train Loss: 46.3452, Val Loss: 195.0036\n",
      "Epoch [2000/10000], Train Loss: 46.3320, Val Loss: 194.9651\n",
      "Epoch [2001/10000], Train Loss: 46.3189, Val Loss: 194.9344\n",
      "Epoch [2002/10000], Train Loss: 46.3057, Val Loss: 194.9018\n",
      "Epoch [2003/10000], Train Loss: 46.2926, Val Loss: 194.8658\n",
      "Epoch [2004/10000], Train Loss: 46.2795, Val Loss: 194.8269\n",
      "Epoch [2005/10000], Train Loss: 46.2662, Val Loss: 194.7862\n",
      "Epoch [2006/10000], Train Loss: 46.2530, Val Loss: 194.7528\n",
      "Epoch [2007/10000], Train Loss: 46.2398, Val Loss: 194.7175\n",
      "Epoch [2008/10000], Train Loss: 46.2266, Val Loss: 194.6796\n",
      "Epoch [2009/10000], Train Loss: 46.2134, Val Loss: 194.6396\n",
      "Epoch [2010/10000], Train Loss: 46.2003, Val Loss: 194.6077\n",
      "Epoch [2011/10000], Train Loss: 46.1869, Val Loss: 194.5734\n",
      "Epoch [2012/10000], Train Loss: 46.1737, Val Loss: 194.5365\n",
      "Epoch [2013/10000], Train Loss: 46.1605, Val Loss: 194.4973\n",
      "Epoch [2014/10000], Train Loss: 46.1472, Val Loss: 194.4563\n",
      "Epoch [2015/10000], Train Loss: 46.1340, Val Loss: 194.4236\n",
      "Epoch [2016/10000], Train Loss: 46.1206, Val Loss: 194.3889\n",
      "Epoch [2017/10000], Train Loss: 46.1073, Val Loss: 194.3520\n",
      "Epoch [2018/10000], Train Loss: 46.0941, Val Loss: 194.3129\n",
      "Epoch [2019/10000], Train Loss: 46.0808, Val Loss: 194.2807\n",
      "Epoch [2020/10000], Train Loss: 46.0675, Val Loss: 194.2452\n",
      "Epoch [2021/10000], Train Loss: 46.0542, Val Loss: 194.2069\n",
      "Epoch [2022/10000], Train Loss: 46.0408, Val Loss: 194.1658\n",
      "Epoch [2023/10000], Train Loss: 46.0274, Val Loss: 194.1324\n",
      "Epoch [2024/10000], Train Loss: 46.0141, Val Loss: 194.0961\n",
      "Epoch [2025/10000], Train Loss: 46.0007, Val Loss: 194.0567\n",
      "Epoch [2026/10000], Train Loss: 45.9874, Val Loss: 194.0153\n",
      "Epoch [2027/10000], Train Loss: 45.9740, Val Loss: 193.9719\n",
      "Epoch [2028/10000], Train Loss: 45.9607, Val Loss: 193.9364\n",
      "Epoch [2029/10000], Train Loss: 45.9471, Val Loss: 193.8993\n",
      "Epoch [2030/10000], Train Loss: 45.9338, Val Loss: 193.8596\n",
      "Epoch [2031/10000], Train Loss: 45.9203, Val Loss: 193.8183\n",
      "Epoch [2032/10000], Train Loss: 45.9068, Val Loss: 193.7752\n",
      "Epoch [2033/10000], Train Loss: 45.8935, Val Loss: 193.7403\n",
      "Epoch [2034/10000], Train Loss: 45.8799, Val Loss: 193.7131\n",
      "Epoch [2035/10000], Train Loss: 45.8666, Val Loss: 193.6817\n",
      "Epoch [2036/10000], Train Loss: 45.8533, Val Loss: 193.6456\n",
      "Epoch [2037/10000], Train Loss: 45.8398, Val Loss: 193.6053\n",
      "Epoch [2038/10000], Train Loss: 45.8262, Val Loss: 193.5618\n",
      "Epoch [2039/10000], Train Loss: 45.8126, Val Loss: 193.5171\n",
      "Epoch [2040/10000], Train Loss: 45.7991, Val Loss: 193.4722\n",
      "Epoch [2041/10000], Train Loss: 45.7858, Val Loss: 193.4361\n",
      "Epoch [2042/10000], Train Loss: 45.7720, Val Loss: 193.3986\n",
      "Epoch [2043/10000], Train Loss: 45.7585, Val Loss: 193.3580\n",
      "Epoch [2044/10000], Train Loss: 45.7450, Val Loss: 193.3149\n",
      "Epoch [2045/10000], Train Loss: 45.7314, Val Loss: 193.2694\n",
      "Epoch [2046/10000], Train Loss: 45.7177, Val Loss: 193.2220\n",
      "Epoch [2047/10000], Train Loss: 45.7042, Val Loss: 193.1842\n",
      "Epoch [2048/10000], Train Loss: 45.6905, Val Loss: 193.1548\n",
      "Epoch [2049/10000], Train Loss: 45.6769, Val Loss: 193.1226\n",
      "Epoch [2050/10000], Train Loss: 45.6634, Val Loss: 193.0872\n",
      "Epoch [2051/10000], Train Loss: 45.6497, Val Loss: 193.0482\n",
      "Epoch [2052/10000], Train Loss: 45.6360, Val Loss: 193.0066\n",
      "Epoch [2053/10000], Train Loss: 45.6224, Val Loss: 192.9632\n",
      "Epoch [2054/10000], Train Loss: 45.6087, Val Loss: 192.9193\n",
      "Epoch [2055/10000], Train Loss: 45.5951, Val Loss: 192.8842\n",
      "Epoch [2056/10000], Train Loss: 45.5812, Val Loss: 192.8467\n",
      "Epoch [2057/10000], Train Loss: 45.5675, Val Loss: 192.8057\n",
      "Epoch [2058/10000], Train Loss: 45.5539, Val Loss: 192.7612\n",
      "Epoch [2059/10000], Train Loss: 45.5401, Val Loss: 192.7136\n",
      "Epoch [2060/10000], Train Loss: 45.5264, Val Loss: 192.6734\n",
      "Epoch [2061/10000], Train Loss: 45.5126, Val Loss: 192.6403\n",
      "Epoch [2062/10000], Train Loss: 45.4989, Val Loss: 192.6028\n",
      "Epoch [2063/10000], Train Loss: 45.4852, Val Loss: 192.5616\n",
      "Epoch [2064/10000], Train Loss: 45.4714, Val Loss: 192.5173\n",
      "Epoch [2065/10000], Train Loss: 45.4575, Val Loss: 192.4713\n",
      "Epoch [2066/10000], Train Loss: 45.4437, Val Loss: 192.4249\n",
      "Epoch [2067/10000], Train Loss: 45.4299, Val Loss: 192.3878\n",
      "Epoch [2068/10000], Train Loss: 45.4160, Val Loss: 192.3490\n",
      "Epoch [2069/10000], Train Loss: 45.4022, Val Loss: 192.3072\n",
      "Epoch [2070/10000], Train Loss: 45.3883, Val Loss: 192.2627\n",
      "Epoch [2071/10000], Train Loss: 45.3745, Val Loss: 192.2158\n",
      "Epoch [2072/10000], Train Loss: 45.3605, Val Loss: 192.1671\n",
      "Epoch [2073/10000], Train Loss: 45.3466, Val Loss: 192.1271\n",
      "Epoch [2074/10000], Train Loss: 45.3326, Val Loss: 192.0858\n",
      "Epoch [2075/10000], Train Loss: 45.3187, Val Loss: 192.0429\n",
      "Epoch [2076/10000], Train Loss: 45.3048, Val Loss: 192.0087\n",
      "Epoch [2077/10000], Train Loss: 45.2909, Val Loss: 191.9713\n",
      "Epoch [2078/10000], Train Loss: 45.2769, Val Loss: 191.9300\n",
      "Epoch [2079/10000], Train Loss: 45.2630, Val Loss: 191.8860\n",
      "Epoch [2080/10000], Train Loss: 45.2489, Val Loss: 191.8398\n",
      "Epoch [2081/10000], Train Loss: 45.2349, Val Loss: 191.7929\n",
      "Epoch [2082/10000], Train Loss: 45.2211, Val Loss: 191.7552\n",
      "Epoch [2083/10000], Train Loss: 45.2069, Val Loss: 191.7249\n",
      "Epoch [2084/10000], Train Loss: 45.1929, Val Loss: 191.6892\n",
      "Epoch [2085/10000], Train Loss: 45.1791, Val Loss: 191.6470\n",
      "Epoch [2086/10000], Train Loss: 45.1650, Val Loss: 191.5990\n",
      "Epoch [2087/10000], Train Loss: 45.1508, Val Loss: 191.5467\n",
      "Epoch [2088/10000], Train Loss: 45.1366, Val Loss: 191.4927\n",
      "Epoch [2089/10000], Train Loss: 45.1225, Val Loss: 191.4391\n",
      "Epoch [2090/10000], Train Loss: 45.1087, Val Loss: 191.3962\n",
      "Epoch [2091/10000], Train Loss: 45.0942, Val Loss: 191.3626\n",
      "Epoch [2092/10000], Train Loss: 45.0801, Val Loss: 191.3248\n",
      "Epoch [2093/10000], Train Loss: 45.0662, Val Loss: 191.2812\n",
      "Epoch [2094/10000], Train Loss: 45.0522, Val Loss: 191.2325\n",
      "Epoch [2095/10000], Train Loss: 45.0378, Val Loss: 191.1803\n",
      "Epoch [2096/10000], Train Loss: 45.0234, Val Loss: 191.1273\n",
      "Epoch [2097/10000], Train Loss: 45.0092, Val Loss: 191.0757\n",
      "Epoch [2098/10000], Train Loss: 44.9951, Val Loss: 191.0357\n",
      "Epoch [2099/10000], Train Loss: 44.9807, Val Loss: 190.9962\n",
      "Epoch [2100/10000], Train Loss: 44.9664, Val Loss: 190.9550\n",
      "Epoch [2101/10000], Train Loss: 44.9521, Val Loss: 190.9120\n",
      "Epoch [2102/10000], Train Loss: 44.9379, Val Loss: 190.8659\n",
      "Epoch [2103/10000], Train Loss: 44.9235, Val Loss: 190.8169\n",
      "Epoch [2104/10000], Train Loss: 44.9091, Val Loss: 190.7668\n",
      "Epoch [2105/10000], Train Loss: 44.8948, Val Loss: 190.7255\n",
      "Epoch [2106/10000], Train Loss: 44.8805, Val Loss: 190.6931\n",
      "Epoch [2107/10000], Train Loss: 44.8661, Val Loss: 190.6561\n",
      "Epoch [2108/10000], Train Loss: 44.8518, Val Loss: 190.6145\n",
      "Epoch [2109/10000], Train Loss: 44.8374, Val Loss: 190.5685\n",
      "Epoch [2110/10000], Train Loss: 44.8229, Val Loss: 190.5187\n",
      "Epoch [2111/10000], Train Loss: 44.8085, Val Loss: 190.4667\n",
      "Epoch [2112/10000], Train Loss: 44.7941, Val Loss: 190.4230\n",
      "Epoch [2113/10000], Train Loss: 44.7796, Val Loss: 190.3769\n",
      "Epoch [2114/10000], Train Loss: 44.7651, Val Loss: 190.3276\n",
      "Epoch [2115/10000], Train Loss: 44.7507, Val Loss: 190.2754\n",
      "Epoch [2116/10000], Train Loss: 44.7361, Val Loss: 190.2206\n",
      "Epoch [2117/10000], Train Loss: 44.7216, Val Loss: 190.1742\n",
      "Epoch [2118/10000], Train Loss: 44.7071, Val Loss: 190.1254\n",
      "Epoch [2119/10000], Train Loss: 44.6925, Val Loss: 190.0745\n",
      "Epoch [2120/10000], Train Loss: 44.6779, Val Loss: 190.0228\n",
      "Epoch [2121/10000], Train Loss: 44.6635, Val Loss: 189.9805\n",
      "Epoch [2122/10000], Train Loss: 44.6488, Val Loss: 189.9366\n",
      "Epoch [2123/10000], Train Loss: 44.6342, Val Loss: 189.8909\n",
      "Epoch [2124/10000], Train Loss: 44.6196, Val Loss: 189.8437\n",
      "Epoch [2125/10000], Train Loss: 44.6049, Val Loss: 189.8050\n",
      "Epoch [2126/10000], Train Loss: 44.5903, Val Loss: 189.7628\n",
      "Epoch [2127/10000], Train Loss: 44.5757, Val Loss: 189.7163\n",
      "Epoch [2128/10000], Train Loss: 44.5610, Val Loss: 189.6665\n",
      "Epoch [2129/10000], Train Loss: 44.5462, Val Loss: 189.6136\n",
      "Epoch [2130/10000], Train Loss: 44.5316, Val Loss: 189.5694\n",
      "Epoch [2131/10000], Train Loss: 44.5168, Val Loss: 189.5221\n",
      "Epoch [2132/10000], Train Loss: 44.5020, Val Loss: 189.4713\n",
      "Epoch [2133/10000], Train Loss: 44.4872, Val Loss: 189.4180\n",
      "Epoch [2134/10000], Train Loss: 44.4725, Val Loss: 189.3719\n",
      "Epoch [2135/10000], Train Loss: 44.4578, Val Loss: 189.3223\n",
      "Epoch [2136/10000], Train Loss: 44.4430, Val Loss: 189.2691\n",
      "Epoch [2137/10000], Train Loss: 44.4281, Val Loss: 189.2135\n",
      "Epoch [2138/10000], Train Loss: 44.4132, Val Loss: 189.1669\n",
      "Epoch [2139/10000], Train Loss: 44.3984, Val Loss: 189.1180\n",
      "Epoch [2140/10000], Train Loss: 44.3835, Val Loss: 189.0670\n",
      "Epoch [2141/10000], Train Loss: 44.3686, Val Loss: 189.0145\n",
      "Epoch [2142/10000], Train Loss: 44.3537, Val Loss: 188.9610\n",
      "Epoch [2143/10000], Train Loss: 44.3388, Val Loss: 188.9167\n",
      "Epoch [2144/10000], Train Loss: 44.3238, Val Loss: 188.8699\n",
      "Epoch [2145/10000], Train Loss: 44.3088, Val Loss: 188.8198\n",
      "Epoch [2146/10000], Train Loss: 44.2939, Val Loss: 188.7672\n",
      "Epoch [2147/10000], Train Loss: 44.2788, Val Loss: 188.7127\n",
      "Epoch [2148/10000], Train Loss: 44.2639, Val Loss: 188.6671\n",
      "Epoch [2149/10000], Train Loss: 44.2488, Val Loss: 188.6290\n",
      "Epoch [2150/10000], Train Loss: 44.2338, Val Loss: 188.5851\n",
      "Epoch [2151/10000], Train Loss: 44.2189, Val Loss: 188.5356\n",
      "Epoch [2152/10000], Train Loss: 44.2038, Val Loss: 188.4812\n",
      "Epoch [2153/10000], Train Loss: 44.1886, Val Loss: 188.4236\n",
      "Epoch [2154/10000], Train Loss: 44.1734, Val Loss: 188.3640\n",
      "Epoch [2155/10000], Train Loss: 44.1583, Val Loss: 188.3040\n",
      "Epoch [2156/10000], Train Loss: 44.1432, Val Loss: 188.2547\n",
      "Epoch [2157/10000], Train Loss: 44.1279, Val Loss: 188.2035\n",
      "Epoch [2158/10000], Train Loss: 44.1128, Val Loss: 188.1496\n",
      "Epoch [2159/10000], Train Loss: 44.0976, Val Loss: 188.0933\n",
      "Epoch [2160/10000], Train Loss: 44.0823, Val Loss: 188.0345\n",
      "Epoch [2161/10000], Train Loss: 44.0670, Val Loss: 187.9753\n",
      "Epoch [2162/10000], Train Loss: 44.0519, Val Loss: 187.9267\n",
      "Epoch [2163/10000], Train Loss: 44.0366, Val Loss: 187.8879\n",
      "Epoch [2164/10000], Train Loss: 44.0212, Val Loss: 187.8456\n",
      "Epoch [2165/10000], Train Loss: 44.0059, Val Loss: 187.7988\n",
      "Epoch [2166/10000], Train Loss: 43.9906, Val Loss: 187.7477\n",
      "Epoch [2167/10000], Train Loss: 43.9752, Val Loss: 187.6930\n",
      "Epoch [2168/10000], Train Loss: 43.9598, Val Loss: 187.6362\n",
      "Epoch [2169/10000], Train Loss: 43.9443, Val Loss: 187.5780\n",
      "Epoch [2170/10000], Train Loss: 43.9291, Val Loss: 187.5288\n",
      "Epoch [2171/10000], Train Loss: 43.9134, Val Loss: 187.4766\n",
      "Epoch [2172/10000], Train Loss: 43.8980, Val Loss: 187.4200\n",
      "Epoch [2173/10000], Train Loss: 43.8826, Val Loss: 187.3603\n",
      "Epoch [2174/10000], Train Loss: 43.8671, Val Loss: 187.2974\n",
      "Epoch [2175/10000], Train Loss: 43.8516, Val Loss: 187.2437\n",
      "Epoch [2176/10000], Train Loss: 43.8360, Val Loss: 187.1981\n",
      "Epoch [2177/10000], Train Loss: 43.8205, Val Loss: 187.1483\n",
      "Epoch [2178/10000], Train Loss: 43.8050, Val Loss: 187.0948\n",
      "Epoch [2179/10000], Train Loss: 43.7893, Val Loss: 187.0378\n",
      "Epoch [2180/10000], Train Loss: 43.7737, Val Loss: 186.9789\n",
      "Epoch [2181/10000], Train Loss: 43.7581, Val Loss: 186.9191\n",
      "Epoch [2182/10000], Train Loss: 43.7424, Val Loss: 186.8694\n",
      "Epoch [2183/10000], Train Loss: 43.7267, Val Loss: 186.8176\n",
      "Epoch [2184/10000], Train Loss: 43.7111, Val Loss: 186.7624\n",
      "Epoch [2185/10000], Train Loss: 43.6954, Val Loss: 186.7039\n",
      "Epoch [2186/10000], Train Loss: 43.6796, Val Loss: 186.6420\n",
      "Epoch [2187/10000], Train Loss: 43.6638, Val Loss: 186.5785\n",
      "Epoch [2188/10000], Train Loss: 43.6481, Val Loss: 186.5245\n",
      "Epoch [2189/10000], Train Loss: 43.6323, Val Loss: 186.4794\n",
      "Epoch [2190/10000], Train Loss: 43.6165, Val Loss: 186.4299\n",
      "Epoch [2191/10000], Train Loss: 43.6008, Val Loss: 186.3754\n",
      "Epoch [2192/10000], Train Loss: 43.5849, Val Loss: 186.3168\n",
      "Epoch [2193/10000], Train Loss: 43.5690, Val Loss: 186.2551\n",
      "Epoch [2194/10000], Train Loss: 43.5531, Val Loss: 186.1925\n",
      "Epoch [2195/10000], Train Loss: 43.5372, Val Loss: 186.1295\n",
      "Epoch [2196/10000], Train Loss: 43.5212, Val Loss: 186.0776\n",
      "Epoch [2197/10000], Train Loss: 43.5052, Val Loss: 186.0234\n",
      "Epoch [2198/10000], Train Loss: 43.4892, Val Loss: 185.9657\n",
      "Epoch [2199/10000], Train Loss: 43.4733, Val Loss: 185.9048\n",
      "Epoch [2200/10000], Train Loss: 43.4572, Val Loss: 185.8403\n",
      "Epoch [2201/10000], Train Loss: 43.4411, Val Loss: 185.7749\n",
      "Epoch [2202/10000], Train Loss: 43.4252, Val Loss: 185.7198\n",
      "Epoch [2203/10000], Train Loss: 43.4091, Val Loss: 185.6744\n",
      "Epoch [2204/10000], Train Loss: 43.3929, Val Loss: 185.6251\n",
      "Epoch [2205/10000], Train Loss: 43.3768, Val Loss: 185.5707\n",
      "Epoch [2206/10000], Train Loss: 43.3607, Val Loss: 185.5119\n",
      "Epoch [2207/10000], Train Loss: 43.3445, Val Loss: 185.4490\n",
      "Epoch [2208/10000], Train Loss: 43.3282, Val Loss: 185.3844\n",
      "Epoch [2209/10000], Train Loss: 43.3121, Val Loss: 185.3288\n",
      "Epoch [2210/10000], Train Loss: 43.2958, Val Loss: 185.2713\n",
      "Epoch [2211/10000], Train Loss: 43.2795, Val Loss: 185.2101\n",
      "Epoch [2212/10000], Train Loss: 43.2632, Val Loss: 185.1459\n",
      "Epoch [2213/10000], Train Loss: 43.2469, Val Loss: 185.0785\n",
      "Epoch [2214/10000], Train Loss: 43.2305, Val Loss: 185.0202\n",
      "Epoch [2215/10000], Train Loss: 43.2142, Val Loss: 184.9589\n",
      "Epoch [2216/10000], Train Loss: 43.1978, Val Loss: 184.8951\n",
      "Epoch [2217/10000], Train Loss: 43.1814, Val Loss: 184.8305\n",
      "Epoch [2218/10000], Train Loss: 43.1651, Val Loss: 184.7750\n",
      "Epoch [2219/10000], Train Loss: 43.1485, Val Loss: 184.7183\n",
      "Epoch [2220/10000], Train Loss: 43.1321, Val Loss: 184.6582\n",
      "Epoch [2221/10000], Train Loss: 43.1156, Val Loss: 184.5969\n",
      "Epoch [2222/10000], Train Loss: 43.0991, Val Loss: 184.5333\n",
      "Epoch [2223/10000], Train Loss: 43.0826, Val Loss: 184.4793\n",
      "Epoch [2224/10000], Train Loss: 43.0660, Val Loss: 184.4218\n",
      "Epoch [2225/10000], Train Loss: 43.0494, Val Loss: 184.3601\n",
      "Epoch [2226/10000], Train Loss: 43.0328, Val Loss: 184.2957\n",
      "Epoch [2227/10000], Train Loss: 43.0162, Val Loss: 184.2387\n",
      "Epoch [2228/10000], Train Loss: 42.9995, Val Loss: 184.1783\n",
      "Epoch [2229/10000], Train Loss: 42.9828, Val Loss: 184.1127\n",
      "Epoch [2230/10000], Train Loss: 42.9661, Val Loss: 184.0451\n",
      "Epoch [2231/10000], Train Loss: 42.9495, Val Loss: 183.9852\n",
      "Epoch [2232/10000], Train Loss: 42.9327, Val Loss: 183.9231\n",
      "Epoch [2233/10000], Train Loss: 42.9159, Val Loss: 183.8566\n",
      "Epoch [2234/10000], Train Loss: 42.8991, Val Loss: 183.7882\n",
      "Epoch [2235/10000], Train Loss: 42.8822, Val Loss: 183.7280\n",
      "Epoch [2236/10000], Train Loss: 42.8654, Val Loss: 183.6652\n",
      "Epoch [2237/10000], Train Loss: 42.8486, Val Loss: 183.5992\n",
      "Epoch [2238/10000], Train Loss: 42.8317, Val Loss: 183.5310\n",
      "Epoch [2239/10000], Train Loss: 42.8148, Val Loss: 183.4614\n",
      "Epoch [2240/10000], Train Loss: 42.7979, Val Loss: 183.4018\n",
      "Epoch [2241/10000], Train Loss: 42.7808, Val Loss: 183.3401\n",
      "Epoch [2242/10000], Train Loss: 42.7638, Val Loss: 183.2756\n",
      "Epoch [2243/10000], Train Loss: 42.7468, Val Loss: 183.2092\n",
      "Epoch [2244/10000], Train Loss: 42.7298, Val Loss: 183.1406\n",
      "Epoch [2245/10000], Train Loss: 42.7128, Val Loss: 183.0818\n",
      "Epoch [2246/10000], Train Loss: 42.6956, Val Loss: 183.0194\n",
      "Epoch [2247/10000], Train Loss: 42.6785, Val Loss: 182.9542\n",
      "Epoch [2248/10000], Train Loss: 42.6613, Val Loss: 182.8862\n",
      "Epoch [2249/10000], Train Loss: 42.6442, Val Loss: 182.8266\n",
      "Epoch [2250/10000], Train Loss: 42.6269, Val Loss: 182.7634\n",
      "Epoch [2251/10000], Train Loss: 42.6098, Val Loss: 182.6962\n",
      "Epoch [2252/10000], Train Loss: 42.5925, Val Loss: 182.6267\n",
      "Epoch [2253/10000], Train Loss: 42.5753, Val Loss: 182.5646\n",
      "Epoch [2254/10000], Train Loss: 42.5579, Val Loss: 182.4999\n",
      "Epoch [2255/10000], Train Loss: 42.5406, Val Loss: 182.4301\n",
      "Epoch [2256/10000], Train Loss: 42.5233, Val Loss: 182.3586\n",
      "Epoch [2257/10000], Train Loss: 42.5059, Val Loss: 182.2939\n",
      "Epoch [2258/10000], Train Loss: 42.4885, Val Loss: 182.2271\n",
      "Epoch [2259/10000], Train Loss: 42.4711, Val Loss: 182.1555\n",
      "Epoch [2260/10000], Train Loss: 42.4536, Val Loss: 182.0827\n",
      "Epoch [2261/10000], Train Loss: 42.4361, Val Loss: 182.0067\n",
      "Epoch [2262/10000], Train Loss: 42.4187, Val Loss: 181.9425\n",
      "Epoch [2263/10000], Train Loss: 42.4011, Val Loss: 181.8750\n",
      "Epoch [2264/10000], Train Loss: 42.3835, Val Loss: 181.8064\n",
      "Epoch [2265/10000], Train Loss: 42.3659, Val Loss: 181.7349\n",
      "Epoch [2266/10000], Train Loss: 42.3482, Val Loss: 181.6627\n",
      "Epoch [2267/10000], Train Loss: 42.3307, Val Loss: 181.5997\n",
      "Epoch [2268/10000], Train Loss: 42.3129, Val Loss: 181.5349\n",
      "Epoch [2269/10000], Train Loss: 42.2952, Val Loss: 181.4669\n",
      "Epoch [2270/10000], Train Loss: 42.2775, Val Loss: 181.3967\n",
      "Epoch [2271/10000], Train Loss: 42.2598, Val Loss: 181.3346\n",
      "Epoch [2272/10000], Train Loss: 42.2419, Val Loss: 181.2686\n",
      "Epoch [2273/10000], Train Loss: 42.2241, Val Loss: 181.1982\n",
      "Epoch [2274/10000], Train Loss: 42.2063, Val Loss: 181.1248\n",
      "Epoch [2275/10000], Train Loss: 42.1885, Val Loss: 181.0587\n",
      "Epoch [2276/10000], Train Loss: 42.1705, Val Loss: 180.9893\n",
      "Epoch [2277/10000], Train Loss: 42.1526, Val Loss: 180.9148\n",
      "Epoch [2278/10000], Train Loss: 42.1347, Val Loss: 180.8380\n",
      "Epoch [2279/10000], Train Loss: 42.1167, Val Loss: 180.7684\n",
      "Epoch [2280/10000], Train Loss: 42.0987, Val Loss: 180.6967\n",
      "Epoch [2281/10000], Train Loss: 42.0807, Val Loss: 180.6199\n",
      "Epoch [2282/10000], Train Loss: 42.0626, Val Loss: 180.5428\n",
      "Epoch [2283/10000], Train Loss: 42.0444, Val Loss: 180.4619\n",
      "Epoch [2284/10000], Train Loss: 42.0264, Val Loss: 180.3943\n",
      "Epoch [2285/10000], Train Loss: 42.0082, Val Loss: 180.3220\n",
      "Epoch [2286/10000], Train Loss: 41.9900, Val Loss: 180.2511\n",
      "Epoch [2287/10000], Train Loss: 41.9718, Val Loss: 180.1744\n",
      "Epoch [2288/10000], Train Loss: 41.9535, Val Loss: 180.1003\n",
      "Epoch [2289/10000], Train Loss: 41.9354, Val Loss: 180.0315\n",
      "Epoch [2290/10000], Train Loss: 41.9170, Val Loss: 179.9652\n",
      "Epoch [2291/10000], Train Loss: 41.8987, Val Loss: 179.8900\n",
      "Epoch [2292/10000], Train Loss: 41.8804, Val Loss: 179.8190\n",
      "Epoch [2293/10000], Train Loss: 41.8621, Val Loss: 179.7489\n",
      "Epoch [2294/10000], Train Loss: 41.8437, Val Loss: 179.6832\n",
      "Epoch [2295/10000], Train Loss: 41.8254, Val Loss: 179.6035\n",
      "Epoch [2296/10000], Train Loss: 41.8070, Val Loss: 179.5307\n",
      "Epoch [2297/10000], Train Loss: 41.7886, Val Loss: 179.4543\n",
      "Epoch [2298/10000], Train Loss: 41.7701, Val Loss: 179.3860\n",
      "Epoch [2299/10000], Train Loss: 41.7516, Val Loss: 179.3011\n",
      "Epoch [2300/10000], Train Loss: 41.7330, Val Loss: 179.2254\n",
      "Epoch [2301/10000], Train Loss: 41.7143, Val Loss: 179.1459\n",
      "Epoch [2302/10000], Train Loss: 41.6955, Val Loss: 179.0734\n",
      "Epoch [2303/10000], Train Loss: 41.6766, Val Loss: 178.9892\n",
      "Epoch [2304/10000], Train Loss: 41.6577, Val Loss: 178.9091\n",
      "Epoch [2305/10000], Train Loss: 41.6388, Val Loss: 178.8246\n",
      "Epoch [2306/10000], Train Loss: 41.6200, Val Loss: 178.7514\n",
      "Epoch [2307/10000], Train Loss: 41.6011, Val Loss: 178.6781\n",
      "Epoch [2308/10000], Train Loss: 41.5823, Val Loss: 178.5988\n",
      "Epoch [2309/10000], Train Loss: 41.5635, Val Loss: 178.5231\n",
      "Epoch [2310/10000], Train Loss: 41.5447, Val Loss: 178.4496\n",
      "Epoch [2311/10000], Train Loss: 41.5258, Val Loss: 178.3797\n",
      "Epoch [2312/10000], Train Loss: 41.5068, Val Loss: 178.2991\n",
      "Epoch [2313/10000], Train Loss: 41.4877, Val Loss: 178.2216\n",
      "Epoch [2314/10000], Train Loss: 41.4686, Val Loss: 178.1474\n",
      "Epoch [2315/10000], Train Loss: 41.4494, Val Loss: 178.0730\n",
      "Epoch [2316/10000], Train Loss: 41.4303, Val Loss: 177.9930\n",
      "Epoch [2317/10000], Train Loss: 41.4111, Val Loss: 177.9093\n",
      "Epoch [2318/10000], Train Loss: 41.3919, Val Loss: 177.8243\n",
      "Epoch [2319/10000], Train Loss: 41.3728, Val Loss: 177.7454\n",
      "Epoch [2320/10000], Train Loss: 41.3535, Val Loss: 177.6669\n",
      "Epoch [2321/10000], Train Loss: 41.3343, Val Loss: 177.5810\n",
      "Epoch [2322/10000], Train Loss: 41.3150, Val Loss: 177.4975\n",
      "Epoch [2323/10000], Train Loss: 41.2956, Val Loss: 177.4189\n",
      "Epoch [2324/10000], Train Loss: 41.2762, Val Loss: 177.3413\n",
      "Epoch [2325/10000], Train Loss: 41.2568, Val Loss: 177.2580\n",
      "Epoch [2326/10000], Train Loss: 41.2373, Val Loss: 177.1748\n",
      "Epoch [2327/10000], Train Loss: 41.2178, Val Loss: 177.0993\n",
      "Epoch [2328/10000], Train Loss: 41.1983, Val Loss: 177.0215\n",
      "Epoch [2329/10000], Train Loss: 41.1788, Val Loss: 176.9408\n",
      "Epoch [2330/10000], Train Loss: 41.1592, Val Loss: 176.8561\n",
      "Epoch [2331/10000], Train Loss: 41.1396, Val Loss: 176.7704\n",
      "Epoch [2332/10000], Train Loss: 41.1199, Val Loss: 176.6912\n",
      "Epoch [2333/10000], Train Loss: 41.1002, Val Loss: 176.6111\n",
      "Epoch [2334/10000], Train Loss: 41.0805, Val Loss: 176.5251\n",
      "Epoch [2335/10000], Train Loss: 41.0608, Val Loss: 176.4389\n",
      "Epoch [2336/10000], Train Loss: 41.0410, Val Loss: 176.3488\n",
      "Epoch [2337/10000], Train Loss: 41.0213, Val Loss: 176.2701\n",
      "Epoch [2338/10000], Train Loss: 41.0013, Val Loss: 176.1977\n",
      "Epoch [2339/10000], Train Loss: 40.9815, Val Loss: 176.1210\n",
      "Epoch [2340/10000], Train Loss: 40.9617, Val Loss: 176.0382\n",
      "Epoch [2341/10000], Train Loss: 40.9417, Val Loss: 175.9509\n",
      "Epoch [2342/10000], Train Loss: 40.9216, Val Loss: 175.8602\n",
      "Epoch [2343/10000], Train Loss: 40.9016, Val Loss: 175.7672\n",
      "Epoch [2344/10000], Train Loss: 40.8815, Val Loss: 175.6843\n",
      "Epoch [2345/10000], Train Loss: 40.8613, Val Loss: 175.5985\n",
      "Epoch [2346/10000], Train Loss: 40.8412, Val Loss: 175.5110\n",
      "Epoch [2347/10000], Train Loss: 40.8210, Val Loss: 175.4193\n",
      "Epoch [2348/10000], Train Loss: 40.8008, Val Loss: 175.3263\n",
      "Epoch [2349/10000], Train Loss: 40.7805, Val Loss: 175.2312\n",
      "Epoch [2350/10000], Train Loss: 40.7602, Val Loss: 175.1477\n",
      "Epoch [2351/10000], Train Loss: 40.7399, Val Loss: 175.0626\n",
      "Epoch [2352/10000], Train Loss: 40.7195, Val Loss: 174.9770\n",
      "Epoch [2353/10000], Train Loss: 40.6991, Val Loss: 174.9007\n",
      "Epoch [2354/10000], Train Loss: 40.6787, Val Loss: 174.8212\n",
      "Epoch [2355/10000], Train Loss: 40.6583, Val Loss: 174.7377\n",
      "Epoch [2356/10000], Train Loss: 40.6378, Val Loss: 174.6502\n",
      "Epoch [2357/10000], Train Loss: 40.6172, Val Loss: 174.5599\n",
      "Epoch [2358/10000], Train Loss: 40.5966, Val Loss: 174.4772\n",
      "Epoch [2359/10000], Train Loss: 40.5760, Val Loss: 174.3905\n",
      "Epoch [2360/10000], Train Loss: 40.5554, Val Loss: 174.2990\n",
      "Epoch [2361/10000], Train Loss: 40.5347, Val Loss: 174.2041\n",
      "Epoch [2362/10000], Train Loss: 40.5139, Val Loss: 174.1056\n",
      "Epoch [2363/10000], Train Loss: 40.4932, Val Loss: 174.0161\n",
      "Epoch [2364/10000], Train Loss: 40.4723, Val Loss: 173.9329\n",
      "Epoch [2365/10000], Train Loss: 40.4516, Val Loss: 173.8459\n",
      "Epoch [2366/10000], Train Loss: 40.4308, Val Loss: 173.7533\n",
      "Epoch [2367/10000], Train Loss: 40.4098, Val Loss: 173.6583\n",
      "Epoch [2368/10000], Train Loss: 40.3888, Val Loss: 173.5602\n",
      "Epoch [2369/10000], Train Loss: 40.3678, Val Loss: 173.4627\n",
      "Epoch [2370/10000], Train Loss: 40.3468, Val Loss: 173.3744\n",
      "Epoch [2371/10000], Train Loss: 40.3257, Val Loss: 173.2861\n",
      "Epoch [2372/10000], Train Loss: 40.3045, Val Loss: 173.1939\n",
      "Epoch [2373/10000], Train Loss: 40.2834, Val Loss: 173.1005\n",
      "Epoch [2374/10000], Train Loss: 40.2622, Val Loss: 173.0027\n",
      "Epoch [2375/10000], Train Loss: 40.2409, Val Loss: 172.9052\n",
      "Epoch [2376/10000], Train Loss: 40.2196, Val Loss: 172.8151\n",
      "Epoch [2377/10000], Train Loss: 40.1983, Val Loss: 172.7358\n",
      "Epoch [2378/10000], Train Loss: 40.1770, Val Loss: 172.6495\n",
      "Epoch [2379/10000], Train Loss: 40.1557, Val Loss: 172.5614\n",
      "Epoch [2380/10000], Train Loss: 40.1342, Val Loss: 172.4650\n",
      "Epoch [2381/10000], Train Loss: 40.1128, Val Loss: 172.3688\n",
      "Epoch [2382/10000], Train Loss: 40.0912, Val Loss: 172.2657\n",
      "Epoch [2383/10000], Train Loss: 40.0697, Val Loss: 172.1659\n",
      "Epoch [2384/10000], Train Loss: 40.0481, Val Loss: 172.0697\n",
      "Epoch [2385/10000], Train Loss: 40.0264, Val Loss: 171.9769\n",
      "Epoch [2386/10000], Train Loss: 40.0047, Val Loss: 171.8744\n",
      "Epoch [2387/10000], Train Loss: 39.9830, Val Loss: 171.7771\n",
      "Epoch [2388/10000], Train Loss: 39.9611, Val Loss: 171.6694\n",
      "Epoch [2389/10000], Train Loss: 39.9393, Val Loss: 171.5806\n",
      "Epoch [2390/10000], Train Loss: 39.9174, Val Loss: 171.4899\n",
      "Epoch [2391/10000], Train Loss: 39.8955, Val Loss: 171.4063\n",
      "Epoch [2392/10000], Train Loss: 39.8734, Val Loss: 171.3075\n",
      "Epoch [2393/10000], Train Loss: 39.8513, Val Loss: 171.2153\n",
      "Epoch [2394/10000], Train Loss: 39.8291, Val Loss: 171.1093\n",
      "Epoch [2395/10000], Train Loss: 39.8067, Val Loss: 171.0101\n",
      "Epoch [2396/10000], Train Loss: 39.7843, Val Loss: 170.9013\n",
      "Epoch [2397/10000], Train Loss: 39.7618, Val Loss: 170.8068\n",
      "Epoch [2398/10000], Train Loss: 39.7393, Val Loss: 170.7055\n",
      "Epoch [2399/10000], Train Loss: 39.7168, Val Loss: 170.6027\n",
      "Epoch [2400/10000], Train Loss: 39.6944, Val Loss: 170.4979\n",
      "Epoch [2401/10000], Train Loss: 39.6719, Val Loss: 170.3889\n",
      "Epoch [2402/10000], Train Loss: 39.6494, Val Loss: 170.2931\n",
      "Epoch [2403/10000], Train Loss: 39.6269, Val Loss: 170.2005\n",
      "Epoch [2404/10000], Train Loss: 39.6042, Val Loss: 170.1101\n",
      "Epoch [2405/10000], Train Loss: 39.5816, Val Loss: 170.0094\n",
      "Epoch [2406/10000], Train Loss: 39.5588, Val Loss: 169.9101\n",
      "Epoch [2407/10000], Train Loss: 39.5360, Val Loss: 169.8027\n",
      "Epoch [2408/10000], Train Loss: 39.5131, Val Loss: 169.6969\n",
      "Epoch [2409/10000], Train Loss: 39.4901, Val Loss: 169.5863\n",
      "Epoch [2410/10000], Train Loss: 39.4673, Val Loss: 169.4858\n",
      "Epoch [2411/10000], Train Loss: 39.4442, Val Loss: 169.3820\n",
      "Epoch [2412/10000], Train Loss: 39.4212, Val Loss: 169.2745\n",
      "Epoch [2413/10000], Train Loss: 39.3981, Val Loss: 169.1661\n",
      "Epoch [2414/10000], Train Loss: 39.3750, Val Loss: 169.0537\n",
      "Epoch [2415/10000], Train Loss: 39.3519, Val Loss: 168.9537\n",
      "Epoch [2416/10000], Train Loss: 39.3287, Val Loss: 168.8584\n",
      "Epoch [2417/10000], Train Loss: 39.3054, Val Loss: 168.7629\n",
      "Epoch [2418/10000], Train Loss: 39.2822, Val Loss: 168.6601\n",
      "Epoch [2419/10000], Train Loss: 39.2588, Val Loss: 168.5562\n",
      "Epoch [2420/10000], Train Loss: 39.2353, Val Loss: 168.4462\n",
      "Epoch [2421/10000], Train Loss: 39.2119, Val Loss: 168.3359\n",
      "Epoch [2422/10000], Train Loss: 39.1884, Val Loss: 168.2315\n",
      "Epoch [2423/10000], Train Loss: 39.1648, Val Loss: 168.1245\n",
      "Epoch [2424/10000], Train Loss: 39.1412, Val Loss: 168.0139\n",
      "Epoch [2425/10000], Train Loss: 39.1176, Val Loss: 167.8998\n",
      "Epoch [2426/10000], Train Loss: 39.0939, Val Loss: 167.7842\n",
      "Epoch [2427/10000], Train Loss: 39.0701, Val Loss: 167.6760\n",
      "Epoch [2428/10000], Train Loss: 39.0463, Val Loss: 167.5674\n",
      "Epoch [2429/10000], Train Loss: 39.0225, Val Loss: 167.4559\n",
      "Epoch [2430/10000], Train Loss: 38.9986, Val Loss: 167.3545\n",
      "Epoch [2431/10000], Train Loss: 38.9747, Val Loss: 167.2485\n",
      "Epoch [2432/10000], Train Loss: 38.9508, Val Loss: 167.1418\n",
      "Epoch [2433/10000], Train Loss: 38.9267, Val Loss: 167.0307\n",
      "Epoch [2434/10000], Train Loss: 38.9026, Val Loss: 166.9185\n",
      "Epoch [2435/10000], Train Loss: 38.8785, Val Loss: 166.8125\n",
      "Epoch [2436/10000], Train Loss: 38.8543, Val Loss: 166.7045\n",
      "Epoch [2437/10000], Train Loss: 38.8301, Val Loss: 166.5920\n",
      "Epoch [2438/10000], Train Loss: 38.8058, Val Loss: 166.4771\n",
      "Epoch [2439/10000], Train Loss: 38.7815, Val Loss: 166.3589\n",
      "Epoch [2440/10000], Train Loss: 38.7572, Val Loss: 166.2485\n",
      "Epoch [2441/10000], Train Loss: 38.7327, Val Loss: 166.1444\n",
      "Epoch [2442/10000], Train Loss: 38.7083, Val Loss: 166.0357\n",
      "Epoch [2443/10000], Train Loss: 38.6838, Val Loss: 165.9222\n",
      "Epoch [2444/10000], Train Loss: 38.6592, Val Loss: 165.8044\n",
      "Epoch [2445/10000], Train Loss: 38.6345, Val Loss: 165.6842\n",
      "Epoch [2446/10000], Train Loss: 38.6098, Val Loss: 165.5625\n",
      "Epoch [2447/10000], Train Loss: 38.5851, Val Loss: 165.4493\n",
      "Epoch [2448/10000], Train Loss: 38.5603, Val Loss: 165.3340\n",
      "Epoch [2449/10000], Train Loss: 38.5354, Val Loss: 165.2170\n",
      "Epoch [2450/10000], Train Loss: 38.5106, Val Loss: 165.0977\n",
      "Epoch [2451/10000], Train Loss: 38.4856, Val Loss: 164.9771\n",
      "Epoch [2452/10000], Train Loss: 38.4606, Val Loss: 164.8561\n",
      "Epoch [2453/10000], Train Loss: 38.4356, Val Loss: 164.7445\n",
      "Epoch [2454/10000], Train Loss: 38.4105, Val Loss: 164.6404\n",
      "Epoch [2455/10000], Train Loss: 38.3853, Val Loss: 164.5327\n",
      "Epoch [2456/10000], Train Loss: 38.3602, Val Loss: 164.4206\n",
      "Epoch [2457/10000], Train Loss: 38.3349, Val Loss: 164.3042\n",
      "Epoch [2458/10000], Train Loss: 38.3096, Val Loss: 164.1835\n",
      "Epoch [2459/10000], Train Loss: 38.2842, Val Loss: 164.0597\n",
      "Epoch [2460/10000], Train Loss: 38.2588, Val Loss: 163.9337\n",
      "Epoch [2461/10000], Train Loss: 38.2334, Val Loss: 163.8147\n",
      "Epoch [2462/10000], Train Loss: 38.2078, Val Loss: 163.6934\n",
      "Epoch [2463/10000], Train Loss: 38.1822, Val Loss: 163.5692\n",
      "Epoch [2464/10000], Train Loss: 38.1566, Val Loss: 163.4433\n",
      "Epoch [2465/10000], Train Loss: 38.1309, Val Loss: 163.3161\n",
      "Epoch [2466/10000], Train Loss: 38.1052, Val Loss: 163.1979\n",
      "Epoch [2467/10000], Train Loss: 38.0794, Val Loss: 163.0867\n",
      "Epoch [2468/10000], Train Loss: 38.0536, Val Loss: 162.9734\n",
      "Epoch [2469/10000], Train Loss: 38.0277, Val Loss: 162.8560\n",
      "Epoch [2470/10000], Train Loss: 38.0017, Val Loss: 162.7358\n",
      "Epoch [2471/10000], Train Loss: 37.9757, Val Loss: 162.6111\n",
      "Epoch [2472/10000], Train Loss: 37.9496, Val Loss: 162.4933\n",
      "Epoch [2473/10000], Train Loss: 37.9235, Val Loss: 162.3699\n",
      "Epoch [2474/10000], Train Loss: 37.8973, Val Loss: 162.2440\n",
      "Epoch [2475/10000], Train Loss: 37.8711, Val Loss: 162.1124\n",
      "Epoch [2476/10000], Train Loss: 37.8448, Val Loss: 161.9808\n",
      "Epoch [2477/10000], Train Loss: 37.8185, Val Loss: 161.8538\n",
      "Epoch [2478/10000], Train Loss: 37.7921, Val Loss: 161.7278\n",
      "Epoch [2479/10000], Train Loss: 37.7657, Val Loss: 161.5965\n",
      "Epoch [2480/10000], Train Loss: 37.7392, Val Loss: 161.4692\n",
      "Epoch [2481/10000], Train Loss: 37.7128, Val Loss: 161.3444\n",
      "Epoch [2482/10000], Train Loss: 37.6862, Val Loss: 161.2253\n",
      "Epoch [2483/10000], Train Loss: 37.6597, Val Loss: 161.0959\n",
      "Epoch [2484/10000], Train Loss: 37.6332, Val Loss: 160.9755\n",
      "Epoch [2485/10000], Train Loss: 37.6067, Val Loss: 160.8497\n",
      "Epoch [2486/10000], Train Loss: 37.5803, Val Loss: 160.7346\n",
      "Epoch [2487/10000], Train Loss: 37.5537, Val Loss: 160.5999\n",
      "Epoch [2488/10000], Train Loss: 37.5270, Val Loss: 160.4778\n",
      "Epoch [2489/10000], Train Loss: 37.4999, Val Loss: 160.3443\n",
      "Epoch [2490/10000], Train Loss: 37.4723, Val Loss: 160.2202\n",
      "Epoch [2491/10000], Train Loss: 37.4445, Val Loss: 160.0816\n",
      "Epoch [2492/10000], Train Loss: 37.4167, Val Loss: 159.9460\n",
      "Epoch [2493/10000], Train Loss: 37.3893, Val Loss: 159.8161\n",
      "Epoch [2494/10000], Train Loss: 37.3620, Val Loss: 159.6802\n",
      "Epoch [2495/10000], Train Loss: 37.3349, Val Loss: 159.5497\n",
      "Epoch [2496/10000], Train Loss: 37.3078, Val Loss: 159.4083\n",
      "Epoch [2497/10000], Train Loss: 37.2804, Val Loss: 159.2840\n",
      "Epoch [2498/10000], Train Loss: 37.2526, Val Loss: 159.1500\n",
      "Epoch [2499/10000], Train Loss: 37.2247, Val Loss: 159.0200\n",
      "Epoch [2500/10000], Train Loss: 37.1968, Val Loss: 158.8865\n",
      "Epoch [2501/10000], Train Loss: 37.1691, Val Loss: 158.7584\n",
      "Epoch [2502/10000], Train Loss: 37.1414, Val Loss: 158.6315\n",
      "Epoch [2503/10000], Train Loss: 37.1137, Val Loss: 158.4948\n",
      "Epoch [2504/10000], Train Loss: 37.0858, Val Loss: 158.3613\n",
      "Epoch [2505/10000], Train Loss: 37.0578, Val Loss: 158.2265\n",
      "Epoch [2506/10000], Train Loss: 37.0296, Val Loss: 158.0922\n",
      "Epoch [2507/10000], Train Loss: 37.0014, Val Loss: 157.9527\n",
      "Epoch [2508/10000], Train Loss: 36.9732, Val Loss: 157.8103\n",
      "Epoch [2509/10000], Train Loss: 36.9451, Val Loss: 157.6766\n",
      "Epoch [2510/10000], Train Loss: 36.9169, Val Loss: 157.5366\n",
      "Epoch [2511/10000], Train Loss: 36.8886, Val Loss: 157.3990\n",
      "Epoch [2512/10000], Train Loss: 36.8602, Val Loss: 157.2559\n",
      "Epoch [2513/10000], Train Loss: 36.8317, Val Loss: 157.1228\n",
      "Epoch [2514/10000], Train Loss: 36.8031, Val Loss: 156.9862\n",
      "Epoch [2515/10000], Train Loss: 36.7744, Val Loss: 156.8469\n",
      "Epoch [2516/10000], Train Loss: 36.7458, Val Loss: 156.7072\n",
      "Epoch [2517/10000], Train Loss: 36.7171, Val Loss: 156.5704\n",
      "Epoch [2518/10000], Train Loss: 36.6884, Val Loss: 156.4337\n",
      "Epoch [2519/10000], Train Loss: 36.6595, Val Loss: 156.2911\n",
      "Epoch [2520/10000], Train Loss: 36.6306, Val Loss: 156.1479\n",
      "Epoch [2521/10000], Train Loss: 36.6016, Val Loss: 156.0089\n",
      "Epoch [2522/10000], Train Loss: 36.5726, Val Loss: 155.8672\n",
      "Epoch [2523/10000], Train Loss: 36.5435, Val Loss: 155.7236\n",
      "Epoch [2524/10000], Train Loss: 36.5143, Val Loss: 155.5762\n",
      "Epoch [2525/10000], Train Loss: 36.4852, Val Loss: 155.4371\n",
      "Epoch [2526/10000], Train Loss: 36.4558, Val Loss: 155.2935\n",
      "Epoch [2527/10000], Train Loss: 36.4265, Val Loss: 155.1492\n",
      "Epoch [2528/10000], Train Loss: 36.3971, Val Loss: 155.0095\n",
      "Epoch [2529/10000], Train Loss: 36.3676, Val Loss: 154.8672\n",
      "Epoch [2530/10000], Train Loss: 36.3381, Val Loss: 154.7220\n",
      "Epoch [2531/10000], Train Loss: 36.3085, Val Loss: 154.5733\n",
      "Epoch [2532/10000], Train Loss: 36.2789, Val Loss: 154.4309\n",
      "Epoch [2533/10000], Train Loss: 36.2491, Val Loss: 154.2844\n",
      "Epoch [2534/10000], Train Loss: 36.2193, Val Loss: 154.1360\n",
      "Epoch [2535/10000], Train Loss: 36.1895, Val Loss: 153.9845\n",
      "Epoch [2536/10000], Train Loss: 36.1595, Val Loss: 153.8316\n",
      "Epoch [2537/10000], Train Loss: 36.1296, Val Loss: 153.6854\n",
      "Epoch [2538/10000], Train Loss: 36.0995, Val Loss: 153.5446\n",
      "Epoch [2539/10000], Train Loss: 36.0694, Val Loss: 153.4012\n",
      "Epoch [2540/10000], Train Loss: 36.0393, Val Loss: 153.2539\n",
      "Epoch [2541/10000], Train Loss: 36.0090, Val Loss: 153.1041\n",
      "Epoch [2542/10000], Train Loss: 35.9787, Val Loss: 152.9509\n",
      "Epoch [2543/10000], Train Loss: 35.9483, Val Loss: 152.7961\n",
      "Epoch [2544/10000], Train Loss: 35.9179, Val Loss: 152.6464\n",
      "Epoch [2545/10000], Train Loss: 35.8873, Val Loss: 152.4945\n",
      "Epoch [2546/10000], Train Loss: 35.8567, Val Loss: 152.3408\n",
      "Epoch [2547/10000], Train Loss: 35.8261, Val Loss: 152.1855\n",
      "Epoch [2548/10000], Train Loss: 35.7954, Val Loss: 152.0296\n",
      "Epoch [2549/10000], Train Loss: 35.7646, Val Loss: 151.8799\n",
      "Epoch [2550/10000], Train Loss: 35.7337, Val Loss: 151.7360\n",
      "Epoch [2551/10000], Train Loss: 35.7028, Val Loss: 151.5886\n",
      "Epoch [2552/10000], Train Loss: 35.6718, Val Loss: 151.4380\n",
      "Epoch [2553/10000], Train Loss: 35.6407, Val Loss: 151.2838\n",
      "Epoch [2554/10000], Train Loss: 35.6096, Val Loss: 151.1261\n",
      "Epoch [2555/10000], Train Loss: 35.5784, Val Loss: 150.9723\n",
      "Epoch [2556/10000], Train Loss: 35.5471, Val Loss: 150.8151\n",
      "Epoch [2557/10000], Train Loss: 35.5158, Val Loss: 150.6550\n",
      "Epoch [2558/10000], Train Loss: 35.4844, Val Loss: 150.4926\n",
      "Epoch [2559/10000], Train Loss: 35.4529, Val Loss: 150.3287\n",
      "Epoch [2560/10000], Train Loss: 35.4214, Val Loss: 150.1711\n",
      "Epoch [2561/10000], Train Loss: 35.3898, Val Loss: 150.0196\n",
      "Epoch [2562/10000], Train Loss: 35.3581, Val Loss: 149.8656\n",
      "Epoch [2563/10000], Train Loss: 35.3264, Val Loss: 149.7093\n",
      "Epoch [2564/10000], Train Loss: 35.2946, Val Loss: 149.5505\n",
      "Epoch [2565/10000], Train Loss: 35.2627, Val Loss: 149.3894\n",
      "Epoch [2566/10000], Train Loss: 35.2308, Val Loss: 149.2329\n",
      "Epoch [2567/10000], Train Loss: 35.1987, Val Loss: 149.0731\n",
      "Epoch [2568/10000], Train Loss: 35.1666, Val Loss: 148.9105\n",
      "Epoch [2569/10000], Train Loss: 35.1344, Val Loss: 148.7451\n",
      "Epoch [2570/10000], Train Loss: 35.1022, Val Loss: 148.5781\n",
      "Epoch [2571/10000], Train Loss: 35.0700, Val Loss: 148.4166\n",
      "Epoch [2572/10000], Train Loss: 35.0375, Val Loss: 148.2602\n",
      "Epoch [2573/10000], Train Loss: 35.0051, Val Loss: 148.1012\n",
      "Epoch [2574/10000], Train Loss: 34.9726, Val Loss: 147.9394\n",
      "Epoch [2575/10000], Train Loss: 34.9400, Val Loss: 147.7751\n",
      "Epoch [2576/10000], Train Loss: 34.9074, Val Loss: 147.6083\n",
      "Epoch [2577/10000], Train Loss: 34.8747, Val Loss: 147.4457\n",
      "Epoch [2578/10000], Train Loss: 34.8418, Val Loss: 147.2866\n",
      "Epoch [2579/10000], Train Loss: 34.8090, Val Loss: 147.1235\n",
      "Epoch [2580/10000], Train Loss: 34.7761, Val Loss: 146.9566\n",
      "Epoch [2581/10000], Train Loss: 34.7430, Val Loss: 146.7863\n",
      "Epoch [2582/10000], Train Loss: 34.7099, Val Loss: 146.6128\n",
      "Epoch [2583/10000], Train Loss: 34.6767, Val Loss: 146.4368\n",
      "Epoch [2584/10000], Train Loss: 34.6435, Val Loss: 146.2656\n",
      "Epoch [2585/10000], Train Loss: 34.6102, Val Loss: 146.0932\n",
      "Epoch [2586/10000], Train Loss: 34.5767, Val Loss: 145.9199\n",
      "Epoch [2587/10000], Train Loss: 34.5433, Val Loss: 145.7473\n",
      "Epoch [2588/10000], Train Loss: 34.5098, Val Loss: 145.5752\n",
      "Epoch [2589/10000], Train Loss: 34.4762, Val Loss: 145.4105\n",
      "Epoch [2590/10000], Train Loss: 34.4425, Val Loss: 145.2518\n",
      "Epoch [2591/10000], Train Loss: 34.4087, Val Loss: 145.0912\n",
      "Epoch [2592/10000], Train Loss: 34.3749, Val Loss: 144.9270\n",
      "Epoch [2593/10000], Train Loss: 34.3410, Val Loss: 144.7587\n",
      "Epoch [2594/10000], Train Loss: 34.3070, Val Loss: 144.5853\n",
      "Epoch [2595/10000], Train Loss: 34.2731, Val Loss: 144.4137\n",
      "Epoch [2596/10000], Train Loss: 34.2389, Val Loss: 144.2430\n",
      "Epoch [2597/10000], Train Loss: 34.2047, Val Loss: 144.0673\n",
      "Epoch [2598/10000], Train Loss: 34.1705, Val Loss: 143.8873\n",
      "Epoch [2599/10000], Train Loss: 34.1361, Val Loss: 143.7047\n",
      "Epoch [2600/10000], Train Loss: 34.1017, Val Loss: 143.5199\n",
      "Epoch [2601/10000], Train Loss: 34.0672, Val Loss: 143.3399\n",
      "Epoch [2602/10000], Train Loss: 34.0327, Val Loss: 143.1646\n",
      "Epoch [2603/10000], Train Loss: 33.9980, Val Loss: 142.9880\n",
      "Epoch [2604/10000], Train Loss: 33.9633, Val Loss: 142.8106\n",
      "Epoch [2605/10000], Train Loss: 33.9285, Val Loss: 142.6323\n",
      "Epoch [2606/10000], Train Loss: 33.8937, Val Loss: 142.4532\n",
      "Epoch [2607/10000], Train Loss: 33.8587, Val Loss: 142.2733\n",
      "Epoch [2608/10000], Train Loss: 33.8237, Val Loss: 142.0924\n",
      "Epoch [2609/10000], Train Loss: 33.7887, Val Loss: 141.9165\n",
      "Epoch [2610/10000], Train Loss: 33.7534, Val Loss: 141.7449\n",
      "Epoch [2611/10000], Train Loss: 33.7182, Val Loss: 141.5709\n",
      "Epoch [2612/10000], Train Loss: 33.6830, Val Loss: 141.3942\n",
      "Epoch [2613/10000], Train Loss: 33.6476, Val Loss: 141.2145\n",
      "Epoch [2614/10000], Train Loss: 33.6121, Val Loss: 141.0315\n",
      "Epoch [2615/10000], Train Loss: 33.5765, Val Loss: 140.8505\n",
      "Epoch [2616/10000], Train Loss: 33.5409, Val Loss: 140.6710\n",
      "Epoch [2617/10000], Train Loss: 33.5052, Val Loss: 140.4872\n",
      "Epoch [2618/10000], Train Loss: 33.4694, Val Loss: 140.2995\n",
      "Epoch [2619/10000], Train Loss: 33.4335, Val Loss: 140.1087\n",
      "Epoch [2620/10000], Train Loss: 33.3976, Val Loss: 139.9161\n",
      "Epoch [2621/10000], Train Loss: 33.3616, Val Loss: 139.7225\n",
      "Epoch [2622/10000], Train Loss: 33.3255, Val Loss: 139.5338\n",
      "Epoch [2623/10000], Train Loss: 33.2894, Val Loss: 139.3500\n",
      "Epoch [2624/10000], Train Loss: 33.2531, Val Loss: 139.1658\n",
      "Epoch [2625/10000], Train Loss: 33.2168, Val Loss: 138.9810\n",
      "Epoch [2626/10000], Train Loss: 33.1804, Val Loss: 138.7953\n",
      "Epoch [2627/10000], Train Loss: 33.1439, Val Loss: 138.6083\n",
      "Epoch [2628/10000], Train Loss: 33.1074, Val Loss: 138.4248\n",
      "Epoch [2629/10000], Train Loss: 33.0708, Val Loss: 138.2439\n",
      "Epoch [2630/10000], Train Loss: 33.0340, Val Loss: 138.0591\n",
      "Epoch [2631/10000], Train Loss: 32.9973, Val Loss: 137.8706\n",
      "Epoch [2632/10000], Train Loss: 32.9604, Val Loss: 137.6784\n",
      "Epoch [2633/10000], Train Loss: 32.9235, Val Loss: 137.4830\n",
      "Epoch [2634/10000], Train Loss: 32.8865, Val Loss: 137.2897\n",
      "Epoch [2635/10000], Train Loss: 32.8494, Val Loss: 137.0985\n",
      "Epoch [2636/10000], Train Loss: 32.8122, Val Loss: 136.9041\n",
      "Epoch [2637/10000], Train Loss: 32.7749, Val Loss: 136.7074\n",
      "Epoch [2638/10000], Train Loss: 32.7376, Val Loss: 136.5088\n",
      "Epoch [2639/10000], Train Loss: 32.7002, Val Loss: 136.3142\n",
      "Epoch [2640/10000], Train Loss: 32.6627, Val Loss: 136.1181\n",
      "Epoch [2641/10000], Train Loss: 32.6252, Val Loss: 135.9257\n",
      "Epoch [2642/10000], Train Loss: 32.5876, Val Loss: 135.7317\n",
      "Epoch [2643/10000], Train Loss: 32.5498, Val Loss: 135.5360\n",
      "Epoch [2644/10000], Train Loss: 32.5120, Val Loss: 135.3388\n",
      "Epoch [2645/10000], Train Loss: 32.4741, Val Loss: 135.1394\n",
      "Epoch [2646/10000], Train Loss: 32.4362, Val Loss: 134.9435\n",
      "Epoch [2647/10000], Train Loss: 32.3981, Val Loss: 134.7499\n",
      "Epoch [2648/10000], Train Loss: 32.3600, Val Loss: 134.5542\n",
      "Epoch [2649/10000], Train Loss: 32.3218, Val Loss: 134.3554\n",
      "Epoch [2650/10000], Train Loss: 32.2835, Val Loss: 134.1553\n",
      "Epoch [2651/10000], Train Loss: 32.2452, Val Loss: 133.9565\n",
      "Epoch [2652/10000], Train Loss: 32.2068, Val Loss: 133.7607\n",
      "Epoch [2653/10000], Train Loss: 32.1683, Val Loss: 133.5597\n",
      "Epoch [2654/10000], Train Loss: 32.1297, Val Loss: 133.3578\n",
      "Epoch [2655/10000], Train Loss: 32.0911, Val Loss: 133.1503\n",
      "Epoch [2656/10000], Train Loss: 32.0524, Val Loss: 132.9442\n",
      "Epoch [2657/10000], Train Loss: 32.0136, Val Loss: 132.7366\n",
      "Epoch [2658/10000], Train Loss: 31.9749, Val Loss: 132.5383\n",
      "Epoch [2659/10000], Train Loss: 31.9362, Val Loss: 132.3314\n",
      "Epoch [2660/10000], Train Loss: 31.8976, Val Loss: 132.1332\n",
      "Epoch [2661/10000], Train Loss: 31.8590, Val Loss: 131.9223\n",
      "Epoch [2662/10000], Train Loss: 31.8206, Val Loss: 131.7240\n",
      "Epoch [2663/10000], Train Loss: 31.7822, Val Loss: 131.5117\n",
      "Epoch [2664/10000], Train Loss: 31.7432, Val Loss: 131.3176\n",
      "Epoch [2665/10000], Train Loss: 31.7034, Val Loss: 131.1080\n",
      "Epoch [2666/10000], Train Loss: 31.6626, Val Loss: 130.9079\n",
      "Epoch [2667/10000], Train Loss: 31.6216, Val Loss: 130.6981\n",
      "Epoch [2668/10000], Train Loss: 31.5812, Val Loss: 130.4879\n",
      "Epoch [2669/10000], Train Loss: 31.5416, Val Loss: 130.2792\n",
      "Epoch [2670/10000], Train Loss: 31.5026, Val Loss: 130.0623\n",
      "Epoch [2671/10000], Train Loss: 31.4632, Val Loss: 129.8563\n",
      "Epoch [2672/10000], Train Loss: 31.4229, Val Loss: 129.6379\n",
      "Epoch [2673/10000], Train Loss: 31.3820, Val Loss: 129.4248\n",
      "Epoch [2674/10000], Train Loss: 31.3413, Val Loss: 129.2102\n",
      "Epoch [2675/10000], Train Loss: 31.3011, Val Loss: 128.9928\n",
      "Epoch [2676/10000], Train Loss: 31.2614, Val Loss: 128.7854\n",
      "Epoch [2677/10000], Train Loss: 31.2212, Val Loss: 128.5733\n",
      "Epoch [2678/10000], Train Loss: 31.1804, Val Loss: 128.3660\n",
      "Epoch [2679/10000], Train Loss: 31.1394, Val Loss: 128.1536\n",
      "Epoch [2680/10000], Train Loss: 31.0985, Val Loss: 127.9437\n",
      "Epoch [2681/10000], Train Loss: 31.0580, Val Loss: 127.7346\n",
      "Epoch [2682/10000], Train Loss: 31.0174, Val Loss: 127.5170\n",
      "Epoch [2683/10000], Train Loss: 30.9766, Val Loss: 127.3053\n",
      "Epoch [2684/10000], Train Loss: 30.9353, Val Loss: 127.0899\n",
      "Epoch [2685/10000], Train Loss: 30.8941, Val Loss: 126.8723\n",
      "Epoch [2686/10000], Train Loss: 30.8530, Val Loss: 126.6527\n",
      "Epoch [2687/10000], Train Loss: 30.8119, Val Loss: 126.4270\n",
      "Epoch [2688/10000], Train Loss: 30.7707, Val Loss: 126.2066\n",
      "Epoch [2689/10000], Train Loss: 30.7292, Val Loss: 125.9847\n",
      "Epoch [2690/10000], Train Loss: 30.6876, Val Loss: 125.7673\n",
      "Epoch [2691/10000], Train Loss: 30.6460, Val Loss: 125.5491\n",
      "Epoch [2692/10000], Train Loss: 30.6045, Val Loss: 125.3280\n",
      "Epoch [2693/10000], Train Loss: 30.5629, Val Loss: 125.1083\n",
      "Epoch [2694/10000], Train Loss: 30.5211, Val Loss: 124.8833\n",
      "Epoch [2695/10000], Train Loss: 30.4792, Val Loss: 124.6620\n",
      "Epoch [2696/10000], Train Loss: 30.4371, Val Loss: 124.4412\n",
      "Epoch [2697/10000], Train Loss: 30.3951, Val Loss: 124.2178\n",
      "Epoch [2698/10000], Train Loss: 30.3531, Val Loss: 123.9952\n",
      "Epoch [2699/10000], Train Loss: 30.3110, Val Loss: 123.7696\n",
      "Epoch [2700/10000], Train Loss: 30.2687, Val Loss: 123.5486\n",
      "Epoch [2701/10000], Train Loss: 30.2263, Val Loss: 123.3281\n",
      "Epoch [2702/10000], Train Loss: 30.1839, Val Loss: 123.1086\n",
      "Epoch [2703/10000], Train Loss: 30.1414, Val Loss: 122.8864\n",
      "Epoch [2704/10000], Train Loss: 30.0988, Val Loss: 122.6586\n",
      "Epoch [2705/10000], Train Loss: 30.0562, Val Loss: 122.4284\n",
      "Epoch [2706/10000], Train Loss: 30.0135, Val Loss: 122.1968\n",
      "Epoch [2707/10000], Train Loss: 29.9707, Val Loss: 121.9665\n",
      "Epoch [2708/10000], Train Loss: 29.9277, Val Loss: 121.7343\n",
      "Epoch [2709/10000], Train Loss: 29.8848, Val Loss: 121.5004\n",
      "Epoch [2710/10000], Train Loss: 29.8418, Val Loss: 121.2676\n",
      "Epoch [2711/10000], Train Loss: 29.7987, Val Loss: 121.0368\n",
      "Epoch [2712/10000], Train Loss: 29.7555, Val Loss: 120.8097\n",
      "Epoch [2713/10000], Train Loss: 29.7121, Val Loss: 120.5844\n",
      "Epoch [2714/10000], Train Loss: 29.6688, Val Loss: 120.3574\n",
      "Epoch [2715/10000], Train Loss: 29.6254, Val Loss: 120.1289\n",
      "Epoch [2716/10000], Train Loss: 29.5819, Val Loss: 119.8968\n",
      "Epoch [2717/10000], Train Loss: 29.5383, Val Loss: 119.6655\n",
      "Epoch [2718/10000], Train Loss: 29.4946, Val Loss: 119.4334\n",
      "Epoch [2719/10000], Train Loss: 29.4509, Val Loss: 119.2015\n",
      "Epoch [2720/10000], Train Loss: 29.4071, Val Loss: 118.9670\n",
      "Epoch [2721/10000], Train Loss: 29.3632, Val Loss: 118.7298\n",
      "Epoch [2722/10000], Train Loss: 29.3192, Val Loss: 118.4912\n",
      "Epoch [2723/10000], Train Loss: 29.2752, Val Loss: 118.2525\n",
      "Epoch [2724/10000], Train Loss: 29.2311, Val Loss: 118.0152\n",
      "Epoch [2725/10000], Train Loss: 29.1869, Val Loss: 117.7789\n",
      "Epoch [2726/10000], Train Loss: 29.1426, Val Loss: 117.5413\n",
      "Epoch [2727/10000], Train Loss: 29.0983, Val Loss: 117.3035\n",
      "Epoch [2728/10000], Train Loss: 29.0539, Val Loss: 117.0674\n",
      "Epoch [2729/10000], Train Loss: 29.0094, Val Loss: 116.8332\n",
      "Epoch [2730/10000], Train Loss: 28.9648, Val Loss: 116.5966\n",
      "Epoch [2731/10000], Train Loss: 28.9201, Val Loss: 116.3602\n",
      "Epoch [2732/10000], Train Loss: 28.8754, Val Loss: 116.1206\n",
      "Epoch [2733/10000], Train Loss: 28.8306, Val Loss: 115.8773\n",
      "Epoch [2734/10000], Train Loss: 28.7857, Val Loss: 115.6341\n",
      "Epoch [2735/10000], Train Loss: 28.7407, Val Loss: 115.3907\n",
      "Epoch [2736/10000], Train Loss: 28.6957, Val Loss: 115.1461\n",
      "Epoch [2737/10000], Train Loss: 28.6506, Val Loss: 114.9032\n",
      "Epoch [2738/10000], Train Loss: 28.6055, Val Loss: 114.6596\n",
      "Epoch [2739/10000], Train Loss: 28.5603, Val Loss: 114.4182\n",
      "Epoch [2740/10000], Train Loss: 28.5149, Val Loss: 114.1777\n",
      "Epoch [2741/10000], Train Loss: 28.4696, Val Loss: 113.9381\n",
      "Epoch [2742/10000], Train Loss: 28.4241, Val Loss: 113.6956\n",
      "Epoch [2743/10000], Train Loss: 28.3785, Val Loss: 113.4500\n",
      "Epoch [2744/10000], Train Loss: 28.3329, Val Loss: 113.2037\n",
      "Epoch [2745/10000], Train Loss: 28.2873, Val Loss: 112.9566\n",
      "Epoch [2746/10000], Train Loss: 28.2415, Val Loss: 112.7071\n",
      "Epoch [2747/10000], Train Loss: 28.1957, Val Loss: 112.4582\n",
      "Epoch [2748/10000], Train Loss: 28.1498, Val Loss: 112.2081\n",
      "Epoch [2749/10000], Train Loss: 28.1038, Val Loss: 111.9597\n",
      "Epoch [2750/10000], Train Loss: 28.0578, Val Loss: 111.7128\n",
      "Epoch [2751/10000], Train Loss: 28.0117, Val Loss: 111.4672\n",
      "Epoch [2752/10000], Train Loss: 27.9655, Val Loss: 111.2197\n",
      "Epoch [2753/10000], Train Loss: 27.9193, Val Loss: 110.9703\n",
      "Epoch [2754/10000], Train Loss: 27.8729, Val Loss: 110.7207\n",
      "Epoch [2755/10000], Train Loss: 27.8265, Val Loss: 110.4706\n",
      "Epoch [2756/10000], Train Loss: 27.7801, Val Loss: 110.2201\n",
      "Epoch [2757/10000], Train Loss: 27.7336, Val Loss: 109.9675\n",
      "Epoch [2758/10000], Train Loss: 27.6870, Val Loss: 109.7133\n",
      "Epoch [2759/10000], Train Loss: 27.6403, Val Loss: 109.4599\n",
      "Epoch [2760/10000], Train Loss: 27.5936, Val Loss: 109.2071\n",
      "Epoch [2761/10000], Train Loss: 27.5468, Val Loss: 108.9550\n",
      "Epoch [2762/10000], Train Loss: 27.4999, Val Loss: 108.7035\n",
      "Epoch [2763/10000], Train Loss: 27.4530, Val Loss: 108.4526\n",
      "Epoch [2764/10000], Train Loss: 27.4060, Val Loss: 108.2000\n",
      "Epoch [2765/10000], Train Loss: 27.3590, Val Loss: 107.9470\n",
      "Epoch [2766/10000], Train Loss: 27.3119, Val Loss: 107.6933\n",
      "Epoch [2767/10000], Train Loss: 27.2647, Val Loss: 107.4383\n",
      "Epoch [2768/10000], Train Loss: 27.2174, Val Loss: 107.1802\n",
      "Epoch [2769/10000], Train Loss: 27.1701, Val Loss: 106.9194\n",
      "Epoch [2770/10000], Train Loss: 27.1227, Val Loss: 106.6585\n",
      "Epoch [2771/10000], Train Loss: 27.0753, Val Loss: 106.3982\n",
      "Epoch [2772/10000], Train Loss: 27.0278, Val Loss: 106.1392\n",
      "Epoch [2773/10000], Train Loss: 26.9802, Val Loss: 105.8822\n",
      "Epoch [2774/10000], Train Loss: 26.9325, Val Loss: 105.6270\n",
      "Epoch [2775/10000], Train Loss: 26.8849, Val Loss: 105.3711\n",
      "Epoch [2776/10000], Train Loss: 26.8371, Val Loss: 105.1153\n",
      "Epoch [2777/10000], Train Loss: 26.7893, Val Loss: 104.8585\n",
      "Epoch [2778/10000], Train Loss: 26.7414, Val Loss: 104.6001\n",
      "Epoch [2779/10000], Train Loss: 26.6935, Val Loss: 104.3400\n",
      "Epoch [2780/10000], Train Loss: 26.6454, Val Loss: 104.0773\n",
      "Epoch [2781/10000], Train Loss: 26.5974, Val Loss: 103.8141\n",
      "Epoch [2782/10000], Train Loss: 26.5493, Val Loss: 103.5514\n",
      "Epoch [2783/10000], Train Loss: 26.5011, Val Loss: 103.2894\n",
      "Epoch [2784/10000], Train Loss: 26.4529, Val Loss: 103.0281\n",
      "Epoch [2785/10000], Train Loss: 26.4045, Val Loss: 102.7670\n",
      "Epoch [2786/10000], Train Loss: 26.3561, Val Loss: 102.5057\n",
      "Epoch [2787/10000], Train Loss: 26.3076, Val Loss: 102.2438\n",
      "Epoch [2788/10000], Train Loss: 26.2591, Val Loss: 101.9807\n",
      "Epoch [2789/10000], Train Loss: 26.2104, Val Loss: 101.7125\n",
      "Epoch [2790/10000], Train Loss: 26.1618, Val Loss: 101.4465\n",
      "Epoch [2791/10000], Train Loss: 26.1131, Val Loss: 101.1787\n",
      "Epoch [2792/10000], Train Loss: 26.0644, Val Loss: 100.9097\n",
      "Epoch [2793/10000], Train Loss: 26.0156, Val Loss: 100.6399\n",
      "Epoch [2794/10000], Train Loss: 25.9667, Val Loss: 100.3695\n",
      "Epoch [2795/10000], Train Loss: 25.9178, Val Loss: 100.0985\n",
      "Epoch [2796/10000], Train Loss: 25.8688, Val Loss: 99.8304\n",
      "Epoch [2797/10000], Train Loss: 25.8198, Val Loss: 99.5643\n",
      "Epoch [2798/10000], Train Loss: 25.7707, Val Loss: 99.2960\n",
      "Epoch [2799/10000], Train Loss: 25.7215, Val Loss: 99.0252\n",
      "Epoch [2800/10000], Train Loss: 25.6724, Val Loss: 98.7525\n",
      "Epoch [2801/10000], Train Loss: 25.6231, Val Loss: 98.4779\n",
      "Epoch [2802/10000], Train Loss: 25.5738, Val Loss: 98.2024\n",
      "Epoch [2803/10000], Train Loss: 25.5245, Val Loss: 97.9266\n",
      "Epoch [2804/10000], Train Loss: 25.4751, Val Loss: 97.6503\n",
      "Epoch [2805/10000], Train Loss: 25.4256, Val Loss: 97.3767\n",
      "Epoch [2806/10000], Train Loss: 25.3762, Val Loss: 97.1049\n",
      "Epoch [2807/10000], Train Loss: 25.3266, Val Loss: 96.8342\n",
      "Epoch [2808/10000], Train Loss: 25.2770, Val Loss: 96.5634\n",
      "Epoch [2809/10000], Train Loss: 25.2273, Val Loss: 96.2921\n",
      "Epoch [2810/10000], Train Loss: 25.1777, Val Loss: 96.0174\n",
      "Epoch [2811/10000], Train Loss: 25.1279, Val Loss: 95.7401\n",
      "Epoch [2812/10000], Train Loss: 25.0782, Val Loss: 95.4612\n",
      "Epoch [2813/10000], Train Loss: 25.0283, Val Loss: 95.1815\n",
      "Epoch [2814/10000], Train Loss: 24.9785, Val Loss: 94.9012\n",
      "Epoch [2815/10000], Train Loss: 24.9286, Val Loss: 94.6226\n",
      "Epoch [2816/10000], Train Loss: 24.8786, Val Loss: 94.3453\n",
      "Epoch [2817/10000], Train Loss: 24.8286, Val Loss: 94.0681\n",
      "Epoch [2818/10000], Train Loss: 24.7783, Val Loss: 93.7433\n",
      "Epoch [2819/10000], Train Loss: 24.7212, Val Loss: 93.3835\n",
      "Epoch [2820/10000], Train Loss: 24.6594, Val Loss: 93.0024\n",
      "Epoch [2821/10000], Train Loss: 24.5946, Val Loss: 92.4372\n",
      "Epoch [2822/10000], Train Loss: 24.5287, Val Loss: 91.8321\n",
      "Epoch [2823/10000], Train Loss: 24.4676, Val Loss: 91.2497\n",
      "Epoch [2824/10000], Train Loss: 24.4033, Val Loss: 90.6882\n",
      "Epoch [2825/10000], Train Loss: 24.3349, Val Loss: 90.1897\n",
      "Epoch [2826/10000], Train Loss: 24.2399, Val Loss: 89.6827\n",
      "Epoch [2827/10000], Train Loss: 24.1664, Val Loss: 89.2662\n",
      "Epoch [2828/10000], Train Loss: 24.0978, Val Loss: 88.9703\n",
      "Epoch [2829/10000], Train Loss: 24.0243, Val Loss: 88.8053\n",
      "Epoch [2830/10000], Train Loss: 23.9470, Val Loss: 88.6249\n",
      "Epoch [2831/10000], Train Loss: 23.8674, Val Loss: 88.4556\n",
      "Epoch [2832/10000], Train Loss: 23.7864, Val Loss: 88.2108\n",
      "Epoch [2833/10000], Train Loss: 23.7044, Val Loss: 87.9500\n",
      "Epoch [2834/10000], Train Loss: 23.6224, Val Loss: 87.6616\n",
      "Epoch [2835/10000], Train Loss: 23.5425, Val Loss: 87.4379\n",
      "Epoch [2836/10000], Train Loss: 23.4693, Val Loss: 87.2595\n",
      "Epoch [2837/10000], Train Loss: 23.3942, Val Loss: 87.0911\n",
      "Epoch [2838/10000], Train Loss: 23.3189, Val Loss: 86.9053\n",
      "Epoch [2839/10000], Train Loss: 23.2430, Val Loss: 86.6700\n",
      "Epoch [2840/10000], Train Loss: 23.1653, Val Loss: 86.3944\n",
      "Epoch [2841/10000], Train Loss: 23.0869, Val Loss: 86.0912\n",
      "Epoch [2842/10000], Train Loss: 23.0099, Val Loss: 85.7856\n",
      "Epoch [2843/10000], Train Loss: 22.9348, Val Loss: 85.4906\n",
      "Epoch [2844/10000], Train Loss: 22.8611, Val Loss: 85.2083\n",
      "Epoch [2845/10000], Train Loss: 22.7886, Val Loss: 84.9297\n",
      "Epoch [2846/10000], Train Loss: 22.7175, Val Loss: 84.6465\n",
      "Epoch [2847/10000], Train Loss: 22.6474, Val Loss: 84.3537\n",
      "Epoch [2848/10000], Train Loss: 22.5772, Val Loss: 84.0628\n",
      "Epoch [2849/10000], Train Loss: 22.5070, Val Loss: 83.7894\n",
      "Epoch [2850/10000], Train Loss: 22.4369, Val Loss: 83.5505\n",
      "Epoch [2851/10000], Train Loss: 22.3669, Val Loss: 83.3538\n",
      "Epoch [2852/10000], Train Loss: 22.2968, Val Loss: 83.1891\n",
      "Epoch [2853/10000], Train Loss: 22.2265, Val Loss: 83.0409\n",
      "Epoch [2854/10000], Train Loss: 22.1565, Val Loss: 82.8813\n",
      "Epoch [2855/10000], Train Loss: 22.0867, Val Loss: 82.6928\n",
      "Epoch [2856/10000], Train Loss: 22.0172, Val Loss: 82.4634\n",
      "Epoch [2857/10000], Train Loss: 21.9478, Val Loss: 82.1941\n",
      "Epoch [2858/10000], Train Loss: 21.8785, Val Loss: 81.8947\n",
      "Epoch [2859/10000], Train Loss: 21.8091, Val Loss: 81.5736\n",
      "Epoch [2860/10000], Train Loss: 21.7398, Val Loss: 81.2429\n",
      "Epoch [2861/10000], Train Loss: 21.6700, Val Loss: 80.9062\n",
      "Epoch [2862/10000], Train Loss: 21.6001, Val Loss: 80.5696\n",
      "Epoch [2863/10000], Train Loss: 21.5303, Val Loss: 80.2360\n",
      "Epoch [2864/10000], Train Loss: 21.4606, Val Loss: 79.9099\n",
      "Epoch [2865/10000], Train Loss: 21.3908, Val Loss: 79.5971\n",
      "Epoch [2866/10000], Train Loss: 21.3211, Val Loss: 79.2993\n",
      "Epoch [2867/10000], Train Loss: 21.2516, Val Loss: 79.0171\n",
      "Epoch [2868/10000], Train Loss: 21.1821, Val Loss: 78.7435\n",
      "Epoch [2869/10000], Train Loss: 21.1126, Val Loss: 78.4708\n",
      "Epoch [2870/10000], Train Loss: 21.0433, Val Loss: 78.1903\n",
      "Epoch [2871/10000], Train Loss: 20.9738, Val Loss: 77.8969\n",
      "Epoch [2872/10000], Train Loss: 20.9041, Val Loss: 77.5915\n",
      "Epoch [2873/10000], Train Loss: 20.8343, Val Loss: 77.2791\n",
      "Epoch [2874/10000], Train Loss: 20.7644, Val Loss: 76.9676\n",
      "Epoch [2875/10000], Train Loss: 20.6955, Val Loss: 76.6806\n",
      "Epoch [2876/10000], Train Loss: 20.6259, Val Loss: 76.4020\n",
      "Epoch [2877/10000], Train Loss: 20.5573, Val Loss: 76.1234\n",
      "Epoch [2878/10000], Train Loss: 20.4868, Val Loss: 75.8327\n",
      "Epoch [2879/10000], Train Loss: 20.4204, Val Loss: 75.5418\n",
      "Epoch [2880/10000], Train Loss: 20.3500, Val Loss: 75.2499\n",
      "Epoch [2881/10000], Train Loss: 20.2805, Val Loss: 74.9378\n",
      "Epoch [2882/10000], Train Loss: 20.2120, Val Loss: 74.6104\n",
      "Epoch [2883/10000], Train Loss: 20.1400, Val Loss: 74.2748\n",
      "Epoch [2884/10000], Train Loss: 20.0734, Val Loss: 73.9577\n",
      "Epoch [2885/10000], Train Loss: 20.0025, Val Loss: 73.6645\n",
      "Epoch [2886/10000], Train Loss: 19.9309, Val Loss: 73.3727\n",
      "Epoch [2887/10000], Train Loss: 19.8622, Val Loss: 73.0802\n",
      "Epoch [2888/10000], Train Loss: 19.7900, Val Loss: 72.7821\n",
      "Epoch [2889/10000], Train Loss: 19.7194, Val Loss: 72.4982\n",
      "Epoch [2890/10000], Train Loss: 19.6476, Val Loss: 72.1988\n",
      "Epoch [2891/10000], Train Loss: 19.5773, Val Loss: 71.8884\n",
      "Epoch [2892/10000], Train Loss: 19.5074, Val Loss: 71.6038\n",
      "Epoch [2893/10000], Train Loss: 19.4384, Val Loss: 71.3167\n",
      "Epoch [2894/10000], Train Loss: 19.3687, Val Loss: 71.0232\n",
      "Epoch [2895/10000], Train Loss: 19.2965, Val Loss: 70.7164\n",
      "Epoch [2896/10000], Train Loss: 19.2250, Val Loss: 70.3906\n",
      "Epoch [2897/10000], Train Loss: 19.1665, Val Loss: 70.1458\n",
      "Epoch [2898/10000], Train Loss: 19.0940, Val Loss: 69.8934\n",
      "Epoch [2899/10000], Train Loss: 19.0410, Val Loss: 69.5970\n",
      "Epoch [2900/10000], Train Loss: 18.9616, Val Loss: 69.2604\n",
      "Epoch [2901/10000], Train Loss: 18.8772, Val Loss: 68.8949\n",
      "Epoch [2902/10000], Train Loss: 18.8125, Val Loss: 68.4999\n",
      "Epoch [2903/10000], Train Loss: 18.7714, Val Loss: 68.1930\n",
      "Epoch [2904/10000], Train Loss: 18.6671, Val Loss: 67.9605\n",
      "Epoch [2905/10000], Train Loss: 18.6273, Val Loss: 67.7415\n",
      "Epoch [2906/10000], Train Loss: 18.5557, Val Loss: 67.5040\n",
      "Epoch [2907/10000], Train Loss: 18.4569, Val Loss: 67.2456\n",
      "Epoch [2908/10000], Train Loss: 18.3885, Val Loss: 66.9307\n",
      "Epoch [2909/10000], Train Loss: 18.3520, Val Loss: 66.6402\n",
      "Epoch [2910/10000], Train Loss: 18.2391, Val Loss: 66.3676\n",
      "Epoch [2911/10000], Train Loss: 18.1965, Val Loss: 66.0790\n",
      "Epoch [2912/10000], Train Loss: 18.1353, Val Loss: 65.7602\n",
      "Epoch [2913/10000], Train Loss: 18.0353, Val Loss: 65.4469\n",
      "Epoch [2914/10000], Train Loss: 17.9607, Val Loss: 65.1263\n",
      "Epoch [2915/10000], Train Loss: 17.9123, Val Loss: 64.7960\n",
      "Epoch [2916/10000], Train Loss: 17.8216, Val Loss: 64.4781\n",
      "Epoch [2917/10000], Train Loss: 17.7446, Val Loss: 64.2054\n",
      "Epoch [2918/10000], Train Loss: 17.6877, Val Loss: 63.9574\n",
      "Epoch [2919/10000], Train Loss: 17.6141, Val Loss: 63.7243\n",
      "Epoch [2920/10000], Train Loss: 17.5296, Val Loss: 63.5055\n",
      "Epoch [2921/10000], Train Loss: 17.4624, Val Loss: 63.2706\n",
      "Epoch [2922/10000], Train Loss: 17.4000, Val Loss: 63.0488\n",
      "Epoch [2923/10000], Train Loss: 17.3141, Val Loss: 62.8111\n",
      "Epoch [2924/10000], Train Loss: 17.2498, Val Loss: 62.5348\n",
      "Epoch [2925/10000], Train Loss: 17.1839, Val Loss: 62.2127\n",
      "Epoch [2926/10000], Train Loss: 17.1021, Val Loss: 61.8767\n",
      "Epoch [2927/10000], Train Loss: 17.0278, Val Loss: 61.5510\n",
      "Epoch [2928/10000], Train Loss: 16.9748, Val Loss: 61.4152\n",
      "Epoch [2929/10000], Train Loss: 16.8920, Val Loss: 61.2566\n",
      "Epoch [2930/10000], Train Loss: 16.8501, Val Loss: 60.9622\n",
      "Epoch [2931/10000], Train Loss: 16.7647, Val Loss: 60.5733\n",
      "Epoch [2932/10000], Train Loss: 16.6722, Val Loss: 60.1827\n",
      "Epoch [2933/10000], Train Loss: 16.6344, Val Loss: 59.9900\n",
      "Epoch [2934/10000], Train Loss: 16.5293, Val Loss: 59.8052\n",
      "Epoch [2935/10000], Train Loss: 16.4774, Val Loss: 59.5436\n",
      "Epoch [2936/10000], Train Loss: 16.4080, Val Loss: 59.2027\n",
      "Epoch [2937/10000], Train Loss: 16.3174, Val Loss: 58.8596\n",
      "Epoch [2938/10000], Train Loss: 16.2544, Val Loss: 58.6157\n",
      "Epoch [2939/10000], Train Loss: 16.1789, Val Loss: 58.4660\n",
      "Epoch [2940/10000], Train Loss: 16.1040, Val Loss: 58.2841\n",
      "Epoch [2941/10000], Train Loss: 16.0460, Val Loss: 58.0028\n",
      "Epoch [2942/10000], Train Loss: 15.9671, Val Loss: 57.6594\n",
      "Epoch [2943/10000], Train Loss: 15.8867, Val Loss: 57.3300\n",
      "Epoch [2944/10000], Train Loss: 15.8291, Val Loss: 57.1179\n",
      "Epoch [2945/10000], Train Loss: 15.7451, Val Loss: 56.9260\n",
      "Epoch [2946/10000], Train Loss: 15.6744, Val Loss: 56.7026\n",
      "Epoch [2947/10000], Train Loss: 15.6075, Val Loss: 56.4159\n",
      "Epoch [2948/10000], Train Loss: 15.5307, Val Loss: 56.0981\n",
      "Epoch [2949/10000], Train Loss: 15.4562, Val Loss: 55.8028\n",
      "Epoch [2950/10000], Train Loss: 15.3920, Val Loss: 55.6463\n",
      "Epoch [2951/10000], Train Loss: 15.3115, Val Loss: 55.4813\n",
      "Epoch [2952/10000], Train Loss: 15.2446, Val Loss: 55.2450\n",
      "Epoch [2953/10000], Train Loss: 15.1720, Val Loss: 54.9423\n",
      "Epoch [2954/10000], Train Loss: 15.0946, Val Loss: 54.6376\n",
      "Epoch [2955/10000], Train Loss: 15.0375, Val Loss: 54.6839\n",
      "Epoch [2956/10000], Train Loss: 14.9662, Val Loss: 54.5699\n",
      "Epoch [2957/10000], Train Loss: 14.9127, Val Loss: 54.1800\n",
      "Epoch [2958/10000], Train Loss: 14.8164, Val Loss: 53.6832\n",
      "Epoch [2959/10000], Train Loss: 14.7562, Val Loss: 53.5486\n",
      "Epoch [2960/10000], Train Loss: 14.6683, Val Loss: 53.3496\n",
      "Epoch [2961/10000], Train Loss: 14.6068, Val Loss: 53.0084\n",
      "Epoch [2962/10000], Train Loss: 14.5299, Val Loss: 52.5990\n",
      "Epoch [2963/10000], Train Loss: 14.4512, Val Loss: 52.2588\n",
      "Epoch [2964/10000], Train Loss: 14.4017, Val Loss: 52.3860\n",
      "Epoch [2965/10000], Train Loss: 14.3192, Val Loss: 52.3877\n",
      "Epoch [2966/10000], Train Loss: 14.2731, Val Loss: 52.0661\n",
      "Epoch [2967/10000], Train Loss: 14.1773, Val Loss: 51.5909\n",
      "Epoch [2968/10000], Train Loss: 14.1032, Val Loss: 51.2931\n",
      "Epoch [2969/10000], Train Loss: 14.0378, Val Loss: 51.1906\n",
      "Epoch [2970/10000], Train Loss: 13.9529, Val Loss: 51.0399\n",
      "Epoch [2971/10000], Train Loss: 13.8940, Val Loss: 50.7222\n",
      "Epoch [2972/10000], Train Loss: 13.8168, Val Loss: 50.3156\n",
      "Epoch [2973/10000], Train Loss: 13.7381, Val Loss: 49.9867\n",
      "Epoch [2974/10000], Train Loss: 13.6808, Val Loss: 49.9261\n",
      "Epoch [2975/10000], Train Loss: 13.5947, Val Loss: 49.8819\n",
      "Epoch [2976/10000], Train Loss: 13.5280, Val Loss: 49.6915\n",
      "Epoch [2977/10000], Train Loss: 13.4581, Val Loss: 49.3374\n",
      "Epoch [2978/10000], Train Loss: 13.3790, Val Loss: 48.9641\n",
      "Epoch [2979/10000], Train Loss: 13.3131, Val Loss: 48.8278\n",
      "Epoch [2980/10000], Train Loss: 13.2352, Val Loss: 48.7072\n",
      "Epoch [2981/10000], Train Loss: 13.1651, Val Loss: 48.5010\n",
      "Epoch [2982/10000], Train Loss: 13.0938, Val Loss: 48.1981\n",
      "Epoch [2983/10000], Train Loss: 13.0194, Val Loss: 47.8845\n",
      "Epoch [2984/10000], Train Loss: 12.9535, Val Loss: 47.7780\n",
      "Epoch [2985/10000], Train Loss: 12.8763, Val Loss: 47.6131\n",
      "Epoch [2986/10000], Train Loss: 12.8073, Val Loss: 47.3240\n",
      "Epoch [2987/10000], Train Loss: 12.7333, Val Loss: 46.9777\n",
      "Epoch [2988/10000], Train Loss: 12.6679, Val Loss: 47.1289\n",
      "Epoch [2989/10000], Train Loss: 12.6110, Val Loss: 46.9338\n",
      "Epoch [2990/10000], Train Loss: 12.5431, Val Loss: 46.3814\n",
      "Epoch [2991/10000], Train Loss: 12.4514, Val Loss: 45.9822\n",
      "Epoch [2992/10000], Train Loss: 12.3985, Val Loss: 46.1299\n",
      "Epoch [2993/10000], Train Loss: 12.3258, Val Loss: 45.9626\n",
      "Epoch [2994/10000], Train Loss: 12.2687, Val Loss: 45.3843\n",
      "Epoch [2995/10000], Train Loss: 12.1718, Val Loss: 44.7984\n",
      "Epoch [2996/10000], Train Loss: 12.1381, Val Loss: 44.9063\n",
      "Epoch [2997/10000], Train Loss: 12.0327, Val Loss: 44.9480\n",
      "Epoch [2998/10000], Train Loss: 11.9817, Val Loss: 44.6345\n",
      "Epoch [2999/10000], Train Loss: 11.9009, Val Loss: 44.1317\n",
      "Epoch [3000/10000], Train Loss: 11.8272, Val Loss: 43.9018\n",
      "Epoch [3001/10000], Train Loss: 11.7612, Val Loss: 43.9337\n",
      "Epoch [3002/10000], Train Loss: 11.6897, Val Loss: 43.8148\n",
      "Epoch [3003/10000], Train Loss: 11.6287, Val Loss: 43.4253\n",
      "Epoch [3004/10000], Train Loss: 11.5522, Val Loss: 42.9955\n",
      "Epoch [3005/10000], Train Loss: 11.4860, Val Loss: 42.7814\n",
      "Epoch [3006/10000], Train Loss: 11.4249, Val Loss: 42.9033\n",
      "Epoch [3007/10000], Train Loss: 11.3488, Val Loss: 42.9244\n",
      "Epoch [3008/10000], Train Loss: 11.2917, Val Loss: 42.6455\n",
      "Epoch [3009/10000], Train Loss: 11.2157, Val Loss: 42.2462\n",
      "Epoch [3010/10000], Train Loss: 11.1489, Val Loss: 42.1317\n",
      "Epoch [3011/10000], Train Loss: 11.0807, Val Loss: 42.0934\n",
      "Epoch [3012/10000], Train Loss: 11.0138, Val Loss: 41.9936\n",
      "Epoch [3013/10000], Train Loss: 10.9495, Val Loss: 41.7678\n",
      "Epoch [3014/10000], Train Loss: 10.8817, Val Loss: 41.5134\n",
      "Epoch [3015/10000], Train Loss: 10.8175, Val Loss: 41.4879\n",
      "Epoch [3016/10000], Train Loss: 10.7512, Val Loss: 41.4031\n",
      "Epoch [3017/10000], Train Loss: 10.6879, Val Loss: 41.1952\n",
      "Epoch [3018/10000], Train Loss: 10.6224, Val Loss: 40.9415\n",
      "Epoch [3019/10000], Train Loss: 10.5624, Val Loss: 40.8903\n",
      "Epoch [3020/10000], Train Loss: 10.4953, Val Loss: 40.7545\n",
      "Epoch [3021/10000], Train Loss: 10.4332, Val Loss: 40.5013\n",
      "Epoch [3022/10000], Train Loss: 10.3711, Val Loss: 40.3760\n",
      "Epoch [3023/10000], Train Loss: 10.3082, Val Loss: 40.3197\n",
      "Epoch [3024/10000], Train Loss: 10.2501, Val Loss: 40.0536\n",
      "Epoch [3025/10000], Train Loss: 10.1857, Val Loss: 39.8544\n",
      "Epoch [3026/10000], Train Loss: 10.1256, Val Loss: 39.7482\n",
      "Epoch [3027/10000], Train Loss: 10.0663, Val Loss: 39.5067\n",
      "Epoch [3028/10000], Train Loss: 10.0055, Val Loss: 39.3612\n",
      "Epoch [3029/10000], Train Loss: 9.9468, Val Loss: 39.1383\n",
      "Epoch [3030/10000], Train Loss: 9.8882, Val Loss: 39.0529\n",
      "Epoch [3031/10000], Train Loss: 9.8305, Val Loss: 38.8746\n",
      "Epoch [3032/10000], Train Loss: 9.7723, Val Loss: 38.6551\n",
      "Epoch [3033/10000], Train Loss: 9.7216, Val Loss: 38.9060\n",
      "Epoch [3034/10000], Train Loss: 9.6794, Val Loss: 38.6432\n",
      "Epoch [3035/10000], Train Loss: 9.6154, Val Loss: 38.0580\n",
      "Epoch [3036/10000], Train Loss: 9.5653, Val Loss: 38.0669\n",
      "Epoch [3037/10000], Train Loss: 9.4955, Val Loss: 37.9941\n",
      "Epoch [3038/10000], Train Loss: 9.4463, Val Loss: 37.6991\n",
      "Epoch [3039/10000], Train Loss: 9.3886, Val Loss: 37.3775\n",
      "Epoch [3040/10000], Train Loss: 9.3411, Val Loss: 37.6263\n",
      "Epoch [3041/10000], Train Loss: 9.2959, Val Loss: 37.4957\n",
      "Epoch [3042/10000], Train Loss: 9.2460, Val Loss: 37.0161\n",
      "Epoch [3043/10000], Train Loss: 9.1833, Val Loss: 36.6714\n",
      "Epoch [3044/10000], Train Loss: 9.1580, Val Loss: 37.0286\n",
      "Epoch [3045/10000], Train Loss: 9.0923, Val Loss: 37.0360\n",
      "Epoch [3046/10000], Train Loss: 9.0611, Val Loss: 36.4738\n",
      "Epoch [3047/10000], Train Loss: 8.9850, Val Loss: 36.0208\n",
      "Epoch [3048/10000], Train Loss: 8.9705, Val Loss: 36.3267\n",
      "Epoch [3049/10000], Train Loss: 8.8925, Val Loss: 36.5072\n",
      "Epoch [3050/10000], Train Loss: 8.8693, Val Loss: 36.1306\n",
      "Epoch [3051/10000], Train Loss: 8.8014, Val Loss: 35.6500\n",
      "Epoch [3052/10000], Train Loss: 8.7664, Val Loss: 35.5453\n",
      "Epoch [3053/10000], Train Loss: 8.7213, Val Loss: 35.7654\n",
      "Epoch [3054/10000], Train Loss: 8.6668, Val Loss: 35.8533\n",
      "Epoch [3055/10000], Train Loss: 8.6366, Val Loss: 35.5138\n",
      "Epoch [3056/10000], Train Loss: 8.5799, Val Loss: 35.1252\n",
      "Epoch [3057/10000], Train Loss: 8.5455, Val Loss: 35.0472\n",
      "Epoch [3058/10000], Train Loss: 8.5012, Val Loss: 35.2020\n",
      "Epoch [3059/10000], Train Loss: 8.4561, Val Loss: 35.1997\n",
      "Epoch [3060/10000], Train Loss: 8.4225, Val Loss: 34.8685\n",
      "Epoch [3061/10000], Train Loss: 8.3753, Val Loss: 34.5139\n",
      "Epoch [3062/10000], Train Loss: 8.3431, Val Loss: 34.3907\n",
      "Epoch [3063/10000], Train Loss: 8.3008, Val Loss: 34.4330\n",
      "Epoch [3064/10000], Train Loss: 8.2645, Val Loss: 34.3403\n",
      "Epoch [3065/10000], Train Loss: 8.2285, Val Loss: 34.0527\n",
      "Epoch [3066/10000], Train Loss: 8.1886, Val Loss: 33.8031\n",
      "Epoch [3067/10000], Train Loss: 8.1668, Val Loss: 33.9332\n",
      "Epoch [3068/10000], Train Loss: 8.1312, Val Loss: 33.6309\n",
      "Epoch [3069/10000], Train Loss: 8.0965, Val Loss: 33.0259\n",
      "Epoch [3070/10000], Train Loss: 8.0625, Val Loss: 32.9111\n",
      "Epoch [3071/10000], Train Loss: 8.0204, Val Loss: 33.0713\n",
      "Epoch [3072/10000], Train Loss: 8.0038, Val Loss: 32.7862\n",
      "Epoch [3073/10000], Train Loss: 7.9590, Val Loss: 32.3074\n",
      "Epoch [3074/10000], Train Loss: 7.9429, Val Loss: 32.3164\n",
      "Epoch [3075/10000], Train Loss: 7.8926, Val Loss: 32.2862\n",
      "Epoch [3076/10000], Train Loss: 7.8688, Val Loss: 31.9995\n",
      "Epoch [3077/10000], Train Loss: 7.8329, Val Loss: 31.6665\n",
      "Epoch [3078/10000], Train Loss: 7.8143, Val Loss: 31.7684\n",
      "Epoch [3079/10000], Train Loss: 7.7763, Val Loss: 31.6715\n",
      "Epoch [3080/10000], Train Loss: 7.7520, Val Loss: 31.3406\n",
      "Epoch [3081/10000], Train Loss: 7.7193, Val Loss: 31.2395\n",
      "Epoch [3082/10000], Train Loss: 7.6904, Val Loss: 31.1008\n",
      "Epoch [3083/10000], Train Loss: 7.6628, Val Loss: 30.9244\n",
      "Epoch [3084/10000], Train Loss: 7.6364, Val Loss: 30.8986\n",
      "Epoch [3085/10000], Train Loss: 7.6154, Val Loss: 30.6351\n",
      "Epoch [3086/10000], Train Loss: 7.5850, Val Loss: 30.3143\n",
      "Epoch [3087/10000], Train Loss: 7.5669, Val Loss: 30.2941\n",
      "Epoch [3088/10000], Train Loss: 7.5355, Val Loss: 30.1848\n",
      "Epoch [3089/10000], Train Loss: 7.5133, Val Loss: 29.9194\n",
      "Epoch [3090/10000], Train Loss: 7.4856, Val Loss: 29.8369\n",
      "Epoch [3091/10000], Train Loss: 7.4621, Val Loss: 29.6623\n",
      "Epoch [3092/10000], Train Loss: 7.4384, Val Loss: 29.4516\n",
      "Epoch [3093/10000], Train Loss: 7.4154, Val Loss: 29.4347\n",
      "Epoch [3094/10000], Train Loss: 7.3952, Val Loss: 29.2725\n",
      "Epoch [3095/10000], Train Loss: 7.3704, Val Loss: 29.0245\n",
      "Epoch [3096/10000], Train Loss: 7.3505, Val Loss: 29.0239\n",
      "Epoch [3097/10000], Train Loss: 7.3264, Val Loss: 28.9425\n",
      "Epoch [3098/10000], Train Loss: 7.3053, Val Loss: 28.7428\n",
      "Epoch [3099/10000], Train Loss: 7.2836, Val Loss: 28.5700\n",
      "Epoch [3100/10000], Train Loss: 7.2661, Val Loss: 28.6061\n",
      "Epoch [3101/10000], Train Loss: 7.2465, Val Loss: 28.4385\n",
      "Epoch [3102/10000], Train Loss: 7.2251, Val Loss: 28.1430\n",
      "Epoch [3103/10000], Train Loss: 7.2063, Val Loss: 28.1017\n",
      "Epoch [3104/10000], Train Loss: 7.1803, Val Loss: 28.0747\n",
      "Epoch [3105/10000], Train Loss: 7.1636, Val Loss: 27.9002\n",
      "Epoch [3106/10000], Train Loss: 7.1427, Val Loss: 27.6652\n",
      "Epoch [3107/10000], Train Loss: 7.1242, Val Loss: 27.6386\n",
      "Epoch [3108/10000], Train Loss: 7.1056, Val Loss: 27.5111\n",
      "Epoch [3109/10000], Train Loss: 7.0866, Val Loss: 27.3250\n",
      "Epoch [3110/10000], Train Loss: 7.0684, Val Loss: 27.2922\n",
      "Epoch [3111/10000], Train Loss: 7.0484, Val Loss: 27.2001\n",
      "Epoch [3112/10000], Train Loss: 7.0309, Val Loss: 27.0047\n",
      "Epoch [3113/10000], Train Loss: 7.0128, Val Loss: 26.9445\n",
      "Epoch [3114/10000], Train Loss: 6.9960, Val Loss: 26.8154\n",
      "Epoch [3115/10000], Train Loss: 6.9778, Val Loss: 26.6468\n",
      "Epoch [3116/10000], Train Loss: 6.9619, Val Loss: 26.6345\n",
      "Epoch [3117/10000], Train Loss: 6.9446, Val Loss: 26.5155\n",
      "Epoch [3118/10000], Train Loss: 6.9277, Val Loss: 26.3196\n",
      "Epoch [3119/10000], Train Loss: 6.9115, Val Loss: 26.2793\n",
      "Epoch [3120/10000], Train Loss: 6.8938, Val Loss: 26.1955\n",
      "Epoch [3121/10000], Train Loss: 6.8779, Val Loss: 26.0283\n",
      "Epoch [3122/10000], Train Loss: 6.8610, Val Loss: 25.9802\n",
      "Epoch [3123/10000], Train Loss: 6.8460, Val Loss: 25.8441\n",
      "Epoch [3124/10000], Train Loss: 6.8299, Val Loss: 25.6688\n",
      "Epoch [3125/10000], Train Loss: 6.8155, Val Loss: 25.6573\n",
      "Epoch [3126/10000], Train Loss: 6.7993, Val Loss: 25.5618\n",
      "Epoch [3127/10000], Train Loss: 6.7848, Val Loss: 25.3937\n",
      "Epoch [3128/10000], Train Loss: 6.7691, Val Loss: 25.3306\n",
      "Epoch [3129/10000], Train Loss: 6.7536, Val Loss: 25.2237\n",
      "Epoch [3130/10000], Train Loss: 6.7388, Val Loss: 25.0842\n",
      "Epoch [3131/10000], Train Loss: 6.7239, Val Loss: 25.0690\n",
      "Epoch [3132/10000], Train Loss: 6.7098, Val Loss: 24.9720\n",
      "Epoch [3133/10000], Train Loss: 6.6950, Val Loss: 24.7935\n",
      "Epoch [3134/10000], Train Loss: 6.6807, Val Loss: 24.7483\n",
      "Epoch [3135/10000], Train Loss: 6.6668, Val Loss: 24.6485\n",
      "Epoch [3136/10000], Train Loss: 6.6523, Val Loss: 24.5210\n",
      "Epoch [3137/10000], Train Loss: 6.6377, Val Loss: 24.4878\n",
      "Epoch [3138/10000], Train Loss: 6.6244, Val Loss: 24.3879\n",
      "Epoch [3139/10000], Train Loss: 6.6105, Val Loss: 24.2345\n",
      "Epoch [3140/10000], Train Loss: 6.5969, Val Loss: 24.1951\n",
      "Epoch [3141/10000], Train Loss: 6.5835, Val Loss: 24.1216\n",
      "Epoch [3142/10000], Train Loss: 6.5699, Val Loss: 23.9789\n",
      "Epoch [3143/10000], Train Loss: 6.5561, Val Loss: 23.8921\n",
      "Epoch [3144/10000], Train Loss: 6.5435, Val Loss: 23.9057\n",
      "Epoch [3145/10000], Train Loss: 6.5328, Val Loss: 23.7844\n",
      "Epoch [3146/10000], Train Loss: 6.5180, Val Loss: 23.6090\n",
      "Epoch [3147/10000], Train Loss: 6.5067, Val Loss: 23.5807\n",
      "Epoch [3148/10000], Train Loss: 6.4918, Val Loss: 23.5487\n",
      "Epoch [3149/10000], Train Loss: 6.4803, Val Loss: 23.4024\n",
      "Epoch [3150/10000], Train Loss: 6.4652, Val Loss: 23.2561\n",
      "Epoch [3151/10000], Train Loss: 6.4556, Val Loss: 23.2523\n",
      "Epoch [3152/10000], Train Loss: 6.4419, Val Loss: 23.1961\n",
      "Epoch [3153/10000], Train Loss: 6.4295, Val Loss: 23.0669\n",
      "Epoch [3154/10000], Train Loss: 6.4166, Val Loss: 23.0087\n",
      "Epoch [3155/10000], Train Loss: 6.4035, Val Loss: 22.9141\n",
      "Epoch [3156/10000], Train Loss: 6.3911, Val Loss: 22.7614\n",
      "Epoch [3157/10000], Train Loss: 6.3790, Val Loss: 22.6539\n",
      "Epoch [3158/10000], Train Loss: 6.3679, Val Loss: 22.6640\n",
      "Epoch [3159/10000], Train Loss: 6.3564, Val Loss: 22.6034\n",
      "Epoch [3160/10000], Train Loss: 6.3427, Val Loss: 22.4882\n",
      "Epoch [3161/10000], Train Loss: 6.3324, Val Loss: 22.4506\n",
      "Epoch [3162/10000], Train Loss: 6.3192, Val Loss: 22.3891\n",
      "Epoch [3163/10000], Train Loss: 6.3082, Val Loss: 22.2592\n",
      "Epoch [3164/10000], Train Loss: 6.2957, Val Loss: 22.2055\n",
      "Epoch [3165/10000], Train Loss: 6.2837, Val Loss: 22.1270\n",
      "Epoch [3166/10000], Train Loss: 6.2729, Val Loss: 22.0322\n",
      "Epoch [3167/10000], Train Loss: 6.2617, Val Loss: 21.9563\n",
      "Epoch [3168/10000], Train Loss: 6.2497, Val Loss: 21.9434\n",
      "Epoch [3169/10000], Train Loss: 6.2403, Val Loss: 21.8387\n",
      "Epoch [3170/10000], Train Loss: 6.2272, Val Loss: 21.7161\n",
      "Epoch [3171/10000], Train Loss: 6.2187, Val Loss: 21.7123\n",
      "Epoch [3172/10000], Train Loss: 6.2043, Val Loss: 21.6603\n",
      "Epoch [3173/10000], Train Loss: 6.1943, Val Loss: 21.5060\n",
      "Epoch [3174/10000], Train Loss: 6.1821, Val Loss: 21.4108\n",
      "Epoch [3175/10000], Train Loss: 6.1713, Val Loss: 21.3353\n",
      "Epoch [3176/10000], Train Loss: 6.1601, Val Loss: 21.2822\n",
      "Epoch [3177/10000], Train Loss: 6.1491, Val Loss: 21.2689\n",
      "Epoch [3178/10000], Train Loss: 6.1395, Val Loss: 21.1610\n",
      "Epoch [3179/10000], Train Loss: 6.1275, Val Loss: 21.0435\n",
      "Epoch [3180/10000], Train Loss: 6.1193, Val Loss: 21.0304\n",
      "Epoch [3181/10000], Train Loss: 6.1061, Val Loss: 20.9889\n",
      "Epoch [3182/10000], Train Loss: 6.0960, Val Loss: 20.8694\n",
      "Epoch [3183/10000], Train Loss: 6.0848, Val Loss: 20.7959\n",
      "Epoch [3184/10000], Train Loss: 6.0744, Val Loss: 20.7272\n",
      "Epoch [3185/10000], Train Loss: 6.0640, Val Loss: 20.6972\n",
      "Epoch [3186/10000], Train Loss: 6.0540, Val Loss: 20.6087\n",
      "Epoch [3187/10000], Train Loss: 6.0433, Val Loss: 20.5482\n",
      "Epoch [3188/10000], Train Loss: 6.0330, Val Loss: 20.4555\n",
      "Epoch [3189/10000], Train Loss: 6.0220, Val Loss: 20.4147\n",
      "Epoch [3190/10000], Train Loss: 6.0127, Val Loss: 20.3223\n",
      "Epoch [3191/10000], Train Loss: 6.0020, Val Loss: 20.2381\n",
      "Epoch [3192/10000], Train Loss: 5.9929, Val Loss: 20.2144\n",
      "Epoch [3193/10000], Train Loss: 5.9824, Val Loss: 20.1563\n",
      "Epoch [3194/10000], Train Loss: 5.9723, Val Loss: 20.0461\n",
      "Epoch [3195/10000], Train Loss: 5.9625, Val Loss: 20.0063\n",
      "Epoch [3196/10000], Train Loss: 5.9515, Val Loss: 19.9427\n",
      "Epoch [3197/10000], Train Loss: 5.9417, Val Loss: 19.8374\n",
      "Epoch [3198/10000], Train Loss: 5.9318, Val Loss: 19.7550\n",
      "Epoch [3199/10000], Train Loss: 5.9230, Val Loss: 19.7470\n",
      "Epoch [3200/10000], Train Loss: 5.9126, Val Loss: 19.7001\n",
      "Epoch [3201/10000], Train Loss: 5.9026, Val Loss: 19.5997\n",
      "Epoch [3202/10000], Train Loss: 5.8936, Val Loss: 19.5506\n",
      "Epoch [3203/10000], Train Loss: 5.8827, Val Loss: 19.4866\n",
      "Epoch [3204/10000], Train Loss: 5.8735, Val Loss: 19.4016\n",
      "Epoch [3205/10000], Train Loss: 5.8638, Val Loss: 19.3649\n",
      "Epoch [3206/10000], Train Loss: 5.8544, Val Loss: 19.2997\n",
      "Epoch [3207/10000], Train Loss: 5.8448, Val Loss: 19.2162\n",
      "Epoch [3208/10000], Train Loss: 5.8353, Val Loss: 19.1861\n",
      "Epoch [3209/10000], Train Loss: 5.8257, Val Loss: 19.1271\n",
      "Epoch [3210/10000], Train Loss: 5.8163, Val Loss: 19.0392\n",
      "Epoch [3211/10000], Train Loss: 5.8076, Val Loss: 18.9964\n",
      "Epoch [3212/10000], Train Loss: 5.7980, Val Loss: 18.9584\n",
      "Epoch [3213/10000], Train Loss: 5.7902, Val Loss: 18.8435\n",
      "Epoch [3214/10000], Train Loss: 5.7796, Val Loss: 18.7774\n",
      "Epoch [3215/10000], Train Loss: 5.7711, Val Loss: 18.7550\n",
      "Epoch [3216/10000], Train Loss: 5.7619, Val Loss: 18.6720\n",
      "Epoch [3217/10000], Train Loss: 5.7519, Val Loss: 18.5702\n",
      "Epoch [3218/10000], Train Loss: 5.7438, Val Loss: 18.5506\n",
      "Epoch [3219/10000], Train Loss: 5.7337, Val Loss: 18.5468\n",
      "Epoch [3220/10000], Train Loss: 5.7265, Val Loss: 18.4523\n",
      "Epoch [3221/10000], Train Loss: 5.7156, Val Loss: 18.3766\n",
      "Epoch [3222/10000], Train Loss: 5.7080, Val Loss: 18.3406\n",
      "Epoch [3223/10000], Train Loss: 5.6985, Val Loss: 18.2728\n",
      "Epoch [3224/10000], Train Loss: 5.6896, Val Loss: 18.1829\n",
      "Epoch [3225/10000], Train Loss: 5.6810, Val Loss: 18.1538\n",
      "Epoch [3226/10000], Train Loss: 5.6716, Val Loss: 18.1062\n",
      "Epoch [3227/10000], Train Loss: 5.6631, Val Loss: 18.0445\n",
      "Epoch [3228/10000], Train Loss: 5.6545, Val Loss: 17.9927\n",
      "Epoch [3229/10000], Train Loss: 5.6459, Val Loss: 17.9201\n",
      "Epoch [3230/10000], Train Loss: 5.6371, Val Loss: 17.8465\n",
      "Epoch [3231/10000], Train Loss: 5.6292, Val Loss: 17.8125\n",
      "Epoch [3232/10000], Train Loss: 5.6204, Val Loss: 17.7469\n",
      "Epoch [3233/10000], Train Loss: 5.6121, Val Loss: 17.6668\n",
      "Epoch [3234/10000], Train Loss: 5.6040, Val Loss: 17.6414\n",
      "Epoch [3235/10000], Train Loss: 5.5950, Val Loss: 17.6249\n",
      "Epoch [3236/10000], Train Loss: 5.5879, Val Loss: 17.5324\n",
      "Epoch [3237/10000], Train Loss: 5.5786, Val Loss: 17.4467\n",
      "Epoch [3238/10000], Train Loss: 5.5704, Val Loss: 17.4129\n",
      "Epoch [3239/10000], Train Loss: 5.5623, Val Loss: 17.3605\n",
      "Epoch [3240/10000], Train Loss: 5.5536, Val Loss: 17.3070\n",
      "Epoch [3241/10000], Train Loss: 5.5464, Val Loss: 17.2811\n",
      "Epoch [3242/10000], Train Loss: 5.5380, Val Loss: 17.2271\n",
      "Epoch [3243/10000], Train Loss: 5.5294, Val Loss: 17.1376\n",
      "Epoch [3244/10000], Train Loss: 5.5221, Val Loss: 17.0874\n",
      "Epoch [3245/10000], Train Loss: 5.5143, Val Loss: 17.0555\n",
      "Epoch [3246/10000], Train Loss: 5.5063, Val Loss: 16.9830\n",
      "Epoch [3247/10000], Train Loss: 5.4977, Val Loss: 16.9323\n",
      "Epoch [3248/10000], Train Loss: 5.4905, Val Loss: 16.8906\n",
      "Epoch [3249/10000], Train Loss: 5.4828, Val Loss: 16.8124\n",
      "Epoch [3250/10000], Train Loss: 5.4741, Val Loss: 16.7273\n",
      "Epoch [3251/10000], Train Loss: 5.4675, Val Loss: 16.7106\n",
      "Epoch [3252/10000], Train Loss: 5.4595, Val Loss: 16.7057\n",
      "Epoch [3253/10000], Train Loss: 5.4521, Val Loss: 16.6407\n",
      "Epoch [3254/10000], Train Loss: 5.4437, Val Loss: 16.5788\n",
      "Epoch [3255/10000], Train Loss: 5.4369, Val Loss: 16.5364\n",
      "Epoch [3256/10000], Train Loss: 5.4286, Val Loss: 16.4561\n",
      "Epoch [3257/10000], Train Loss: 5.4208, Val Loss: 16.3777\n",
      "Epoch [3258/10000], Train Loss: 5.4138, Val Loss: 16.3569\n",
      "Epoch [3259/10000], Train Loss: 5.4057, Val Loss: 16.3616\n",
      "Epoch [3260/10000], Train Loss: 5.3986, Val Loss: 16.2991\n",
      "Epoch [3261/10000], Train Loss: 5.3911, Val Loss: 16.2414\n",
      "Epoch [3262/10000], Train Loss: 5.3841, Val Loss: 16.1932\n",
      "Epoch [3263/10000], Train Loss: 5.3763, Val Loss: 16.1515\n",
      "Epoch [3264/10000], Train Loss: 5.3697, Val Loss: 16.0526\n",
      "Epoch [3265/10000], Train Loss: 5.3622, Val Loss: 15.9950\n",
      "Epoch [3266/10000], Train Loss: 5.3551, Val Loss: 15.9695\n",
      "Epoch [3267/10000], Train Loss: 5.3480, Val Loss: 15.9489\n",
      "Epoch [3268/10000], Train Loss: 5.3410, Val Loss: 15.8875\n",
      "Epoch [3269/10000], Train Loss: 5.3344, Val Loss: 15.8622\n",
      "Epoch [3270/10000], Train Loss: 5.3275, Val Loss: 15.8112\n",
      "Epoch [3271/10000], Train Loss: 5.3211, Val Loss: 15.7420\n",
      "Epoch [3272/10000], Train Loss: 5.3138, Val Loss: 15.6711\n",
      "Epoch [3273/10000], Train Loss: 5.3065, Val Loss: 15.6613\n",
      "Epoch [3274/10000], Train Loss: 5.3000, Val Loss: 15.6065\n",
      "Epoch [3275/10000], Train Loss: 5.2930, Val Loss: 15.5506\n",
      "Epoch [3276/10000], Train Loss: 5.2854, Val Loss: 15.5078\n",
      "Epoch [3277/10000], Train Loss: 5.2781, Val Loss: 15.4890\n",
      "Epoch [3278/10000], Train Loss: 5.2717, Val Loss: 15.4380\n",
      "Epoch [3279/10000], Train Loss: 5.2648, Val Loss: 15.3887\n",
      "Epoch [3280/10000], Train Loss: 5.2580, Val Loss: 15.3612\n",
      "Epoch [3281/10000], Train Loss: 5.2521, Val Loss: 15.2933\n",
      "Epoch [3282/10000], Train Loss: 5.2455, Val Loss: 15.2269\n",
      "Epoch [3283/10000], Train Loss: 5.2387, Val Loss: 15.1777\n",
      "Epoch [3284/10000], Train Loss: 5.2323, Val Loss: 15.1629\n",
      "Epoch [3285/10000], Train Loss: 5.2257, Val Loss: 15.1188\n",
      "Epoch [3286/10000], Train Loss: 5.2188, Val Loss: 15.0881\n",
      "Epoch [3287/10000], Train Loss: 5.2126, Val Loss: 15.0505\n",
      "Epoch [3288/10000], Train Loss: 5.2058, Val Loss: 14.9858\n",
      "Epoch [3289/10000], Train Loss: 5.1997, Val Loss: 14.9022\n",
      "Epoch [3290/10000], Train Loss: 5.1938, Val Loss: 14.8536\n",
      "Epoch [3291/10000], Train Loss: 5.1874, Val Loss: 14.8528\n",
      "Epoch [3292/10000], Train Loss: 5.1807, Val Loss: 14.8284\n",
      "Epoch [3293/10000], Train Loss: 5.1748, Val Loss: 14.7628\n",
      "Epoch [3294/10000], Train Loss: 5.1685, Val Loss: 14.7122\n",
      "Epoch [3295/10000], Train Loss: 5.1625, Val Loss: 14.6938\n",
      "Epoch [3296/10000], Train Loss: 5.1561, Val Loss: 14.6640\n",
      "Epoch [3297/10000], Train Loss: 5.1501, Val Loss: 14.5923\n",
      "Epoch [3298/10000], Train Loss: 5.1439, Val Loss: 14.5416\n",
      "Epoch [3299/10000], Train Loss: 5.1383, Val Loss: 14.5252\n",
      "Epoch [3300/10000], Train Loss: 5.1322, Val Loss: 14.5077\n",
      "Epoch [3301/10000], Train Loss: 5.1262, Val Loss: 14.4559\n",
      "Epoch [3302/10000], Train Loss: 5.1208, Val Loss: 14.4003\n",
      "Epoch [3303/10000], Train Loss: 5.1150, Val Loss: 14.3578\n",
      "Epoch [3304/10000], Train Loss: 5.1086, Val Loss: 14.3258\n",
      "Epoch [3305/10000], Train Loss: 5.1036, Val Loss: 14.2790\n",
      "Epoch [3306/10000], Train Loss: 5.0978, Val Loss: 14.2359\n",
      "Epoch [3307/10000], Train Loss: 5.0918, Val Loss: 14.2061\n",
      "Epoch [3308/10000], Train Loss: 5.0860, Val Loss: 14.1815\n",
      "Epoch [3309/10000], Train Loss: 5.0809, Val Loss: 14.1289\n",
      "Epoch [3310/10000], Train Loss: 5.0750, Val Loss: 14.0611\n",
      "Epoch [3311/10000], Train Loss: 5.0691, Val Loss: 14.0206\n",
      "Epoch [3312/10000], Train Loss: 5.0639, Val Loss: 14.0120\n",
      "Epoch [3313/10000], Train Loss: 5.0579, Val Loss: 14.0026\n",
      "Epoch [3314/10000], Train Loss: 5.0525, Val Loss: 13.9670\n",
      "Epoch [3315/10000], Train Loss: 5.0473, Val Loss: 13.9151\n",
      "Epoch [3316/10000], Train Loss: 5.0419, Val Loss: 13.8653\n",
      "Epoch [3317/10000], Train Loss: 5.0364, Val Loss: 13.8297\n",
      "Epoch [3318/10000], Train Loss: 5.0311, Val Loss: 13.7826\n",
      "Epoch [3319/10000], Train Loss: 5.0258, Val Loss: 13.7458\n",
      "Epoch [3320/10000], Train Loss: 5.0206, Val Loss: 13.7149\n",
      "Epoch [3321/10000], Train Loss: 5.0152, Val Loss: 13.6907\n",
      "Epoch [3322/10000], Train Loss: 5.0103, Val Loss: 13.6561\n",
      "Epoch [3323/10000], Train Loss: 5.0053, Val Loss: 13.6098\n",
      "Epoch [3324/10000], Train Loss: 5.0000, Val Loss: 13.5664\n",
      "Epoch [3325/10000], Train Loss: 4.9947, Val Loss: 13.5330\n",
      "Epoch [3326/10000], Train Loss: 4.9900, Val Loss: 13.4998\n",
      "Epoch [3327/10000], Train Loss: 4.9851, Val Loss: 13.4581\n",
      "Epoch [3328/10000], Train Loss: 4.9797, Val Loss: 13.4232\n",
      "Epoch [3329/10000], Train Loss: 4.9751, Val Loss: 13.3986\n",
      "Epoch [3330/10000], Train Loss: 4.9703, Val Loss: 13.3811\n",
      "Epoch [3331/10000], Train Loss: 4.9655, Val Loss: 13.3454\n",
      "Epoch [3332/10000], Train Loss: 4.9604, Val Loss: 13.3017\n",
      "Epoch [3333/10000], Train Loss: 4.9553, Val Loss: 13.2498\n",
      "Epoch [3334/10000], Train Loss: 4.9504, Val Loss: 13.2101\n",
      "Epoch [3335/10000], Train Loss: 4.9459, Val Loss: 13.1792\n",
      "Epoch [3336/10000], Train Loss: 4.9411, Val Loss: 13.1619\n",
      "Epoch [3337/10000], Train Loss: 4.9360, Val Loss: 13.1465\n",
      "Epoch [3338/10000], Train Loss: 4.9320, Val Loss: 13.1235\n",
      "Epoch [3339/10000], Train Loss: 4.9273, Val Loss: 13.0800\n",
      "Epoch [3340/10000], Train Loss: 4.9222, Val Loss: 13.0344\n",
      "Epoch [3341/10000], Train Loss: 4.9178, Val Loss: 12.9981\n",
      "Epoch [3342/10000], Train Loss: 4.9131, Val Loss: 12.9791\n",
      "Epoch [3343/10000], Train Loss: 4.9088, Val Loss: 12.9573\n",
      "Epoch [3344/10000], Train Loss: 4.9044, Val Loss: 12.9226\n",
      "Epoch [3345/10000], Train Loss: 4.8996, Val Loss: 12.8802\n",
      "Epoch [3346/10000], Train Loss: 4.8954, Val Loss: 12.8430\n",
      "Epoch [3347/10000], Train Loss: 4.8913, Val Loss: 12.8142\n",
      "Epoch [3348/10000], Train Loss: 4.8868, Val Loss: 12.7812\n",
      "Epoch [3349/10000], Train Loss: 4.8822, Val Loss: 12.7489\n",
      "Epoch [3350/10000], Train Loss: 4.8779, Val Loss: 12.7107\n",
      "Epoch [3351/10000], Train Loss: 4.8737, Val Loss: 12.6790\n",
      "Epoch [3352/10000], Train Loss: 4.8693, Val Loss: 12.6491\n",
      "Epoch [3353/10000], Train Loss: 4.8652, Val Loss: 12.6300\n",
      "Epoch [3354/10000], Train Loss: 4.8609, Val Loss: 12.6107\n",
      "Epoch [3355/10000], Train Loss: 4.8567, Val Loss: 12.5914\n",
      "Epoch [3356/10000], Train Loss: 4.8525, Val Loss: 12.5577\n",
      "Epoch [3357/10000], Train Loss: 4.8484, Val Loss: 12.5234\n",
      "Epoch [3358/10000], Train Loss: 4.8445, Val Loss: 12.4862\n",
      "Epoch [3359/10000], Train Loss: 4.8405, Val Loss: 12.4692\n",
      "Epoch [3360/10000], Train Loss: 4.8365, Val Loss: 12.4402\n",
      "Epoch [3361/10000], Train Loss: 4.8326, Val Loss: 12.4157\n",
      "Epoch [3362/10000], Train Loss: 4.8287, Val Loss: 12.3763\n",
      "Epoch [3363/10000], Train Loss: 4.8248, Val Loss: 12.3547\n",
      "Epoch [3364/10000], Train Loss: 4.8208, Val Loss: 12.3228\n",
      "Epoch [3365/10000], Train Loss: 4.8172, Val Loss: 12.2997\n",
      "Epoch [3366/10000], Train Loss: 4.8133, Val Loss: 12.2563\n",
      "Epoch [3367/10000], Train Loss: 4.8093, Val Loss: 12.2341\n",
      "Epoch [3368/10000], Train Loss: 4.8055, Val Loss: 12.2091\n",
      "Epoch [3369/10000], Train Loss: 4.8015, Val Loss: 12.1984\n",
      "Epoch [3370/10000], Train Loss: 4.7978, Val Loss: 12.1663\n",
      "Epoch [3371/10000], Train Loss: 4.7938, Val Loss: 12.1321\n",
      "Epoch [3372/10000], Train Loss: 4.7902, Val Loss: 12.0980\n",
      "Epoch [3373/10000], Train Loss: 4.7866, Val Loss: 12.0770\n",
      "Epoch [3374/10000], Train Loss: 4.7828, Val Loss: 12.0589\n",
      "Epoch [3375/10000], Train Loss: 4.7789, Val Loss: 12.0361\n",
      "Epoch [3376/10000], Train Loss: 4.7759, Val Loss: 12.0095\n",
      "Epoch [3377/10000], Train Loss: 4.7723, Val Loss: 11.9774\n",
      "Epoch [3378/10000], Train Loss: 4.7684, Val Loss: 11.9526\n",
      "Epoch [3379/10000], Train Loss: 4.7653, Val Loss: 11.9248\n",
      "Epoch [3380/10000], Train Loss: 4.7619, Val Loss: 11.9074\n",
      "Epoch [3381/10000], Train Loss: 4.7583, Val Loss: 11.8817\n",
      "Epoch [3382/10000], Train Loss: 4.7548, Val Loss: 11.8593\n",
      "Epoch [3383/10000], Train Loss: 4.7514, Val Loss: 11.8200\n",
      "Epoch [3384/10000], Train Loss: 4.7477, Val Loss: 11.7876\n",
      "Epoch [3385/10000], Train Loss: 4.7445, Val Loss: 11.7619\n",
      "Epoch [3386/10000], Train Loss: 4.7412, Val Loss: 11.7551\n",
      "Epoch [3387/10000], Train Loss: 4.7376, Val Loss: 11.7459\n",
      "Epoch [3388/10000], Train Loss: 4.7344, Val Loss: 11.7269\n",
      "Epoch [3389/10000], Train Loss: 4.7311, Val Loss: 11.6906\n",
      "Epoch [3390/10000], Train Loss: 4.7277, Val Loss: 11.6556\n",
      "Epoch [3391/10000], Train Loss: 4.7247, Val Loss: 11.6288\n",
      "Epoch [3392/10000], Train Loss: 4.7214, Val Loss: 11.6109\n",
      "Epoch [3393/10000], Train Loss: 4.7180, Val Loss: 11.5971\n",
      "Epoch [3394/10000], Train Loss: 4.7152, Val Loss: 11.5771\n",
      "Epoch [3395/10000], Train Loss: 4.7121, Val Loss: 11.5554\n",
      "Epoch [3396/10000], Train Loss: 4.7086, Val Loss: 11.5287\n",
      "Epoch [3397/10000], Train Loss: 4.7058, Val Loss: 11.5058\n",
      "Epoch [3398/10000], Train Loss: 4.7030, Val Loss: 11.4822\n",
      "Epoch [3399/10000], Train Loss: 4.6997, Val Loss: 11.4619\n",
      "Epoch [3400/10000], Train Loss: 4.6965, Val Loss: 11.4368\n",
      "Epoch [3401/10000], Train Loss: 4.6935, Val Loss: 11.4078\n",
      "Epoch [3402/10000], Train Loss: 4.6904, Val Loss: 11.3765\n",
      "Epoch [3403/10000], Train Loss: 4.6876, Val Loss: 11.3573\n",
      "Epoch [3404/10000], Train Loss: 4.6847, Val Loss: 11.3472\n",
      "Epoch [3405/10000], Train Loss: 4.6816, Val Loss: 11.3418\n",
      "Epoch [3406/10000], Train Loss: 4.6786, Val Loss: 11.3278\n",
      "Epoch [3407/10000], Train Loss: 4.6761, Val Loss: 11.3029\n",
      "Epoch [3408/10000], Train Loss: 4.6730, Val Loss: 11.2715\n",
      "Epoch [3409/10000], Train Loss: 4.6701, Val Loss: 11.2470\n",
      "Epoch [3410/10000], Train Loss: 4.6674, Val Loss: 11.2301\n",
      "Epoch [3411/10000], Train Loss: 4.6644, Val Loss: 11.2199\n",
      "Epoch [3412/10000], Train Loss: 4.6618, Val Loss: 11.2046\n",
      "Epoch [3413/10000], Train Loss: 4.6591, Val Loss: 11.1809\n",
      "Epoch [3414/10000], Train Loss: 4.6561, Val Loss: 11.1546\n",
      "Epoch [3415/10000], Train Loss: 4.6535, Val Loss: 11.1330\n",
      "Epoch [3416/10000], Train Loss: 4.6507, Val Loss: 11.1175\n",
      "Epoch [3417/10000], Train Loss: 4.6482, Val Loss: 11.1004\n",
      "Epoch [3418/10000], Train Loss: 4.6455, Val Loss: 11.0774\n",
      "Epoch [3419/10000], Train Loss: 4.6427, Val Loss: 11.0546\n",
      "Epoch [3420/10000], Train Loss: 4.6401, Val Loss: 11.0358\n",
      "Epoch [3421/10000], Train Loss: 4.6375, Val Loss: 11.0201\n",
      "Epoch [3422/10000], Train Loss: 4.6349, Val Loss: 11.0001\n",
      "Epoch [3423/10000], Train Loss: 4.6323, Val Loss: 10.9794\n",
      "Epoch [3424/10000], Train Loss: 4.6298, Val Loss: 10.9649\n",
      "Epoch [3425/10000], Train Loss: 4.6274, Val Loss: 10.9518\n",
      "Epoch [3426/10000], Train Loss: 4.6248, Val Loss: 10.9348\n",
      "Epoch [3427/10000], Train Loss: 4.6224, Val Loss: 10.9106\n",
      "Epoch [3428/10000], Train Loss: 4.6200, Val Loss: 10.8899\n",
      "Epoch [3429/10000], Train Loss: 4.6175, Val Loss: 10.8720\n",
      "Epoch [3430/10000], Train Loss: 4.6150, Val Loss: 10.8577\n",
      "Epoch [3431/10000], Train Loss: 4.6128, Val Loss: 10.8342\n",
      "Epoch [3432/10000], Train Loss: 4.6103, Val Loss: 10.8157\n",
      "Epoch [3433/10000], Train Loss: 4.6078, Val Loss: 10.8005\n",
      "Epoch [3434/10000], Train Loss: 4.6056, Val Loss: 10.7964\n",
      "Epoch [3435/10000], Train Loss: 4.6032, Val Loss: 10.7811\n",
      "Epoch [3436/10000], Train Loss: 4.6010, Val Loss: 10.7656\n",
      "Epoch [3437/10000], Train Loss: 4.5987, Val Loss: 10.7344\n",
      "Epoch [3438/10000], Train Loss: 4.5967, Val Loss: 10.7191\n",
      "Epoch [3439/10000], Train Loss: 4.5947, Val Loss: 10.6941\n",
      "Epoch [3440/10000], Train Loss: 4.5926, Val Loss: 10.6906\n",
      "Epoch [3441/10000], Train Loss: 4.5905, Val Loss: 10.6683\n",
      "Epoch [3442/10000], Train Loss: 4.5888, Val Loss: 10.6658\n",
      "Epoch [3443/10000], Train Loss: 4.5868, Val Loss: 10.6359\n",
      "Epoch [3444/10000], Train Loss: 4.5847, Val Loss: 10.6319\n",
      "Epoch [3445/10000], Train Loss: 4.5825, Val Loss: 10.6069\n",
      "Epoch [3446/10000], Train Loss: 4.5798, Val Loss: 10.6053\n",
      "Epoch [3447/10000], Train Loss: 4.5769, Val Loss: 10.5849\n",
      "Epoch [3448/10000], Train Loss: 4.5746, Val Loss: 10.5692\n",
      "Epoch [3449/10000], Train Loss: 4.5721, Val Loss: 10.5480\n",
      "Epoch [3450/10000], Train Loss: 4.5697, Val Loss: 10.5297\n",
      "Epoch [3451/10000], Train Loss: 4.5679, Val Loss: 10.5262\n",
      "Epoch [3452/10000], Train Loss: 4.5660, Val Loss: 10.5121\n",
      "Epoch [3453/10000], Train Loss: 4.5643, Val Loss: 10.5063\n",
      "Epoch [3454/10000], Train Loss: 4.5622, Val Loss: 10.4783\n",
      "Epoch [3455/10000], Train Loss: 4.5599, Val Loss: 10.4613\n",
      "Epoch [3456/10000], Train Loss: 4.5577, Val Loss: 10.4402\n",
      "Epoch [3457/10000], Train Loss: 4.5554, Val Loss: 10.4281\n",
      "Epoch [3458/10000], Train Loss: 4.5533, Val Loss: 10.4186\n",
      "Epoch [3459/10000], Train Loss: 4.5517, Val Loss: 10.4019\n",
      "Epoch [3460/10000], Train Loss: 4.5498, Val Loss: 10.3919\n",
      "Epoch [3461/10000], Train Loss: 4.5477, Val Loss: 10.3742\n",
      "Epoch [3462/10000], Train Loss: 4.5459, Val Loss: 10.3675\n",
      "Epoch [3463/10000], Train Loss: 4.5439, Val Loss: 10.3526\n",
      "Epoch [3464/10000], Train Loss: 4.5417, Val Loss: 10.3419\n",
      "Epoch [3465/10000], Train Loss: 4.5399, Val Loss: 10.3251\n",
      "Epoch [3466/10000], Train Loss: 4.5379, Val Loss: 10.3058\n",
      "Epoch [3467/10000], Train Loss: 4.5361, Val Loss: 10.2928\n",
      "Epoch [3468/10000], Train Loss: 4.5343, Val Loss: 10.2795\n",
      "Epoch [3469/10000], Train Loss: 4.5324, Val Loss: 10.2750\n",
      "Epoch [3470/10000], Train Loss: 4.5305, Val Loss: 10.2600\n",
      "Epoch [3471/10000], Train Loss: 4.5287, Val Loss: 10.2454\n",
      "Epoch [3472/10000], Train Loss: 4.5268, Val Loss: 10.2299\n",
      "Epoch [3473/10000], Train Loss: 4.5250, Val Loss: 10.2194\n",
      "Epoch [3474/10000], Train Loss: 4.5232, Val Loss: 10.2117\n",
      "Epoch [3475/10000], Train Loss: 4.5214, Val Loss: 10.2012\n",
      "Epoch [3476/10000], Train Loss: 4.5197, Val Loss: 10.1931\n",
      "Epoch [3477/10000], Train Loss: 4.5179, Val Loss: 10.1815\n",
      "Epoch [3478/10000], Train Loss: 4.5162, Val Loss: 10.1729\n",
      "Epoch [3479/10000], Train Loss: 4.5145, Val Loss: 10.1584\n",
      "Epoch [3480/10000], Train Loss: 4.5127, Val Loss: 10.1475\n",
      "Epoch [3481/10000], Train Loss: 4.5110, Val Loss: 10.1387\n",
      "Epoch [3482/10000], Train Loss: 4.5093, Val Loss: 10.1296\n",
      "Epoch [3483/10000], Train Loss: 4.5076, Val Loss: 10.1196\n",
      "Epoch [3484/10000], Train Loss: 4.5059, Val Loss: 10.1047\n",
      "Epoch [3485/10000], Train Loss: 4.5044, Val Loss: 10.0926\n",
      "Epoch [3486/10000], Train Loss: 4.5027, Val Loss: 10.0814\n",
      "Epoch [3487/10000], Train Loss: 4.5011, Val Loss: 10.0729\n",
      "Epoch [3488/10000], Train Loss: 4.4994, Val Loss: 10.0642\n",
      "Epoch [3489/10000], Train Loss: 4.4980, Val Loss: 10.0550\n",
      "Epoch [3490/10000], Train Loss: 4.4963, Val Loss: 10.0456\n",
      "Epoch [3491/10000], Train Loss: 4.4946, Val Loss: 10.0360\n",
      "Epoch [3492/10000], Train Loss: 4.4931, Val Loss: 10.0281\n",
      "Epoch [3493/10000], Train Loss: 4.4915, Val Loss: 10.0192\n",
      "Epoch [3494/10000], Train Loss: 4.4899, Val Loss: 10.0099\n",
      "Epoch [3495/10000], Train Loss: 4.4884, Val Loss: 9.9964\n",
      "Epoch [3496/10000], Train Loss: 4.4867, Val Loss: 9.9831\n",
      "Epoch [3497/10000], Train Loss: 4.4853, Val Loss: 9.9728\n",
      "Epoch [3498/10000], Train Loss: 4.4839, Val Loss: 9.9668\n",
      "Epoch [3499/10000], Train Loss: 4.4823, Val Loss: 9.9612\n",
      "Epoch [3500/10000], Train Loss: 4.4808, Val Loss: 9.9524\n",
      "Epoch [3501/10000], Train Loss: 4.4793, Val Loss: 9.9403\n",
      "Epoch [3502/10000], Train Loss: 4.4777, Val Loss: 9.9286\n",
      "Epoch [3503/10000], Train Loss: 4.4763, Val Loss: 9.9225\n",
      "Epoch [3504/10000], Train Loss: 4.4748, Val Loss: 9.9174\n",
      "Epoch [3505/10000], Train Loss: 4.4733, Val Loss: 9.9125\n",
      "Epoch [3506/10000], Train Loss: 4.4719, Val Loss: 9.9046\n",
      "Epoch [3507/10000], Train Loss: 4.4704, Val Loss: 9.8950\n",
      "Epoch [3508/10000], Train Loss: 4.4690, Val Loss: 9.8838\n",
      "Epoch [3509/10000], Train Loss: 4.4676, Val Loss: 9.8728\n",
      "Epoch [3510/10000], Train Loss: 4.4662, Val Loss: 9.8650\n",
      "Epoch [3511/10000], Train Loss: 4.4648, Val Loss: 9.8597\n",
      "Epoch [3512/10000], Train Loss: 4.4634, Val Loss: 9.8518\n",
      "Epoch [3513/10000], Train Loss: 4.4620, Val Loss: 9.8411\n",
      "Epoch [3514/10000], Train Loss: 4.4607, Val Loss: 9.8306\n",
      "Epoch [3515/10000], Train Loss: 4.4593, Val Loss: 9.8224\n",
      "Epoch [3516/10000], Train Loss: 4.4579, Val Loss: 9.8141\n",
      "Epoch [3517/10000], Train Loss: 4.4565, Val Loss: 9.8050\n",
      "Epoch [3518/10000], Train Loss: 4.4553, Val Loss: 9.7982\n",
      "Epoch [3519/10000], Train Loss: 4.4539, Val Loss: 9.7932\n",
      "Epoch [3520/10000], Train Loss: 4.4525, Val Loss: 9.7883\n",
      "Epoch [3521/10000], Train Loss: 4.4513, Val Loss: 9.7808\n",
      "Epoch [3522/10000], Train Loss: 4.4500, Val Loss: 9.7725\n",
      "Epoch [3523/10000], Train Loss: 4.4486, Val Loss: 9.7632\n",
      "Epoch [3524/10000], Train Loss: 4.4473, Val Loss: 9.7536\n",
      "Epoch [3525/10000], Train Loss: 4.4461, Val Loss: 9.7447\n",
      "Epoch [3526/10000], Train Loss: 4.4448, Val Loss: 9.7382\n",
      "Epoch [3527/10000], Train Loss: 4.4435, Val Loss: 9.7346\n",
      "Epoch [3528/10000], Train Loss: 4.4422, Val Loss: 9.7305\n",
      "Epoch [3529/10000], Train Loss: 4.4410, Val Loss: 9.7239\n",
      "Epoch [3530/10000], Train Loss: 4.4397, Val Loss: 9.7138\n",
      "Epoch [3531/10000], Train Loss: 4.4384, Val Loss: 9.7023\n",
      "Epoch [3532/10000], Train Loss: 4.4372, Val Loss: 9.6926\n",
      "Epoch [3533/10000], Train Loss: 4.4360, Val Loss: 9.6882\n",
      "Epoch [3534/10000], Train Loss: 4.4348, Val Loss: 9.6853\n",
      "Epoch [3535/10000], Train Loss: 4.4335, Val Loss: 9.6817\n",
      "Epoch [3536/10000], Train Loss: 4.4323, Val Loss: 9.6741\n",
      "Epoch [3537/10000], Train Loss: 4.4311, Val Loss: 9.6666\n",
      "Epoch [3538/10000], Train Loss: 4.4299, Val Loss: 9.6586\n",
      "Epoch [3539/10000], Train Loss: 4.4287, Val Loss: 9.6501\n",
      "Epoch [3540/10000], Train Loss: 4.4275, Val Loss: 9.6433\n",
      "Epoch [3541/10000], Train Loss: 4.4264, Val Loss: 9.6378\n",
      "Epoch [3542/10000], Train Loss: 4.4252, Val Loss: 9.6327\n",
      "Epoch [3543/10000], Train Loss: 4.4240, Val Loss: 9.6243\n",
      "Epoch [3544/10000], Train Loss: 4.4228, Val Loss: 9.6170\n",
      "Epoch [3545/10000], Train Loss: 4.4217, Val Loss: 9.6106\n",
      "Epoch [3546/10000], Train Loss: 4.4206, Val Loss: 9.6052\n",
      "Epoch [3547/10000], Train Loss: 4.4194, Val Loss: 9.5992\n",
      "Epoch [3548/10000], Train Loss: 4.4183, Val Loss: 9.5929\n",
      "Epoch [3549/10000], Train Loss: 4.4172, Val Loss: 9.5859\n",
      "Epoch [3550/10000], Train Loss: 4.4161, Val Loss: 9.5777\n",
      "Epoch [3551/10000], Train Loss: 4.4149, Val Loss: 9.5700\n",
      "Epoch [3552/10000], Train Loss: 4.4138, Val Loss: 9.5653\n",
      "Epoch [3553/10000], Train Loss: 4.4128, Val Loss: 9.5612\n",
      "Epoch [3554/10000], Train Loss: 4.4116, Val Loss: 9.5555\n",
      "Epoch [3555/10000], Train Loss: 4.4106, Val Loss: 9.5480\n",
      "Epoch [3556/10000], Train Loss: 4.4096, Val Loss: 9.5409\n",
      "Epoch [3557/10000], Train Loss: 4.4085, Val Loss: 9.5333\n",
      "Epoch [3558/10000], Train Loss: 4.4074, Val Loss: 9.5243\n",
      "Epoch [3559/10000], Train Loss: 4.4063, Val Loss: 9.5153\n",
      "Epoch [3560/10000], Train Loss: 4.4052, Val Loss: 9.5117\n",
      "Epoch [3561/10000], Train Loss: 4.4043, Val Loss: 9.5116\n",
      "Epoch [3562/10000], Train Loss: 4.4031, Val Loss: 9.5104\n",
      "Epoch [3563/10000], Train Loss: 4.4021, Val Loss: 9.5051\n",
      "Epoch [3564/10000], Train Loss: 4.4011, Val Loss: 9.4988\n",
      "Epoch [3565/10000], Train Loss: 4.4001, Val Loss: 9.4909\n",
      "Epoch [3566/10000], Train Loss: 4.3990, Val Loss: 9.4811\n",
      "Epoch [3567/10000], Train Loss: 4.3979, Val Loss: 9.4701\n",
      "Epoch [3568/10000], Train Loss: 4.3969, Val Loss: 9.4664\n",
      "Epoch [3569/10000], Train Loss: 4.3960, Val Loss: 9.4673\n",
      "Epoch [3570/10000], Train Loss: 4.3949, Val Loss: 9.4687\n",
      "Epoch [3571/10000], Train Loss: 4.3939, Val Loss: 9.4640\n",
      "Epoch [3572/10000], Train Loss: 4.3930, Val Loss: 9.4590\n",
      "Epoch [3573/10000], Train Loss: 4.3920, Val Loss: 9.4505\n",
      "Epoch [3574/10000], Train Loss: 4.3910, Val Loss: 9.4419\n",
      "Epoch [3575/10000], Train Loss: 4.3899, Val Loss: 9.4291\n",
      "Epoch [3576/10000], Train Loss: 4.3890, Val Loss: 9.4252\n",
      "Epoch [3577/10000], Train Loss: 4.3881, Val Loss: 9.4224\n",
      "Epoch [3578/10000], Train Loss: 4.3871, Val Loss: 9.4276\n",
      "Epoch [3579/10000], Train Loss: 4.3862, Val Loss: 9.4234\n",
      "Epoch [3580/10000], Train Loss: 4.3855, Val Loss: 9.4254\n",
      "Epoch [3581/10000], Train Loss: 4.3847, Val Loss: 9.4135\n",
      "Epoch [3582/10000], Train Loss: 4.3840, Val Loss: 9.4129\n",
      "Epoch [3583/10000], Train Loss: 4.3834, Val Loss: 9.3972\n",
      "Epoch [3584/10000], Train Loss: 4.3829, Val Loss: 9.4008\n",
      "Epoch [3585/10000], Train Loss: 4.3824, Val Loss: 9.3851\n",
      "Epoch [3586/10000], Train Loss: 4.3818, Val Loss: 9.3920\n",
      "Epoch [3587/10000], Train Loss: 4.3808, Val Loss: 9.3796\n",
      "Epoch [3588/10000], Train Loss: 4.3795, Val Loss: 9.3862\n",
      "Epoch [3589/10000], Train Loss: 4.3778, Val Loss: 9.3744\n",
      "Epoch [3590/10000], Train Loss: 4.3762, Val Loss: 9.3713\n",
      "Epoch [3591/10000], Train Loss: 4.3748, Val Loss: 9.3658\n",
      "Epoch [3592/10000], Train Loss: 4.3738, Val Loss: 9.3575\n",
      "Epoch [3593/10000], Train Loss: 4.3732, Val Loss: 9.3545\n",
      "Epoch [3594/10000], Train Loss: 4.3726, Val Loss: 9.3419\n",
      "Epoch [3595/10000], Train Loss: 4.3719, Val Loss: 9.3459\n",
      "Epoch [3596/10000], Train Loss: 4.3709, Val Loss: 9.3402\n",
      "Epoch [3597/10000], Train Loss: 4.3698, Val Loss: 9.3406\n",
      "Epoch [3598/10000], Train Loss: 4.3686, Val Loss: 9.3334\n",
      "Epoch [3599/10000], Train Loss: 4.3675, Val Loss: 9.3292\n",
      "Epoch [3600/10000], Train Loss: 4.3667, Val Loss: 9.3285\n",
      "Epoch [3601/10000], Train Loss: 4.3659, Val Loss: 9.3204\n",
      "Epoch [3602/10000], Train Loss: 4.3653, Val Loss: 9.3177\n",
      "Epoch [3603/10000], Train Loss: 4.3643, Val Loss: 9.3079\n",
      "Epoch [3604/10000], Train Loss: 4.3635, Val Loss: 9.3060\n",
      "Epoch [3605/10000], Train Loss: 4.3625, Val Loss: 9.2988\n",
      "Epoch [3606/10000], Train Loss: 4.3615, Val Loss: 9.2924\n",
      "Epoch [3607/10000], Train Loss: 4.3606, Val Loss: 9.2869\n",
      "Epoch [3608/10000], Train Loss: 4.3598, Val Loss: 9.2792\n",
      "Epoch [3609/10000], Train Loss: 4.3590, Val Loss: 9.2785\n",
      "Epoch [3610/10000], Train Loss: 4.3582, Val Loss: 9.2751\n",
      "Epoch [3611/10000], Train Loss: 4.3574, Val Loss: 9.2781\n",
      "Epoch [3612/10000], Train Loss: 4.3564, Val Loss: 9.2761\n",
      "Epoch [3613/10000], Train Loss: 4.3555, Val Loss: 9.2745\n",
      "Epoch [3614/10000], Train Loss: 4.3547, Val Loss: 9.2709\n",
      "Epoch [3615/10000], Train Loss: 4.3538, Val Loss: 9.2651\n",
      "Epoch [3616/10000], Train Loss: 4.3530, Val Loss: 9.2620\n",
      "Epoch [3617/10000], Train Loss: 4.3523, Val Loss: 9.2567\n",
      "Epoch [3618/10000], Train Loss: 4.3514, Val Loss: 9.2556\n",
      "Epoch [3619/10000], Train Loss: 4.3506, Val Loss: 9.2508\n",
      "Epoch [3620/10000], Train Loss: 4.3498, Val Loss: 9.2471\n",
      "Epoch [3621/10000], Train Loss: 4.3490, Val Loss: 9.2409\n",
      "Epoch [3622/10000], Train Loss: 4.3481, Val Loss: 9.2333\n",
      "Epoch [3623/10000], Train Loss: 4.3473, Val Loss: 9.2275\n",
      "Epoch [3624/10000], Train Loss: 4.3465, Val Loss: 9.2234\n",
      "Epoch [3625/10000], Train Loss: 4.3458, Val Loss: 9.2247\n",
      "Epoch [3626/10000], Train Loss: 4.3449, Val Loss: 9.2239\n",
      "Epoch [3627/10000], Train Loss: 4.3441, Val Loss: 9.2239\n",
      "Epoch [3628/10000], Train Loss: 4.3433, Val Loss: 9.2211\n",
      "Epoch [3629/10000], Train Loss: 4.3425, Val Loss: 9.2179\n",
      "Epoch [3630/10000], Train Loss: 4.3417, Val Loss: 9.2130\n",
      "Epoch [3631/10000], Train Loss: 4.3409, Val Loss: 9.2085\n",
      "Epoch [3632/10000], Train Loss: 4.3403, Val Loss: 9.2074\n",
      "Epoch [3633/10000], Train Loss: 4.3394, Val Loss: 9.2048\n",
      "Epoch [3634/10000], Train Loss: 4.3386, Val Loss: 9.2015\n",
      "Epoch [3635/10000], Train Loss: 4.3379, Val Loss: 9.1951\n",
      "Epoch [3636/10000], Train Loss: 4.3371, Val Loss: 9.1897\n",
      "Epoch [3637/10000], Train Loss: 4.3363, Val Loss: 9.1827\n",
      "Epoch [3638/10000], Train Loss: 4.3355, Val Loss: 9.1760\n",
      "Epoch [3639/10000], Train Loss: 4.3348, Val Loss: 9.1732\n",
      "Epoch [3640/10000], Train Loss: 4.3340, Val Loss: 9.1745\n",
      "Epoch [3641/10000], Train Loss: 4.3333, Val Loss: 9.1774\n",
      "Epoch [3642/10000], Train Loss: 4.3325, Val Loss: 9.1761\n",
      "Epoch [3643/10000], Train Loss: 4.3318, Val Loss: 9.1743\n",
      "Epoch [3644/10000], Train Loss: 4.3310, Val Loss: 9.1707\n",
      "Epoch [3645/10000], Train Loss: 4.3303, Val Loss: 9.1663\n",
      "Epoch [3646/10000], Train Loss: 4.3295, Val Loss: 9.1599\n",
      "Epoch [3647/10000], Train Loss: 4.3288, Val Loss: 9.1556\n",
      "Epoch [3648/10000], Train Loss: 4.3280, Val Loss: 9.1541\n",
      "Epoch [3649/10000], Train Loss: 4.3273, Val Loss: 9.1538\n",
      "Epoch [3650/10000], Train Loss: 4.3265, Val Loss: 9.1530\n",
      "Epoch [3651/10000], Train Loss: 4.3258, Val Loss: 9.1503\n",
      "Epoch [3652/10000], Train Loss: 4.3251, Val Loss: 9.1455\n",
      "Epoch [3653/10000], Train Loss: 4.3244, Val Loss: 9.1394\n",
      "Epoch [3654/10000], Train Loss: 4.3236, Val Loss: 9.1341\n",
      "Epoch [3655/10000], Train Loss: 4.3229, Val Loss: 9.1304\n",
      "Epoch [3656/10000], Train Loss: 4.3222, Val Loss: 9.1280\n",
      "Epoch [3657/10000], Train Loss: 4.3214, Val Loss: 9.1279\n",
      "Epoch [3658/10000], Train Loss: 4.3207, Val Loss: 9.1289\n",
      "Epoch [3659/10000], Train Loss: 4.3200, Val Loss: 9.1288\n",
      "Epoch [3660/10000], Train Loss: 4.3193, Val Loss: 9.1266\n",
      "Epoch [3661/10000], Train Loss: 4.3186, Val Loss: 9.1228\n",
      "Epoch [3662/10000], Train Loss: 4.3179, Val Loss: 9.1181\n",
      "Epoch [3663/10000], Train Loss: 4.3171, Val Loss: 9.1126\n",
      "Epoch [3664/10000], Train Loss: 4.3165, Val Loss: 9.1087\n",
      "Epoch [3665/10000], Train Loss: 4.3158, Val Loss: 9.1065\n",
      "Epoch [3666/10000], Train Loss: 4.3151, Val Loss: 9.1068\n",
      "Epoch [3667/10000], Train Loss: 4.3143, Val Loss: 9.1064\n",
      "Epoch [3668/10000], Train Loss: 4.3137, Val Loss: 9.1051\n",
      "Epoch [3669/10000], Train Loss: 4.3129, Val Loss: 9.1016\n",
      "Epoch [3670/10000], Train Loss: 4.3123, Val Loss: 9.0982\n",
      "Epoch [3671/10000], Train Loss: 4.3116, Val Loss: 9.0941\n",
      "Epoch [3672/10000], Train Loss: 4.3109, Val Loss: 9.0911\n",
      "Epoch [3673/10000], Train Loss: 4.3102, Val Loss: 9.0888\n",
      "Epoch [3674/10000], Train Loss: 4.3095, Val Loss: 9.0870\n",
      "Epoch [3675/10000], Train Loss: 4.3088, Val Loss: 9.0846\n",
      "Epoch [3676/10000], Train Loss: 4.3081, Val Loss: 9.0826\n",
      "Epoch [3677/10000], Train Loss: 4.3075, Val Loss: 9.0804\n",
      "Epoch [3678/10000], Train Loss: 4.3068, Val Loss: 9.0784\n",
      "Epoch [3679/10000], Train Loss: 4.3061, Val Loss: 9.0755\n",
      "Epoch [3680/10000], Train Loss: 4.3054, Val Loss: 9.0717\n",
      "Epoch [3681/10000], Train Loss: 4.3047, Val Loss: 9.0673\n",
      "Epoch [3682/10000], Train Loss: 4.3040, Val Loss: 9.0653\n",
      "Epoch [3683/10000], Train Loss: 4.3034, Val Loss: 9.0652\n",
      "Epoch [3684/10000], Train Loss: 4.3027, Val Loss: 9.0649\n",
      "Epoch [3685/10000], Train Loss: 4.3020, Val Loss: 9.0639\n",
      "Epoch [3686/10000], Train Loss: 4.3014, Val Loss: 9.0616\n",
      "Epoch [3687/10000], Train Loss: 4.3007, Val Loss: 9.0582\n",
      "Epoch [3688/10000], Train Loss: 4.3000, Val Loss: 9.0531\n",
      "Epoch [3689/10000], Train Loss: 4.2994, Val Loss: 9.0507\n",
      "Epoch [3690/10000], Train Loss: 4.2987, Val Loss: 9.0502\n",
      "Epoch [3691/10000], Train Loss: 4.2981, Val Loss: 9.0505\n",
      "Epoch [3692/10000], Train Loss: 4.2974, Val Loss: 9.0488\n",
      "Epoch [3693/10000], Train Loss: 4.2968, Val Loss: 9.0467\n",
      "Epoch [3694/10000], Train Loss: 4.2961, Val Loss: 9.0438\n",
      "Epoch [3695/10000], Train Loss: 4.2954, Val Loss: 9.0401\n",
      "Epoch [3696/10000], Train Loss: 4.2948, Val Loss: 9.0375\n",
      "Epoch [3697/10000], Train Loss: 4.2941, Val Loss: 9.0368\n",
      "Epoch [3698/10000], Train Loss: 4.2935, Val Loss: 9.0363\n",
      "Epoch [3699/10000], Train Loss: 4.2928, Val Loss: 9.0344\n",
      "Epoch [3700/10000], Train Loss: 4.2922, Val Loss: 9.0319\n",
      "Epoch [3701/10000], Train Loss: 4.2915, Val Loss: 9.0292\n",
      "Epoch [3702/10000], Train Loss: 4.2909, Val Loss: 9.0262\n",
      "Epoch [3703/10000], Train Loss: 4.2902, Val Loss: 9.0241\n",
      "Epoch [3704/10000], Train Loss: 4.2896, Val Loss: 9.0232\n",
      "Epoch [3705/10000], Train Loss: 4.2890, Val Loss: 9.0221\n",
      "Epoch [3706/10000], Train Loss: 4.2883, Val Loss: 9.0200\n",
      "Epoch [3707/10000], Train Loss: 4.2877, Val Loss: 9.0173\n",
      "Epoch [3708/10000], Train Loss: 4.2871, Val Loss: 9.0146\n",
      "Epoch [3709/10000], Train Loss: 4.2864, Val Loss: 9.0112\n",
      "Epoch [3710/10000], Train Loss: 4.2858, Val Loss: 9.0094\n",
      "Epoch [3711/10000], Train Loss: 4.2852, Val Loss: 9.0092\n",
      "Epoch [3712/10000], Train Loss: 4.2845, Val Loss: 9.0104\n",
      "Epoch [3713/10000], Train Loss: 4.2839, Val Loss: 9.0089\n",
      "Epoch [3714/10000], Train Loss: 4.2833, Val Loss: 9.0069\n",
      "Epoch [3715/10000], Train Loss: 4.2827, Val Loss: 9.0036\n",
      "Epoch [3716/10000], Train Loss: 4.2821, Val Loss: 9.0008\n",
      "Epoch [3717/10000], Train Loss: 4.2814, Val Loss: 8.9957\n",
      "Epoch [3718/10000], Train Loss: 4.2808, Val Loss: 8.9945\n",
      "Epoch [3719/10000], Train Loss: 4.2802, Val Loss: 8.9947\n",
      "Epoch [3720/10000], Train Loss: 4.2796, Val Loss: 8.9978\n",
      "Epoch [3721/10000], Train Loss: 4.2790, Val Loss: 8.9957\n",
      "Epoch [3722/10000], Train Loss: 4.2784, Val Loss: 8.9951\n",
      "Epoch [3723/10000], Train Loss: 4.2778, Val Loss: 8.9905\n",
      "Epoch [3724/10000], Train Loss: 4.2772, Val Loss: 8.9886\n",
      "Epoch [3725/10000], Train Loss: 4.2766, Val Loss: 8.9809\n",
      "Epoch [3726/10000], Train Loss: 4.2761, Val Loss: 8.9815\n",
      "Epoch [3727/10000], Train Loss: 4.2755, Val Loss: 8.9802\n",
      "Epoch [3728/10000], Train Loss: 4.2750, Val Loss: 8.9863\n",
      "Epoch [3729/10000], Train Loss: 4.2745, Val Loss: 8.9818\n",
      "Epoch [3730/10000], Train Loss: 4.2741, Val Loss: 8.9844\n",
      "Epoch [3731/10000], Train Loss: 4.2736, Val Loss: 8.9770\n",
      "Epoch [3732/10000], Train Loss: 4.2732, Val Loss: 8.9777\n",
      "Epoch [3733/10000], Train Loss: 4.2726, Val Loss: 8.9664\n",
      "Epoch [3734/10000], Train Loss: 4.2721, Val Loss: 8.9693\n",
      "Epoch [3735/10000], Train Loss: 4.2714, Val Loss: 8.9659\n",
      "Epoch [3736/10000], Train Loss: 4.2707, Val Loss: 8.9736\n",
      "Epoch [3737/10000], Train Loss: 4.2699, Val Loss: 8.9708\n",
      "Epoch [3738/10000], Train Loss: 4.2690, Val Loss: 8.9729\n",
      "Epoch [3739/10000], Train Loss: 4.2682, Val Loss: 8.9686\n",
      "Epoch [3740/10000], Train Loss: 4.2674, Val Loss: 8.9643\n",
      "Epoch [3741/10000], Train Loss: 4.2668, Val Loss: 8.9584\n",
      "Epoch [3742/10000], Train Loss: 4.2662, Val Loss: 8.9523\n",
      "Epoch [3743/10000], Train Loss: 4.2657, Val Loss: 8.9542\n",
      "Epoch [3744/10000], Train Loss: 4.2652, Val Loss: 8.9540\n",
      "Epoch [3745/10000], Train Loss: 4.2647, Val Loss: 8.9603\n",
      "Epoch [3746/10000], Train Loss: 4.2641, Val Loss: 8.9596\n",
      "Epoch [3747/10000], Train Loss: 4.2635, Val Loss: 8.9613\n",
      "Epoch [3748/10000], Train Loss: 4.2628, Val Loss: 8.9549\n",
      "Epoch [3749/10000], Train Loss: 4.2621, Val Loss: 8.9500\n",
      "Epoch [3750/10000], Train Loss: 4.2615, Val Loss: 8.9432\n",
      "Epoch [3751/10000], Train Loss: 4.2608, Val Loss: 8.9395\n",
      "Epoch [3752/10000], Train Loss: 4.2602, Val Loss: 8.9399\n",
      "Epoch [3753/10000], Train Loss: 4.2597, Val Loss: 8.9419\n",
      "Epoch [3754/10000], Train Loss: 4.2591, Val Loss: 8.9475\n",
      "Epoch [3755/10000], Train Loss: 4.2585, Val Loss: 8.9487\n",
      "Epoch [3756/10000], Train Loss: 4.2580, Val Loss: 8.9510\n",
      "Epoch [3757/10000], Train Loss: 4.2574, Val Loss: 8.9471\n",
      "Epoch [3758/10000], Train Loss: 4.2568, Val Loss: 8.9435\n",
      "Epoch [3759/10000], Train Loss: 4.2562, Val Loss: 8.9370\n",
      "Epoch [3760/10000], Train Loss: 4.2556, Val Loss: 8.9342\n",
      "Epoch [3761/10000], Train Loss: 4.2550, Val Loss: 8.9321\n",
      "Epoch [3762/10000], Train Loss: 4.2544, Val Loss: 8.9315\n",
      "Epoch [3763/10000], Train Loss: 4.2538, Val Loss: 8.9331\n",
      "Epoch [3764/10000], Train Loss: 4.2532, Val Loss: 8.9350\n",
      "Epoch [3765/10000], Train Loss: 4.2527, Val Loss: 8.9374\n",
      "Epoch [3766/10000], Train Loss: 4.2521, Val Loss: 8.9352\n",
      "Epoch [3767/10000], Train Loss: 4.2515, Val Loss: 8.9320\n",
      "Epoch [3768/10000], Train Loss: 4.2510, Val Loss: 8.9264\n",
      "Epoch [3769/10000], Train Loss: 4.2504, Val Loss: 8.9229\n",
      "Epoch [3770/10000], Train Loss: 4.2498, Val Loss: 8.9188\n",
      "Epoch [3771/10000], Train Loss: 4.2492, Val Loss: 8.9175\n",
      "Epoch [3772/10000], Train Loss: 4.2486, Val Loss: 8.9182\n",
      "Epoch [3773/10000], Train Loss: 4.2480, Val Loss: 8.9207\n",
      "Epoch [3774/10000], Train Loss: 4.2475, Val Loss: 8.9222\n",
      "Epoch [3775/10000], Train Loss: 4.2469, Val Loss: 8.9220\n",
      "Epoch [3776/10000], Train Loss: 4.2463, Val Loss: 8.9216\n",
      "Epoch [3777/10000], Train Loss: 4.2458, Val Loss: 8.9202\n",
      "Epoch [3778/10000], Train Loss: 4.2452, Val Loss: 8.9187\n",
      "Epoch [3779/10000], Train Loss: 4.2446, Val Loss: 8.9154\n",
      "Epoch [3780/10000], Train Loss: 4.2441, Val Loss: 8.9142\n",
      "Epoch [3781/10000], Train Loss: 4.2435, Val Loss: 8.9124\n",
      "Epoch [3782/10000], Train Loss: 4.2430, Val Loss: 8.9111\n",
      "Epoch [3783/10000], Train Loss: 4.2424, Val Loss: 8.9079\n",
      "Epoch [3784/10000], Train Loss: 4.2418, Val Loss: 8.9076\n",
      "Epoch [3785/10000], Train Loss: 4.2412, Val Loss: 8.9075\n",
      "Epoch [3786/10000], Train Loss: 4.2407, Val Loss: 8.9085\n",
      "Epoch [3787/10000], Train Loss: 4.2401, Val Loss: 8.9082\n",
      "Epoch [3788/10000], Train Loss: 4.2396, Val Loss: 8.9088\n",
      "Epoch [3789/10000], Train Loss: 4.2390, Val Loss: 8.9067\n",
      "Epoch [3790/10000], Train Loss: 4.2385, Val Loss: 8.9035\n",
      "Epoch [3791/10000], Train Loss: 4.2379, Val Loss: 8.8995\n",
      "Epoch [3792/10000], Train Loss: 4.2373, Val Loss: 8.8966\n",
      "Epoch [3793/10000], Train Loss: 4.2368, Val Loss: 8.8935\n",
      "Epoch [3794/10000], Train Loss: 4.2362, Val Loss: 8.8925\n",
      "Epoch [3795/10000], Train Loss: 4.2356, Val Loss: 8.8933\n",
      "Epoch [3796/10000], Train Loss: 4.2351, Val Loss: 8.8955\n",
      "Epoch [3797/10000], Train Loss: 4.2345, Val Loss: 8.8964\n",
      "Epoch [3798/10000], Train Loss: 4.2340, Val Loss: 8.8967\n",
      "Epoch [3799/10000], Train Loss: 4.2334, Val Loss: 8.8963\n",
      "Epoch [3800/10000], Train Loss: 4.2328, Val Loss: 8.8960\n",
      "Epoch [3801/10000], Train Loss: 4.2323, Val Loss: 8.8955\n",
      "Epoch [3802/10000], Train Loss: 4.2317, Val Loss: 8.8963\n",
      "Epoch [3803/10000], Train Loss: 4.2312, Val Loss: 8.8976\n",
      "Epoch [3804/10000], Train Loss: 4.2306, Val Loss: 8.8970\n",
      "Epoch [3805/10000], Train Loss: 4.2301, Val Loss: 8.8946\n",
      "Epoch [3806/10000], Train Loss: 4.2296, Val Loss: 8.8915\n",
      "Epoch [3807/10000], Train Loss: 4.2290, Val Loss: 8.8882\n",
      "Epoch [3808/10000], Train Loss: 4.2284, Val Loss: 8.8842\n",
      "Epoch [3809/10000], Train Loss: 4.2279, Val Loss: 8.8830\n",
      "Epoch [3810/10000], Train Loss: 4.2274, Val Loss: 8.8841\n",
      "Epoch [3811/10000], Train Loss: 4.2268, Val Loss: 8.8873\n",
      "Epoch [3812/10000], Train Loss: 4.2262, Val Loss: 8.8885\n",
      "Epoch [3813/10000], Train Loss: 4.2257, Val Loss: 8.8904\n",
      "Epoch [3814/10000], Train Loss: 4.2251, Val Loss: 8.8903\n",
      "Epoch [3815/10000], Train Loss: 4.2246, Val Loss: 8.8904\n",
      "Epoch [3816/10000], Train Loss: 4.2241, Val Loss: 8.8874\n",
      "Epoch [3817/10000], Train Loss: 4.2236, Val Loss: 8.8852\n",
      "Epoch [3818/10000], Train Loss: 4.2230, Val Loss: 8.8814\n",
      "Epoch [3819/10000], Train Loss: 4.2225, Val Loss: 8.8800\n",
      "Epoch [3820/10000], Train Loss: 4.2219, Val Loss: 8.8760\n",
      "Epoch [3821/10000], Train Loss: 4.2214, Val Loss: 8.8751\n",
      "Epoch [3822/10000], Train Loss: 4.2209, Val Loss: 8.8734\n",
      "Epoch [3823/10000], Train Loss: 4.2204, Val Loss: 8.8761\n",
      "Epoch [3824/10000], Train Loss: 4.2199, Val Loss: 8.8748\n",
      "Epoch [3825/10000], Train Loss: 4.2194, Val Loss: 8.8776\n",
      "Epoch [3826/10000], Train Loss: 4.2189, Val Loss: 8.8756\n",
      "Epoch [3827/10000], Train Loss: 4.2184, Val Loss: 8.8788\n",
      "Epoch [3828/10000], Train Loss: 4.2180, Val Loss: 8.8752\n",
      "Epoch [3829/10000], Train Loss: 4.2176, Val Loss: 8.8792\n",
      "Epoch [3830/10000], Train Loss: 4.2173, Val Loss: 8.8760\n",
      "Epoch [3831/10000], Train Loss: 4.2170, Val Loss: 8.8812\n",
      "Epoch [3832/10000], Train Loss: 4.2166, Val Loss: 8.8743\n",
      "Epoch [3833/10000], Train Loss: 4.2163, Val Loss: 8.8765\n",
      "Epoch [3834/10000], Train Loss: 4.2158, Val Loss: 8.8683\n",
      "Epoch [3835/10000], Train Loss: 4.2152, Val Loss: 8.8694\n",
      "Epoch [3836/10000], Train Loss: 4.2144, Val Loss: 8.8614\n",
      "Epoch [3837/10000], Train Loss: 4.2135, Val Loss: 8.8637\n",
      "Epoch [3838/10000], Train Loss: 4.2125, Val Loss: 8.8633\n",
      "Epoch [3839/10000], Train Loss: 4.2117, Val Loss: 8.8660\n",
      "Epoch [3840/10000], Train Loss: 4.2111, Val Loss: 8.8676\n",
      "Epoch [3841/10000], Train Loss: 4.2106, Val Loss: 8.8670\n",
      "Epoch [3842/10000], Train Loss: 4.2102, Val Loss: 8.8694\n",
      "Epoch [3843/10000], Train Loss: 4.2098, Val Loss: 8.8653\n",
      "Epoch [3844/10000], Train Loss: 4.2094, Val Loss: 8.8669\n",
      "Epoch [3845/10000], Train Loss: 4.2088, Val Loss: 8.8645\n",
      "Epoch [3846/10000], Train Loss: 4.2082, Val Loss: 8.8676\n",
      "Epoch [3847/10000], Train Loss: 4.2076, Val Loss: 8.8644\n",
      "Epoch [3848/10000], Train Loss: 4.2069, Val Loss: 8.8629\n",
      "Epoch [3849/10000], Train Loss: 4.2063, Val Loss: 8.8601\n",
      "Epoch [3850/10000], Train Loss: 4.2057, Val Loss: 8.8562\n",
      "Epoch [3851/10000], Train Loss: 4.2052, Val Loss: 8.8532\n",
      "Epoch [3852/10000], Train Loss: 4.2048, Val Loss: 8.8503\n",
      "Epoch [3853/10000], Train Loss: 4.2043, Val Loss: 8.8536\n",
      "Epoch [3854/10000], Train Loss: 4.2038, Val Loss: 8.8539\n",
      "Epoch [3855/10000], Train Loss: 4.2032, Val Loss: 8.8565\n",
      "Epoch [3856/10000], Train Loss: 4.2026, Val Loss: 8.8563\n",
      "Epoch [3857/10000], Train Loss: 4.2021, Val Loss: 8.8575\n",
      "Epoch [3858/10000], Train Loss: 4.2015, Val Loss: 8.8557\n",
      "Epoch [3859/10000], Train Loss: 4.2009, Val Loss: 8.8540\n",
      "Epoch [3860/10000], Train Loss: 4.2004, Val Loss: 8.8546\n",
      "Epoch [3861/10000], Train Loss: 4.1999, Val Loss: 8.8552\n",
      "Epoch [3862/10000], Train Loss: 4.1994, Val Loss: 8.8575\n",
      "Epoch [3863/10000], Train Loss: 4.1989, Val Loss: 8.8574\n",
      "Epoch [3864/10000], Train Loss: 4.1984, Val Loss: 8.8576\n",
      "Epoch [3865/10000], Train Loss: 4.1978, Val Loss: 8.8539\n",
      "Epoch [3866/10000], Train Loss: 4.1973, Val Loss: 8.8502\n",
      "Epoch [3867/10000], Train Loss: 4.1967, Val Loss: 8.8455\n",
      "Epoch [3868/10000], Train Loss: 4.1962, Val Loss: 8.8424\n",
      "Epoch [3869/10000], Train Loss: 4.1957, Val Loss: 8.8421\n",
      "Epoch [3870/10000], Train Loss: 4.1952, Val Loss: 8.8437\n",
      "Epoch [3871/10000], Train Loss: 4.1946, Val Loss: 8.8468\n",
      "Epoch [3872/10000], Train Loss: 4.1941, Val Loss: 8.8479\n",
      "Epoch [3873/10000], Train Loss: 4.1936, Val Loss: 8.8485\n",
      "Epoch [3874/10000], Train Loss: 4.1931, Val Loss: 8.8467\n",
      "Epoch [3875/10000], Train Loss: 4.1925, Val Loss: 8.8454\n",
      "Epoch [3876/10000], Train Loss: 4.1920, Val Loss: 8.8438\n",
      "Epoch [3877/10000], Train Loss: 4.1915, Val Loss: 8.8445\n",
      "Epoch [3878/10000], Train Loss: 4.1909, Val Loss: 8.8461\n",
      "Epoch [3879/10000], Train Loss: 4.1904, Val Loss: 8.8484\n",
      "Epoch [3880/10000], Train Loss: 4.1899, Val Loss: 8.8505\n",
      "Epoch [3881/10000], Train Loss: 4.1894, Val Loss: 8.8517\n",
      "Epoch [3882/10000], Train Loss: 4.1889, Val Loss: 8.8517\n",
      "Epoch [3883/10000], Train Loss: 4.1883, Val Loss: 8.8482\n",
      "Epoch [3884/10000], Train Loss: 4.1878, Val Loss: 8.8445\n",
      "Epoch [3885/10000], Train Loss: 4.1873, Val Loss: 8.8406\n",
      "Epoch [3886/10000], Train Loss: 4.1868, Val Loss: 8.8380\n",
      "Epoch [3887/10000], Train Loss: 4.1863, Val Loss: 8.8356\n",
      "Epoch [3888/10000], Train Loss: 4.1857, Val Loss: 8.8366\n",
      "Epoch [3889/10000], Train Loss: 4.1852, Val Loss: 8.8383\n",
      "Epoch [3890/10000], Train Loss: 4.1847, Val Loss: 8.8397\n",
      "Epoch [3891/10000], Train Loss: 4.1842, Val Loss: 8.8391\n",
      "Epoch [3892/10000], Train Loss: 4.1836, Val Loss: 8.8384\n",
      "Epoch [3893/10000], Train Loss: 4.1831, Val Loss: 8.8373\n",
      "Epoch [3894/10000], Train Loss: 4.1826, Val Loss: 8.8360\n",
      "Epoch [3895/10000], Train Loss: 4.1821, Val Loss: 8.8361\n",
      "Epoch [3896/10000], Train Loss: 4.1815, Val Loss: 8.8375\n",
      "Epoch [3897/10000], Train Loss: 4.1810, Val Loss: 8.8398\n",
      "Epoch [3898/10000], Train Loss: 4.1805, Val Loss: 8.8409\n",
      "Epoch [3899/10000], Train Loss: 4.1800, Val Loss: 8.8421\n",
      "Epoch [3900/10000], Train Loss: 4.1795, Val Loss: 8.8425\n",
      "Epoch [3901/10000], Train Loss: 4.1789, Val Loss: 8.8421\n",
      "Epoch [3902/10000], Train Loss: 4.1784, Val Loss: 8.8386\n",
      "Epoch [3903/10000], Train Loss: 4.1779, Val Loss: 8.8354\n",
      "Epoch [3904/10000], Train Loss: 4.1774, Val Loss: 8.8324\n",
      "Epoch [3905/10000], Train Loss: 4.1769, Val Loss: 8.8298\n",
      "Epoch [3906/10000], Train Loss: 4.1764, Val Loss: 8.8271\n",
      "Epoch [3907/10000], Train Loss: 4.1758, Val Loss: 8.8276\n",
      "Epoch [3908/10000], Train Loss: 4.1753, Val Loss: 8.8288\n",
      "Epoch [3909/10000], Train Loss: 4.1748, Val Loss: 8.8297\n",
      "Epoch [3910/10000], Train Loss: 4.1743, Val Loss: 8.8290\n",
      "Epoch [3911/10000], Train Loss: 4.1738, Val Loss: 8.8291\n",
      "Epoch [3912/10000], Train Loss: 4.1733, Val Loss: 8.8282\n",
      "Epoch [3913/10000], Train Loss: 4.1727, Val Loss: 8.8273\n",
      "Epoch [3914/10000], Train Loss: 4.1722, Val Loss: 8.8270\n",
      "Epoch [3915/10000], Train Loss: 4.1717, Val Loss: 8.8287\n",
      "Epoch [3916/10000], Train Loss: 4.1712, Val Loss: 8.8301\n",
      "Epoch [3917/10000], Train Loss: 4.1707, Val Loss: 8.8312\n",
      "Epoch [3918/10000], Train Loss: 4.1701, Val Loss: 8.8321\n",
      "Epoch [3919/10000], Train Loss: 4.1696, Val Loss: 8.8331\n",
      "Epoch [3920/10000], Train Loss: 4.1691, Val Loss: 8.8332\n",
      "Epoch [3921/10000], Train Loss: 4.1686, Val Loss: 8.8333\n",
      "Epoch [3922/10000], Train Loss: 4.1681, Val Loss: 8.8337\n",
      "Epoch [3923/10000], Train Loss: 4.1676, Val Loss: 8.8323\n",
      "Epoch [3924/10000], Train Loss: 4.1671, Val Loss: 8.8296\n",
      "Epoch [3925/10000], Train Loss: 4.1666, Val Loss: 8.8267\n",
      "Epoch [3926/10000], Train Loss: 4.1660, Val Loss: 8.8237\n",
      "Epoch [3927/10000], Train Loss: 4.1655, Val Loss: 8.8203\n",
      "Epoch [3928/10000], Train Loss: 4.1650, Val Loss: 8.8194\n",
      "Epoch [3929/10000], Train Loss: 4.1645, Val Loss: 8.8202\n",
      "Epoch [3930/10000], Train Loss: 4.1640, Val Loss: 8.8218\n",
      "Epoch [3931/10000], Train Loss: 4.1635, Val Loss: 8.8219\n",
      "Epoch [3932/10000], Train Loss: 4.1630, Val Loss: 8.8225\n",
      "Epoch [3933/10000], Train Loss: 4.1624, Val Loss: 8.8218\n",
      "Epoch [3934/10000], Train Loss: 4.1619, Val Loss: 8.8213\n",
      "Epoch [3935/10000], Train Loss: 4.1614, Val Loss: 8.8200\n",
      "Epoch [3936/10000], Train Loss: 4.1609, Val Loss: 8.8214\n",
      "Epoch [3937/10000], Train Loss: 4.1604, Val Loss: 8.8220\n",
      "Epoch [3938/10000], Train Loss: 4.1599, Val Loss: 8.8240\n",
      "Epoch [3939/10000], Train Loss: 4.1594, Val Loss: 8.8241\n",
      "Epoch [3940/10000], Train Loss: 4.1590, Val Loss: 8.8266\n",
      "Epoch [3941/10000], Train Loss: 4.1585, Val Loss: 8.8257\n",
      "Epoch [3942/10000], Train Loss: 4.1580, Val Loss: 8.8275\n",
      "Epoch [3943/10000], Train Loss: 4.1576, Val Loss: 8.8263\n",
      "Epoch [3944/10000], Train Loss: 4.1572, Val Loss: 8.8301\n",
      "Epoch [3945/10000], Train Loss: 4.1568, Val Loss: 8.8294\n",
      "Epoch [3946/10000], Train Loss: 4.1565, Val Loss: 8.8336\n",
      "Epoch [3947/10000], Train Loss: 4.1563, Val Loss: 8.8295\n",
      "Epoch [3948/10000], Train Loss: 4.1560, Val Loss: 8.8303\n",
      "Epoch [3949/10000], Train Loss: 4.1558, Val Loss: 8.8225\n",
      "Epoch [3950/10000], Train Loss: 4.1554, Val Loss: 8.8218\n",
      "Epoch [3951/10000], Train Loss: 4.1549, Val Loss: 8.8143\n",
      "Epoch [3952/10000], Train Loss: 4.1542, Val Loss: 8.8169\n",
      "Epoch [3953/10000], Train Loss: 4.1533, Val Loss: 8.8154\n",
      "Epoch [3954/10000], Train Loss: 4.1523, Val Loss: 8.8188\n",
      "Epoch [3955/10000], Train Loss: 4.1514, Val Loss: 8.8186\n",
      "Epoch [3956/10000], Train Loss: 4.1507, Val Loss: 8.8187\n",
      "Epoch [3957/10000], Train Loss: 4.1501, Val Loss: 8.8186\n",
      "Epoch [3958/10000], Train Loss: 4.1498, Val Loss: 8.8155\n",
      "Epoch [3959/10000], Train Loss: 4.1495, Val Loss: 8.8170\n",
      "Epoch [3960/10000], Train Loss: 4.1491, Val Loss: 8.8156\n",
      "Epoch [3961/10000], Train Loss: 4.1486, Val Loss: 8.8191\n",
      "Epoch [3962/10000], Train Loss: 4.1480, Val Loss: 8.8187\n",
      "Epoch [3963/10000], Train Loss: 4.1473, Val Loss: 8.8215\n",
      "Epoch [3964/10000], Train Loss: 4.1467, Val Loss: 8.8218\n",
      "Epoch [3965/10000], Train Loss: 4.1460, Val Loss: 8.8219\n",
      "Epoch [3966/10000], Train Loss: 4.1455, Val Loss: 8.8224\n",
      "Epoch [3967/10000], Train Loss: 4.1451, Val Loss: 8.8222\n",
      "Epoch [3968/10000], Train Loss: 4.1446, Val Loss: 8.8251\n",
      "Epoch [3969/10000], Train Loss: 4.1442, Val Loss: 8.8257\n",
      "Epoch [3970/10000], Train Loss: 4.1437, Val Loss: 8.8294\n",
      "Epoch [3971/10000], Train Loss: 4.1431, Val Loss: 8.8297\n",
      "Epoch [3972/10000], Train Loss: 4.1426, Val Loss: 8.8283\n",
      "Epoch [3973/10000], Train Loss: 4.1420, Val Loss: 8.8238\n",
      "Epoch [3974/10000], Train Loss: 4.1414, Val Loss: 8.8192\n",
      "Epoch [3975/10000], Train Loss: 4.1409, Val Loss: 8.8152\n",
      "Epoch [3976/10000], Train Loss: 4.1405, Val Loss: 8.8113\n",
      "Epoch [3977/10000], Train Loss: 4.1400, Val Loss: 8.8125\n",
      "Epoch [3978/10000], Train Loss: 4.1395, Val Loss: 8.8143\n",
      "Epoch [3979/10000], Train Loss: 4.1390, Val Loss: 8.8171\n",
      "Epoch [3980/10000], Train Loss: 4.1385, Val Loss: 8.8169\n",
      "Epoch [3981/10000], Train Loss: 4.1379, Val Loss: 8.8170\n",
      "Epoch [3982/10000], Train Loss: 4.1374, Val Loss: 8.8154\n",
      "Epoch [3983/10000], Train Loss: 4.1368, Val Loss: 8.8132\n",
      "Epoch [3984/10000], Train Loss: 4.1363, Val Loss: 8.8128\n",
      "Epoch [3985/10000], Train Loss: 4.1358, Val Loss: 8.8138\n",
      "Epoch [3986/10000], Train Loss: 4.1353, Val Loss: 8.8162\n",
      "Epoch [3987/10000], Train Loss: 4.1348, Val Loss: 8.8173\n",
      "Epoch [3988/10000], Train Loss: 4.1343, Val Loss: 8.8193\n",
      "Epoch [3989/10000], Train Loss: 4.1338, Val Loss: 8.8196\n",
      "Epoch [3990/10000], Train Loss: 4.1333, Val Loss: 8.8195\n",
      "Epoch [3991/10000], Train Loss: 4.1328, Val Loss: 8.8191\n",
      "Epoch [3992/10000], Train Loss: 4.1322, Val Loss: 8.8202\n",
      "Epoch [3993/10000], Train Loss: 4.1317, Val Loss: 8.8222\n",
      "Epoch [3994/10000], Train Loss: 4.1312, Val Loss: 8.8243\n",
      "Epoch [3995/10000], Train Loss: 4.1307, Val Loss: 8.8269\n",
      "Epoch [3996/10000], Train Loss: 4.1302, Val Loss: 8.8288\n",
      "Epoch [3997/10000], Train Loss: 4.1297, Val Loss: 8.8300\n",
      "Epoch [3998/10000], Train Loss: 4.1292, Val Loss: 8.8292\n",
      "Epoch [3999/10000], Train Loss: 4.1287, Val Loss: 8.8266\n",
      "Epoch [4000/10000], Train Loss: 4.1282, Val Loss: 8.8227\n",
      "Epoch [4001/10000], Train Loss: 4.1277, Val Loss: 8.8192\n",
      "Epoch [4002/10000], Train Loss: 4.1271, Val Loss: 8.8157\n",
      "Epoch [4003/10000], Train Loss: 4.1266, Val Loss: 8.8136\n",
      "Epoch [4004/10000], Train Loss: 4.1261, Val Loss: 8.8142\n",
      "Epoch [4005/10000], Train Loss: 4.1256, Val Loss: 8.8157\n",
      "Epoch [4006/10000], Train Loss: 4.1251, Val Loss: 8.8167\n",
      "Epoch [4007/10000], Train Loss: 4.1246, Val Loss: 8.8164\n",
      "Epoch [4008/10000], Train Loss: 4.1241, Val Loss: 8.8160\n",
      "Epoch [4009/10000], Train Loss: 4.1236, Val Loss: 8.8144\n",
      "Epoch [4010/10000], Train Loss: 4.1231, Val Loss: 8.8134\n",
      "Epoch [4011/10000], Train Loss: 4.1226, Val Loss: 8.8135\n",
      "Epoch [4012/10000], Train Loss: 4.1220, Val Loss: 8.8150\n",
      "Epoch [4013/10000], Train Loss: 4.1215, Val Loss: 8.8162\n",
      "Epoch [4014/10000], Train Loss: 4.1210, Val Loss: 8.8174\n",
      "Epoch [4015/10000], Train Loss: 4.1205, Val Loss: 8.8184\n",
      "Epoch [4016/10000], Train Loss: 4.1200, Val Loss: 8.8188\n",
      "Epoch [4017/10000], Train Loss: 4.1195, Val Loss: 8.8188\n",
      "Epoch [4018/10000], Train Loss: 4.1190, Val Loss: 8.8192\n",
      "Epoch [4019/10000], Train Loss: 4.1185, Val Loss: 8.8208\n",
      "Epoch [4020/10000], Train Loss: 4.1179, Val Loss: 8.8226\n",
      "Epoch [4021/10000], Train Loss: 4.1174, Val Loss: 8.8248\n",
      "Epoch [4022/10000], Train Loss: 4.1169, Val Loss: 8.8269\n",
      "Epoch [4023/10000], Train Loss: 4.1164, Val Loss: 8.8286\n",
      "Epoch [4024/10000], Train Loss: 4.1159, Val Loss: 8.8292\n",
      "Epoch [4025/10000], Train Loss: 4.1154, Val Loss: 8.8292\n",
      "Epoch [4026/10000], Train Loss: 4.1149, Val Loss: 8.8267\n",
      "Epoch [4027/10000], Train Loss: 4.1144, Val Loss: 8.8232\n",
      "Epoch [4028/10000], Train Loss: 4.1139, Val Loss: 8.8195\n",
      "Epoch [4029/10000], Train Loss: 4.1134, Val Loss: 8.8161\n",
      "Epoch [4030/10000], Train Loss: 4.1129, Val Loss: 8.8134\n",
      "Epoch [4031/10000], Train Loss: 4.1124, Val Loss: 8.8138\n",
      "Epoch [4032/10000], Train Loss: 4.1118, Val Loss: 8.8153\n",
      "Epoch [4033/10000], Train Loss: 4.1113, Val Loss: 8.8165\n",
      "Epoch [4034/10000], Train Loss: 4.1108, Val Loss: 8.8164\n",
      "Epoch [4035/10000], Train Loss: 4.1103, Val Loss: 8.8161\n",
      "Epoch [4036/10000], Train Loss: 4.1098, Val Loss: 8.8147\n",
      "Epoch [4037/10000], Train Loss: 4.1093, Val Loss: 8.8135\n",
      "Epoch [4038/10000], Train Loss: 4.1088, Val Loss: 8.8136\n",
      "Epoch [4039/10000], Train Loss: 4.1083, Val Loss: 8.8150\n",
      "Epoch [4040/10000], Train Loss: 4.1077, Val Loss: 8.8162\n",
      "Epoch [4041/10000], Train Loss: 4.1072, Val Loss: 8.8174\n",
      "Epoch [4042/10000], Train Loss: 4.1067, Val Loss: 8.8185\n",
      "Epoch [4043/10000], Train Loss: 4.1062, Val Loss: 8.8191\n",
      "Epoch [4044/10000], Train Loss: 4.1057, Val Loss: 8.8191\n",
      "Epoch [4045/10000], Train Loss: 4.1052, Val Loss: 8.8197\n",
      "Epoch [4046/10000], Train Loss: 4.1047, Val Loss: 8.8212\n",
      "Epoch [4047/10000], Train Loss: 4.1041, Val Loss: 8.8232\n",
      "Epoch [4048/10000], Train Loss: 4.1036, Val Loss: 8.8253\n",
      "Epoch [4049/10000], Train Loss: 4.1031, Val Loss: 8.8276\n",
      "Epoch [4050/10000], Train Loss: 4.1026, Val Loss: 8.8292\n",
      "Epoch [4051/10000], Train Loss: 4.1021, Val Loss: 8.8301\n",
      "Epoch [4052/10000], Train Loss: 4.1016, Val Loss: 8.8306\n",
      "Epoch [4053/10000], Train Loss: 4.1011, Val Loss: 8.8311\n",
      "Epoch [4054/10000], Train Loss: 4.1006, Val Loss: 8.8289\n",
      "Epoch [4055/10000], Train Loss: 4.1001, Val Loss: 8.8258\n",
      "Epoch [4056/10000], Train Loss: 4.0996, Val Loss: 8.8223\n",
      "Epoch [4057/10000], Train Loss: 4.0991, Val Loss: 8.8187\n",
      "Epoch [4058/10000], Train Loss: 4.0985, Val Loss: 8.8155\n",
      "Epoch [4059/10000], Train Loss: 4.0980, Val Loss: 8.8158\n",
      "Epoch [4060/10000], Train Loss: 4.0975, Val Loss: 8.8171\n",
      "Epoch [4061/10000], Train Loss: 4.0970, Val Loss: 8.8185\n",
      "Epoch [4062/10000], Train Loss: 4.0966, Val Loss: 8.8182\n",
      "Epoch [4063/10000], Train Loss: 4.0961, Val Loss: 8.8186\n",
      "Epoch [4064/10000], Train Loss: 4.0956, Val Loss: 8.8168\n",
      "Epoch [4065/10000], Train Loss: 4.0951, Val Loss: 8.8162\n",
      "Epoch [4066/10000], Train Loss: 4.0947, Val Loss: 8.8155\n",
      "Epoch [4067/10000], Train Loss: 4.0942, Val Loss: 8.8179\n",
      "Epoch [4068/10000], Train Loss: 4.0938, Val Loss: 8.8180\n",
      "Epoch [4069/10000], Train Loss: 4.0935, Val Loss: 8.8207\n",
      "Epoch [4070/10000], Train Loss: 4.0931, Val Loss: 8.8208\n",
      "Epoch [4071/10000], Train Loss: 4.0928, Val Loss: 8.8235\n",
      "Epoch [4072/10000], Train Loss: 4.0926, Val Loss: 8.8218\n",
      "Epoch [4073/10000], Train Loss: 4.0923, Val Loss: 8.8247\n",
      "Epoch [4074/10000], Train Loss: 4.0920, Val Loss: 8.8242\n",
      "Epoch [4075/10000], Train Loss: 4.0915, Val Loss: 8.8280\n",
      "Epoch [4076/10000], Train Loss: 4.0908, Val Loss: 8.8279\n",
      "Epoch [4077/10000], Train Loss: 4.0899, Val Loss: 8.8315\n",
      "Epoch [4078/10000], Train Loss: 4.0890, Val Loss: 8.8316\n",
      "Epoch [4079/10000], Train Loss: 4.0880, Val Loss: 8.8327\n",
      "Epoch [4080/10000], Train Loss: 4.0873, Val Loss: 8.8334\n",
      "Epoch [4081/10000], Train Loss: 4.0867, Val Loss: 8.8336\n",
      "Epoch [4082/10000], Train Loss: 4.0863, Val Loss: 8.8323\n",
      "Epoch [4083/10000], Train Loss: 4.0860, Val Loss: 8.8281\n",
      "Epoch [4084/10000], Train Loss: 4.0856, Val Loss: 8.8259\n",
      "Epoch [4085/10000], Train Loss: 4.0852, Val Loss: 8.8208\n",
      "Epoch [4086/10000], Train Loss: 4.0846, Val Loss: 8.8186\n",
      "Epoch [4087/10000], Train Loss: 4.0839, Val Loss: 8.8180\n",
      "Epoch [4088/10000], Train Loss: 4.0832, Val Loss: 8.8200\n",
      "Epoch [4089/10000], Train Loss: 4.0826, Val Loss: 8.8207\n",
      "Epoch [4090/10000], Train Loss: 4.0821, Val Loss: 8.8207\n",
      "Epoch [4091/10000], Train Loss: 4.0816, Val Loss: 8.8210\n",
      "Epoch [4092/10000], Train Loss: 4.0812, Val Loss: 8.8191\n",
      "Epoch [4093/10000], Train Loss: 4.0807, Val Loss: 8.8184\n",
      "Epoch [4094/10000], Train Loss: 4.0802, Val Loss: 8.8180\n",
      "Epoch [4095/10000], Train Loss: 4.0797, Val Loss: 8.8198\n",
      "Epoch [4096/10000], Train Loss: 4.0791, Val Loss: 8.8205\n",
      "Epoch [4097/10000], Train Loss: 4.0785, Val Loss: 8.8220\n",
      "Epoch [4098/10000], Train Loss: 4.0779, Val Loss: 8.8234\n",
      "Epoch [4099/10000], Train Loss: 4.0774, Val Loss: 8.8238\n",
      "Epoch [4100/10000], Train Loss: 4.0769, Val Loss: 8.8240\n",
      "Epoch [4101/10000], Train Loss: 4.0764, Val Loss: 8.8246\n",
      "Epoch [4102/10000], Train Loss: 4.0759, Val Loss: 8.8268\n",
      "Epoch [4103/10000], Train Loss: 4.0754, Val Loss: 8.8284\n",
      "Epoch [4104/10000], Train Loss: 4.0749, Val Loss: 8.8312\n",
      "Epoch [4105/10000], Train Loss: 4.0744, Val Loss: 8.8334\n",
      "Epoch [4106/10000], Train Loss: 4.0738, Val Loss: 8.8350\n",
      "Epoch [4107/10000], Train Loss: 4.0733, Val Loss: 8.8356\n",
      "Epoch [4108/10000], Train Loss: 4.0727, Val Loss: 8.8365\n",
      "Epoch [4109/10000], Train Loss: 4.0722, Val Loss: 8.8372\n",
      "Epoch [4110/10000], Train Loss: 4.0717, Val Loss: 8.8348\n",
      "Epoch [4111/10000], Train Loss: 4.0712, Val Loss: 8.8318\n",
      "Epoch [4112/10000], Train Loss: 4.0707, Val Loss: 8.8282\n",
      "Epoch [4113/10000], Train Loss: 4.0702, Val Loss: 8.8243\n",
      "Epoch [4114/10000], Train Loss: 4.0697, Val Loss: 8.8209\n",
      "Epoch [4115/10000], Train Loss: 4.0692, Val Loss: 8.8216\n",
      "Epoch [4116/10000], Train Loss: 4.0686, Val Loss: 8.8231\n",
      "Epoch [4117/10000], Train Loss: 4.0681, Val Loss: 8.8239\n",
      "Epoch [4118/10000], Train Loss: 4.0676, Val Loss: 8.8242\n",
      "Epoch [4119/10000], Train Loss: 4.0671, Val Loss: 8.8240\n",
      "Epoch [4120/10000], Train Loss: 4.0665, Val Loss: 8.8226\n",
      "Epoch [4121/10000], Train Loss: 4.0660, Val Loss: 8.8211\n",
      "Epoch [4122/10000], Train Loss: 4.0655, Val Loss: 8.8217\n",
      "Epoch [4123/10000], Train Loss: 4.0650, Val Loss: 8.8229\n",
      "Epoch [4124/10000], Train Loss: 4.0645, Val Loss: 8.8242\n",
      "Epoch [4125/10000], Train Loss: 4.0639, Val Loss: 8.8256\n",
      "Epoch [4126/10000], Train Loss: 4.0634, Val Loss: 8.8272\n",
      "Epoch [4127/10000], Train Loss: 4.0629, Val Loss: 8.8274\n",
      "Epoch [4128/10000], Train Loss: 4.0624, Val Loss: 8.8276\n",
      "Epoch [4129/10000], Train Loss: 4.0618, Val Loss: 8.8287\n",
      "Epoch [4130/10000], Train Loss: 4.0613, Val Loss: 8.8305\n",
      "Epoch [4131/10000], Train Loss: 4.0608, Val Loss: 8.8326\n",
      "Epoch [4132/10000], Train Loss: 4.0603, Val Loss: 8.8353\n",
      "Epoch [4133/10000], Train Loss: 4.0597, Val Loss: 8.8378\n",
      "Epoch [4134/10000], Train Loss: 4.0592, Val Loss: 8.8390\n",
      "Epoch [4135/10000], Train Loss: 4.0587, Val Loss: 8.8398\n",
      "Epoch [4136/10000], Train Loss: 4.0582, Val Loss: 8.8408\n",
      "Epoch [4137/10000], Train Loss: 4.0577, Val Loss: 8.8415\n",
      "Epoch [4138/10000], Train Loss: 4.0572, Val Loss: 8.8392\n",
      "Epoch [4139/10000], Train Loss: 4.0566, Val Loss: 8.8362\n",
      "Epoch [4140/10000], Train Loss: 4.0561, Val Loss: 8.8326\n",
      "Epoch [4141/10000], Train Loss: 4.0556, Val Loss: 8.8282\n",
      "Epoch [4142/10000], Train Loss: 4.0551, Val Loss: 8.8252\n",
      "Epoch [4143/10000], Train Loss: 4.0545, Val Loss: 8.8258\n",
      "Epoch [4144/10000], Train Loss: 4.0540, Val Loss: 8.8273\n",
      "Epoch [4145/10000], Train Loss: 4.0535, Val Loss: 8.8281\n",
      "Epoch [4146/10000], Train Loss: 4.0530, Val Loss: 8.8286\n",
      "Epoch [4147/10000], Train Loss: 4.0524, Val Loss: 8.8283\n",
      "Epoch [4148/10000], Train Loss: 4.0519, Val Loss: 8.8266\n",
      "Epoch [4149/10000], Train Loss: 4.0514, Val Loss: 8.8254\n",
      "Epoch [4150/10000], Train Loss: 4.0509, Val Loss: 8.8261\n",
      "Epoch [4151/10000], Train Loss: 4.0503, Val Loss: 8.8273\n",
      "Epoch [4152/10000], Train Loss: 4.0498, Val Loss: 8.8286\n",
      "Epoch [4153/10000], Train Loss: 4.0493, Val Loss: 8.8303\n",
      "Epoch [4154/10000], Train Loss: 4.0488, Val Loss: 8.8317\n",
      "Epoch [4155/10000], Train Loss: 4.0482, Val Loss: 8.8318\n",
      "Epoch [4156/10000], Train Loss: 4.0477, Val Loss: 8.8322\n",
      "Epoch [4157/10000], Train Loss: 4.0472, Val Loss: 8.8335\n",
      "Epoch [4158/10000], Train Loss: 4.0466, Val Loss: 8.8354\n",
      "Epoch [4159/10000], Train Loss: 4.0461, Val Loss: 8.8376\n",
      "Epoch [4160/10000], Train Loss: 4.0456, Val Loss: 8.8405\n",
      "Epoch [4161/10000], Train Loss: 4.0451, Val Loss: 8.8428\n",
      "Epoch [4162/10000], Train Loss: 4.0445, Val Loss: 8.8440\n",
      "Epoch [4163/10000], Train Loss: 4.0440, Val Loss: 8.8449\n",
      "Epoch [4164/10000], Train Loss: 4.0435, Val Loss: 8.8453\n",
      "Epoch [4165/10000], Train Loss: 4.0430, Val Loss: 8.8427\n",
      "Epoch [4166/10000], Train Loss: 4.0424, Val Loss: 8.8390\n",
      "Epoch [4167/10000], Train Loss: 4.0419, Val Loss: 8.8354\n",
      "Epoch [4168/10000], Train Loss: 4.0414, Val Loss: 8.8313\n",
      "Epoch [4169/10000], Train Loss: 4.0409, Val Loss: 8.8286\n",
      "Epoch [4170/10000], Train Loss: 4.0403, Val Loss: 8.8296\n",
      "Epoch [4171/10000], Train Loss: 4.0398, Val Loss: 8.8314\n",
      "Epoch [4172/10000], Train Loss: 4.0393, Val Loss: 8.8322\n",
      "Epoch [4173/10000], Train Loss: 4.0388, Val Loss: 8.8322\n",
      "Epoch [4174/10000], Train Loss: 4.0382, Val Loss: 8.8319\n",
      "Epoch [4175/10000], Train Loss: 4.0377, Val Loss: 8.8301\n",
      "Epoch [4176/10000], Train Loss: 4.0372, Val Loss: 8.8293\n",
      "Epoch [4177/10000], Train Loss: 4.0367, Val Loss: 8.8302\n",
      "Epoch [4178/10000], Train Loss: 4.0362, Val Loss: 8.8319\n",
      "Epoch [4179/10000], Train Loss: 4.0357, Val Loss: 8.8330\n",
      "Epoch [4180/10000], Train Loss: 4.0352, Val Loss: 8.8349\n",
      "Epoch [4181/10000], Train Loss: 4.0347, Val Loss: 8.8359\n",
      "Epoch [4182/10000], Train Loss: 4.0342, Val Loss: 8.8364\n",
      "Epoch [4183/10000], Train Loss: 4.0337, Val Loss: 8.8366\n",
      "Epoch [4184/10000], Train Loss: 4.0333, Val Loss: 8.8388\n",
      "Epoch [4185/10000], Train Loss: 4.0328, Val Loss: 8.8406\n",
      "Epoch [4186/10000], Train Loss: 4.0324, Val Loss: 8.8437\n",
      "Epoch [4187/10000], Train Loss: 4.0320, Val Loss: 8.8462\n",
      "Epoch [4188/10000], Train Loss: 4.0315, Val Loss: 8.8490\n",
      "Epoch [4189/10000], Train Loss: 4.0311, Val Loss: 8.8494\n",
      "Epoch [4190/10000], Train Loss: 4.0306, Val Loss: 8.8502\n",
      "Epoch [4191/10000], Train Loss: 4.0301, Val Loss: 8.8470\n",
      "Epoch [4192/10000], Train Loss: 4.0296, Val Loss: 8.8433\n",
      "Epoch [4193/10000], Train Loss: 4.0289, Val Loss: 8.8385\n",
      "Epoch [4194/10000], Train Loss: 4.0282, Val Loss: 8.8346\n",
      "Epoch [4195/10000], Train Loss: 4.0274, Val Loss: 8.8321\n",
      "Epoch [4196/10000], Train Loss: 4.0267, Val Loss: 8.8333\n",
      "Epoch [4197/10000], Train Loss: 4.0260, Val Loss: 8.8353\n",
      "Epoch [4198/10000], Train Loss: 4.0254, Val Loss: 8.8363\n",
      "Epoch [4199/10000], Train Loss: 4.0249, Val Loss: 8.8364\n",
      "Epoch [4200/10000], Train Loss: 4.0244, Val Loss: 8.8354\n",
      "Epoch [4201/10000], Train Loss: 4.0240, Val Loss: 8.8341\n",
      "Epoch [4202/10000], Train Loss: 4.0235, Val Loss: 8.8334\n",
      "Epoch [4203/10000], Train Loss: 4.0230, Val Loss: 8.8349\n",
      "Epoch [4204/10000], Train Loss: 4.0225, Val Loss: 8.8364\n",
      "Epoch [4205/10000], Train Loss: 4.0219, Val Loss: 8.8380\n",
      "Epoch [4206/10000], Train Loss: 4.0213, Val Loss: 8.8393\n",
      "Epoch [4207/10000], Train Loss: 4.0207, Val Loss: 8.8403\n",
      "Epoch [4208/10000], Train Loss: 4.0201, Val Loss: 8.8403\n",
      "Epoch [4209/10000], Train Loss: 4.0195, Val Loss: 8.8411\n",
      "Epoch [4210/10000], Train Loss: 4.0190, Val Loss: 8.8429\n",
      "Epoch [4211/10000], Train Loss: 4.0184, Val Loss: 8.8454\n",
      "Epoch [4212/10000], Train Loss: 4.0179, Val Loss: 8.8483\n",
      "Epoch [4213/10000], Train Loss: 4.0174, Val Loss: 8.8512\n",
      "Epoch [4214/10000], Train Loss: 4.0169, Val Loss: 8.8532\n",
      "Epoch [4215/10000], Train Loss: 4.0164, Val Loss: 8.8531\n",
      "Epoch [4216/10000], Train Loss: 4.0158, Val Loss: 8.8501\n",
      "Epoch [4217/10000], Train Loss: 4.0153, Val Loss: 8.8455\n",
      "Epoch [4218/10000], Train Loss: 4.0147, Val Loss: 8.8408\n",
      "Epoch [4219/10000], Train Loss: 4.0142, Val Loss: 8.8362\n",
      "Epoch [4220/10000], Train Loss: 4.0136, Val Loss: 8.8346\n",
      "Epoch [4221/10000], Train Loss: 4.0131, Val Loss: 8.8364\n",
      "Epoch [4222/10000], Train Loss: 4.0125, Val Loss: 8.8387\n",
      "Epoch [4223/10000], Train Loss: 4.0120, Val Loss: 8.8399\n",
      "Epoch [4224/10000], Train Loss: 4.0114, Val Loss: 8.8399\n",
      "Epoch [4225/10000], Train Loss: 4.0109, Val Loss: 8.8386\n",
      "Epoch [4226/10000], Train Loss: 4.0104, Val Loss: 8.8367\n",
      "Epoch [4227/10000], Train Loss: 4.0098, Val Loss: 8.8365\n",
      "Epoch [4228/10000], Train Loss: 4.0093, Val Loss: 8.8381\n",
      "Epoch [4229/10000], Train Loss: 4.0087, Val Loss: 8.8400\n",
      "Epoch [4230/10000], Train Loss: 4.0082, Val Loss: 8.8418\n",
      "Epoch [4231/10000], Train Loss: 4.0076, Val Loss: 8.8434\n",
      "Epoch [4232/10000], Train Loss: 4.0071, Val Loss: 8.8439\n",
      "Epoch [4233/10000], Train Loss: 4.0065, Val Loss: 8.8440\n",
      "Epoch [4234/10000], Train Loss: 4.0060, Val Loss: 8.8450\n",
      "Epoch [4235/10000], Train Loss: 4.0054, Val Loss: 8.8471\n",
      "Epoch [4236/10000], Train Loss: 4.0049, Val Loss: 8.8497\n",
      "Epoch [4237/10000], Train Loss: 4.0043, Val Loss: 8.8530\n",
      "Epoch [4238/10000], Train Loss: 4.0038, Val Loss: 8.8560\n",
      "Epoch [4239/10000], Train Loss: 4.0032, Val Loss: 8.8568\n",
      "Epoch [4240/10000], Train Loss: 4.0027, Val Loss: 8.8534\n",
      "Epoch [4241/10000], Train Loss: 4.0022, Val Loss: 8.8484\n",
      "Epoch [4242/10000], Train Loss: 4.0016, Val Loss: 8.8430\n",
      "Epoch [4243/10000], Train Loss: 4.0011, Val Loss: 8.8380\n",
      "Epoch [4244/10000], Train Loss: 4.0005, Val Loss: 8.8366\n",
      "Epoch [4245/10000], Train Loss: 4.0000, Val Loss: 8.8391\n",
      "Epoch [4246/10000], Train Loss: 3.9994, Val Loss: 8.8418\n",
      "Epoch [4247/10000], Train Loss: 3.9989, Val Loss: 8.8432\n",
      "Epoch [4248/10000], Train Loss: 3.9983, Val Loss: 8.8434\n",
      "Epoch [4249/10000], Train Loss: 3.9978, Val Loss: 8.8418\n",
      "Epoch [4250/10000], Train Loss: 3.9972, Val Loss: 8.8395\n",
      "Epoch [4251/10000], Train Loss: 3.9967, Val Loss: 8.8395\n",
      "Epoch [4252/10000], Train Loss: 3.9961, Val Loss: 8.8415\n",
      "Epoch [4253/10000], Train Loss: 3.9956, Val Loss: 8.8436\n",
      "Epoch [4254/10000], Train Loss: 3.9950, Val Loss: 8.8458\n",
      "Epoch [4255/10000], Train Loss: 3.9945, Val Loss: 8.8476\n",
      "Epoch [4256/10000], Train Loss: 3.9939, Val Loss: 8.8479\n",
      "Epoch [4257/10000], Train Loss: 3.9934, Val Loss: 8.8477\n",
      "Epoch [4258/10000], Train Loss: 3.9928, Val Loss: 8.8490\n",
      "Epoch [4259/10000], Train Loss: 3.9923, Val Loss: 8.8512\n",
      "Epoch [4260/10000], Train Loss: 3.9917, Val Loss: 8.8542\n",
      "Epoch [4261/10000], Train Loss: 3.9912, Val Loss: 8.8579\n",
      "Epoch [4262/10000], Train Loss: 3.9906, Val Loss: 8.8609\n",
      "Epoch [4263/10000], Train Loss: 3.9901, Val Loss: 8.8614\n",
      "Epoch [4264/10000], Train Loss: 3.9895, Val Loss: 8.8578\n",
      "Epoch [4265/10000], Train Loss: 3.9890, Val Loss: 8.8527\n",
      "Epoch [4266/10000], Train Loss: 3.9884, Val Loss: 8.8472\n",
      "Epoch [4267/10000], Train Loss: 3.9879, Val Loss: 8.8424\n",
      "Epoch [4268/10000], Train Loss: 3.9873, Val Loss: 8.8414\n",
      "Epoch [4269/10000], Train Loss: 3.9868, Val Loss: 8.8441\n",
      "Epoch [4270/10000], Train Loss: 3.9863, Val Loss: 8.8468\n",
      "Epoch [4271/10000], Train Loss: 3.9857, Val Loss: 8.8480\n",
      "Epoch [4272/10000], Train Loss: 3.9852, Val Loss: 8.8481\n",
      "Epoch [4273/10000], Train Loss: 3.9847, Val Loss: 8.8462\n",
      "Epoch [4274/10000], Train Loss: 3.9842, Val Loss: 8.8444\n",
      "Epoch [4275/10000], Train Loss: 3.9838, Val Loss: 8.8447\n",
      "Epoch [4276/10000], Train Loss: 3.9833, Val Loss: 8.8472\n",
      "Epoch [4277/10000], Train Loss: 3.9830, Val Loss: 8.8494\n",
      "Epoch [4278/10000], Train Loss: 3.9826, Val Loss: 8.8522\n",
      "Epoch [4279/10000], Train Loss: 3.9823, Val Loss: 8.8537\n",
      "Epoch [4280/10000], Train Loss: 3.9820, Val Loss: 8.8543\n",
      "Epoch [4281/10000], Train Loss: 3.9817, Val Loss: 8.8542\n",
      "Epoch [4282/10000], Train Loss: 3.9812, Val Loss: 8.8558\n",
      "Epoch [4283/10000], Train Loss: 3.9806, Val Loss: 8.8579\n",
      "Epoch [4284/10000], Train Loss: 3.9798, Val Loss: 8.8609\n",
      "Epoch [4285/10000], Train Loss: 3.9789, Val Loss: 8.8632\n",
      "Epoch [4286/10000], Train Loss: 3.9779, Val Loss: 8.8614\n",
      "Epoch [4287/10000], Train Loss: 3.9770, Val Loss: 8.8560\n",
      "Epoch [4288/10000], Train Loss: 3.9762, Val Loss: 8.8497\n",
      "Epoch [4289/10000], Train Loss: 3.9756, Val Loss: 8.8437\n",
      "Epoch [4290/10000], Train Loss: 3.9752, Val Loss: 8.8412\n",
      "Epoch [4291/10000], Train Loss: 3.9749, Val Loss: 8.8441\n",
      "Epoch [4292/10000], Train Loss: 3.9745, Val Loss: 8.8479\n",
      "Epoch [4293/10000], Train Loss: 3.9739, Val Loss: 8.8503\n",
      "Epoch [4294/10000], Train Loss: 3.9732, Val Loss: 8.8507\n",
      "Epoch [4295/10000], Train Loss: 3.9725, Val Loss: 8.8492\n",
      "Epoch [4296/10000], Train Loss: 3.9718, Val Loss: 8.8466\n",
      "Epoch [4297/10000], Train Loss: 3.9711, Val Loss: 8.8461\n",
      "Epoch [4298/10000], Train Loss: 3.9706, Val Loss: 8.8482\n",
      "Epoch [4299/10000], Train Loss: 3.9700, Val Loss: 8.8508\n",
      "Epoch [4300/10000], Train Loss: 3.9696, Val Loss: 8.8538\n",
      "Epoch [4301/10000], Train Loss: 3.9690, Val Loss: 8.8561\n",
      "Epoch [4302/10000], Train Loss: 3.9685, Val Loss: 8.8566\n",
      "Epoch [4303/10000], Train Loss: 3.9679, Val Loss: 8.8562\n",
      "Epoch [4304/10000], Train Loss: 3.9672, Val Loss: 8.8573\n",
      "Epoch [4305/10000], Train Loss: 3.9666, Val Loss: 8.8596\n",
      "Epoch [4306/10000], Train Loss: 3.9660, Val Loss: 8.8622\n",
      "Epoch [4307/10000], Train Loss: 3.9655, Val Loss: 8.8620\n",
      "Epoch [4308/10000], Train Loss: 3.9650, Val Loss: 8.8588\n",
      "Epoch [4309/10000], Train Loss: 3.9644, Val Loss: 8.8529\n",
      "Epoch [4310/10000], Train Loss: 3.9639, Val Loss: 8.8458\n",
      "Epoch [4311/10000], Train Loss: 3.9633, Val Loss: 8.8427\n",
      "Epoch [4312/10000], Train Loss: 3.9627, Val Loss: 8.8440\n",
      "Epoch [4313/10000], Train Loss: 3.9621, Val Loss: 8.8473\n",
      "Epoch [4314/10000], Train Loss: 3.9615, Val Loss: 8.8504\n",
      "Epoch [4315/10000], Train Loss: 3.9609, Val Loss: 8.8523\n",
      "Epoch [4316/10000], Train Loss: 3.9603, Val Loss: 8.8514\n",
      "Epoch [4317/10000], Train Loss: 3.9598, Val Loss: 8.8493\n",
      "Epoch [4318/10000], Train Loss: 3.9592, Val Loss: 8.8489\n",
      "Epoch [4319/10000], Train Loss: 3.9587, Val Loss: 8.8498\n",
      "Epoch [4320/10000], Train Loss: 3.9581, Val Loss: 8.8520\n",
      "Epoch [4321/10000], Train Loss: 3.9575, Val Loss: 8.8552\n",
      "Epoch [4322/10000], Train Loss: 3.9569, Val Loss: 8.8579\n",
      "Epoch [4323/10000], Train Loss: 3.9564, Val Loss: 8.8588\n",
      "Epoch [4324/10000], Train Loss: 3.9558, Val Loss: 8.8594\n",
      "Epoch [4325/10000], Train Loss: 3.9552, Val Loss: 8.8596\n",
      "Epoch [4326/10000], Train Loss: 3.9546, Val Loss: 8.8571\n",
      "Epoch [4327/10000], Train Loss: 3.9541, Val Loss: 8.8541\n",
      "Epoch [4328/10000], Train Loss: 3.9535, Val Loss: 8.8508\n",
      "Epoch [4329/10000], Train Loss: 3.9529, Val Loss: 8.8462\n",
      "Epoch [4330/10000], Train Loss: 3.9523, Val Loss: 8.8437\n",
      "Epoch [4331/10000], Train Loss: 3.9518, Val Loss: 8.8448\n",
      "Epoch [4332/10000], Train Loss: 3.9512, Val Loss: 8.8461\n",
      "Epoch [4333/10000], Train Loss: 3.9506, Val Loss: 8.8471\n",
      "Epoch [4334/10000], Train Loss: 3.9501, Val Loss: 8.8484\n",
      "Epoch [4335/10000], Train Loss: 3.9494, Val Loss: 8.8486\n",
      "Epoch [4336/10000], Train Loss: 3.9489, Val Loss: 8.8482\n",
      "Epoch [4337/10000], Train Loss: 3.9483, Val Loss: 8.8496\n",
      "Epoch [4338/10000], Train Loss: 3.9477, Val Loss: 8.8515\n",
      "Epoch [4339/10000], Train Loss: 3.9471, Val Loss: 8.8528\n",
      "Epoch [4340/10000], Train Loss: 3.9465, Val Loss: 8.8547\n",
      "Epoch [4341/10000], Train Loss: 3.9460, Val Loss: 8.8567\n",
      "Epoch [4342/10000], Train Loss: 3.9454, Val Loss: 8.8577\n",
      "Epoch [4343/10000], Train Loss: 3.9448, Val Loss: 8.8591\n",
      "Epoch [4344/10000], Train Loss: 3.9442, Val Loss: 8.8609\n",
      "Epoch [4345/10000], Train Loss: 3.9437, Val Loss: 8.8590\n",
      "Epoch [4346/10000], Train Loss: 3.9431, Val Loss: 8.8557\n",
      "Epoch [4347/10000], Train Loss: 3.9426, Val Loss: 8.8519\n",
      "Epoch [4348/10000], Train Loss: 3.9420, Val Loss: 8.8465\n",
      "Epoch [4349/10000], Train Loss: 3.9413, Val Loss: 8.8439\n",
      "Epoch [4350/10000], Train Loss: 3.9408, Val Loss: 8.8455\n",
      "Epoch [4351/10000], Train Loss: 3.9402, Val Loss: 8.8477\n",
      "Epoch [4352/10000], Train Loss: 3.9396, Val Loss: 8.8491\n",
      "Epoch [4353/10000], Train Loss: 3.9390, Val Loss: 8.8506\n",
      "Epoch [4354/10000], Train Loss: 3.9384, Val Loss: 8.8503\n",
      "Epoch [4355/10000], Train Loss: 3.9378, Val Loss: 8.8493\n",
      "Epoch [4356/10000], Train Loss: 3.9373, Val Loss: 8.8506\n",
      "Epoch [4357/10000], Train Loss: 3.9367, Val Loss: 8.8529\n",
      "Epoch [4358/10000], Train Loss: 3.9361, Val Loss: 8.8547\n",
      "Epoch [4359/10000], Train Loss: 3.9355, Val Loss: 8.8572\n",
      "Epoch [4360/10000], Train Loss: 3.9349, Val Loss: 8.8594\n",
      "Epoch [4361/10000], Train Loss: 3.9343, Val Loss: 8.8601\n",
      "Epoch [4362/10000], Train Loss: 3.9337, Val Loss: 8.8603\n",
      "Epoch [4363/10000], Train Loss: 3.9331, Val Loss: 8.8580\n",
      "Epoch [4364/10000], Train Loss: 3.9326, Val Loss: 8.8541\n",
      "Epoch [4365/10000], Train Loss: 3.9320, Val Loss: 8.8501\n",
      "Epoch [4366/10000], Train Loss: 3.9314, Val Loss: 8.8464\n",
      "Epoch [4367/10000], Train Loss: 3.9308, Val Loss: 8.8451\n",
      "Epoch [4368/10000], Train Loss: 3.9302, Val Loss: 8.8465\n",
      "Epoch [4369/10000], Train Loss: 3.9297, Val Loss: 8.8484\n",
      "Epoch [4370/10000], Train Loss: 3.9291, Val Loss: 8.8493\n",
      "Epoch [4371/10000], Train Loss: 3.9285, Val Loss: 8.8497\n",
      "Epoch [4372/10000], Train Loss: 3.9279, Val Loss: 8.8492\n",
      "Epoch [4373/10000], Train Loss: 3.9273, Val Loss: 8.8492\n",
      "Epoch [4374/10000], Train Loss: 3.9267, Val Loss: 8.8509\n",
      "Epoch [4375/10000], Train Loss: 3.9261, Val Loss: 8.8536\n",
      "Epoch [4376/10000], Train Loss: 3.9255, Val Loss: 8.8560\n",
      "Epoch [4377/10000], Train Loss: 3.9249, Val Loss: 8.8583\n",
      "Epoch [4378/10000], Train Loss: 3.9243, Val Loss: 8.8597\n",
      "Epoch [4379/10000], Train Loss: 3.9237, Val Loss: 8.8606\n",
      "Epoch [4380/10000], Train Loss: 3.9231, Val Loss: 8.8610\n",
      "Epoch [4381/10000], Train Loss: 3.9225, Val Loss: 8.8590\n",
      "Epoch [4382/10000], Train Loss: 3.9220, Val Loss: 8.8555\n",
      "Epoch [4383/10000], Train Loss: 3.9214, Val Loss: 8.8517\n",
      "Epoch [4384/10000], Train Loss: 3.9208, Val Loss: 8.8473\n",
      "Epoch [4385/10000], Train Loss: 3.9202, Val Loss: 8.8460\n",
      "Epoch [4386/10000], Train Loss: 3.9196, Val Loss: 8.8474\n",
      "Epoch [4387/10000], Train Loss: 3.9190, Val Loss: 8.8496\n",
      "Epoch [4388/10000], Train Loss: 3.9185, Val Loss: 8.8506\n",
      "Epoch [4389/10000], Train Loss: 3.9179, Val Loss: 8.8518\n",
      "Epoch [4390/10000], Train Loss: 3.9173, Val Loss: 8.8509\n",
      "Epoch [4391/10000], Train Loss: 3.9168, Val Loss: 8.8513\n",
      "Epoch [4392/10000], Train Loss: 3.9162, Val Loss: 8.8525\n",
      "Epoch [4393/10000], Train Loss: 3.9157, Val Loss: 8.8557\n",
      "Epoch [4394/10000], Train Loss: 3.9152, Val Loss: 8.8574\n",
      "Epoch [4395/10000], Train Loss: 3.9147, Val Loss: 8.8610\n",
      "Epoch [4396/10000], Train Loss: 3.9142, Val Loss: 8.8620\n",
      "Epoch [4397/10000], Train Loss: 3.9137, Val Loss: 8.8639\n",
      "Epoch [4398/10000], Train Loss: 3.9133, Val Loss: 8.8637\n",
      "Epoch [4399/10000], Train Loss: 3.9128, Val Loss: 8.8626\n",
      "Epoch [4400/10000], Train Loss: 3.9123, Val Loss: 8.8579\n",
      "Epoch [4401/10000], Train Loss: 3.9117, Val Loss: 8.8549\n",
      "Epoch [4402/10000], Train Loss: 3.9110, Val Loss: 8.8497\n",
      "Epoch [4403/10000], Train Loss: 3.9101, Val Loss: 8.8487\n",
      "Epoch [4404/10000], Train Loss: 3.9093, Val Loss: 8.8496\n",
      "Epoch [4405/10000], Train Loss: 3.9084, Val Loss: 8.8518\n",
      "Epoch [4406/10000], Train Loss: 3.9077, Val Loss: 8.8527\n",
      "Epoch [4407/10000], Train Loss: 3.9069, Val Loss: 8.8535\n",
      "Epoch [4408/10000], Train Loss: 3.9063, Val Loss: 8.8533\n",
      "Epoch [4409/10000], Train Loss: 3.9058, Val Loss: 8.8529\n",
      "Epoch [4410/10000], Train Loss: 3.9053, Val Loss: 8.8554\n",
      "Epoch [4411/10000], Train Loss: 3.9048, Val Loss: 8.8574\n",
      "Epoch [4412/10000], Train Loss: 3.9042, Val Loss: 8.8603\n",
      "Epoch [4413/10000], Train Loss: 3.9036, Val Loss: 8.8623\n",
      "Epoch [4414/10000], Train Loss: 3.9029, Val Loss: 8.8643\n",
      "Epoch [4415/10000], Train Loss: 3.9023, Val Loss: 8.8637\n",
      "Epoch [4416/10000], Train Loss: 3.9016, Val Loss: 8.8608\n",
      "Epoch [4417/10000], Train Loss: 3.9009, Val Loss: 8.8564\n",
      "Epoch [4418/10000], Train Loss: 3.9003, Val Loss: 8.8517\n",
      "Epoch [4419/10000], Train Loss: 3.8996, Val Loss: 8.8478\n",
      "Epoch [4420/10000], Train Loss: 3.8990, Val Loss: 8.8476\n",
      "Epoch [4421/10000], Train Loss: 3.8984, Val Loss: 8.8502\n",
      "Epoch [4422/10000], Train Loss: 3.8978, Val Loss: 8.8517\n",
      "Epoch [4423/10000], Train Loss: 3.8973, Val Loss: 8.8531\n",
      "Epoch [4424/10000], Train Loss: 3.8967, Val Loss: 8.8527\n",
      "Epoch [4425/10000], Train Loss: 3.8960, Val Loss: 8.8518\n",
      "Epoch [4426/10000], Train Loss: 3.8954, Val Loss: 8.8518\n",
      "Epoch [4427/10000], Train Loss: 3.8948, Val Loss: 8.8544\n",
      "Epoch [4428/10000], Train Loss: 3.8941, Val Loss: 8.8571\n",
      "Epoch [4429/10000], Train Loss: 3.8935, Val Loss: 8.8602\n",
      "Epoch [4430/10000], Train Loss: 3.8929, Val Loss: 8.8627\n",
      "Epoch [4431/10000], Train Loss: 3.8922, Val Loss: 8.8629\n",
      "Epoch [4432/10000], Train Loss: 3.8917, Val Loss: 8.8587\n",
      "Epoch [4433/10000], Train Loss: 3.8911, Val Loss: 8.8534\n",
      "Epoch [4434/10000], Train Loss: 3.8905, Val Loss: 8.8482\n",
      "Epoch [4435/10000], Train Loss: 3.8898, Val Loss: 8.8436\n",
      "Epoch [4436/10000], Train Loss: 3.8892, Val Loss: 8.8448\n",
      "Epoch [4437/10000], Train Loss: 3.8886, Val Loss: 8.8482\n",
      "Epoch [4438/10000], Train Loss: 3.8880, Val Loss: 8.8506\n",
      "Epoch [4439/10000], Train Loss: 3.8874, Val Loss: 8.8513\n",
      "Epoch [4440/10000], Train Loss: 3.8867, Val Loss: 8.8509\n",
      "Epoch [4441/10000], Train Loss: 3.8861, Val Loss: 8.8487\n",
      "Epoch [4442/10000], Train Loss: 3.8855, Val Loss: 8.8490\n",
      "Epoch [4443/10000], Train Loss: 3.8848, Val Loss: 8.8520\n",
      "Epoch [4444/10000], Train Loss: 3.8842, Val Loss: 8.8553\n",
      "Epoch [4445/10000], Train Loss: 3.8836, Val Loss: 8.8588\n",
      "Epoch [4446/10000], Train Loss: 3.8829, Val Loss: 8.8617\n",
      "Epoch [4447/10000], Train Loss: 3.8823, Val Loss: 8.8616\n",
      "Epoch [4448/10000], Train Loss: 3.8817, Val Loss: 8.8570\n",
      "Epoch [4449/10000], Train Loss: 3.8811, Val Loss: 8.8521\n",
      "Epoch [4450/10000], Train Loss: 3.8805, Val Loss: 8.8466\n",
      "Epoch [4451/10000], Train Loss: 3.8799, Val Loss: 8.8427\n",
      "Epoch [4452/10000], Train Loss: 3.8792, Val Loss: 8.8441\n",
      "Epoch [4453/10000], Train Loss: 3.8786, Val Loss: 8.8478\n",
      "Epoch [4454/10000], Train Loss: 3.8780, Val Loss: 8.8495\n",
      "Epoch [4455/10000], Train Loss: 3.8774, Val Loss: 8.8505\n",
      "Epoch [4456/10000], Train Loss: 3.8767, Val Loss: 8.8497\n",
      "Epoch [4457/10000], Train Loss: 3.8761, Val Loss: 8.8479\n",
      "Epoch [4458/10000], Train Loss: 3.8754, Val Loss: 8.8488\n",
      "Epoch [4459/10000], Train Loss: 3.8748, Val Loss: 8.8522\n",
      "Epoch [4460/10000], Train Loss: 3.8742, Val Loss: 8.8554\n",
      "Epoch [4461/10000], Train Loss: 3.8735, Val Loss: 8.8589\n",
      "Epoch [4462/10000], Train Loss: 3.8729, Val Loss: 8.8615\n",
      "Epoch [4463/10000], Train Loss: 3.8723, Val Loss: 8.8610\n",
      "Epoch [4464/10000], Train Loss: 3.8717, Val Loss: 8.8568\n",
      "Epoch [4465/10000], Train Loss: 3.8710, Val Loss: 8.8519\n",
      "Epoch [4466/10000], Train Loss: 3.8704, Val Loss: 8.8468\n",
      "Epoch [4467/10000], Train Loss: 3.8698, Val Loss: 8.8431\n",
      "Epoch [4468/10000], Train Loss: 3.8691, Val Loss: 8.8447\n",
      "Epoch [4469/10000], Train Loss: 3.8685, Val Loss: 8.8477\n",
      "Epoch [4470/10000], Train Loss: 3.8679, Val Loss: 8.8496\n",
      "Epoch [4471/10000], Train Loss: 3.8672, Val Loss: 8.8503\n",
      "Epoch [4472/10000], Train Loss: 3.8666, Val Loss: 8.8498\n",
      "Epoch [4473/10000], Train Loss: 3.8660, Val Loss: 8.8481\n",
      "Epoch [4474/10000], Train Loss: 3.8653, Val Loss: 8.8496\n",
      "Epoch [4475/10000], Train Loss: 3.8647, Val Loss: 8.8525\n",
      "Epoch [4476/10000], Train Loss: 3.8641, Val Loss: 8.8562\n",
      "Epoch [4477/10000], Train Loss: 3.8634, Val Loss: 8.8592\n",
      "Epoch [4478/10000], Train Loss: 3.8628, Val Loss: 8.8610\n",
      "Epoch [4479/10000], Train Loss: 3.8622, Val Loss: 8.8559\n",
      "Epoch [4480/10000], Train Loss: 3.8616, Val Loss: 8.8501\n",
      "Epoch [4481/10000], Train Loss: 3.8609, Val Loss: 8.8435\n",
      "Epoch [4482/10000], Train Loss: 3.8603, Val Loss: 8.8391\n",
      "Epoch [4483/10000], Train Loss: 3.8597, Val Loss: 8.8400\n",
      "Epoch [4484/10000], Train Loss: 3.8591, Val Loss: 8.8457\n",
      "Epoch [4485/10000], Train Loss: 3.8585, Val Loss: 8.8479\n",
      "Epoch [4486/10000], Train Loss: 3.8579, Val Loss: 8.8497\n",
      "Epoch [4487/10000], Train Loss: 3.8573, Val Loss: 8.8479\n",
      "Epoch [4488/10000], Train Loss: 3.8567, Val Loss: 8.8463\n",
      "Epoch [4489/10000], Train Loss: 3.8561, Val Loss: 8.8456\n",
      "Epoch [4490/10000], Train Loss: 3.8556, Val Loss: 8.8506\n",
      "Epoch [4491/10000], Train Loss: 3.8550, Val Loss: 8.8532\n",
      "Epoch [4492/10000], Train Loss: 3.8545, Val Loss: 8.8588\n",
      "Epoch [4493/10000], Train Loss: 3.8540, Val Loss: 8.8596\n",
      "Epoch [4494/10000], Train Loss: 3.8535, Val Loss: 8.8564\n",
      "Epoch [4495/10000], Train Loss: 3.8529, Val Loss: 8.8480\n",
      "Epoch [4496/10000], Train Loss: 3.8523, Val Loss: 8.8431\n",
      "Epoch [4497/10000], Train Loss: 3.8515, Val Loss: 8.8368\n",
      "Epoch [4498/10000], Train Loss: 3.8507, Val Loss: 8.8397\n",
      "Epoch [4499/10000], Train Loss: 3.8498, Val Loss: 8.8443\n",
      "Epoch [4500/10000], Train Loss: 3.8489, Val Loss: 8.8478\n",
      "Epoch [4501/10000], Train Loss: 3.8481, Val Loss: 8.8478\n",
      "Epoch [4502/10000], Train Loss: 3.8473, Val Loss: 8.8466\n",
      "Epoch [4503/10000], Train Loss: 3.8466, Val Loss: 8.8440\n",
      "Epoch [4504/10000], Train Loss: 3.8460, Val Loss: 8.8443\n",
      "Epoch [4505/10000], Train Loss: 3.8454, Val Loss: 8.8492\n",
      "Epoch [4506/10000], Train Loss: 3.8448, Val Loss: 8.8528\n",
      "Epoch [4507/10000], Train Loss: 3.8442, Val Loss: 8.8568\n",
      "Epoch [4508/10000], Train Loss: 3.8437, Val Loss: 8.8535\n",
      "Epoch [4509/10000], Train Loss: 3.8430, Val Loss: 8.8466\n",
      "Epoch [4510/10000], Train Loss: 3.8422, Val Loss: 8.8373\n",
      "Epoch [4511/10000], Train Loss: 3.8415, Val Loss: 8.8318\n",
      "Epoch [4512/10000], Train Loss: 3.8408, Val Loss: 8.8323\n",
      "Epoch [4513/10000], Train Loss: 3.8401, Val Loss: 8.8385\n",
      "Epoch [4514/10000], Train Loss: 3.8394, Val Loss: 8.8442\n",
      "Epoch [4515/10000], Train Loss: 3.8388, Val Loss: 8.8457\n",
      "Epoch [4516/10000], Train Loss: 3.8381, Val Loss: 8.8442\n",
      "Epoch [4517/10000], Train Loss: 3.8375, Val Loss: 8.8405\n",
      "Epoch [4518/10000], Train Loss: 3.8368, Val Loss: 8.8401\n",
      "Epoch [4519/10000], Train Loss: 3.8362, Val Loss: 8.8429\n",
      "Epoch [4520/10000], Train Loss: 3.8355, Val Loss: 8.8485\n",
      "Epoch [4521/10000], Train Loss: 3.8348, Val Loss: 8.8523\n",
      "Epoch [4522/10000], Train Loss: 3.8342, Val Loss: 8.8508\n",
      "Epoch [4523/10000], Train Loss: 3.8336, Val Loss: 8.8436\n",
      "Epoch [4524/10000], Train Loss: 3.8329, Val Loss: 8.8348\n",
      "Epoch [4525/10000], Train Loss: 3.8322, Val Loss: 8.8278\n",
      "Epoch [4526/10000], Train Loss: 3.8315, Val Loss: 8.8289\n",
      "Epoch [4527/10000], Train Loss: 3.8308, Val Loss: 8.8354\n",
      "Epoch [4528/10000], Train Loss: 3.8301, Val Loss: 8.8413\n",
      "Epoch [4529/10000], Train Loss: 3.8295, Val Loss: 8.8440\n",
      "Epoch [4530/10000], Train Loss: 3.8288, Val Loss: 8.8418\n",
      "Epoch [4531/10000], Train Loss: 3.8281, Val Loss: 8.8381\n",
      "Epoch [4532/10000], Train Loss: 3.8275, Val Loss: 8.8371\n",
      "Epoch [4533/10000], Train Loss: 3.8268, Val Loss: 8.8407\n",
      "Epoch [4534/10000], Train Loss: 3.8261, Val Loss: 8.8458\n",
      "Epoch [4535/10000], Train Loss: 3.8255, Val Loss: 8.8510\n",
      "Epoch [4536/10000], Train Loss: 3.8249, Val Loss: 8.8490\n",
      "Epoch [4537/10000], Train Loss: 3.8242, Val Loss: 8.8419\n",
      "Epoch [4538/10000], Train Loss: 3.8235, Val Loss: 8.8326\n",
      "Epoch [4539/10000], Train Loss: 3.8228, Val Loss: 8.8255\n",
      "Epoch [4540/10000], Train Loss: 3.8221, Val Loss: 8.8265\n",
      "Epoch [4541/10000], Train Loss: 3.8215, Val Loss: 8.8334\n",
      "Epoch [4542/10000], Train Loss: 3.8207, Val Loss: 8.8397\n",
      "Epoch [4543/10000], Train Loss: 3.8201, Val Loss: 8.8422\n",
      "Epoch [4544/10000], Train Loss: 3.8194, Val Loss: 8.8403\n",
      "Epoch [4545/10000], Train Loss: 3.8187, Val Loss: 8.8359\n",
      "Epoch [4546/10000], Train Loss: 3.8180, Val Loss: 8.8353\n",
      "Epoch [4547/10000], Train Loss: 3.8174, Val Loss: 8.8386\n",
      "Epoch [4548/10000], Train Loss: 3.8167, Val Loss: 8.8433\n",
      "Epoch [4549/10000], Train Loss: 3.8160, Val Loss: 8.8436\n",
      "Epoch [4550/10000], Train Loss: 3.8154, Val Loss: 8.8397\n",
      "Epoch [4551/10000], Train Loss: 3.8147, Val Loss: 8.8306\n",
      "Epoch [4552/10000], Train Loss: 3.8140, Val Loss: 8.8220\n",
      "Epoch [4553/10000], Train Loss: 3.8133, Val Loss: 8.8206\n",
      "Epoch [4554/10000], Train Loss: 3.8126, Val Loss: 8.8253\n",
      "Epoch [4555/10000], Train Loss: 3.8119, Val Loss: 8.8321\n",
      "Epoch [4556/10000], Train Loss: 3.8112, Val Loss: 8.8374\n",
      "Epoch [4557/10000], Train Loss: 3.8106, Val Loss: 8.8372\n",
      "Epoch [4558/10000], Train Loss: 3.8099, Val Loss: 8.8334\n",
      "Epoch [4559/10000], Train Loss: 3.8092, Val Loss: 8.8316\n",
      "Epoch [4560/10000], Train Loss: 3.8085, Val Loss: 8.8328\n",
      "Epoch [4561/10000], Train Loss: 3.8078, Val Loss: 8.8365\n",
      "Epoch [4562/10000], Train Loss: 3.8071, Val Loss: 8.8375\n",
      "Epoch [4563/10000], Train Loss: 3.8065, Val Loss: 8.8345\n",
      "Epoch [4564/10000], Train Loss: 3.8058, Val Loss: 8.8269\n",
      "Epoch [4565/10000], Train Loss: 3.8051, Val Loss: 8.8192\n",
      "Epoch [4566/10000], Train Loss: 3.8044, Val Loss: 8.8173\n",
      "Epoch [4567/10000], Train Loss: 3.8037, Val Loss: 8.8210\n",
      "Epoch [4568/10000], Train Loss: 3.8030, Val Loss: 8.8272\n",
      "Epoch [4569/10000], Train Loss: 3.8023, Val Loss: 8.8325\n",
      "Epoch [4570/10000], Train Loss: 3.8016, Val Loss: 8.8332\n",
      "Epoch [4571/10000], Train Loss: 3.8009, Val Loss: 8.8305\n",
      "Epoch [4572/10000], Train Loss: 3.8002, Val Loss: 8.8289\n",
      "Epoch [4573/10000], Train Loss: 3.7995, Val Loss: 8.8298\n",
      "Epoch [4574/10000], Train Loss: 3.7989, Val Loss: 8.8330\n",
      "Epoch [4575/10000], Train Loss: 3.7981, Val Loss: 8.8335\n",
      "Epoch [4576/10000], Train Loss: 3.7975, Val Loss: 8.8306\n",
      "Epoch [4577/10000], Train Loss: 3.7968, Val Loss: 8.8236\n",
      "Epoch [4578/10000], Train Loss: 3.7960, Val Loss: 8.8163\n",
      "Epoch [4579/10000], Train Loss: 3.7954, Val Loss: 8.8148\n",
      "Epoch [4580/10000], Train Loss: 3.7947, Val Loss: 8.8184\n",
      "Epoch [4581/10000], Train Loss: 3.7940, Val Loss: 8.8241\n",
      "Epoch [4582/10000], Train Loss: 3.7933, Val Loss: 8.8290\n",
      "Epoch [4583/10000], Train Loss: 3.7925, Val Loss: 8.8297\n",
      "Epoch [4584/10000], Train Loss: 3.7918, Val Loss: 8.8274\n",
      "Epoch [4585/10000], Train Loss: 3.7911, Val Loss: 8.8263\n",
      "Epoch [4586/10000], Train Loss: 3.7904, Val Loss: 8.8275\n",
      "Epoch [4587/10000], Train Loss: 3.7898, Val Loss: 8.8304\n",
      "Epoch [4588/10000], Train Loss: 3.7890, Val Loss: 8.8308\n",
      "Epoch [4589/10000], Train Loss: 3.7884, Val Loss: 8.8274\n",
      "Epoch [4590/10000], Train Loss: 3.7876, Val Loss: 8.8203\n",
      "Epoch [4591/10000], Train Loss: 3.7869, Val Loss: 8.8133\n",
      "Epoch [4592/10000], Train Loss: 3.7862, Val Loss: 8.8123\n",
      "Epoch [4593/10000], Train Loss: 3.7855, Val Loss: 8.8160\n",
      "Epoch [4594/10000], Train Loss: 3.7848, Val Loss: 8.8219\n",
      "Epoch [4595/10000], Train Loss: 3.7841, Val Loss: 8.8262\n",
      "Epoch [4596/10000], Train Loss: 3.7834, Val Loss: 8.8268\n",
      "Epoch [4597/10000], Train Loss: 3.7827, Val Loss: 8.8241\n",
      "Epoch [4598/10000], Train Loss: 3.7820, Val Loss: 8.8238\n",
      "Epoch [4599/10000], Train Loss: 3.7814, Val Loss: 8.8236\n",
      "Epoch [4600/10000], Train Loss: 3.7807, Val Loss: 8.8232\n",
      "Epoch [4601/10000], Train Loss: 3.7802, Val Loss: 8.8199\n",
      "Epoch [4602/10000], Train Loss: 3.7797, Val Loss: 8.8166\n",
      "Epoch [4603/10000], Train Loss: 3.7793, Val Loss: 8.8087\n",
      "Epoch [4604/10000], Train Loss: 3.7791, Val Loss: 8.8113\n",
      "Epoch [4605/10000], Train Loss: 3.7791, Val Loss: 8.8111\n",
      "Epoch [4606/10000], Train Loss: 3.7794, Val Loss: 8.8197\n",
      "Epoch [4607/10000], Train Loss: 3.7796, Val Loss: 8.8211\n",
      "Epoch [4608/10000], Train Loss: 3.7795, Val Loss: 8.8258\n",
      "Epoch [4609/10000], Train Loss: 3.7784, Val Loss: 8.8208\n",
      "Epoch [4610/10000], Train Loss: 3.7763, Val Loss: 8.8205\n",
      "Epoch [4611/10000], Train Loss: 3.7738, Val Loss: 8.8190\n",
      "Epoch [4612/10000], Train Loss: 3.7720, Val Loss: 8.8157\n",
      "Epoch [4613/10000], Train Loss: 3.7715, Val Loss: 8.8146\n",
      "Epoch [4614/10000], Train Loss: 3.7717, Val Loss: 8.8086\n",
      "Epoch [4615/10000], Train Loss: 3.7717, Val Loss: 8.8043\n",
      "Epoch [4616/10000], Train Loss: 3.7708, Val Loss: 8.8031\n",
      "Epoch [4617/10000], Train Loss: 3.7692, Val Loss: 8.8060\n",
      "Epoch [4618/10000], Train Loss: 3.7678, Val Loss: 8.8096\n",
      "Epoch [4619/10000], Train Loss: 3.7670, Val Loss: 8.8138\n",
      "Epoch [4620/10000], Train Loss: 3.7668, Val Loss: 8.8153\n",
      "Epoch [4621/10000], Train Loss: 3.7664, Val Loss: 8.8135\n",
      "Epoch [4622/10000], Train Loss: 3.7656, Val Loss: 8.8147\n",
      "Epoch [4623/10000], Train Loss: 3.7644, Val Loss: 8.8146\n",
      "Epoch [4624/10000], Train Loss: 3.7633, Val Loss: 8.8119\n",
      "Epoch [4625/10000], Train Loss: 3.7627, Val Loss: 8.8095\n",
      "Epoch [4626/10000], Train Loss: 3.7622, Val Loss: 8.8027\n",
      "Epoch [4627/10000], Train Loss: 3.7616, Val Loss: 8.7974\n",
      "Epoch [4628/10000], Train Loss: 3.7608, Val Loss: 8.7979\n",
      "Epoch [4629/10000], Train Loss: 3.7598, Val Loss: 8.8011\n",
      "Epoch [4630/10000], Train Loss: 3.7589, Val Loss: 8.8057\n",
      "Epoch [4631/10000], Train Loss: 3.7583, Val Loss: 8.8100\n",
      "Epoch [4632/10000], Train Loss: 3.7577, Val Loss: 8.8101\n",
      "Epoch [4633/10000], Train Loss: 3.7570, Val Loss: 8.8086\n",
      "Epoch [4634/10000], Train Loss: 3.7561, Val Loss: 8.8096\n",
      "Epoch [4635/10000], Train Loss: 3.7553, Val Loss: 8.8098\n",
      "Epoch [4636/10000], Train Loss: 3.7545, Val Loss: 8.8080\n",
      "Epoch [4637/10000], Train Loss: 3.7539, Val Loss: 8.8054\n",
      "Epoch [4638/10000], Train Loss: 3.7532, Val Loss: 8.7982\n",
      "Epoch [4639/10000], Train Loss: 3.7524, Val Loss: 8.7928\n",
      "Epoch [4640/10000], Train Loss: 3.7516, Val Loss: 8.7932\n",
      "Epoch [4641/10000], Train Loss: 3.7508, Val Loss: 8.7962\n",
      "Epoch [4642/10000], Train Loss: 3.7501, Val Loss: 8.8014\n",
      "Epoch [4643/10000], Train Loss: 3.7494, Val Loss: 8.8057\n",
      "Epoch [4644/10000], Train Loss: 3.7486, Val Loss: 8.8056\n",
      "Epoch [4645/10000], Train Loss: 3.7479, Val Loss: 8.8046\n",
      "Epoch [4646/10000], Train Loss: 3.7471, Val Loss: 8.8052\n",
      "Epoch [4647/10000], Train Loss: 3.7465, Val Loss: 8.8052\n",
      "Epoch [4648/10000], Train Loss: 3.7456, Val Loss: 8.8036\n",
      "Epoch [4649/10000], Train Loss: 3.7449, Val Loss: 8.8007\n",
      "Epoch [4650/10000], Train Loss: 3.7442, Val Loss: 8.7938\n",
      "Epoch [4651/10000], Train Loss: 3.7434, Val Loss: 8.7886\n",
      "Epoch [4652/10000], Train Loss: 3.7426, Val Loss: 8.7888\n",
      "Epoch [4653/10000], Train Loss: 3.7419, Val Loss: 8.7918\n",
      "Epoch [4654/10000], Train Loss: 3.7411, Val Loss: 8.7971\n",
      "Epoch [4655/10000], Train Loss: 3.7404, Val Loss: 8.8011\n",
      "Epoch [4656/10000], Train Loss: 3.7396, Val Loss: 8.8010\n",
      "Epoch [4657/10000], Train Loss: 3.7389, Val Loss: 8.8003\n",
      "Epoch [4658/10000], Train Loss: 3.7382, Val Loss: 8.7994\n",
      "Epoch [4659/10000], Train Loss: 3.7374, Val Loss: 8.7947\n",
      "Epoch [4660/10000], Train Loss: 3.7367, Val Loss: 8.7907\n",
      "Epoch [4661/10000], Train Loss: 3.7359, Val Loss: 8.7854\n",
      "Epoch [4662/10000], Train Loss: 3.7351, Val Loss: 8.7804\n",
      "Epoch [4663/10000], Train Loss: 3.7344, Val Loss: 8.7817\n",
      "Epoch [4664/10000], Train Loss: 3.7336, Val Loss: 8.7845\n",
      "Epoch [4665/10000], Train Loss: 3.7329, Val Loss: 8.7874\n",
      "Epoch [4666/10000], Train Loss: 3.7321, Val Loss: 8.7913\n",
      "Epoch [4667/10000], Train Loss: 3.7313, Val Loss: 8.7917\n",
      "Epoch [4668/10000], Train Loss: 3.7306, Val Loss: 8.7919\n",
      "Epoch [4669/10000], Train Loss: 3.7298, Val Loss: 8.7939\n",
      "Epoch [4670/10000], Train Loss: 3.7292, Val Loss: 8.7941\n",
      "Epoch [4671/10000], Train Loss: 3.7283, Val Loss: 8.7912\n",
      "Epoch [4672/10000], Train Loss: 3.7275, Val Loss: 8.7871\n",
      "Epoch [4673/10000], Train Loss: 3.7268, Val Loss: 8.7795\n",
      "Epoch [4674/10000], Train Loss: 3.7260, Val Loss: 8.7746\n",
      "Epoch [4675/10000], Train Loss: 3.7252, Val Loss: 8.7766\n",
      "Epoch [4676/10000], Train Loss: 3.7245, Val Loss: 8.7807\n",
      "Epoch [4677/10000], Train Loss: 3.7237, Val Loss: 8.7862\n",
      "Epoch [4678/10000], Train Loss: 3.7229, Val Loss: 8.7898\n",
      "Epoch [4679/10000], Train Loss: 3.7221, Val Loss: 8.7884\n",
      "Epoch [4680/10000], Train Loss: 3.7214, Val Loss: 8.7864\n",
      "Epoch [4681/10000], Train Loss: 3.7207, Val Loss: 8.7809\n",
      "Epoch [4682/10000], Train Loss: 3.7199, Val Loss: 8.7746\n",
      "Epoch [4683/10000], Train Loss: 3.7191, Val Loss: 8.7693\n",
      "Epoch [4684/10000], Train Loss: 3.7183, Val Loss: 8.7657\n",
      "Epoch [4685/10000], Train Loss: 3.7176, Val Loss: 8.7670\n",
      "Epoch [4686/10000], Train Loss: 3.7168, Val Loss: 8.7704\n",
      "Epoch [4687/10000], Train Loss: 3.7160, Val Loss: 8.7727\n",
      "Epoch [4688/10000], Train Loss: 3.7152, Val Loss: 8.7747\n",
      "Epoch [4689/10000], Train Loss: 3.7144, Val Loss: 8.7756\n",
      "Epoch [4690/10000], Train Loss: 3.7137, Val Loss: 8.7767\n",
      "Epoch [4691/10000], Train Loss: 3.7129, Val Loss: 8.7797\n",
      "Epoch [4692/10000], Train Loss: 3.7122, Val Loss: 8.7812\n",
      "Epoch [4693/10000], Train Loss: 3.7113, Val Loss: 8.7776\n",
      "Epoch [4694/10000], Train Loss: 3.7106, Val Loss: 8.7723\n",
      "Epoch [4695/10000], Train Loss: 3.7097, Val Loss: 8.7642\n",
      "Epoch [4696/10000], Train Loss: 3.7090, Val Loss: 8.7591\n",
      "Epoch [4697/10000], Train Loss: 3.7082, Val Loss: 8.7621\n",
      "Epoch [4698/10000], Train Loss: 3.7074, Val Loss: 8.7676\n",
      "Epoch [4699/10000], Train Loss: 3.7066, Val Loss: 8.7737\n",
      "Epoch [4700/10000], Train Loss: 3.7058, Val Loss: 8.7770\n",
      "Epoch [4701/10000], Train Loss: 3.7050, Val Loss: 8.7750\n",
      "Epoch [4702/10000], Train Loss: 3.7043, Val Loss: 8.7725\n",
      "Epoch [4703/10000], Train Loss: 3.7036, Val Loss: 8.7673\n",
      "Epoch [4704/10000], Train Loss: 3.7027, Val Loss: 8.7619\n",
      "Epoch [4705/10000], Train Loss: 3.7019, Val Loss: 8.7571\n",
      "Epoch [4706/10000], Train Loss: 3.7011, Val Loss: 8.7538\n",
      "Epoch [4707/10000], Train Loss: 3.7003, Val Loss: 8.7549\n",
      "Epoch [4708/10000], Train Loss: 3.6996, Val Loss: 8.7578\n",
      "Epoch [4709/10000], Train Loss: 3.6987, Val Loss: 8.7602\n",
      "Epoch [4710/10000], Train Loss: 3.6979, Val Loss: 8.7624\n",
      "Epoch [4711/10000], Train Loss: 3.6971, Val Loss: 8.7638\n",
      "Epoch [4712/10000], Train Loss: 3.6963, Val Loss: 8.7655\n",
      "Epoch [4713/10000], Train Loss: 3.6956, Val Loss: 8.7672\n",
      "Epoch [4714/10000], Train Loss: 3.6948, Val Loss: 8.7629\n",
      "Epoch [4715/10000], Train Loss: 3.6940, Val Loss: 8.7567\n",
      "Epoch [4716/10000], Train Loss: 3.6931, Val Loss: 8.7492\n",
      "Epoch [4717/10000], Train Loss: 3.6923, Val Loss: 8.7437\n",
      "Epoch [4718/10000], Train Loss: 3.6916, Val Loss: 8.7463\n",
      "Epoch [4719/10000], Train Loss: 3.6908, Val Loss: 8.7514\n",
      "Epoch [4720/10000], Train Loss: 3.6899, Val Loss: 8.7567\n",
      "Epoch [4721/10000], Train Loss: 3.6891, Val Loss: 8.7607\n",
      "Epoch [4722/10000], Train Loss: 3.6883, Val Loss: 8.7599\n",
      "Epoch [4723/10000], Train Loss: 3.6875, Val Loss: 8.7591\n",
      "Epoch [4724/10000], Train Loss: 3.6868, Val Loss: 8.7594\n",
      "Epoch [4725/10000], Train Loss: 3.6859, Val Loss: 8.7558\n",
      "Epoch [4726/10000], Train Loss: 3.6851, Val Loss: 8.7524\n",
      "Epoch [4727/10000], Train Loss: 3.6843, Val Loss: 8.7465\n",
      "Epoch [4728/10000], Train Loss: 3.6835, Val Loss: 8.7408\n",
      "Epoch [4729/10000], Train Loss: 3.6827, Val Loss: 8.7425\n",
      "Epoch [4730/10000], Train Loss: 3.6819, Val Loss: 8.7447\n",
      "Epoch [4731/10000], Train Loss: 3.6811, Val Loss: 8.7426\n",
      "Epoch [4732/10000], Train Loss: 3.6803, Val Loss: 8.7383\n",
      "Epoch [4733/10000], Train Loss: 3.6796, Val Loss: 8.7270\n",
      "Epoch [4734/10000], Train Loss: 3.6787, Val Loss: 8.7184\n",
      "Epoch [4735/10000], Train Loss: 3.6779, Val Loss: 8.7184\n",
      "Epoch [4736/10000], Train Loss: 3.6770, Val Loss: 8.7201\n",
      "Epoch [4737/10000], Train Loss: 3.6763, Val Loss: 8.7251\n",
      "Epoch [4738/10000], Train Loss: 3.6754, Val Loss: 8.7283\n",
      "Epoch [4739/10000], Train Loss: 3.6746, Val Loss: 8.7262\n",
      "Epoch [4740/10000], Train Loss: 3.6737, Val Loss: 8.7266\n",
      "Epoch [4741/10000], Train Loss: 3.6729, Val Loss: 8.7282\n",
      "Epoch [4742/10000], Train Loss: 3.6721, Val Loss: 8.7320\n",
      "Epoch [4743/10000], Train Loss: 3.6712, Val Loss: 8.7399\n",
      "Epoch [4744/10000], Train Loss: 3.6704, Val Loss: 8.7436\n",
      "Epoch [4745/10000], Train Loss: 3.6696, Val Loss: 8.7398\n",
      "Epoch [4746/10000], Train Loss: 3.6688, Val Loss: 8.7334\n",
      "Epoch [4747/10000], Train Loss: 3.6679, Val Loss: 8.7240\n",
      "Epoch [4748/10000], Train Loss: 3.6671, Val Loss: 8.7214\n",
      "Epoch [4749/10000], Train Loss: 3.6663, Val Loss: 8.7283\n",
      "Epoch [4750/10000], Train Loss: 3.6654, Val Loss: 8.7352\n",
      "Epoch [4751/10000], Train Loss: 3.6646, Val Loss: 8.7405\n",
      "Epoch [4752/10000], Train Loss: 3.6639, Val Loss: 8.7343\n",
      "Epoch [4753/10000], Train Loss: 3.6631, Val Loss: 8.7212\n",
      "Epoch [4754/10000], Train Loss: 3.6622, Val Loss: 8.7101\n",
      "Epoch [4755/10000], Train Loss: 3.6614, Val Loss: 8.7047\n",
      "Epoch [4756/10000], Train Loss: 3.6605, Val Loss: 8.7099\n",
      "Epoch [4757/10000], Train Loss: 3.6597, Val Loss: 8.7183\n",
      "Epoch [4758/10000], Train Loss: 3.6589, Val Loss: 8.7221\n",
      "Epoch [4759/10000], Train Loss: 3.6580, Val Loss: 8.7209\n",
      "Epoch [4760/10000], Train Loss: 3.6571, Val Loss: 8.7164\n",
      "Epoch [4761/10000], Train Loss: 3.6563, Val Loss: 8.7145\n",
      "Epoch [4762/10000], Train Loss: 3.6554, Val Loss: 8.7199\n",
      "Epoch [4763/10000], Train Loss: 3.6546, Val Loss: 8.7265\n",
      "Epoch [4764/10000], Train Loss: 3.6538, Val Loss: 8.7268\n",
      "Epoch [4765/10000], Train Loss: 3.6530, Val Loss: 8.7211\n",
      "Epoch [4766/10000], Train Loss: 3.6521, Val Loss: 8.7087\n",
      "Epoch [4767/10000], Train Loss: 3.6512, Val Loss: 8.7009\n",
      "Epoch [4768/10000], Train Loss: 3.6504, Val Loss: 8.7040\n",
      "Epoch [4769/10000], Train Loss: 3.6496, Val Loss: 8.7107\n",
      "Epoch [4770/10000], Train Loss: 3.6487, Val Loss: 8.7141\n",
      "Epoch [4771/10000], Train Loss: 3.6480, Val Loss: 8.7093\n",
      "Epoch [4772/10000], Train Loss: 3.6471, Val Loss: 8.6944\n",
      "Epoch [4773/10000], Train Loss: 3.6462, Val Loss: 8.6832\n",
      "Epoch [4774/10000], Train Loss: 3.6454, Val Loss: 8.6819\n",
      "Epoch [4775/10000], Train Loss: 3.6445, Val Loss: 8.6870\n",
      "Epoch [4776/10000], Train Loss: 3.6437, Val Loss: 8.6967\n",
      "Epoch [4777/10000], Train Loss: 3.6428, Val Loss: 8.7006\n",
      "Epoch [4778/10000], Train Loss: 3.6419, Val Loss: 8.6984\n",
      "Epoch [4779/10000], Train Loss: 3.6410, Val Loss: 8.6959\n",
      "Epoch [4780/10000], Train Loss: 3.6402, Val Loss: 8.6952\n",
      "Epoch [4781/10000], Train Loss: 3.6393, Val Loss: 8.7009\n",
      "Epoch [4782/10000], Train Loss: 3.6384, Val Loss: 8.7092\n",
      "Epoch [4783/10000], Train Loss: 3.6376, Val Loss: 8.7086\n",
      "Epoch [4784/10000], Train Loss: 3.6367, Val Loss: 8.7030\n",
      "Epoch [4785/10000], Train Loss: 3.6359, Val Loss: 8.6914\n",
      "Epoch [4786/10000], Train Loss: 3.6350, Val Loss: 8.6837\n",
      "Epoch [4787/10000], Train Loss: 3.6342, Val Loss: 8.6891\n",
      "Epoch [4788/10000], Train Loss: 3.6333, Val Loss: 8.6965\n",
      "Epoch [4789/10000], Train Loss: 3.6324, Val Loss: 8.6991\n",
      "Epoch [4790/10000], Train Loss: 3.6317, Val Loss: 8.6933\n",
      "Epoch [4791/10000], Train Loss: 3.6308, Val Loss: 8.6772\n",
      "Epoch [4792/10000], Train Loss: 3.6299, Val Loss: 8.6665\n",
      "Epoch [4793/10000], Train Loss: 3.6290, Val Loss: 8.6670\n",
      "Epoch [4794/10000], Train Loss: 3.6282, Val Loss: 8.6724\n",
      "Epoch [4795/10000], Train Loss: 3.6273, Val Loss: 8.6833\n",
      "Epoch [4796/10000], Train Loss: 3.6264, Val Loss: 8.6859\n",
      "Epoch [4797/10000], Train Loss: 3.6255, Val Loss: 8.6830\n",
      "Epoch [4798/10000], Train Loss: 3.6246, Val Loss: 8.6801\n",
      "Epoch [4799/10000], Train Loss: 3.6238, Val Loss: 8.6796\n",
      "Epoch [4800/10000], Train Loss: 3.6229, Val Loss: 8.6859\n",
      "Epoch [4801/10000], Train Loss: 3.6221, Val Loss: 8.6951\n",
      "Epoch [4802/10000], Train Loss: 3.6212, Val Loss: 8.6934\n",
      "Epoch [4803/10000], Train Loss: 3.6203, Val Loss: 8.6877\n",
      "Epoch [4804/10000], Train Loss: 3.6193, Val Loss: 8.6748\n",
      "Epoch [4805/10000], Train Loss: 3.6184, Val Loss: 8.6669\n",
      "Epoch [4806/10000], Train Loss: 3.6177, Val Loss: 8.6653\n",
      "Epoch [4807/10000], Train Loss: 3.6167, Val Loss: 8.6651\n",
      "Epoch [4808/10000], Train Loss: 3.6159, Val Loss: 8.6620\n",
      "Epoch [4809/10000], Train Loss: 3.6149, Val Loss: 8.6566\n",
      "Epoch [4810/10000], Train Loss: 3.6141, Val Loss: 8.6500\n",
      "Epoch [4811/10000], Train Loss: 3.6132, Val Loss: 8.6482\n",
      "Epoch [4812/10000], Train Loss: 3.6123, Val Loss: 8.6497\n",
      "Epoch [4813/10000], Train Loss: 3.6114, Val Loss: 8.6536\n",
      "Epoch [4814/10000], Train Loss: 3.6104, Val Loss: 8.6577\n",
      "Epoch [4815/10000], Train Loss: 3.6096, Val Loss: 8.6597\n",
      "Epoch [4816/10000], Train Loss: 3.6086, Val Loss: 8.6600\n",
      "Epoch [4817/10000], Train Loss: 3.6077, Val Loss: 8.6609\n",
      "Epoch [4818/10000], Train Loss: 3.6068, Val Loss: 8.6636\n",
      "Epoch [4819/10000], Train Loss: 3.6061, Val Loss: 8.6688\n",
      "Epoch [4820/10000], Train Loss: 3.6051, Val Loss: 8.6684\n",
      "Epoch [4821/10000], Train Loss: 3.6042, Val Loss: 8.6648\n",
      "Epoch [4822/10000], Train Loss: 3.6033, Val Loss: 8.6567\n",
      "Epoch [4823/10000], Train Loss: 3.6023, Val Loss: 8.6525\n",
      "Epoch [4824/10000], Train Loss: 3.6015, Val Loss: 8.6546\n",
      "Epoch [4825/10000], Train Loss: 3.6006, Val Loss: 8.6537\n",
      "Epoch [4826/10000], Train Loss: 3.5997, Val Loss: 8.6504\n",
      "Epoch [4827/10000], Train Loss: 3.5989, Val Loss: 8.6415\n",
      "Epoch [4828/10000], Train Loss: 3.5980, Val Loss: 8.6319\n",
      "Epoch [4829/10000], Train Loss: 3.5971, Val Loss: 8.6326\n",
      "Epoch [4830/10000], Train Loss: 3.5963, Val Loss: 8.6342\n",
      "Epoch [4831/10000], Train Loss: 3.5955, Val Loss: 8.6412\n",
      "Epoch [4832/10000], Train Loss: 3.5946, Val Loss: 8.6441\n",
      "Epoch [4833/10000], Train Loss: 3.5939, Val Loss: 8.6439\n",
      "Epoch [4834/10000], Train Loss: 3.5931, Val Loss: 8.6428\n",
      "Epoch [4835/10000], Train Loss: 3.5925, Val Loss: 8.6445\n",
      "Epoch [4836/10000], Train Loss: 3.5919, Val Loss: 8.6462\n",
      "Epoch [4837/10000], Train Loss: 3.5913, Val Loss: 8.6485\n",
      "Epoch [4838/10000], Train Loss: 3.5906, Val Loss: 8.6437\n",
      "Epoch [4839/10000], Train Loss: 3.5898, Val Loss: 8.6363\n",
      "Epoch [4840/10000], Train Loss: 3.5886, Val Loss: 8.6303\n",
      "Epoch [4841/10000], Train Loss: 3.5872, Val Loss: 8.6304\n",
      "Epoch [4842/10000], Train Loss: 3.5859, Val Loss: 8.6358\n",
      "Epoch [4843/10000], Train Loss: 3.5844, Val Loss: 8.6348\n",
      "Epoch [4844/10000], Train Loss: 3.5833, Val Loss: 8.6296\n",
      "Epoch [4845/10000], Train Loss: 3.5823, Val Loss: 8.6175\n",
      "Epoch [4846/10000], Train Loss: 3.5815, Val Loss: 8.6091\n",
      "Epoch [4847/10000], Train Loss: 3.5808, Val Loss: 8.6109\n",
      "Epoch [4848/10000], Train Loss: 3.5801, Val Loss: 8.6150\n",
      "Epoch [4849/10000], Train Loss: 3.5792, Val Loss: 8.6226\n",
      "Epoch [4850/10000], Train Loss: 3.5781, Val Loss: 8.6244\n",
      "Epoch [4851/10000], Train Loss: 3.5769, Val Loss: 8.6226\n",
      "Epoch [4852/10000], Train Loss: 3.5758, Val Loss: 8.6222\n",
      "Epoch [4853/10000], Train Loss: 3.5748, Val Loss: 8.6239\n",
      "Epoch [4854/10000], Train Loss: 3.5739, Val Loss: 8.6297\n",
      "Epoch [4855/10000], Train Loss: 3.5731, Val Loss: 8.6303\n",
      "Epoch [4856/10000], Train Loss: 3.5722, Val Loss: 8.6257\n",
      "Epoch [4857/10000], Train Loss: 3.5714, Val Loss: 8.6153\n",
      "Epoch [4858/10000], Train Loss: 3.5704, Val Loss: 8.6076\n",
      "Epoch [4859/10000], Train Loss: 3.5695, Val Loss: 8.6019\n",
      "Epoch [4860/10000], Train Loss: 3.5684, Val Loss: 8.6007\n",
      "Epoch [4861/10000], Train Loss: 3.5674, Val Loss: 8.5964\n",
      "Epoch [4862/10000], Train Loss: 3.5664, Val Loss: 8.5924\n",
      "Epoch [4863/10000], Train Loss: 3.5655, Val Loss: 8.5898\n",
      "Epoch [4864/10000], Train Loss: 3.5646, Val Loss: 8.5878\n",
      "Epoch [4865/10000], Train Loss: 3.5636, Val Loss: 8.5897\n",
      "Epoch [4866/10000], Train Loss: 3.5627, Val Loss: 8.5908\n",
      "Epoch [4867/10000], Train Loss: 3.5617, Val Loss: 8.5936\n",
      "Epoch [4868/10000], Train Loss: 3.5608, Val Loss: 8.5963\n",
      "Epoch [4869/10000], Train Loss: 3.5597, Val Loss: 8.5985\n",
      "Epoch [4870/10000], Train Loss: 3.5587, Val Loss: 8.6015\n",
      "Epoch [4871/10000], Train Loss: 3.5578, Val Loss: 8.6041\n",
      "Epoch [4872/10000], Train Loss: 3.5569, Val Loss: 8.6016\n",
      "Epoch [4873/10000], Train Loss: 3.5559, Val Loss: 8.5980\n",
      "Epoch [4874/10000], Train Loss: 3.5550, Val Loss: 8.5902\n",
      "Epoch [4875/10000], Train Loss: 3.5539, Val Loss: 8.5876\n",
      "Epoch [4876/10000], Train Loss: 3.5531, Val Loss: 8.5907\n",
      "Epoch [4877/10000], Train Loss: 3.5521, Val Loss: 8.5881\n",
      "Epoch [4878/10000], Train Loss: 3.5511, Val Loss: 8.5852\n",
      "Epoch [4879/10000], Train Loss: 3.5503, Val Loss: 8.5732\n",
      "Epoch [4880/10000], Train Loss: 3.5492, Val Loss: 8.5657\n",
      "Epoch [4881/10000], Train Loss: 3.5483, Val Loss: 8.5669\n",
      "Epoch [4882/10000], Train Loss: 3.5472, Val Loss: 8.5697\n",
      "Epoch [4883/10000], Train Loss: 3.5463, Val Loss: 8.5768\n",
      "Epoch [4884/10000], Train Loss: 3.5453, Val Loss: 8.5780\n",
      "Epoch [4885/10000], Train Loss: 3.5443, Val Loss: 8.5764\n",
      "Epoch [4886/10000], Train Loss: 3.5433, Val Loss: 8.5772\n",
      "Epoch [4887/10000], Train Loss: 3.5424, Val Loss: 8.5766\n",
      "Epoch [4888/10000], Train Loss: 3.5414, Val Loss: 8.5756\n",
      "Epoch [4889/10000], Train Loss: 3.5405, Val Loss: 8.5733\n",
      "Epoch [4890/10000], Train Loss: 3.5394, Val Loss: 8.5649\n",
      "Epoch [4891/10000], Train Loss: 3.5384, Val Loss: 8.5619\n",
      "Epoch [4892/10000], Train Loss: 3.5375, Val Loss: 8.5602\n",
      "Epoch [4893/10000], Train Loss: 3.5366, Val Loss: 8.5567\n",
      "Epoch [4894/10000], Train Loss: 3.5355, Val Loss: 8.5549\n",
      "Epoch [4895/10000], Train Loss: 3.5347, Val Loss: 8.5445\n",
      "Epoch [4896/10000], Train Loss: 3.5336, Val Loss: 8.5398\n",
      "Epoch [4897/10000], Train Loss: 3.5326, Val Loss: 8.5392\n",
      "Epoch [4898/10000], Train Loss: 3.5316, Val Loss: 8.5407\n",
      "Epoch [4899/10000], Train Loss: 3.5307, Val Loss: 8.5466\n",
      "Epoch [4900/10000], Train Loss: 3.5296, Val Loss: 8.5466\n",
      "Epoch [4901/10000], Train Loss: 3.5286, Val Loss: 8.5474\n",
      "Epoch [4902/10000], Train Loss: 3.5276, Val Loss: 8.5495\n",
      "Epoch [4903/10000], Train Loss: 3.5266, Val Loss: 8.5515\n",
      "Epoch [4904/10000], Train Loss: 3.5256, Val Loss: 8.5580\n",
      "Epoch [4905/10000], Train Loss: 3.5247, Val Loss: 8.5551\n",
      "Epoch [4906/10000], Train Loss: 3.5237, Val Loss: 8.5508\n",
      "Epoch [4907/10000], Train Loss: 3.5226, Val Loss: 8.5418\n",
      "Epoch [4908/10000], Train Loss: 3.5216, Val Loss: 8.5351\n",
      "Epoch [4909/10000], Train Loss: 3.5207, Val Loss: 8.5322\n",
      "Epoch [4910/10000], Train Loss: 3.5197, Val Loss: 8.5287\n",
      "Epoch [4911/10000], Train Loss: 3.5187, Val Loss: 8.5237\n",
      "Epoch [4912/10000], Train Loss: 3.5177, Val Loss: 8.5188\n",
      "Epoch [4913/10000], Train Loss: 3.5166, Val Loss: 8.5157\n",
      "Epoch [4914/10000], Train Loss: 3.5157, Val Loss: 8.5171\n",
      "Epoch [4915/10000], Train Loss: 3.5146, Val Loss: 8.5195\n",
      "Epoch [4916/10000], Train Loss: 3.5136, Val Loss: 8.5218\n",
      "Epoch [4917/10000], Train Loss: 3.5125, Val Loss: 8.5234\n",
      "Epoch [4918/10000], Train Loss: 3.5116, Val Loss: 8.5245\n",
      "Epoch [4919/10000], Train Loss: 3.5105, Val Loss: 8.5274\n",
      "Epoch [4920/10000], Train Loss: 3.5095, Val Loss: 8.5299\n",
      "Epoch [4921/10000], Train Loss: 3.5085, Val Loss: 8.5272\n",
      "Epoch [4922/10000], Train Loss: 3.5075, Val Loss: 8.5235\n",
      "Epoch [4923/10000], Train Loss: 3.5064, Val Loss: 8.5151\n",
      "Epoch [4924/10000], Train Loss: 3.5054, Val Loss: 8.5130\n",
      "Epoch [4925/10000], Train Loss: 3.5045, Val Loss: 8.5150\n",
      "Epoch [4926/10000], Train Loss: 3.5035, Val Loss: 8.5125\n",
      "Epoch [4927/10000], Train Loss: 3.5024, Val Loss: 8.5097\n",
      "Epoch [4928/10000], Train Loss: 3.5015, Val Loss: 8.4971\n",
      "Epoch [4929/10000], Train Loss: 3.5003, Val Loss: 8.4909\n",
      "Epoch [4930/10000], Train Loss: 3.4994, Val Loss: 8.4913\n",
      "Epoch [4931/10000], Train Loss: 3.4983, Val Loss: 8.4950\n",
      "Epoch [4932/10000], Train Loss: 3.4973, Val Loss: 8.5027\n",
      "Epoch [4933/10000], Train Loss: 3.4962, Val Loss: 8.5024\n",
      "Epoch [4934/10000], Train Loss: 3.4952, Val Loss: 8.5022\n",
      "Epoch [4935/10000], Train Loss: 3.4941, Val Loss: 8.5024\n",
      "Epoch [4936/10000], Train Loss: 3.4931, Val Loss: 8.5030\n",
      "Epoch [4937/10000], Train Loss: 3.4921, Val Loss: 8.5034\n",
      "Epoch [4938/10000], Train Loss: 3.4911, Val Loss: 8.4991\n",
      "Epoch [4939/10000], Train Loss: 3.4899, Val Loss: 8.4918\n",
      "Epoch [4940/10000], Train Loss: 3.4889, Val Loss: 8.4878\n",
      "Epoch [4941/10000], Train Loss: 3.4880, Val Loss: 8.4865\n",
      "Epoch [4942/10000], Train Loss: 3.4869, Val Loss: 8.4845\n",
      "Epoch [4943/10000], Train Loss: 3.4858, Val Loss: 8.4813\n",
      "Epoch [4944/10000], Train Loss: 3.4848, Val Loss: 8.4715\n",
      "Epoch [4945/10000], Train Loss: 3.4837, Val Loss: 8.4663\n",
      "Epoch [4946/10000], Train Loss: 3.4827, Val Loss: 8.4649\n",
      "Epoch [4947/10000], Train Loss: 3.4816, Val Loss: 8.4680\n",
      "Epoch [4948/10000], Train Loss: 3.4806, Val Loss: 8.4731\n",
      "Epoch [4949/10000], Train Loss: 3.4795, Val Loss: 8.4738\n",
      "Epoch [4950/10000], Train Loss: 3.4784, Val Loss: 8.4750\n",
      "Epoch [4951/10000], Train Loss: 3.4773, Val Loss: 8.4758\n",
      "Epoch [4952/10000], Train Loss: 3.4763, Val Loss: 8.4778\n",
      "Epoch [4953/10000], Train Loss: 3.4753, Val Loss: 8.4764\n",
      "Epoch [4954/10000], Train Loss: 3.4743, Val Loss: 8.4717\n",
      "Epoch [4955/10000], Train Loss: 3.4731, Val Loss: 8.4640\n",
      "Epoch [4956/10000], Train Loss: 3.4720, Val Loss: 8.4587\n",
      "Epoch [4957/10000], Train Loss: 3.4710, Val Loss: 8.4524\n",
      "Epoch [4958/10000], Train Loss: 3.4700, Val Loss: 8.4479\n",
      "Epoch [4959/10000], Train Loss: 3.4689, Val Loss: 8.4413\n",
      "Epoch [4960/10000], Train Loss: 3.4679, Val Loss: 8.4374\n",
      "Epoch [4961/10000], Train Loss: 3.4668, Val Loss: 8.4375\n",
      "Epoch [4962/10000], Train Loss: 3.4658, Val Loss: 8.4379\n",
      "Epoch [4963/10000], Train Loss: 3.4647, Val Loss: 8.4416\n",
      "Epoch [4964/10000], Train Loss: 3.4637, Val Loss: 8.4408\n",
      "Epoch [4965/10000], Train Loss: 3.4626, Val Loss: 8.4429\n",
      "Epoch [4966/10000], Train Loss: 3.4616, Val Loss: 8.4441\n",
      "Epoch [4967/10000], Train Loss: 3.4607, Val Loss: 8.4492\n",
      "Epoch [4968/10000], Train Loss: 3.4600, Val Loss: 8.4529\n",
      "Epoch [4969/10000], Train Loss: 3.4590, Val Loss: 8.4515\n",
      "Epoch [4970/10000], Train Loss: 3.4583, Val Loss: 8.4449\n",
      "Epoch [4971/10000], Train Loss: 3.4575, Val Loss: 8.4386\n",
      "Epoch [4972/10000], Train Loss: 3.4567, Val Loss: 8.4314\n",
      "Epoch [4973/10000], Train Loss: 3.4559, Val Loss: 8.4327\n",
      "Epoch [4974/10000], Train Loss: 3.4547, Val Loss: 8.4220\n",
      "Epoch [4975/10000], Train Loss: 3.4535, Val Loss: 8.4224\n",
      "Epoch [4976/10000], Train Loss: 3.4519, Val Loss: 8.4064\n",
      "Epoch [4977/10000], Train Loss: 3.4503, Val Loss: 8.4137\n",
      "Epoch [4978/10000], Train Loss: 3.4487, Val Loss: 8.4074\n",
      "Epoch [4979/10000], Train Loss: 3.4473, Val Loss: 8.4171\n",
      "Epoch [4980/10000], Train Loss: 3.4462, Val Loss: 8.4176\n",
      "Epoch [4981/10000], Train Loss: 3.4452, Val Loss: 8.4154\n",
      "Epoch [4982/10000], Train Loss: 3.4443, Val Loss: 8.4231\n",
      "Epoch [4983/10000], Train Loss: 3.4434, Val Loss: 8.4140\n",
      "Epoch [4984/10000], Train Loss: 3.4423, Val Loss: 8.4218\n",
      "Epoch [4985/10000], Train Loss: 3.4412, Val Loss: 8.4068\n",
      "Epoch [4986/10000], Train Loss: 3.4398, Val Loss: 8.4073\n",
      "Epoch [4987/10000], Train Loss: 3.4385, Val Loss: 8.4005\n",
      "Epoch [4988/10000], Train Loss: 3.4374, Val Loss: 8.4025\n",
      "Epoch [4989/10000], Train Loss: 3.4362, Val Loss: 8.4015\n",
      "Epoch [4990/10000], Train Loss: 3.4351, Val Loss: 8.3919\n",
      "Epoch [4991/10000], Train Loss: 3.4342, Val Loss: 8.3858\n",
      "Epoch [4992/10000], Train Loss: 3.4330, Val Loss: 8.3745\n",
      "Epoch [4993/10000], Train Loss: 3.4320, Val Loss: 8.3807\n",
      "Epoch [4994/10000], Train Loss: 3.4308, Val Loss: 8.3807\n",
      "Epoch [4995/10000], Train Loss: 3.4297, Val Loss: 8.3897\n",
      "Epoch [4996/10000], Train Loss: 3.4285, Val Loss: 8.3873\n",
      "Epoch [4997/10000], Train Loss: 3.4273, Val Loss: 8.3879\n",
      "Epoch [4998/10000], Train Loss: 3.4261, Val Loss: 8.3889\n",
      "Epoch [4999/10000], Train Loss: 3.4252, Val Loss: 8.3907\n",
      "Epoch [5000/10000], Train Loss: 3.4240, Val Loss: 8.3921\n",
      "Epoch [5001/10000], Train Loss: 3.4229, Val Loss: 8.3851\n",
      "Epoch [5002/10000], Train Loss: 3.4217, Val Loss: 8.3785\n",
      "Epoch [5003/10000], Train Loss: 3.4207, Val Loss: 8.3702\n",
      "Epoch [5004/10000], Train Loss: 3.4194, Val Loss: 8.3652\n",
      "Epoch [5005/10000], Train Loss: 3.4183, Val Loss: 8.3605\n",
      "Epoch [5006/10000], Train Loss: 3.4172, Val Loss: 8.3543\n",
      "Epoch [5007/10000], Train Loss: 3.4161, Val Loss: 8.3511\n",
      "Epoch [5008/10000], Train Loss: 3.4149, Val Loss: 8.3486\n",
      "Epoch [5009/10000], Train Loss: 3.4138, Val Loss: 8.3503\n",
      "Epoch [5010/10000], Train Loss: 3.4127, Val Loss: 8.3509\n",
      "Epoch [5011/10000], Train Loss: 3.4115, Val Loss: 8.3531\n",
      "Epoch [5012/10000], Train Loss: 3.4103, Val Loss: 8.3534\n",
      "Epoch [5013/10000], Train Loss: 3.4092, Val Loss: 8.3568\n",
      "Epoch [5014/10000], Train Loss: 3.4081, Val Loss: 8.3575\n",
      "Epoch [5015/10000], Train Loss: 3.4069, Val Loss: 8.3545\n",
      "Epoch [5016/10000], Train Loss: 3.4058, Val Loss: 8.3485\n",
      "Epoch [5017/10000], Train Loss: 3.4046, Val Loss: 8.3395\n",
      "Epoch [5018/10000], Train Loss: 3.4035, Val Loss: 8.3379\n",
      "Epoch [5019/10000], Train Loss: 3.4024, Val Loss: 8.3302\n",
      "Epoch [5020/10000], Train Loss: 3.4012, Val Loss: 8.3286\n",
      "Epoch [5021/10000], Train Loss: 3.4001, Val Loss: 8.3161\n",
      "Epoch [5022/10000], Train Loss: 3.3990, Val Loss: 8.3146\n",
      "Epoch [5023/10000], Train Loss: 3.3978, Val Loss: 8.3103\n",
      "Epoch [5024/10000], Train Loss: 3.3967, Val Loss: 8.3158\n",
      "Epoch [5025/10000], Train Loss: 3.3955, Val Loss: 8.3175\n",
      "Epoch [5026/10000], Train Loss: 3.3943, Val Loss: 8.3197\n",
      "Epoch [5027/10000], Train Loss: 3.3931, Val Loss: 8.3190\n",
      "Epoch [5028/10000], Train Loss: 3.3919, Val Loss: 8.3201\n",
      "Epoch [5029/10000], Train Loss: 3.3908, Val Loss: 8.3225\n",
      "Epoch [5030/10000], Train Loss: 3.3896, Val Loss: 8.3194\n",
      "Epoch [5031/10000], Train Loss: 3.3885, Val Loss: 8.3161\n",
      "Epoch [5032/10000], Train Loss: 3.3873, Val Loss: 8.3058\n",
      "Epoch [5033/10000], Train Loss: 3.3861, Val Loss: 8.3046\n",
      "Epoch [5034/10000], Train Loss: 3.3850, Val Loss: 8.2947\n",
      "Epoch [5035/10000], Train Loss: 3.3839, Val Loss: 8.2944\n",
      "Epoch [5036/10000], Train Loss: 3.3828, Val Loss: 8.2811\n",
      "Epoch [5037/10000], Train Loss: 3.3816, Val Loss: 8.2821\n",
      "Epoch [5038/10000], Train Loss: 3.3804, Val Loss: 8.2760\n",
      "Epoch [5039/10000], Train Loss: 3.3792, Val Loss: 8.2831\n",
      "Epoch [5040/10000], Train Loss: 3.3780, Val Loss: 8.2818\n",
      "Epoch [5041/10000], Train Loss: 3.3768, Val Loss: 8.2863\n",
      "Epoch [5042/10000], Train Loss: 3.3756, Val Loss: 8.2839\n",
      "Epoch [5043/10000], Train Loss: 3.3743, Val Loss: 8.2880\n",
      "Epoch [5044/10000], Train Loss: 3.3732, Val Loss: 8.2882\n",
      "Epoch [5045/10000], Train Loss: 3.3719, Val Loss: 8.2864\n",
      "Epoch [5046/10000], Train Loss: 3.3708, Val Loss: 8.2805\n",
      "Epoch [5047/10000], Train Loss: 3.3695, Val Loss: 8.2715\n",
      "Epoch [5048/10000], Train Loss: 3.3684, Val Loss: 8.2695\n",
      "Epoch [5049/10000], Train Loss: 3.3672, Val Loss: 8.2611\n",
      "Epoch [5050/10000], Train Loss: 3.3660, Val Loss: 8.2604\n",
      "Epoch [5051/10000], Train Loss: 3.3649, Val Loss: 8.2467\n",
      "Epoch [5052/10000], Train Loss: 3.3637, Val Loss: 8.2476\n",
      "Epoch [5053/10000], Train Loss: 3.3626, Val Loss: 8.2402\n",
      "Epoch [5054/10000], Train Loss: 3.3614, Val Loss: 8.2493\n",
      "Epoch [5055/10000], Train Loss: 3.3602, Val Loss: 8.2460\n",
      "Epoch [5056/10000], Train Loss: 3.3589, Val Loss: 8.2538\n",
      "Epoch [5057/10000], Train Loss: 3.3577, Val Loss: 8.2475\n",
      "Epoch [5058/10000], Train Loss: 3.3565, Val Loss: 8.2556\n",
      "Epoch [5059/10000], Train Loss: 3.3554, Val Loss: 8.2508\n",
      "Epoch [5060/10000], Train Loss: 3.3540, Val Loss: 8.2547\n",
      "Epoch [5061/10000], Train Loss: 3.3528, Val Loss: 8.2428\n",
      "Epoch [5062/10000], Train Loss: 3.3515, Val Loss: 8.2403\n",
      "Epoch [5063/10000], Train Loss: 3.3503, Val Loss: 8.2311\n",
      "Epoch [5064/10000], Train Loss: 3.3490, Val Loss: 8.2296\n",
      "Epoch [5065/10000], Train Loss: 3.3477, Val Loss: 8.2214\n",
      "Epoch [5066/10000], Train Loss: 3.3465, Val Loss: 8.2148\n",
      "Epoch [5067/10000], Train Loss: 3.3453, Val Loss: 8.2090\n",
      "Epoch [5068/10000], Train Loss: 3.3440, Val Loss: 8.2082\n",
      "Epoch [5069/10000], Train Loss: 3.3428, Val Loss: 8.2111\n",
      "Epoch [5070/10000], Train Loss: 3.3415, Val Loss: 8.2132\n",
      "Epoch [5071/10000], Train Loss: 3.3403, Val Loss: 8.2157\n",
      "Epoch [5072/10000], Train Loss: 3.3390, Val Loss: 8.2141\n",
      "Epoch [5073/10000], Train Loss: 3.3377, Val Loss: 8.2181\n",
      "Epoch [5074/10000], Train Loss: 3.3367, Val Loss: 8.2174\n",
      "Epoch [5075/10000], Train Loss: 3.3353, Val Loss: 8.2177\n",
      "Epoch [5076/10000], Train Loss: 3.3341, Val Loss: 8.2089\n",
      "Epoch [5077/10000], Train Loss: 3.3327, Val Loss: 8.2033\n",
      "Epoch [5078/10000], Train Loss: 3.3316, Val Loss: 8.1967\n",
      "Epoch [5079/10000], Train Loss: 3.3303, Val Loss: 8.1933\n",
      "Epoch [5080/10000], Train Loss: 3.3290, Val Loss: 8.1865\n",
      "Epoch [5081/10000], Train Loss: 3.3278, Val Loss: 8.1790\n",
      "Epoch [5082/10000], Train Loss: 3.3265, Val Loss: 8.1730\n",
      "Epoch [5083/10000], Train Loss: 3.3253, Val Loss: 8.1730\n",
      "Epoch [5084/10000], Train Loss: 3.3240, Val Loss: 8.1742\n",
      "Epoch [5085/10000], Train Loss: 3.3227, Val Loss: 8.1791\n",
      "Epoch [5086/10000], Train Loss: 3.3214, Val Loss: 8.1778\n",
      "Epoch [5087/10000], Train Loss: 3.3201, Val Loss: 8.1810\n",
      "Epoch [5088/10000], Train Loss: 3.3188, Val Loss: 8.1790\n",
      "Epoch [5089/10000], Train Loss: 3.3178, Val Loss: 8.1852\n",
      "Epoch [5090/10000], Train Loss: 3.3163, Val Loss: 8.1776\n",
      "Epoch [5091/10000], Train Loss: 3.3151, Val Loss: 8.1776\n",
      "Epoch [5092/10000], Train Loss: 3.3138, Val Loss: 8.1619\n",
      "Epoch [5093/10000], Train Loss: 3.3127, Val Loss: 8.1668\n",
      "Epoch [5094/10000], Train Loss: 3.3114, Val Loss: 8.1505\n",
      "Epoch [5095/10000], Train Loss: 3.3102, Val Loss: 8.1586\n",
      "Epoch [5096/10000], Train Loss: 3.3091, Val Loss: 8.1343\n",
      "Epoch [5097/10000], Train Loss: 3.3080, Val Loss: 8.1485\n",
      "Epoch [5098/10000], Train Loss: 3.3071, Val Loss: 8.1255\n",
      "Epoch [5099/10000], Train Loss: 3.3062, Val Loss: 8.1548\n",
      "Epoch [5100/10000], Train Loss: 3.3054, Val Loss: 8.1275\n",
      "Epoch [5101/10000], Train Loss: 3.3048, Val Loss: 8.1663\n",
      "Epoch [5102/10000], Train Loss: 3.3042, Val Loss: 8.1230\n",
      "Epoch [5103/10000], Train Loss: 3.3036, Val Loss: 8.1761\n",
      "Epoch [5104/10000], Train Loss: 3.3030, Val Loss: 8.1079\n",
      "Epoch [5105/10000], Train Loss: 3.3023, Val Loss: 8.1784\n",
      "Epoch [5106/10000], Train Loss: 3.3010, Val Loss: 8.0826\n",
      "Epoch [5107/10000], Train Loss: 3.3000, Val Loss: 8.1804\n",
      "Epoch [5108/10000], Train Loss: 3.2988, Val Loss: 8.0666\n",
      "Epoch [5109/10000], Train Loss: 3.2977, Val Loss: 8.1669\n",
      "Epoch [5110/10000], Train Loss: 3.2955, Val Loss: 8.0580\n",
      "Epoch [5111/10000], Train Loss: 3.2929, Val Loss: 8.1314\n",
      "Epoch [5112/10000], Train Loss: 3.2898, Val Loss: 8.0803\n",
      "Epoch [5113/10000], Train Loss: 3.2870, Val Loss: 8.0992\n",
      "Epoch [5114/10000], Train Loss: 3.2853, Val Loss: 8.1191\n",
      "Epoch [5115/10000], Train Loss: 3.2843, Val Loss: 8.0773\n",
      "Epoch [5116/10000], Train Loss: 3.2836, Val Loss: 8.1351\n",
      "Epoch [5117/10000], Train Loss: 3.2827, Val Loss: 8.0747\n",
      "Epoch [5118/10000], Train Loss: 3.2814, Val Loss: 8.1227\n",
      "Epoch [5119/10000], Train Loss: 3.2798, Val Loss: 8.0807\n",
      "Epoch [5120/10000], Train Loss: 3.2780, Val Loss: 8.0884\n",
      "Epoch [5121/10000], Train Loss: 3.2764, Val Loss: 8.0897\n",
      "Epoch [5122/10000], Train Loss: 3.2752, Val Loss: 8.0730\n",
      "Epoch [5123/10000], Train Loss: 3.2736, Val Loss: 8.0937\n",
      "Epoch [5124/10000], Train Loss: 3.2722, Val Loss: 8.0604\n",
      "Epoch [5125/10000], Train Loss: 3.2709, Val Loss: 8.0694\n",
      "Epoch [5126/10000], Train Loss: 3.2696, Val Loss: 8.0507\n",
      "Epoch [5127/10000], Train Loss: 3.2684, Val Loss: 8.0589\n",
      "Epoch [5128/10000], Train Loss: 3.2670, Val Loss: 8.0632\n",
      "Epoch [5129/10000], Train Loss: 3.2656, Val Loss: 8.0644\n",
      "Epoch [5130/10000], Train Loss: 3.2640, Val Loss: 8.0661\n",
      "Epoch [5131/10000], Train Loss: 3.2625, Val Loss: 8.0637\n",
      "Epoch [5132/10000], Train Loss: 3.2612, Val Loss: 8.0646\n",
      "Epoch [5133/10000], Train Loss: 3.2600, Val Loss: 8.0621\n",
      "Epoch [5134/10000], Train Loss: 3.2588, Val Loss: 8.0588\n",
      "Epoch [5135/10000], Train Loss: 3.2573, Val Loss: 8.0461\n",
      "Epoch [5136/10000], Train Loss: 3.2562, Val Loss: 8.0485\n",
      "Epoch [5137/10000], Train Loss: 3.2546, Val Loss: 8.0283\n",
      "Epoch [5138/10000], Train Loss: 3.2532, Val Loss: 8.0367\n",
      "Epoch [5139/10000], Train Loss: 3.2518, Val Loss: 8.0136\n",
      "Epoch [5140/10000], Train Loss: 3.2504, Val Loss: 8.0246\n",
      "Epoch [5141/10000], Train Loss: 3.2491, Val Loss: 8.0146\n",
      "Epoch [5142/10000], Train Loss: 3.2476, Val Loss: 8.0193\n",
      "Epoch [5143/10000], Train Loss: 3.2462, Val Loss: 8.0234\n",
      "Epoch [5144/10000], Train Loss: 3.2448, Val Loss: 8.0137\n",
      "Epoch [5145/10000], Train Loss: 3.2435, Val Loss: 8.0288\n",
      "Epoch [5146/10000], Train Loss: 3.2422, Val Loss: 8.0136\n",
      "Epoch [5147/10000], Train Loss: 3.2408, Val Loss: 8.0243\n",
      "Epoch [5148/10000], Train Loss: 3.2395, Val Loss: 8.0061\n",
      "Epoch [5149/10000], Train Loss: 3.2379, Val Loss: 8.0034\n",
      "Epoch [5150/10000], Train Loss: 3.2365, Val Loss: 8.0016\n",
      "Epoch [5151/10000], Train Loss: 3.2355, Val Loss: 7.9981\n",
      "Epoch [5152/10000], Train Loss: 3.2338, Val Loss: 8.0026\n",
      "Epoch [5153/10000], Train Loss: 3.2324, Val Loss: 7.9845\n",
      "Epoch [5154/10000], Train Loss: 3.2311, Val Loss: 7.9808\n",
      "Epoch [5155/10000], Train Loss: 3.2297, Val Loss: 7.9684\n",
      "Epoch [5156/10000], Train Loss: 3.2283, Val Loss: 7.9750\n",
      "Epoch [5157/10000], Train Loss: 3.2268, Val Loss: 7.9791\n",
      "Epoch [5158/10000], Train Loss: 3.2255, Val Loss: 7.9816\n",
      "Epoch [5159/10000], Train Loss: 3.2240, Val Loss: 7.9829\n",
      "Epoch [5160/10000], Train Loss: 3.2226, Val Loss: 7.9760\n",
      "Epoch [5161/10000], Train Loss: 3.2214, Val Loss: 7.9713\n",
      "Epoch [5162/10000], Train Loss: 3.2200, Val Loss: 7.9650\n",
      "Epoch [5163/10000], Train Loss: 3.2185, Val Loss: 7.9586\n",
      "Epoch [5164/10000], Train Loss: 3.2169, Val Loss: 7.9607\n",
      "Epoch [5165/10000], Train Loss: 3.2159, Val Loss: 7.9553\n",
      "Epoch [5166/10000], Train Loss: 3.2142, Val Loss: 7.9513\n",
      "Epoch [5167/10000], Train Loss: 3.2128, Val Loss: 7.9390\n",
      "Epoch [5168/10000], Train Loss: 3.2115, Val Loss: 7.9294\n",
      "Epoch [5169/10000], Train Loss: 3.2101, Val Loss: 7.9287\n",
      "Epoch [5170/10000], Train Loss: 3.2086, Val Loss: 7.9284\n",
      "Epoch [5171/10000], Train Loss: 3.2071, Val Loss: 7.9367\n",
      "Epoch [5172/10000], Train Loss: 3.2057, Val Loss: 7.9312\n",
      "Epoch [5173/10000], Train Loss: 3.2043, Val Loss: 7.9348\n",
      "Epoch [5174/10000], Train Loss: 3.2028, Val Loss: 7.9278\n",
      "Epoch [5175/10000], Train Loss: 3.2015, Val Loss: 7.9268\n",
      "Epoch [5176/10000], Train Loss: 3.2002, Val Loss: 7.9209\n",
      "Epoch [5177/10000], Train Loss: 3.1986, Val Loss: 7.9126\n",
      "Epoch [5178/10000], Train Loss: 3.1970, Val Loss: 7.9135\n",
      "Epoch [5179/10000], Train Loss: 3.1959, Val Loss: 7.9067\n",
      "Epoch [5180/10000], Train Loss: 3.1943, Val Loss: 7.9059\n",
      "Epoch [5181/10000], Train Loss: 3.1928, Val Loss: 7.8929\n",
      "Epoch [5182/10000], Train Loss: 3.1914, Val Loss: 7.8866\n",
      "Epoch [5183/10000], Train Loss: 3.1900, Val Loss: 7.8812\n",
      "Epoch [5184/10000], Train Loss: 3.1885, Val Loss: 7.8838\n",
      "Epoch [5185/10000], Train Loss: 3.1870, Val Loss: 7.8874\n",
      "Epoch [5186/10000], Train Loss: 3.1856, Val Loss: 7.8876\n",
      "Epoch [5187/10000], Train Loss: 3.1841, Val Loss: 7.8878\n",
      "Epoch [5188/10000], Train Loss: 3.1826, Val Loss: 7.8846\n",
      "Epoch [5189/10000], Train Loss: 3.1813, Val Loss: 7.8797\n",
      "Epoch [5190/10000], Train Loss: 3.1800, Val Loss: 7.8749\n",
      "Epoch [5191/10000], Train Loss: 3.1784, Val Loss: 7.8658\n",
      "Epoch [5192/10000], Train Loss: 3.1767, Val Loss: 7.8677\n",
      "Epoch [5193/10000], Train Loss: 3.1756, Val Loss: 7.8621\n",
      "Epoch [5194/10000], Train Loss: 3.1739, Val Loss: 7.8599\n",
      "Epoch [5195/10000], Train Loss: 3.1724, Val Loss: 7.8472\n",
      "Epoch [5196/10000], Train Loss: 3.1710, Val Loss: 7.8392\n",
      "Epoch [5197/10000], Train Loss: 3.1696, Val Loss: 7.8349\n",
      "Epoch [5198/10000], Train Loss: 3.1680, Val Loss: 7.8375\n",
      "Epoch [5199/10000], Train Loss: 3.1665, Val Loss: 7.8419\n",
      "Epoch [5200/10000], Train Loss: 3.1651, Val Loss: 7.8415\n",
      "Epoch [5201/10000], Train Loss: 3.1635, Val Loss: 7.8396\n",
      "Epoch [5202/10000], Train Loss: 3.1622, Val Loss: 7.8255\n",
      "Epoch [5203/10000], Train Loss: 3.1608, Val Loss: 7.8231\n",
      "Epoch [5204/10000], Train Loss: 3.1594, Val Loss: 7.8098\n",
      "Epoch [5205/10000], Train Loss: 3.1576, Val Loss: 7.8213\n",
      "Epoch [5206/10000], Train Loss: 3.1563, Val Loss: 7.8118\n",
      "Epoch [5207/10000], Train Loss: 3.1550, Val Loss: 7.8247\n",
      "Epoch [5208/10000], Train Loss: 3.1533, Val Loss: 7.7980\n",
      "Epoch [5209/10000], Train Loss: 3.1520, Val Loss: 7.8065\n",
      "Epoch [5210/10000], Train Loss: 3.1507, Val Loss: 7.7741\n",
      "Epoch [5211/10000], Train Loss: 3.1492, Val Loss: 7.8026\n",
      "Epoch [5212/10000], Train Loss: 3.1477, Val Loss: 7.7752\n",
      "Epoch [5213/10000], Train Loss: 3.1465, Val Loss: 7.8160\n",
      "Epoch [5214/10000], Train Loss: 3.1453, Val Loss: 7.7691\n",
      "Epoch [5215/10000], Train Loss: 3.1443, Val Loss: 7.8218\n",
      "Epoch [5216/10000], Train Loss: 3.1436, Val Loss: 7.7460\n",
      "Epoch [5217/10000], Train Loss: 3.1436, Val Loss: 7.8311\n",
      "Epoch [5218/10000], Train Loss: 3.1437, Val Loss: 7.7170\n",
      "Epoch [5219/10000], Train Loss: 3.1450, Val Loss: 7.8580\n",
      "Epoch [5220/10000], Train Loss: 3.1470, Val Loss: 7.6937\n",
      "Epoch [5221/10000], Train Loss: 3.1502, Val Loss: 7.8736\n",
      "Epoch [5222/10000], Train Loss: 3.1510, Val Loss: 7.6679\n",
      "Epoch [5223/10000], Train Loss: 3.1508, Val Loss: 7.8351\n",
      "Epoch [5224/10000], Train Loss: 3.1441, Val Loss: 7.6859\n",
      "Epoch [5225/10000], Train Loss: 3.1357, Val Loss: 7.7617\n",
      "Epoch [5226/10000], Train Loss: 3.1277, Val Loss: 7.7580\n",
      "Epoch [5227/10000], Train Loss: 3.1249, Val Loss: 7.6981\n",
      "Epoch [5228/10000], Train Loss: 3.1261, Val Loss: 7.7990\n",
      "Epoch [5229/10000], Train Loss: 3.1276, Val Loss: 7.6886\n",
      "Epoch [5230/10000], Train Loss: 3.1276, Val Loss: 7.7875\n",
      "Epoch [5231/10000], Train Loss: 3.1238, Val Loss: 7.7243\n",
      "Epoch [5232/10000], Train Loss: 3.1191, Val Loss: 7.7265\n",
      "Epoch [5233/10000], Train Loss: 3.1154, Val Loss: 7.7477\n",
      "Epoch [5234/10000], Train Loss: 3.1148, Val Loss: 7.6825\n",
      "Epoch [5235/10000], Train Loss: 3.1150, Val Loss: 7.7454\n",
      "Epoch [5236/10000], Train Loss: 3.1140, Val Loss: 7.6829\n",
      "Epoch [5237/10000], Train Loss: 3.1115, Val Loss: 7.7057\n",
      "Epoch [5238/10000], Train Loss: 3.1081, Val Loss: 7.6976\n",
      "Epoch [5239/10000], Train Loss: 3.1059, Val Loss: 7.6707\n",
      "Epoch [5240/10000], Train Loss: 3.1051, Val Loss: 7.7133\n",
      "Epoch [5241/10000], Train Loss: 3.1046, Val Loss: 7.6725\n",
      "Epoch [5242/10000], Train Loss: 3.1030, Val Loss: 7.7083\n",
      "Epoch [5243/10000], Train Loss: 3.1004, Val Loss: 7.6874\n",
      "Epoch [5244/10000], Train Loss: 3.0981, Val Loss: 7.6739\n",
      "Epoch [5245/10000], Train Loss: 3.0968, Val Loss: 7.6877\n",
      "Epoch [5246/10000], Train Loss: 3.0959, Val Loss: 7.6483\n",
      "Epoch [5247/10000], Train Loss: 3.0945, Val Loss: 7.6827\n",
      "Epoch [5248/10000], Train Loss: 3.0926, Val Loss: 7.6576\n",
      "Epoch [5249/10000], Train Loss: 3.0902, Val Loss: 7.6587\n",
      "Epoch [5250/10000], Train Loss: 3.0886, Val Loss: 7.6556\n",
      "Epoch [5251/10000], Train Loss: 3.0875, Val Loss: 7.6197\n",
      "Epoch [5252/10000], Train Loss: 3.0862, Val Loss: 7.6457\n",
      "Epoch [5253/10000], Train Loss: 3.0843, Val Loss: 7.6233\n",
      "Epoch [5254/10000], Train Loss: 3.0824, Val Loss: 7.6449\n",
      "Epoch [5255/10000], Train Loss: 3.0806, Val Loss: 7.6435\n",
      "Epoch [5256/10000], Train Loss: 3.0790, Val Loss: 7.6260\n",
      "Epoch [5257/10000], Train Loss: 3.0776, Val Loss: 7.6478\n",
      "Epoch [5258/10000], Train Loss: 3.0763, Val Loss: 7.6155\n",
      "Epoch [5259/10000], Train Loss: 3.0747, Val Loss: 7.6349\n",
      "Epoch [5260/10000], Train Loss: 3.0727, Val Loss: 7.6166\n",
      "Epoch [5261/10000], Train Loss: 3.0709, Val Loss: 7.6072\n",
      "Epoch [5262/10000], Train Loss: 3.0695, Val Loss: 7.6112\n",
      "Epoch [5263/10000], Train Loss: 3.0679, Val Loss: 7.5802\n",
      "Epoch [5264/10000], Train Loss: 3.0664, Val Loss: 7.5932\n",
      "Epoch [5265/10000], Train Loss: 3.0646, Val Loss: 7.5794\n",
      "Epoch [5266/10000], Train Loss: 3.0630, Val Loss: 7.5813\n",
      "Epoch [5267/10000], Train Loss: 3.0612, Val Loss: 7.5912\n",
      "Epoch [5268/10000], Train Loss: 3.0597, Val Loss: 7.5743\n",
      "Epoch [5269/10000], Train Loss: 3.0580, Val Loss: 7.5893\n",
      "Epoch [5270/10000], Train Loss: 3.0564, Val Loss: 7.5789\n",
      "Epoch [5271/10000], Train Loss: 3.0549, Val Loss: 7.5857\n",
      "Epoch [5272/10000], Train Loss: 3.0531, Val Loss: 7.5851\n",
      "Epoch [5273/10000], Train Loss: 3.0516, Val Loss: 7.5683\n",
      "Epoch [5274/10000], Train Loss: 3.0498, Val Loss: 7.5684\n",
      "Epoch [5275/10000], Train Loss: 3.0484, Val Loss: 7.5559\n",
      "Epoch [5276/10000], Train Loss: 3.0465, Val Loss: 7.5527\n",
      "Epoch [5277/10000], Train Loss: 3.0448, Val Loss: 7.5483\n",
      "Epoch [5278/10000], Train Loss: 3.0433, Val Loss: 7.5323\n",
      "Epoch [5279/10000], Train Loss: 3.0416, Val Loss: 7.5340\n",
      "Epoch [5280/10000], Train Loss: 3.0400, Val Loss: 7.5267\n",
      "Epoch [5281/10000], Train Loss: 3.0383, Val Loss: 7.5316\n",
      "Epoch [5282/10000], Train Loss: 3.0366, Val Loss: 7.5356\n",
      "Epoch [5283/10000], Train Loss: 3.0349, Val Loss: 7.5316\n",
      "Epoch [5284/10000], Train Loss: 3.0333, Val Loss: 7.5338\n",
      "Epoch [5285/10000], Train Loss: 3.0317, Val Loss: 7.5178\n",
      "Epoch [5286/10000], Train Loss: 3.0301, Val Loss: 7.5155\n",
      "Epoch [5287/10000], Train Loss: 3.0283, Val Loss: 7.5060\n",
      "Epoch [5288/10000], Train Loss: 3.0266, Val Loss: 7.5071\n",
      "Epoch [5289/10000], Train Loss: 3.0253, Val Loss: 7.5089\n",
      "Epoch [5290/10000], Train Loss: 3.0233, Val Loss: 7.4942\n",
      "Epoch [5291/10000], Train Loss: 3.0217, Val Loss: 7.4905\n",
      "Epoch [5292/10000], Train Loss: 3.0201, Val Loss: 7.4703\n",
      "Epoch [5293/10000], Train Loss: 3.0184, Val Loss: 7.4748\n",
      "Epoch [5294/10000], Train Loss: 3.0166, Val Loss: 7.4737\n",
      "Epoch [5295/10000], Train Loss: 3.0149, Val Loss: 7.4786\n",
      "Epoch [5296/10000], Train Loss: 3.0132, Val Loss: 7.4789\n",
      "Epoch [5297/10000], Train Loss: 3.0117, Val Loss: 7.4560\n",
      "Epoch [5298/10000], Train Loss: 3.0101, Val Loss: 7.4548\n",
      "Epoch [5299/10000], Train Loss: 3.0085, Val Loss: 7.4352\n",
      "Epoch [5300/10000], Train Loss: 3.0065, Val Loss: 7.4509\n",
      "Epoch [5301/10000], Train Loss: 3.0049, Val Loss: 7.4456\n",
      "Epoch [5302/10000], Train Loss: 3.0032, Val Loss: 7.4477\n",
      "Epoch [5303/10000], Train Loss: 3.0014, Val Loss: 7.4321\n",
      "Epoch [5304/10000], Train Loss: 2.9998, Val Loss: 7.4167\n",
      "Epoch [5305/10000], Train Loss: 2.9982, Val Loss: 7.4127\n",
      "Epoch [5306/10000], Train Loss: 2.9963, Val Loss: 7.4102\n",
      "Epoch [5307/10000], Train Loss: 2.9945, Val Loss: 7.4226\n",
      "Epoch [5308/10000], Train Loss: 2.9929, Val Loss: 7.4157\n",
      "Epoch [5309/10000], Train Loss: 2.9911, Val Loss: 7.4179\n",
      "Epoch [5310/10000], Train Loss: 2.9893, Val Loss: 7.4087\n",
      "Epoch [5311/10000], Train Loss: 2.9878, Val Loss: 7.4060\n",
      "Epoch [5312/10000], Train Loss: 2.9863, Val Loss: 7.4026\n",
      "Epoch [5313/10000], Train Loss: 2.9843, Val Loss: 7.3928\n",
      "Epoch [5314/10000], Train Loss: 2.9823, Val Loss: 7.3956\n",
      "Epoch [5315/10000], Train Loss: 2.9811, Val Loss: 7.3831\n",
      "Epoch [5316/10000], Train Loss: 2.9790, Val Loss: 7.3818\n",
      "Epoch [5317/10000], Train Loss: 2.9772, Val Loss: 7.3677\n",
      "Epoch [5318/10000], Train Loss: 2.9756, Val Loss: 7.3649\n",
      "Epoch [5319/10000], Train Loss: 2.9739, Val Loss: 7.3600\n",
      "Epoch [5320/10000], Train Loss: 2.9720, Val Loss: 7.3606\n",
      "Epoch [5321/10000], Train Loss: 2.9702, Val Loss: 7.3622\n",
      "Epoch [5322/10000], Train Loss: 2.9686, Val Loss: 7.3581\n",
      "Epoch [5323/10000], Train Loss: 2.9668, Val Loss: 7.3462\n",
      "Epoch [5324/10000], Train Loss: 2.9651, Val Loss: 7.3361\n",
      "Epoch [5325/10000], Train Loss: 2.9635, Val Loss: 7.3262\n",
      "Epoch [5326/10000], Train Loss: 2.9615, Val Loss: 7.3332\n",
      "Epoch [5327/10000], Train Loss: 2.9598, Val Loss: 7.3297\n",
      "Epoch [5328/10000], Train Loss: 2.9580, Val Loss: 7.3369\n",
      "Epoch [5329/10000], Train Loss: 2.9565, Val Loss: 7.3265\n",
      "Epoch [5330/10000], Train Loss: 2.9544, Val Loss: 7.3208\n",
      "Epoch [5331/10000], Train Loss: 2.9530, Val Loss: 7.3081\n",
      "Epoch [5332/10000], Train Loss: 2.9511, Val Loss: 7.3021\n",
      "Epoch [5333/10000], Train Loss: 2.9490, Val Loss: 7.3058\n",
      "Epoch [5334/10000], Train Loss: 2.9473, Val Loss: 7.3032\n",
      "Epoch [5335/10000], Train Loss: 2.9459, Val Loss: 7.3061\n",
      "Epoch [5336/10000], Train Loss: 2.9437, Val Loss: 7.2857\n",
      "Epoch [5337/10000], Train Loss: 2.9421, Val Loss: 7.2876\n",
      "Epoch [5338/10000], Train Loss: 2.9405, Val Loss: 7.2652\n",
      "Epoch [5339/10000], Train Loss: 2.9385, Val Loss: 7.2828\n",
      "Epoch [5340/10000], Train Loss: 2.9366, Val Loss: 7.2667\n",
      "Epoch [5341/10000], Train Loss: 2.9351, Val Loss: 7.2841\n",
      "Epoch [5342/10000], Train Loss: 2.9332, Val Loss: 7.2470\n",
      "Epoch [5343/10000], Train Loss: 2.9314, Val Loss: 7.2579\n",
      "Epoch [5344/10000], Train Loss: 2.9298, Val Loss: 7.2251\n",
      "Epoch [5345/10000], Train Loss: 2.9279, Val Loss: 7.2534\n",
      "Epoch [5346/10000], Train Loss: 2.9259, Val Loss: 7.2347\n",
      "Epoch [5347/10000], Train Loss: 2.9241, Val Loss: 7.2539\n",
      "Epoch [5348/10000], Train Loss: 2.9223, Val Loss: 7.2308\n",
      "Epoch [5349/10000], Train Loss: 2.9203, Val Loss: 7.2289\n",
      "Epoch [5350/10000], Train Loss: 2.9187, Val Loss: 7.2137\n",
      "Epoch [5351/10000], Train Loss: 2.9169, Val Loss: 7.2115\n",
      "Epoch [5352/10000], Train Loss: 2.9148, Val Loss: 7.2169\n",
      "Epoch [5353/10000], Train Loss: 2.9130, Val Loss: 7.2101\n",
      "Epoch [5354/10000], Train Loss: 2.9113, Val Loss: 7.2167\n",
      "Epoch [5355/10000], Train Loss: 2.9093, Val Loss: 7.1871\n",
      "Epoch [5356/10000], Train Loss: 2.9078, Val Loss: 7.2005\n",
      "Epoch [5357/10000], Train Loss: 2.9061, Val Loss: 7.1671\n",
      "Epoch [5358/10000], Train Loss: 2.9042, Val Loss: 7.1996\n",
      "Epoch [5359/10000], Train Loss: 2.9023, Val Loss: 7.1674\n",
      "Epoch [5360/10000], Train Loss: 2.9006, Val Loss: 7.2009\n",
      "Epoch [5361/10000], Train Loss: 2.8988, Val Loss: 7.1630\n",
      "Epoch [5362/10000], Train Loss: 2.8968, Val Loss: 7.1822\n",
      "Epoch [5363/10000], Train Loss: 2.8951, Val Loss: 7.1482\n",
      "Epoch [5364/10000], Train Loss: 2.8932, Val Loss: 7.1646\n",
      "Epoch [5365/10000], Train Loss: 2.8908, Val Loss: 7.1463\n",
      "Epoch [5366/10000], Train Loss: 2.8891, Val Loss: 7.1613\n",
      "Epoch [5367/10000], Train Loss: 2.8876, Val Loss: 7.1441\n",
      "Epoch [5368/10000], Train Loss: 2.8851, Val Loss: 7.1444\n",
      "Epoch [5369/10000], Train Loss: 2.8834, Val Loss: 7.1261\n",
      "Epoch [5370/10000], Train Loss: 2.8817, Val Loss: 7.1231\n",
      "Epoch [5371/10000], Train Loss: 2.8796, Val Loss: 7.1205\n",
      "Epoch [5372/10000], Train Loss: 2.8776, Val Loss: 7.1222\n",
      "Epoch [5373/10000], Train Loss: 2.8759, Val Loss: 7.1221\n",
      "Epoch [5374/10000], Train Loss: 2.8739, Val Loss: 7.1009\n",
      "Epoch [5375/10000], Train Loss: 2.8721, Val Loss: 7.1001\n",
      "Epoch [5376/10000], Train Loss: 2.8704, Val Loss: 7.0754\n",
      "Epoch [5377/10000], Train Loss: 2.8684, Val Loss: 7.1012\n",
      "Epoch [5378/10000], Train Loss: 2.8665, Val Loss: 7.0750\n",
      "Epoch [5379/10000], Train Loss: 2.8648, Val Loss: 7.1094\n",
      "Epoch [5380/10000], Train Loss: 2.8630, Val Loss: 7.0658\n",
      "Epoch [5381/10000], Train Loss: 2.8612, Val Loss: 7.1081\n",
      "Epoch [5382/10000], Train Loss: 2.8598, Val Loss: 7.0502\n",
      "Epoch [5383/10000], Train Loss: 2.8584, Val Loss: 7.1022\n",
      "Epoch [5384/10000], Train Loss: 2.8564, Val Loss: 7.0344\n",
      "Epoch [5385/10000], Train Loss: 2.8545, Val Loss: 7.0962\n",
      "Epoch [5386/10000], Train Loss: 2.8533, Val Loss: 7.0251\n",
      "Epoch [5387/10000], Train Loss: 2.8507, Val Loss: 7.0795\n",
      "Epoch [5388/10000], Train Loss: 2.8486, Val Loss: 7.0115\n",
      "Epoch [5389/10000], Train Loss: 2.8467, Val Loss: 7.0568\n",
      "Epoch [5390/10000], Train Loss: 2.8444, Val Loss: 7.0049\n",
      "Epoch [5391/10000], Train Loss: 2.8421, Val Loss: 7.0451\n",
      "Epoch [5392/10000], Train Loss: 2.8400, Val Loss: 7.0116\n",
      "Epoch [5393/10000], Train Loss: 2.8380, Val Loss: 7.0371\n",
      "Epoch [5394/10000], Train Loss: 2.8359, Val Loss: 6.9984\n",
      "Epoch [5395/10000], Train Loss: 2.8340, Val Loss: 7.0094\n",
      "Epoch [5396/10000], Train Loss: 2.8322, Val Loss: 6.9822\n",
      "Epoch [5397/10000], Train Loss: 2.8298, Val Loss: 7.0039\n",
      "Epoch [5398/10000], Train Loss: 2.8280, Val Loss: 6.9841\n",
      "Epoch [5399/10000], Train Loss: 2.8262, Val Loss: 7.0022\n",
      "Epoch [5400/10000], Train Loss: 2.8240, Val Loss: 6.9635\n",
      "Epoch [5401/10000], Train Loss: 2.8223, Val Loss: 6.9813\n",
      "Epoch [5402/10000], Train Loss: 2.8205, Val Loss: 6.9388\n",
      "Epoch [5403/10000], Train Loss: 2.8184, Val Loss: 6.9781\n",
      "Epoch [5404/10000], Train Loss: 2.8165, Val Loss: 6.9407\n",
      "Epoch [5405/10000], Train Loss: 2.8148, Val Loss: 6.9827\n",
      "Epoch [5406/10000], Train Loss: 2.8128, Val Loss: 6.9326\n",
      "Epoch [5407/10000], Train Loss: 2.8108, Val Loss: 6.9632\n",
      "Epoch [5408/10000], Train Loss: 2.8091, Val Loss: 6.9145\n",
      "Epoch [5409/10000], Train Loss: 2.8069, Val Loss: 6.9483\n",
      "Epoch [5410/10000], Train Loss: 2.8045, Val Loss: 6.9107\n",
      "Epoch [5411/10000], Train Loss: 2.8027, Val Loss: 6.9452\n",
      "Epoch [5412/10000], Train Loss: 2.8011, Val Loss: 6.9061\n",
      "Epoch [5413/10000], Train Loss: 2.7984, Val Loss: 6.9264\n",
      "Epoch [5414/10000], Train Loss: 2.7966, Val Loss: 6.8876\n",
      "Epoch [5415/10000], Train Loss: 2.7947, Val Loss: 6.9063\n",
      "Epoch [5416/10000], Train Loss: 2.7923, Val Loss: 6.8815\n",
      "Epoch [5417/10000], Train Loss: 2.7903, Val Loss: 6.9046\n",
      "Epoch [5418/10000], Train Loss: 2.7885, Val Loss: 6.8777\n",
      "Epoch [5419/10000], Train Loss: 2.7862, Val Loss: 6.8843\n",
      "Epoch [5420/10000], Train Loss: 2.7843, Val Loss: 6.8536\n",
      "Epoch [5421/10000], Train Loss: 2.7824, Val Loss: 6.8646\n",
      "Epoch [5422/10000], Train Loss: 2.7802, Val Loss: 6.8471\n",
      "Epoch [5423/10000], Train Loss: 2.7781, Val Loss: 6.8691\n",
      "Epoch [5424/10000], Train Loss: 2.7762, Val Loss: 6.8433\n",
      "Epoch [5425/10000], Train Loss: 2.7743, Val Loss: 6.8666\n",
      "Epoch [5426/10000], Train Loss: 2.7724, Val Loss: 6.8191\n",
      "Epoch [5427/10000], Train Loss: 2.7709, Val Loss: 6.8546\n",
      "Epoch [5428/10000], Train Loss: 2.7690, Val Loss: 6.7991\n",
      "Epoch [5429/10000], Train Loss: 2.7669, Val Loss: 6.8578\n",
      "Epoch [5430/10000], Train Loss: 2.7653, Val Loss: 6.7919\n",
      "Epoch [5431/10000], Train Loss: 2.7640, Val Loss: 6.8582\n",
      "Epoch [5432/10000], Train Loss: 2.7618, Val Loss: 6.7711\n",
      "Epoch [5433/10000], Train Loss: 2.7606, Val Loss: 6.8453\n",
      "Epoch [5434/10000], Train Loss: 2.7590, Val Loss: 6.7518\n",
      "Epoch [5435/10000], Train Loss: 2.7569, Val Loss: 6.8389\n",
      "Epoch [5436/10000], Train Loss: 2.7547, Val Loss: 6.7523\n",
      "Epoch [5437/10000], Train Loss: 2.7529, Val Loss: 6.8309\n",
      "Epoch [5438/10000], Train Loss: 2.7501, Val Loss: 6.7400\n",
      "Epoch [5439/10000], Train Loss: 2.7478, Val Loss: 6.7977\n",
      "Epoch [5440/10000], Train Loss: 2.7453, Val Loss: 6.7318\n",
      "Epoch [5441/10000], Train Loss: 2.7424, Val Loss: 6.7795\n",
      "Epoch [5442/10000], Train Loss: 2.7396, Val Loss: 6.7465\n",
      "Epoch [5443/10000], Train Loss: 2.7373, Val Loss: 6.7642\n",
      "Epoch [5444/10000], Train Loss: 2.7352, Val Loss: 6.7531\n",
      "Epoch [5445/10000], Train Loss: 2.7329, Val Loss: 6.7331\n",
      "Epoch [5446/10000], Train Loss: 2.7312, Val Loss: 6.7468\n",
      "Epoch [5447/10000], Train Loss: 2.7293, Val Loss: 6.7063\n",
      "Epoch [5448/10000], Train Loss: 2.7271, Val Loss: 6.7520\n",
      "Epoch [5449/10000], Train Loss: 2.7255, Val Loss: 6.6972\n",
      "Epoch [5450/10000], Train Loss: 2.7242, Val Loss: 6.7495\n",
      "Epoch [5451/10000], Train Loss: 2.7215, Val Loss: 6.6798\n",
      "Epoch [5452/10000], Train Loss: 2.7199, Val Loss: 6.7293\n",
      "Epoch [5453/10000], Train Loss: 2.7177, Val Loss: 6.6664\n",
      "Epoch [5454/10000], Train Loss: 2.7150, Val Loss: 6.7131\n",
      "Epoch [5455/10000], Train Loss: 2.7126, Val Loss: 6.6722\n",
      "Epoch [5456/10000], Train Loss: 2.7108, Val Loss: 6.7001\n",
      "Epoch [5457/10000], Train Loss: 2.7079, Val Loss: 6.6611\n",
      "Epoch [5458/10000], Train Loss: 2.7058, Val Loss: 6.6691\n",
      "Epoch [5459/10000], Train Loss: 2.7038, Val Loss: 6.6481\n",
      "Epoch [5460/10000], Train Loss: 2.7013, Val Loss: 6.6585\n",
      "Epoch [5461/10000], Train Loss: 2.6991, Val Loss: 6.6525\n",
      "Epoch [5462/10000], Train Loss: 2.6971, Val Loss: 6.6501\n",
      "Epoch [5463/10000], Train Loss: 2.6948, Val Loss: 6.6330\n",
      "Epoch [5464/10000], Train Loss: 2.6928, Val Loss: 6.6222\n",
      "Epoch [5465/10000], Train Loss: 2.6908, Val Loss: 6.6141\n",
      "Epoch [5466/10000], Train Loss: 2.6884, Val Loss: 6.6169\n",
      "Epoch [5467/10000], Train Loss: 2.6862, Val Loss: 6.6183\n",
      "Epoch [5468/10000], Train Loss: 2.6842, Val Loss: 6.6145\n",
      "Epoch [5469/10000], Train Loss: 2.6819, Val Loss: 6.6106\n",
      "Epoch [5470/10000], Train Loss: 2.6798, Val Loss: 6.5935\n",
      "Epoch [5471/10000], Train Loss: 2.6781, Val Loss: 6.5963\n",
      "Epoch [5472/10000], Train Loss: 2.6758, Val Loss: 6.5760\n",
      "Epoch [5473/10000], Train Loss: 2.6733, Val Loss: 6.5948\n",
      "Epoch [5474/10000], Train Loss: 2.6714, Val Loss: 6.5678\n",
      "Epoch [5475/10000], Train Loss: 2.6697, Val Loss: 6.5929\n",
      "Epoch [5476/10000], Train Loss: 2.6671, Val Loss: 6.5478\n",
      "Epoch [5477/10000], Train Loss: 2.6656, Val Loss: 6.5808\n",
      "Epoch [5478/10000], Train Loss: 2.6636, Val Loss: 6.5255\n",
      "Epoch [5479/10000], Train Loss: 2.6612, Val Loss: 6.5751\n",
      "Epoch [5480/10000], Train Loss: 2.6592, Val Loss: 6.5191\n",
      "Epoch [5481/10000], Train Loss: 2.6577, Val Loss: 6.5737\n",
      "Epoch [5482/10000], Train Loss: 2.6551, Val Loss: 6.4996\n",
      "Epoch [5483/10000], Train Loss: 2.6534, Val Loss: 6.5534\n",
      "Epoch [5484/10000], Train Loss: 2.6514, Val Loss: 6.4803\n",
      "Epoch [5485/10000], Train Loss: 2.6489, Val Loss: 6.5450\n",
      "Epoch [5486/10000], Train Loss: 2.6465, Val Loss: 6.4822\n",
      "Epoch [5487/10000], Train Loss: 2.6445, Val Loss: 6.5358\n",
      "Epoch [5488/10000], Train Loss: 2.6417, Val Loss: 6.4660\n",
      "Epoch [5489/10000], Train Loss: 2.6396, Val Loss: 6.5056\n",
      "Epoch [5490/10000], Train Loss: 2.6373, Val Loss: 6.4527\n",
      "Epoch [5491/10000], Train Loss: 2.6346, Val Loss: 6.4942\n",
      "Epoch [5492/10000], Train Loss: 2.6321, Val Loss: 6.4613\n",
      "Epoch [5493/10000], Train Loss: 2.6298, Val Loss: 6.4845\n",
      "Epoch [5494/10000], Train Loss: 2.6275, Val Loss: 6.4603\n",
      "Epoch [5495/10000], Train Loss: 2.6251, Val Loss: 6.4591\n",
      "Epoch [5496/10000], Train Loss: 2.6232, Val Loss: 6.4496\n",
      "Epoch [5497/10000], Train Loss: 2.6207, Val Loss: 6.4380\n",
      "Epoch [5498/10000], Train Loss: 2.6181, Val Loss: 6.4496\n",
      "Epoch [5499/10000], Train Loss: 2.6163, Val Loss: 6.4238\n",
      "Epoch [5500/10000], Train Loss: 2.6139, Val Loss: 6.4324\n",
      "Epoch [5501/10000], Train Loss: 2.6117, Val Loss: 6.3966\n",
      "Epoch [5502/10000], Train Loss: 2.6097, Val Loss: 6.4174\n",
      "Epoch [5503/10000], Train Loss: 2.6074, Val Loss: 6.3864\n",
      "Epoch [5504/10000], Train Loss: 2.6050, Val Loss: 6.4163\n",
      "Epoch [5505/10000], Train Loss: 2.6029, Val Loss: 6.3813\n",
      "Epoch [5506/10000], Train Loss: 2.6007, Val Loss: 6.4143\n",
      "Epoch [5507/10000], Train Loss: 2.5983, Val Loss: 6.3780\n",
      "Epoch [5508/10000], Train Loss: 2.5960, Val Loss: 6.4184\n",
      "Epoch [5509/10000], Train Loss: 2.5943, Val Loss: 6.3689\n",
      "Epoch [5510/10000], Train Loss: 2.5922, Val Loss: 6.4058\n",
      "Epoch [5511/10000], Train Loss: 2.5895, Val Loss: 6.3436\n",
      "Epoch [5512/10000], Train Loss: 2.5882, Val Loss: 6.3916\n",
      "Epoch [5513/10000], Train Loss: 2.5855, Val Loss: 6.3255\n",
      "Epoch [5514/10000], Train Loss: 2.5833, Val Loss: 6.3791\n",
      "Epoch [5515/10000], Train Loss: 2.5813, Val Loss: 6.3075\n",
      "Epoch [5516/10000], Train Loss: 2.5790, Val Loss: 6.3631\n",
      "Epoch [5517/10000], Train Loss: 2.5766, Val Loss: 6.2979\n",
      "Epoch [5518/10000], Train Loss: 2.5742, Val Loss: 6.3572\n",
      "Epoch [5519/10000], Train Loss: 2.5718, Val Loss: 6.3013\n",
      "Epoch [5520/10000], Train Loss: 2.5694, Val Loss: 6.3325\n",
      "Epoch [5521/10000], Train Loss: 2.5668, Val Loss: 6.2794\n",
      "Epoch [5522/10000], Train Loss: 2.5643, Val Loss: 6.3008\n",
      "Epoch [5523/10000], Train Loss: 2.5615, Val Loss: 6.2803\n",
      "Epoch [5524/10000], Train Loss: 2.5593, Val Loss: 6.2971\n",
      "Epoch [5525/10000], Train Loss: 2.5568, Val Loss: 6.2816\n",
      "Epoch [5526/10000], Train Loss: 2.5543, Val Loss: 6.2691\n",
      "Epoch [5527/10000], Train Loss: 2.5524, Val Loss: 6.2624\n",
      "Epoch [5528/10000], Train Loss: 2.5501, Val Loss: 6.2382\n",
      "Epoch [5529/10000], Train Loss: 2.5475, Val Loss: 6.2641\n",
      "Epoch [5530/10000], Train Loss: 2.5454, Val Loss: 6.2318\n",
      "Epoch [5531/10000], Train Loss: 2.5434, Val Loss: 6.2682\n",
      "Epoch [5532/10000], Train Loss: 2.5412, Val Loss: 6.2008\n",
      "Epoch [5533/10000], Train Loss: 2.5396, Val Loss: 6.2499\n",
      "Epoch [5534/10000], Train Loss: 2.5375, Val Loss: 6.1796\n",
      "Epoch [5535/10000], Train Loss: 2.5350, Val Loss: 6.2508\n",
      "Epoch [5536/10000], Train Loss: 2.5329, Val Loss: 6.1769\n",
      "Epoch [5537/10000], Train Loss: 2.5309, Val Loss: 6.2414\n",
      "Epoch [5538/10000], Train Loss: 2.5283, Val Loss: 6.1555\n",
      "Epoch [5539/10000], Train Loss: 2.5265, Val Loss: 6.2187\n",
      "Epoch [5540/10000], Train Loss: 2.5240, Val Loss: 6.1437\n",
      "Epoch [5541/10000], Train Loss: 2.5211, Val Loss: 6.2091\n",
      "Epoch [5542/10000], Train Loss: 2.5184, Val Loss: 6.1474\n",
      "Epoch [5543/10000], Train Loss: 2.5159, Val Loss: 6.1945\n",
      "Epoch [5544/10000], Train Loss: 2.5128, Val Loss: 6.1500\n",
      "Epoch [5545/10000], Train Loss: 2.5103, Val Loss: 6.1696\n",
      "Epoch [5546/10000], Train Loss: 2.5082, Val Loss: 6.1471\n",
      "Epoch [5547/10000], Train Loss: 2.5052, Val Loss: 6.1405\n",
      "Epoch [5548/10000], Train Loss: 2.5024, Val Loss: 6.1457\n",
      "Epoch [5549/10000], Train Loss: 2.5009, Val Loss: 6.1213\n",
      "Epoch [5550/10000], Train Loss: 2.4980, Val Loss: 6.1345\n",
      "Epoch [5551/10000], Train Loss: 2.4957, Val Loss: 6.0964\n",
      "Epoch [5552/10000], Train Loss: 2.4937, Val Loss: 6.1218\n",
      "Epoch [5553/10000], Train Loss: 2.4911, Val Loss: 6.0819\n",
      "Epoch [5554/10000], Train Loss: 2.4885, Val Loss: 6.1168\n",
      "Epoch [5555/10000], Train Loss: 2.4863, Val Loss: 6.0777\n",
      "Epoch [5556/10000], Train Loss: 2.4839, Val Loss: 6.1142\n",
      "Epoch [5557/10000], Train Loss: 2.4816, Val Loss: 6.0588\n",
      "Epoch [5558/10000], Train Loss: 2.4796, Val Loss: 6.0925\n",
      "Epoch [5559/10000], Train Loss: 2.4771, Val Loss: 6.0425\n",
      "Epoch [5560/10000], Train Loss: 2.4742, Val Loss: 6.0860\n",
      "Epoch [5561/10000], Train Loss: 2.4721, Val Loss: 6.0414\n",
      "Epoch [5562/10000], Train Loss: 2.4699, Val Loss: 6.0760\n",
      "Epoch [5563/10000], Train Loss: 2.4668, Val Loss: 6.0258\n",
      "Epoch [5564/10000], Train Loss: 2.4650, Val Loss: 6.0566\n",
      "Epoch [5565/10000], Train Loss: 2.4625, Val Loss: 6.0077\n",
      "Epoch [5566/10000], Train Loss: 2.4595, Val Loss: 6.0448\n",
      "Epoch [5567/10000], Train Loss: 2.4572, Val Loss: 6.0064\n",
      "Epoch [5568/10000], Train Loss: 2.4552, Val Loss: 6.0380\n",
      "Epoch [5569/10000], Train Loss: 2.4521, Val Loss: 5.9868\n",
      "Epoch [5570/10000], Train Loss: 2.4502, Val Loss: 6.0163\n",
      "Epoch [5571/10000], Train Loss: 2.4478, Val Loss: 5.9710\n",
      "Epoch [5572/10000], Train Loss: 2.4447, Val Loss: 6.0076\n",
      "Epoch [5573/10000], Train Loss: 2.4424, Val Loss: 5.9673\n",
      "Epoch [5574/10000], Train Loss: 2.4404, Val Loss: 5.9971\n",
      "Epoch [5575/10000], Train Loss: 2.4372, Val Loss: 5.9481\n",
      "Epoch [5576/10000], Train Loss: 2.4353, Val Loss: 5.9761\n",
      "Epoch [5577/10000], Train Loss: 2.4329, Val Loss: 5.9305\n",
      "Epoch [5578/10000], Train Loss: 2.4300, Val Loss: 5.9682\n",
      "Epoch [5579/10000], Train Loss: 2.4275, Val Loss: 5.9276\n",
      "Epoch [5580/10000], Train Loss: 2.4254, Val Loss: 5.9593\n",
      "Epoch [5581/10000], Train Loss: 2.4225, Val Loss: 5.9047\n",
      "Epoch [5582/10000], Train Loss: 2.4205, Val Loss: 5.9403\n",
      "Epoch [5583/10000], Train Loss: 2.4181, Val Loss: 5.8879\n",
      "Epoch [5584/10000], Train Loss: 2.4152, Val Loss: 5.9333\n",
      "Epoch [5585/10000], Train Loss: 2.4128, Val Loss: 5.8827\n",
      "Epoch [5586/10000], Train Loss: 2.4106, Val Loss: 5.9251\n",
      "Epoch [5587/10000], Train Loss: 2.4078, Val Loss: 5.8619\n",
      "Epoch [5588/10000], Train Loss: 2.4058, Val Loss: 5.9055\n",
      "Epoch [5589/10000], Train Loss: 2.4034, Val Loss: 5.8451\n",
      "Epoch [5590/10000], Train Loss: 2.4005, Val Loss: 5.8978\n",
      "Epoch [5591/10000], Train Loss: 2.3980, Val Loss: 5.8421\n",
      "Epoch [5592/10000], Train Loss: 2.3957, Val Loss: 5.8878\n",
      "Epoch [5593/10000], Train Loss: 2.3928, Val Loss: 5.8223\n",
      "Epoch [5594/10000], Train Loss: 2.3909, Val Loss: 5.8677\n",
      "Epoch [5595/10000], Train Loss: 2.3883, Val Loss: 5.8069\n",
      "Epoch [5596/10000], Train Loss: 2.3853, Val Loss: 5.8573\n",
      "Epoch [5597/10000], Train Loss: 2.3828, Val Loss: 5.8050\n",
      "Epoch [5598/10000], Train Loss: 2.3804, Val Loss: 5.8467\n",
      "Epoch [5599/10000], Train Loss: 2.3774, Val Loss: 5.7873\n",
      "Epoch [5600/10000], Train Loss: 2.3754, Val Loss: 5.8242\n",
      "Epoch [5601/10000], Train Loss: 2.3727, Val Loss: 5.7732\n",
      "Epoch [5602/10000], Train Loss: 2.3696, Val Loss: 5.8126\n",
      "Epoch [5603/10000], Train Loss: 2.3671, Val Loss: 5.7723\n",
      "Epoch [5604/10000], Train Loss: 2.3647, Val Loss: 5.8005\n",
      "Epoch [5605/10000], Train Loss: 2.3617, Val Loss: 5.7552\n",
      "Epoch [5606/10000], Train Loss: 2.3597, Val Loss: 5.7788\n",
      "Epoch [5607/10000], Train Loss: 2.3570, Val Loss: 5.7401\n",
      "Epoch [5608/10000], Train Loss: 2.3539, Val Loss: 5.7676\n",
      "Epoch [5609/10000], Train Loss: 2.3515, Val Loss: 5.7377\n",
      "Epoch [5610/10000], Train Loss: 2.3492, Val Loss: 5.7577\n",
      "Epoch [5611/10000], Train Loss: 2.3461, Val Loss: 5.7182\n",
      "Epoch [5612/10000], Train Loss: 2.3441, Val Loss: 5.7379\n",
      "Epoch [5613/10000], Train Loss: 2.3415, Val Loss: 5.7010\n",
      "Epoch [5614/10000], Train Loss: 2.3384, Val Loss: 5.7287\n",
      "Epoch [5615/10000], Train Loss: 2.3360, Val Loss: 5.6960\n",
      "Epoch [5616/10000], Train Loss: 2.3337, Val Loss: 5.7205\n",
      "Epoch [5617/10000], Train Loss: 2.3307, Val Loss: 5.6752\n",
      "Epoch [5618/10000], Train Loss: 2.3288, Val Loss: 5.7029\n",
      "Epoch [5619/10000], Train Loss: 2.3262, Val Loss: 5.6560\n",
      "Epoch [5620/10000], Train Loss: 2.3231, Val Loss: 5.6951\n",
      "Epoch [5621/10000], Train Loss: 2.3207, Val Loss: 5.6491\n",
      "Epoch [5622/10000], Train Loss: 2.3185, Val Loss: 5.6887\n",
      "Epoch [5623/10000], Train Loss: 2.3155, Val Loss: 5.6269\n",
      "Epoch [5624/10000], Train Loss: 2.3137, Val Loss: 5.6732\n",
      "Epoch [5625/10000], Train Loss: 2.3111, Val Loss: 5.6068\n",
      "Epoch [5626/10000], Train Loss: 2.3081, Val Loss: 5.6663\n",
      "Epoch [5627/10000], Train Loss: 2.3058, Val Loss: 5.5991\n",
      "Epoch [5628/10000], Train Loss: 2.3037, Val Loss: 5.6600\n",
      "Epoch [5629/10000], Train Loss: 2.3006, Val Loss: 5.5782\n",
      "Epoch [5630/10000], Train Loss: 2.2988, Val Loss: 5.6434\n",
      "Epoch [5631/10000], Train Loss: 2.2961, Val Loss: 5.5603\n",
      "Epoch [5632/10000], Train Loss: 2.2930, Val Loss: 5.6329\n",
      "Epoch [5633/10000], Train Loss: 2.2905, Val Loss: 5.5564\n",
      "Epoch [5634/10000], Train Loss: 2.2882, Val Loss: 5.6210\n",
      "Epoch [5635/10000], Train Loss: 2.2847, Val Loss: 5.5413\n",
      "Epoch [5636/10000], Train Loss: 2.2826, Val Loss: 5.5976\n",
      "Epoch [5637/10000], Train Loss: 2.2797, Val Loss: 5.5299\n",
      "Epoch [5638/10000], Train Loss: 2.2762, Val Loss: 5.5793\n",
      "Epoch [5639/10000], Train Loss: 2.2734, Val Loss: 5.5324\n",
      "Epoch [5640/10000], Train Loss: 2.2710, Val Loss: 5.5614\n",
      "Epoch [5641/10000], Train Loss: 2.2674, Val Loss: 5.5217\n",
      "Epoch [5642/10000], Train Loss: 2.2653, Val Loss: 5.5345\n",
      "Epoch [5643/10000], Train Loss: 2.2624, Val Loss: 5.5122\n",
      "Epoch [5644/10000], Train Loss: 2.2591, Val Loss: 5.5158\n",
      "Epoch [5645/10000], Train Loss: 2.2566, Val Loss: 5.5137\n",
      "Epoch [5646/10000], Train Loss: 2.2544, Val Loss: 5.5006\n",
      "Epoch [5647/10000], Train Loss: 2.2510, Val Loss: 5.4979\n",
      "Epoch [5648/10000], Train Loss: 2.2490, Val Loss: 5.4804\n",
      "Epoch [5649/10000], Train Loss: 2.2462, Val Loss: 5.4792\n",
      "Epoch [5650/10000], Train Loss: 2.2429, Val Loss: 5.4705\n",
      "Epoch [5651/10000], Train Loss: 2.2405, Val Loss: 5.4707\n",
      "Epoch [5652/10000], Train Loss: 2.2383, Val Loss: 5.4642\n",
      "Epoch [5653/10000], Train Loss: 2.2348, Val Loss: 5.4480\n",
      "Epoch [5654/10000], Train Loss: 2.2329, Val Loss: 5.4482\n",
      "Epoch [5655/10000], Train Loss: 2.2301, Val Loss: 5.4278\n",
      "Epoch [5656/10000], Train Loss: 2.2267, Val Loss: 5.4373\n",
      "Epoch [5657/10000], Train Loss: 2.2244, Val Loss: 5.4207\n",
      "Epoch [5658/10000], Train Loss: 2.2221, Val Loss: 5.4297\n",
      "Epoch [5659/10000], Train Loss: 2.2187, Val Loss: 5.3991\n",
      "Epoch [5660/10000], Train Loss: 2.2168, Val Loss: 5.4146\n",
      "Epoch [5661/10000], Train Loss: 2.2140, Val Loss: 5.3771\n",
      "Epoch [5662/10000], Train Loss: 2.2107, Val Loss: 5.4069\n",
      "Epoch [5663/10000], Train Loss: 2.2084, Val Loss: 5.3664\n",
      "Epoch [5664/10000], Train Loss: 2.2062, Val Loss: 5.4028\n",
      "Epoch [5665/10000], Train Loss: 2.2028, Val Loss: 5.3427\n",
      "Epoch [5666/10000], Train Loss: 2.2011, Val Loss: 5.3909\n",
      "Epoch [5667/10000], Train Loss: 2.1984, Val Loss: 5.3195\n",
      "Epoch [5668/10000], Train Loss: 2.1952, Val Loss: 5.3844\n",
      "Epoch [5669/10000], Train Loss: 2.1930, Val Loss: 5.3085\n",
      "Epoch [5670/10000], Train Loss: 2.1911, Val Loss: 5.3807\n",
      "Epoch [5671/10000], Train Loss: 2.1878, Val Loss: 5.2865\n",
      "Epoch [5672/10000], Train Loss: 2.1864, Val Loss: 5.3685\n",
      "Epoch [5673/10000], Train Loss: 2.1837, Val Loss: 5.2655\n",
      "Epoch [5674/10000], Train Loss: 2.1805, Val Loss: 5.3590\n",
      "Epoch [5675/10000], Train Loss: 2.1781, Val Loss: 5.2583\n",
      "Epoch [5676/10000], Train Loss: 2.1760, Val Loss: 5.3487\n",
      "Epoch [5677/10000], Train Loss: 2.1721, Val Loss: 5.2443\n",
      "Epoch [5678/10000], Train Loss: 2.1700, Val Loss: 5.3247\n",
      "Epoch [5679/10000], Train Loss: 2.1665, Val Loss: 5.2351\n",
      "Epoch [5680/10000], Train Loss: 2.1625, Val Loss: 5.2987\n",
      "Epoch [5681/10000], Train Loss: 2.1594, Val Loss: 5.2428\n",
      "Epoch [5682/10000], Train Loss: 2.1567, Val Loss: 5.2726\n",
      "Epoch [5683/10000], Train Loss: 2.1526, Val Loss: 5.2420\n",
      "Epoch [5684/10000], Train Loss: 2.1505, Val Loss: 5.2384\n",
      "Epoch [5685/10000], Train Loss: 2.1474, Val Loss: 5.2383\n",
      "Epoch [5686/10000], Train Loss: 2.1440, Val Loss: 5.2139\n",
      "Epoch [5687/10000], Train Loss: 2.1418, Val Loss: 5.2358\n",
      "Epoch [5688/10000], Train Loss: 2.1389, Val Loss: 5.1808\n",
      "Epoch [5689/10000], Train Loss: 2.1363, Val Loss: 5.2192\n",
      "Epoch [5690/10000], Train Loss: 2.1339, Val Loss: 5.1624\n",
      "Epoch [5691/10000], Train Loss: 2.1310, Val Loss: 5.2083\n",
      "Epoch [5692/10000], Train Loss: 2.1279, Val Loss: 5.1582\n",
      "Epoch [5693/10000], Train Loss: 2.1252, Val Loss: 5.1944\n",
      "Epoch [5694/10000], Train Loss: 2.1220, Val Loss: 5.1641\n",
      "Epoch [5695/10000], Train Loss: 2.1188, Val Loss: 5.1877\n",
      "Epoch [5696/10000], Train Loss: 2.1158, Val Loss: 5.1805\n",
      "Epoch [5697/10000], Train Loss: 2.1134, Val Loss: 5.1816\n",
      "Epoch [5698/10000], Train Loss: 2.1103, Val Loss: 5.1693\n",
      "Epoch [5699/10000], Train Loss: 2.1074, Val Loss: 5.1498\n",
      "Epoch [5700/10000], Train Loss: 2.1044, Val Loss: 5.1290\n",
      "Epoch [5701/10000], Train Loss: 2.1016, Val Loss: 5.1231\n",
      "Epoch [5702/10000], Train Loss: 2.0988, Val Loss: 5.1103\n",
      "Epoch [5703/10000], Train Loss: 2.0961, Val Loss: 5.1067\n",
      "Epoch [5704/10000], Train Loss: 2.0931, Val Loss: 5.0992\n",
      "Epoch [5705/10000], Train Loss: 2.0903, Val Loss: 5.0945\n",
      "Epoch [5706/10000], Train Loss: 2.0874, Val Loss: 5.0963\n",
      "Epoch [5707/10000], Train Loss: 2.0844, Val Loss: 5.0899\n",
      "Epoch [5708/10000], Train Loss: 2.0816, Val Loss: 5.0913\n",
      "Epoch [5709/10000], Train Loss: 2.0788, Val Loss: 5.0654\n",
      "Epoch [5710/10000], Train Loss: 2.0760, Val Loss: 5.0701\n",
      "Epoch [5711/10000], Train Loss: 2.0731, Val Loss: 5.0496\n",
      "Epoch [5712/10000], Train Loss: 2.0702, Val Loss: 5.0602\n",
      "Epoch [5713/10000], Train Loss: 2.0676, Val Loss: 5.0260\n",
      "Epoch [5714/10000], Train Loss: 2.0647, Val Loss: 5.0312\n",
      "Epoch [5715/10000], Train Loss: 2.0620, Val Loss: 5.0036\n",
      "Epoch [5716/10000], Train Loss: 2.0590, Val Loss: 5.0169\n",
      "Epoch [5717/10000], Train Loss: 2.0562, Val Loss: 4.9993\n",
      "Epoch [5718/10000], Train Loss: 2.0532, Val Loss: 5.0090\n",
      "Epoch [5719/10000], Train Loss: 2.0501, Val Loss: 5.0009\n",
      "Epoch [5720/10000], Train Loss: 2.0472, Val Loss: 5.0062\n",
      "Epoch [5721/10000], Train Loss: 2.0441, Val Loss: 5.0032\n",
      "Epoch [5722/10000], Train Loss: 2.0420, Val Loss: 5.0059\n",
      "Epoch [5723/10000], Train Loss: 2.0385, Val Loss: 4.9862\n",
      "Epoch [5724/10000], Train Loss: 2.0364, Val Loss: 4.9599\n",
      "Epoch [5725/10000], Train Loss: 2.0331, Val Loss: 4.9436\n",
      "Epoch [5726/10000], Train Loss: 2.0300, Val Loss: 4.9287\n",
      "Epoch [5727/10000], Train Loss: 2.0276, Val Loss: 4.9363\n",
      "Epoch [5728/10000], Train Loss: 2.0246, Val Loss: 4.9147\n",
      "Epoch [5729/10000], Train Loss: 2.0213, Val Loss: 4.9259\n",
      "Epoch [5730/10000], Train Loss: 2.0186, Val Loss: 4.9079\n",
      "Epoch [5731/10000], Train Loss: 2.0157, Val Loss: 4.9217\n",
      "Epoch [5732/10000], Train Loss: 2.0123, Val Loss: 4.9043\n",
      "Epoch [5733/10000], Train Loss: 2.0099, Val Loss: 4.9158\n",
      "Epoch [5734/10000], Train Loss: 2.0065, Val Loss: 4.8842\n",
      "Epoch [5735/10000], Train Loss: 2.0037, Val Loss: 4.8975\n",
      "Epoch [5736/10000], Train Loss: 2.0008, Val Loss: 4.8688\n",
      "Epoch [5737/10000], Train Loss: 1.9977, Val Loss: 4.8967\n",
      "Epoch [5738/10000], Train Loss: 1.9952, Val Loss: 4.8650\n",
      "Epoch [5739/10000], Train Loss: 1.9920, Val Loss: 4.8636\n",
      "Epoch [5740/10000], Train Loss: 1.9891, Val Loss: 4.8421\n",
      "Epoch [5741/10000], Train Loss: 1.9861, Val Loss: 4.8422\n",
      "Epoch [5742/10000], Train Loss: 1.9830, Val Loss: 4.8395\n",
      "Epoch [5743/10000], Train Loss: 1.9801, Val Loss: 4.8318\n",
      "Epoch [5744/10000], Train Loss: 1.9772, Val Loss: 4.8316\n",
      "Epoch [5745/10000], Train Loss: 1.9744, Val Loss: 4.8056\n",
      "Epoch [5746/10000], Train Loss: 1.9720, Val Loss: 4.8132\n",
      "Epoch [5747/10000], Train Loss: 1.9685, Val Loss: 4.7816\n",
      "Epoch [5748/10000], Train Loss: 1.9656, Val Loss: 4.8053\n",
      "Epoch [5749/10000], Train Loss: 1.9630, Val Loss: 4.7727\n",
      "Epoch [5750/10000], Train Loss: 1.9598, Val Loss: 4.7991\n",
      "Epoch [5751/10000], Train Loss: 1.9574, Val Loss: 4.7449\n",
      "Epoch [5752/10000], Train Loss: 1.9557, Val Loss: 4.7927\n",
      "Epoch [5753/10000], Train Loss: 1.9521, Val Loss: 4.7132\n",
      "Epoch [5754/10000], Train Loss: 1.9497, Val Loss: 4.7937\n",
      "Epoch [5755/10000], Train Loss: 1.9484, Val Loss: 4.6823\n",
      "Epoch [5756/10000], Train Loss: 1.9453, Val Loss: 4.7922\n",
      "Epoch [5757/10000], Train Loss: 1.9439, Val Loss: 4.6472\n",
      "Epoch [5758/10000], Train Loss: 1.9429, Val Loss: 4.7982\n",
      "Epoch [5759/10000], Train Loss: 1.9407, Val Loss: 4.6131\n",
      "Epoch [5760/10000], Train Loss: 1.9403, Val Loss: 4.8101\n",
      "Epoch [5761/10000], Train Loss: 1.9387, Val Loss: 4.5983\n",
      "Epoch [5762/10000], Train Loss: 1.9363, Val Loss: 4.8109\n",
      "Epoch [5763/10000], Train Loss: 1.9316, Val Loss: 4.6204\n",
      "Epoch [5764/10000], Train Loss: 1.9264, Val Loss: 4.7704\n",
      "Epoch [5765/10000], Train Loss: 1.9192, Val Loss: 4.6684\n",
      "Epoch [5766/10000], Train Loss: 1.9129, Val Loss: 4.6756\n",
      "Epoch [5767/10000], Train Loss: 1.9089, Val Loss: 4.6871\n",
      "Epoch [5768/10000], Train Loss: 1.9065, Val Loss: 4.5914\n",
      "Epoch [5769/10000], Train Loss: 1.9052, Val Loss: 4.6917\n",
      "Epoch [5770/10000], Train Loss: 1.9036, Val Loss: 4.5719\n",
      "Epoch [5771/10000], Train Loss: 1.9008, Val Loss: 4.6643\n",
      "Epoch [5772/10000], Train Loss: 1.8966, Val Loss: 4.5870\n",
      "Epoch [5773/10000], Train Loss: 1.8922, Val Loss: 4.6204\n",
      "Epoch [5774/10000], Train Loss: 1.8879, Val Loss: 4.6204\n",
      "Epoch [5775/10000], Train Loss: 1.8845, Val Loss: 4.5813\n",
      "Epoch [5776/10000], Train Loss: 1.8826, Val Loss: 4.6395\n",
      "Epoch [5777/10000], Train Loss: 1.8802, Val Loss: 4.5529\n",
      "Epoch [5778/10000], Train Loss: 1.8779, Val Loss: 4.6196\n",
      "Epoch [5779/10000], Train Loss: 1.8744, Val Loss: 4.5514\n",
      "Epoch [5780/10000], Train Loss: 1.8704, Val Loss: 4.5871\n",
      "Epoch [5781/10000], Train Loss: 1.8669, Val Loss: 4.5503\n",
      "Epoch [5782/10000], Train Loss: 1.8634, Val Loss: 4.5307\n",
      "Epoch [5783/10000], Train Loss: 1.8607, Val Loss: 4.5528\n",
      "Epoch [5784/10000], Train Loss: 1.8579, Val Loss: 4.5084\n",
      "Epoch [5785/10000], Train Loss: 1.8552, Val Loss: 4.5493\n",
      "Epoch [5786/10000], Train Loss: 1.8519, Val Loss: 4.5053\n",
      "Epoch [5787/10000], Train Loss: 1.8485, Val Loss: 4.5337\n",
      "Epoch [5788/10000], Train Loss: 1.8451, Val Loss: 4.5265\n",
      "Epoch [5789/10000], Train Loss: 1.8422, Val Loss: 4.5121\n",
      "Epoch [5790/10000], Train Loss: 1.8392, Val Loss: 4.5166\n",
      "Epoch [5791/10000], Train Loss: 1.8362, Val Loss: 4.4879\n",
      "Epoch [5792/10000], Train Loss: 1.8332, Val Loss: 4.4989\n",
      "Epoch [5793/10000], Train Loss: 1.8302, Val Loss: 4.4541\n",
      "Epoch [5794/10000], Train Loss: 1.8270, Val Loss: 4.4677\n",
      "Epoch [5795/10000], Train Loss: 1.8240, Val Loss: 4.4445\n",
      "Epoch [5796/10000], Train Loss: 1.8208, Val Loss: 4.4431\n",
      "Epoch [5797/10000], Train Loss: 1.8178, Val Loss: 4.4425\n",
      "Epoch [5798/10000], Train Loss: 1.8146, Val Loss: 4.4230\n",
      "Epoch [5799/10000], Train Loss: 1.8116, Val Loss: 4.4479\n",
      "Epoch [5800/10000], Train Loss: 1.8085, Val Loss: 4.4237\n",
      "Epoch [5801/10000], Train Loss: 1.8054, Val Loss: 4.4362\n",
      "Epoch [5802/10000], Train Loss: 1.8025, Val Loss: 4.4055\n",
      "Epoch [5803/10000], Train Loss: 1.7994, Val Loss: 4.4129\n",
      "Epoch [5804/10000], Train Loss: 1.7960, Val Loss: 4.4008\n",
      "Epoch [5805/10000], Train Loss: 1.7936, Val Loss: 4.3900\n",
      "Epoch [5806/10000], Train Loss: 1.7899, Val Loss: 4.3767\n",
      "Epoch [5807/10000], Train Loss: 1.7871, Val Loss: 4.3656\n",
      "Epoch [5808/10000], Train Loss: 1.7840, Val Loss: 4.3593\n",
      "Epoch [5809/10000], Train Loss: 1.7808, Val Loss: 4.3509\n",
      "Epoch [5810/10000], Train Loss: 1.7778, Val Loss: 4.3472\n",
      "Epoch [5811/10000], Train Loss: 1.7747, Val Loss: 4.3452\n",
      "Epoch [5812/10000], Train Loss: 1.7714, Val Loss: 4.3480\n",
      "Epoch [5813/10000], Train Loss: 1.7683, Val Loss: 4.3474\n",
      "Epoch [5814/10000], Train Loss: 1.7653, Val Loss: 4.3445\n",
      "Epoch [5815/10000], Train Loss: 1.7624, Val Loss: 4.3218\n",
      "Epoch [5816/10000], Train Loss: 1.7591, Val Loss: 4.3277\n",
      "Epoch [5817/10000], Train Loss: 1.7564, Val Loss: 4.3021\n",
      "Epoch [5818/10000], Train Loss: 1.7529, Val Loss: 4.2896\n",
      "Epoch [5819/10000], Train Loss: 1.7499, Val Loss: 4.2842\n",
      "Epoch [5820/10000], Train Loss: 1.7469, Val Loss: 4.2626\n",
      "Epoch [5821/10000], Train Loss: 1.7438, Val Loss: 4.2733\n",
      "Epoch [5822/10000], Train Loss: 1.7407, Val Loss: 4.2508\n",
      "Epoch [5823/10000], Train Loss: 1.7376, Val Loss: 4.2605\n",
      "Epoch [5824/10000], Train Loss: 1.7344, Val Loss: 4.2545\n",
      "Epoch [5825/10000], Train Loss: 1.7312, Val Loss: 4.2558\n",
      "Epoch [5826/10000], Train Loss: 1.7280, Val Loss: 4.2577\n",
      "Epoch [5827/10000], Train Loss: 1.7255, Val Loss: 4.2496\n",
      "Epoch [5828/10000], Train Loss: 1.7219, Val Loss: 4.2378\n",
      "Epoch [5829/10000], Train Loss: 1.7188, Val Loss: 4.2367\n",
      "Epoch [5830/10000], Train Loss: 1.7159, Val Loss: 4.2167\n",
      "Epoch [5831/10000], Train Loss: 1.7125, Val Loss: 4.2009\n",
      "Epoch [5832/10000], Train Loss: 1.7095, Val Loss: 4.1960\n",
      "Epoch [5833/10000], Train Loss: 1.7064, Val Loss: 4.1740\n",
      "Epoch [5834/10000], Train Loss: 1.7033, Val Loss: 4.1853\n",
      "Epoch [5835/10000], Train Loss: 1.7002, Val Loss: 4.1643\n",
      "Epoch [5836/10000], Train Loss: 1.6970, Val Loss: 4.1742\n",
      "Epoch [5837/10000], Train Loss: 1.6939, Val Loss: 4.1659\n",
      "Epoch [5838/10000], Train Loss: 1.6906, Val Loss: 4.1692\n",
      "Epoch [5839/10000], Train Loss: 1.6876, Val Loss: 4.1674\n",
      "Epoch [5840/10000], Train Loss: 1.6846, Val Loss: 4.1375\n",
      "Epoch [5841/10000], Train Loss: 1.6815, Val Loss: 4.1564\n",
      "Epoch [5842/10000], Train Loss: 1.6782, Val Loss: 4.1224\n",
      "Epoch [5843/10000], Train Loss: 1.6758, Val Loss: 4.1430\n",
      "Epoch [5844/10000], Train Loss: 1.6723, Val Loss: 4.0950\n",
      "Epoch [5845/10000], Train Loss: 1.6694, Val Loss: 4.1164\n",
      "Epoch [5846/10000], Train Loss: 1.6662, Val Loss: 4.0845\n",
      "Epoch [5847/10000], Train Loss: 1.6629, Val Loss: 4.0951\n",
      "Epoch [5848/10000], Train Loss: 1.6598, Val Loss: 4.0797\n",
      "Epoch [5849/10000], Train Loss: 1.6565, Val Loss: 4.0819\n",
      "Epoch [5850/10000], Train Loss: 1.6531, Val Loss: 4.0900\n",
      "Epoch [5851/10000], Train Loss: 1.6500, Val Loss: 4.0796\n",
      "Epoch [5852/10000], Train Loss: 1.6469, Val Loss: 4.0883\n",
      "Epoch [5853/10000], Train Loss: 1.6440, Val Loss: 4.0511\n",
      "Epoch [5854/10000], Train Loss: 1.6408, Val Loss: 4.0770\n",
      "Epoch [5855/10000], Train Loss: 1.6381, Val Loss: 4.0313\n",
      "Epoch [5856/10000], Train Loss: 1.6346, Val Loss: 4.0386\n",
      "Epoch [5857/10000], Train Loss: 1.6314, Val Loss: 4.0145\n",
      "Epoch [5858/10000], Train Loss: 1.6283, Val Loss: 4.0102\n",
      "Epoch [5859/10000], Train Loss: 1.6250, Val Loss: 4.0082\n",
      "Epoch [5860/10000], Train Loss: 1.6219, Val Loss: 3.9924\n",
      "Epoch [5861/10000], Train Loss: 1.6187, Val Loss: 4.0037\n",
      "Epoch [5862/10000], Train Loss: 1.6155, Val Loss: 3.9902\n",
      "Epoch [5863/10000], Train Loss: 1.6124, Val Loss: 4.0058\n",
      "Epoch [5864/10000], Train Loss: 1.6091, Val Loss: 3.9894\n",
      "Epoch [5865/10000], Train Loss: 1.6067, Val Loss: 4.0033\n",
      "Epoch [5866/10000], Train Loss: 1.6030, Val Loss: 3.9686\n",
      "Epoch [5867/10000], Train Loss: 1.5999, Val Loss: 3.9915\n",
      "Epoch [5868/10000], Train Loss: 1.5970, Val Loss: 3.9497\n",
      "Epoch [5869/10000], Train Loss: 1.5935, Val Loss: 3.9535\n",
      "Epoch [5870/10000], Train Loss: 1.5903, Val Loss: 3.9320\n",
      "Epoch [5871/10000], Train Loss: 1.5871, Val Loss: 3.9224\n",
      "Epoch [5872/10000], Train Loss: 1.5840, Val Loss: 3.9292\n",
      "Epoch [5873/10000], Train Loss: 1.5809, Val Loss: 3.9085\n",
      "Epoch [5874/10000], Train Loss: 1.5777, Val Loss: 3.9275\n",
      "Epoch [5875/10000], Train Loss: 1.5746, Val Loss: 3.9055\n",
      "Epoch [5876/10000], Train Loss: 1.5714, Val Loss: 3.9314\n",
      "Epoch [5877/10000], Train Loss: 1.5683, Val Loss: 3.9046\n",
      "Epoch [5878/10000], Train Loss: 1.5652, Val Loss: 3.9022\n",
      "Epoch [5879/10000], Train Loss: 1.5620, Val Loss: 3.8983\n",
      "Epoch [5880/10000], Train Loss: 1.5586, Val Loss: 3.8865\n",
      "Epoch [5881/10000], Train Loss: 1.5560, Val Loss: 3.8926\n",
      "Epoch [5882/10000], Train Loss: 1.5525, Val Loss: 3.8512\n",
      "Epoch [5883/10000], Train Loss: 1.5497, Val Loss: 3.8788\n",
      "Epoch [5884/10000], Train Loss: 1.5465, Val Loss: 3.8344\n",
      "Epoch [5885/10000], Train Loss: 1.5434, Val Loss: 3.8690\n",
      "Epoch [5886/10000], Train Loss: 1.5405, Val Loss: 3.8236\n",
      "Epoch [5887/10000], Train Loss: 1.5373, Val Loss: 3.8652\n",
      "Epoch [5888/10000], Train Loss: 1.5339, Val Loss: 3.8317\n",
      "Epoch [5889/10000], Train Loss: 1.5309, Val Loss: 3.8678\n",
      "Epoch [5890/10000], Train Loss: 1.5276, Val Loss: 3.8293\n",
      "Epoch [5891/10000], Train Loss: 1.5243, Val Loss: 3.8390\n",
      "Epoch [5892/10000], Train Loss: 1.5208, Val Loss: 3.8235\n",
      "Epoch [5893/10000], Train Loss: 1.5179, Val Loss: 3.8166\n",
      "Epoch [5894/10000], Train Loss: 1.5144, Val Loss: 3.7933\n",
      "Epoch [5895/10000], Train Loss: 1.5114, Val Loss: 3.7942\n",
      "Epoch [5896/10000], Train Loss: 1.5082, Val Loss: 3.7758\n",
      "Epoch [5897/10000], Train Loss: 1.5051, Val Loss: 3.7818\n",
      "Epoch [5898/10000], Train Loss: 1.5020, Val Loss: 3.7688\n",
      "Epoch [5899/10000], Train Loss: 1.4987, Val Loss: 3.7718\n",
      "Epoch [5900/10000], Train Loss: 1.4954, Val Loss: 3.7754\n",
      "Epoch [5901/10000], Train Loss: 1.4922, Val Loss: 3.7698\n",
      "Epoch [5902/10000], Train Loss: 1.4889, Val Loss: 3.7819\n",
      "Epoch [5903/10000], Train Loss: 1.4865, Val Loss: 3.7656\n",
      "Epoch [5904/10000], Train Loss: 1.4827, Val Loss: 3.7629\n",
      "Epoch [5905/10000], Train Loss: 1.4796, Val Loss: 3.7582\n",
      "Epoch [5906/10000], Train Loss: 1.4765, Val Loss: 3.7424\n",
      "Epoch [5907/10000], Train Loss: 1.4732, Val Loss: 3.7270\n",
      "Epoch [5908/10000], Train Loss: 1.4701, Val Loss: 3.7193\n",
      "Epoch [5909/10000], Train Loss: 1.4670, Val Loss: 3.7059\n",
      "Epoch [5910/10000], Train Loss: 1.4639, Val Loss: 3.7115\n",
      "Epoch [5911/10000], Train Loss: 1.4607, Val Loss: 3.6970\n",
      "Epoch [5912/10000], Train Loss: 1.4575, Val Loss: 3.7056\n",
      "Epoch [5913/10000], Train Loss: 1.4543, Val Loss: 3.6961\n",
      "Epoch [5914/10000], Train Loss: 1.4510, Val Loss: 3.7102\n",
      "Epoch [5915/10000], Train Loss: 1.4480, Val Loss: 3.6928\n",
      "Epoch [5916/10000], Train Loss: 1.4449, Val Loss: 3.6835\n",
      "Epoch [5917/10000], Train Loss: 1.4417, Val Loss: 3.6849\n",
      "Epoch [5918/10000], Train Loss: 1.4383, Val Loss: 3.6707\n",
      "Epoch [5919/10000], Train Loss: 1.4357, Val Loss: 3.6769\n",
      "Epoch [5920/10000], Train Loss: 1.4323, Val Loss: 3.6344\n",
      "Epoch [5921/10000], Train Loss: 1.4295, Val Loss: 3.6661\n",
      "Epoch [5922/10000], Train Loss: 1.4263, Val Loss: 3.6149\n",
      "Epoch [5923/10000], Train Loss: 1.4233, Val Loss: 3.6612\n",
      "Epoch [5924/10000], Train Loss: 1.4206, Val Loss: 3.5966\n",
      "Epoch [5925/10000], Train Loss: 1.4176, Val Loss: 3.6678\n",
      "Epoch [5926/10000], Train Loss: 1.4148, Val Loss: 3.5957\n",
      "Epoch [5927/10000], Train Loss: 1.4123, Val Loss: 3.6842\n",
      "Epoch [5928/10000], Train Loss: 1.4098, Val Loss: 3.5764\n",
      "Epoch [5929/10000], Train Loss: 1.4076, Val Loss: 3.6783\n",
      "Epoch [5930/10000], Train Loss: 1.4050, Val Loss: 3.5466\n",
      "Epoch [5931/10000], Train Loss: 1.4036, Val Loss: 3.6908\n",
      "Epoch [5932/10000], Train Loss: 1.4023, Val Loss: 3.4855\n",
      "Epoch [5933/10000], Train Loss: 1.4029, Val Loss: 3.7125\n",
      "Epoch [5934/10000], Train Loss: 1.4028, Val Loss: 3.4408\n",
      "Epoch [5935/10000], Train Loss: 1.4037, Val Loss: 3.7249\n",
      "Epoch [5936/10000], Train Loss: 1.4006, Val Loss: 3.4382\n",
      "Epoch [5937/10000], Train Loss: 1.3954, Val Loss: 3.6645\n",
      "Epoch [5938/10000], Train Loss: 1.3852, Val Loss: 3.5099\n",
      "Epoch [5939/10000], Train Loss: 1.3758, Val Loss: 3.5579\n",
      "Epoch [5940/10000], Train Loss: 1.3695, Val Loss: 3.6108\n",
      "Epoch [5941/10000], Train Loss: 1.3681, Val Loss: 3.4855\n",
      "Epoch [5942/10000], Train Loss: 1.3669, Val Loss: 3.6241\n",
      "Epoch [5943/10000], Train Loss: 1.3648, Val Loss: 3.4868\n",
      "Epoch [5944/10000], Train Loss: 1.3614, Val Loss: 3.5657\n",
      "Epoch [5945/10000], Train Loss: 1.3567, Val Loss: 3.5064\n",
      "Epoch [5946/10000], Train Loss: 1.3516, Val Loss: 3.4828\n",
      "Epoch [5947/10000], Train Loss: 1.3476, Val Loss: 3.5295\n",
      "Epoch [5948/10000], Train Loss: 1.3449, Val Loss: 3.4563\n",
      "Epoch [5949/10000], Train Loss: 1.3428, Val Loss: 3.5197\n",
      "Epoch [5950/10000], Train Loss: 1.3402, Val Loss: 3.4677\n",
      "Epoch [5951/10000], Train Loss: 1.3365, Val Loss: 3.4911\n",
      "Epoch [5952/10000], Train Loss: 1.3320, Val Loss: 3.4961\n",
      "Epoch [5953/10000], Train Loss: 1.3283, Val Loss: 3.4687\n",
      "Epoch [5954/10000], Train Loss: 1.3254, Val Loss: 3.4797\n",
      "Epoch [5955/10000], Train Loss: 1.3230, Val Loss: 3.4569\n",
      "Epoch [5956/10000], Train Loss: 1.3198, Val Loss: 3.4703\n",
      "Epoch [5957/10000], Train Loss: 1.3168, Val Loss: 3.4462\n",
      "Epoch [5958/10000], Train Loss: 1.3126, Val Loss: 3.4304\n",
      "Epoch [5959/10000], Train Loss: 1.3099, Val Loss: 3.4373\n",
      "Epoch [5960/10000], Train Loss: 1.3070, Val Loss: 3.4124\n",
      "Epoch [5961/10000], Train Loss: 1.3041, Val Loss: 3.4291\n",
      "Epoch [5962/10000], Train Loss: 1.3009, Val Loss: 3.3982\n",
      "Epoch [5963/10000], Train Loss: 1.2972, Val Loss: 3.4217\n",
      "Epoch [5964/10000], Train Loss: 1.2938, Val Loss: 3.4160\n",
      "Epoch [5965/10000], Train Loss: 1.2909, Val Loss: 3.4120\n",
      "Epoch [5966/10000], Train Loss: 1.2878, Val Loss: 3.4245\n",
      "Epoch [5967/10000], Train Loss: 1.2850, Val Loss: 3.3753\n",
      "Epoch [5968/10000], Train Loss: 1.2818, Val Loss: 3.4198\n",
      "Epoch [5969/10000], Train Loss: 1.2788, Val Loss: 3.3690\n",
      "Epoch [5970/10000], Train Loss: 1.2752, Val Loss: 3.3626\n",
      "Epoch [5971/10000], Train Loss: 1.2723, Val Loss: 3.3726\n",
      "Epoch [5972/10000], Train Loss: 1.2693, Val Loss: 3.3259\n",
      "Epoch [5973/10000], Train Loss: 1.2665, Val Loss: 3.3711\n",
      "Epoch [5974/10000], Train Loss: 1.2634, Val Loss: 3.3210\n",
      "Epoch [5975/10000], Train Loss: 1.2599, Val Loss: 3.3465\n",
      "Epoch [5976/10000], Train Loss: 1.2566, Val Loss: 3.3459\n",
      "Epoch [5977/10000], Train Loss: 1.2534, Val Loss: 3.3290\n",
      "Epoch [5978/10000], Train Loss: 1.2503, Val Loss: 3.3620\n",
      "Epoch [5979/10000], Train Loss: 1.2479, Val Loss: 3.3226\n",
      "Epoch [5980/10000], Train Loss: 1.2442, Val Loss: 3.3345\n",
      "Epoch [5981/10000], Train Loss: 1.2411, Val Loss: 3.3283\n",
      "Epoch [5982/10000], Train Loss: 1.2378, Val Loss: 3.3058\n",
      "Epoch [5983/10000], Train Loss: 1.2348, Val Loss: 3.2987\n",
      "Epoch [5984/10000], Train Loss: 1.2318, Val Loss: 3.2819\n",
      "Epoch [5985/10000], Train Loss: 1.2287, Val Loss: 3.2788\n",
      "Epoch [5986/10000], Train Loss: 1.2257, Val Loss: 3.2766\n",
      "Epoch [5987/10000], Train Loss: 1.2226, Val Loss: 3.2675\n",
      "Epoch [5988/10000], Train Loss: 1.2195, Val Loss: 3.2691\n",
      "Epoch [5989/10000], Train Loss: 1.2164, Val Loss: 3.2692\n",
      "Epoch [5990/10000], Train Loss: 1.2132, Val Loss: 3.2723\n",
      "Epoch [5991/10000], Train Loss: 1.2100, Val Loss: 3.2673\n",
      "Epoch [5992/10000], Train Loss: 1.2072, Val Loss: 3.2431\n",
      "Epoch [5993/10000], Train Loss: 1.2043, Val Loss: 3.2605\n",
      "Epoch [5994/10000], Train Loss: 1.2009, Val Loss: 3.2372\n",
      "Epoch [5995/10000], Train Loss: 1.1982, Val Loss: 3.2429\n",
      "Epoch [5996/10000], Train Loss: 1.1950, Val Loss: 3.2090\n",
      "Epoch [5997/10000], Train Loss: 1.1923, Val Loss: 3.2225\n",
      "Epoch [5998/10000], Train Loss: 1.1890, Val Loss: 3.2049\n",
      "Epoch [5999/10000], Train Loss: 1.1858, Val Loss: 3.2011\n",
      "Epoch [6000/10000], Train Loss: 1.1829, Val Loss: 3.1996\n",
      "Epoch [6001/10000], Train Loss: 1.1797, Val Loss: 3.1940\n",
      "Epoch [6002/10000], Train Loss: 1.1765, Val Loss: 3.2119\n",
      "Epoch [6003/10000], Train Loss: 1.1736, Val Loss: 3.1956\n",
      "Epoch [6004/10000], Train Loss: 1.1703, Val Loss: 3.2079\n",
      "Epoch [6005/10000], Train Loss: 1.1683, Val Loss: 3.1979\n",
      "Epoch [6006/10000], Train Loss: 1.1644, Val Loss: 3.1811\n",
      "Epoch [6007/10000], Train Loss: 1.1624, Val Loss: 3.1655\n",
      "Epoch [6008/10000], Train Loss: 1.1589, Val Loss: 3.1490\n",
      "Epoch [6009/10000], Train Loss: 1.1554, Val Loss: 3.1398\n",
      "Epoch [6010/10000], Train Loss: 1.1533, Val Loss: 3.1298\n",
      "Epoch [6011/10000], Train Loss: 1.1497, Val Loss: 3.1296\n",
      "Epoch [6012/10000], Train Loss: 1.1465, Val Loss: 3.1305\n",
      "Epoch [6013/10000], Train Loss: 1.1439, Val Loss: 3.1283\n",
      "Epoch [6014/10000], Train Loss: 1.1404, Val Loss: 3.1216\n",
      "Epoch [6015/10000], Train Loss: 1.1372, Val Loss: 3.1234\n",
      "Epoch [6016/10000], Train Loss: 1.1349, Val Loss: 3.1277\n",
      "Epoch [6017/10000], Train Loss: 1.1312, Val Loss: 3.1040\n",
      "Epoch [6018/10000], Train Loss: 1.1289, Val Loss: 3.1192\n",
      "Epoch [6019/10000], Train Loss: 1.1254, Val Loss: 3.0923\n",
      "Epoch [6020/10000], Train Loss: 1.1221, Val Loss: 3.1113\n",
      "Epoch [6021/10000], Train Loss: 1.1202, Val Loss: 3.0901\n",
      "Epoch [6022/10000], Train Loss: 1.1160, Val Loss: 3.0729\n",
      "Epoch [6023/10000], Train Loss: 1.1139, Val Loss: 3.0913\n",
      "Epoch [6024/10000], Train Loss: 1.1106, Val Loss: 3.0538\n",
      "Epoch [6025/10000], Train Loss: 1.1074, Val Loss: 3.0766\n",
      "Epoch [6026/10000], Train Loss: 1.1049, Val Loss: 3.0489\n",
      "Epoch [6027/10000], Train Loss: 1.1014, Val Loss: 3.0731\n",
      "Epoch [6028/10000], Train Loss: 1.0981, Val Loss: 3.0664\n",
      "Epoch [6029/10000], Train Loss: 1.0954, Val Loss: 3.0634\n",
      "Epoch [6030/10000], Train Loss: 1.0922, Val Loss: 3.0680\n",
      "Epoch [6031/10000], Train Loss: 1.0892, Val Loss: 3.0335\n",
      "Epoch [6032/10000], Train Loss: 1.0864, Val Loss: 3.0610\n",
      "Epoch [6033/10000], Train Loss: 1.0839, Val Loss: 2.9914\n",
      "Epoch [6034/10000], Train Loss: 1.0813, Val Loss: 3.0371\n",
      "Epoch [6035/10000], Train Loss: 1.0783, Val Loss: 2.9775\n",
      "Epoch [6036/10000], Train Loss: 1.0753, Val Loss: 3.0106\n",
      "Epoch [6037/10000], Train Loss: 1.0720, Val Loss: 2.9834\n",
      "Epoch [6038/10000], Train Loss: 1.0687, Val Loss: 2.9890\n",
      "Epoch [6039/10000], Train Loss: 1.0656, Val Loss: 2.9954\n",
      "Epoch [6040/10000], Train Loss: 1.0626, Val Loss: 2.9755\n",
      "Epoch [6041/10000], Train Loss: 1.0597, Val Loss: 3.0056\n",
      "Epoch [6042/10000], Train Loss: 1.0570, Val Loss: 2.9734\n",
      "Epoch [6043/10000], Train Loss: 1.0542, Val Loss: 2.9814\n",
      "Epoch [6044/10000], Train Loss: 1.0513, Val Loss: 2.9706\n",
      "Epoch [6045/10000], Train Loss: 1.0479, Val Loss: 2.9640\n",
      "Epoch [6046/10000], Train Loss: 1.0453, Val Loss: 2.9648\n",
      "Epoch [6047/10000], Train Loss: 1.0422, Val Loss: 2.9249\n",
      "Epoch [6048/10000], Train Loss: 1.0398, Val Loss: 2.9568\n",
      "Epoch [6049/10000], Train Loss: 1.0370, Val Loss: 2.9117\n",
      "Epoch [6050/10000], Train Loss: 1.0340, Val Loss: 2.9424\n",
      "Epoch [6051/10000], Train Loss: 1.0312, Val Loss: 2.9033\n",
      "Epoch [6052/10000], Train Loss: 1.0280, Val Loss: 2.9348\n",
      "Epoch [6053/10000], Train Loss: 1.0248, Val Loss: 2.9210\n",
      "Epoch [6054/10000], Train Loss: 1.0218, Val Loss: 2.9256\n",
      "Epoch [6055/10000], Train Loss: 1.0187, Val Loss: 2.9268\n",
      "Epoch [6056/10000], Train Loss: 1.0166, Val Loss: 2.9176\n",
      "Epoch [6057/10000], Train Loss: 1.0130, Val Loss: 2.9164\n",
      "Epoch [6058/10000], Train Loss: 1.0102, Val Loss: 2.9061\n",
      "Epoch [6059/10000], Train Loss: 1.0073, Val Loss: 2.8997\n",
      "Epoch [6060/10000], Train Loss: 1.0045, Val Loss: 2.8679\n",
      "Epoch [6061/10000], Train Loss: 1.0017, Val Loss: 2.8861\n",
      "Epoch [6062/10000], Train Loss: 0.9990, Val Loss: 2.8479\n",
      "Epoch [6063/10000], Train Loss: 0.9962, Val Loss: 2.8730\n",
      "Epoch [6064/10000], Train Loss: 0.9932, Val Loss: 2.8413\n",
      "Epoch [6065/10000], Train Loss: 0.9903, Val Loss: 2.8598\n",
      "Epoch [6066/10000], Train Loss: 0.9874, Val Loss: 2.8526\n",
      "Epoch [6067/10000], Train Loss: 0.9844, Val Loss: 2.8527\n",
      "Epoch [6068/10000], Train Loss: 0.9814, Val Loss: 2.8567\n",
      "Epoch [6069/10000], Train Loss: 0.9792, Val Loss: 2.8454\n",
      "Epoch [6070/10000], Train Loss: 0.9760, Val Loss: 2.8417\n",
      "Epoch [6071/10000], Train Loss: 0.9734, Val Loss: 2.8416\n",
      "Epoch [6072/10000], Train Loss: 0.9701, Val Loss: 2.8212\n",
      "Epoch [6073/10000], Train Loss: 0.9682, Val Loss: 2.8284\n",
      "Epoch [6074/10000], Train Loss: 0.9647, Val Loss: 2.7915\n",
      "Epoch [6075/10000], Train Loss: 0.9623, Val Loss: 2.8199\n",
      "Epoch [6076/10000], Train Loss: 0.9595, Val Loss: 2.7753\n",
      "Epoch [6077/10000], Train Loss: 0.9565, Val Loss: 2.8007\n",
      "Epoch [6078/10000], Train Loss: 0.9540, Val Loss: 2.7694\n",
      "Epoch [6079/10000], Train Loss: 0.9509, Val Loss: 2.7963\n",
      "Epoch [6080/10000], Train Loss: 0.9480, Val Loss: 2.7806\n",
      "Epoch [6081/10000], Train Loss: 0.9452, Val Loss: 2.7893\n",
      "Epoch [6082/10000], Train Loss: 0.9421, Val Loss: 2.7817\n",
      "Epoch [6083/10000], Train Loss: 0.9401, Val Loss: 2.7872\n",
      "Epoch [6084/10000], Train Loss: 0.9365, Val Loss: 2.7661\n",
      "Epoch [6085/10000], Train Loss: 0.9339, Val Loss: 2.7778\n",
      "Epoch [6086/10000], Train Loss: 0.9310, Val Loss: 2.7467\n",
      "Epoch [6087/10000], Train Loss: 0.9284, Val Loss: 2.7396\n",
      "Epoch [6088/10000], Train Loss: 0.9256, Val Loss: 2.7387\n",
      "Epoch [6089/10000], Train Loss: 0.9229, Val Loss: 2.7123\n",
      "Epoch [6090/10000], Train Loss: 0.9204, Val Loss: 2.7323\n",
      "Epoch [6091/10000], Train Loss: 0.9176, Val Loss: 2.6969\n",
      "Epoch [6092/10000], Train Loss: 0.9149, Val Loss: 2.7326\n",
      "Epoch [6093/10000], Train Loss: 0.9122, Val Loss: 2.6984\n",
      "Epoch [6094/10000], Train Loss: 0.9093, Val Loss: 2.7284\n",
      "Epoch [6095/10000], Train Loss: 0.9065, Val Loss: 2.6960\n",
      "Epoch [6096/10000], Train Loss: 0.9043, Val Loss: 2.7267\n",
      "Epoch [6097/10000], Train Loss: 0.9015, Val Loss: 2.6854\n",
      "Epoch [6098/10000], Train Loss: 0.8991, Val Loss: 2.7165\n",
      "Epoch [6099/10000], Train Loss: 0.8959, Val Loss: 2.6624\n",
      "Epoch [6100/10000], Train Loss: 0.8942, Val Loss: 2.7070\n",
      "Epoch [6101/10000], Train Loss: 0.8909, Val Loss: 2.6412\n",
      "Epoch [6102/10000], Train Loss: 0.8887, Val Loss: 2.6985\n",
      "Epoch [6103/10000], Train Loss: 0.8862, Val Loss: 2.6230\n",
      "Epoch [6104/10000], Train Loss: 0.8833, Val Loss: 2.6777\n",
      "Epoch [6105/10000], Train Loss: 0.8808, Val Loss: 2.6142\n",
      "Epoch [6106/10000], Train Loss: 0.8778, Val Loss: 2.6729\n",
      "Epoch [6107/10000], Train Loss: 0.8749, Val Loss: 2.6270\n",
      "Epoch [6108/10000], Train Loss: 0.8721, Val Loss: 2.6623\n",
      "Epoch [6109/10000], Train Loss: 0.8691, Val Loss: 2.6250\n",
      "Epoch [6110/10000], Train Loss: 0.8671, Val Loss: 2.6558\n",
      "Epoch [6111/10000], Train Loss: 0.8636, Val Loss: 2.6154\n",
      "Epoch [6112/10000], Train Loss: 0.8610, Val Loss: 2.6414\n",
      "Epoch [6113/10000], Train Loss: 0.8582, Val Loss: 2.6017\n",
      "Epoch [6114/10000], Train Loss: 0.8556, Val Loss: 2.6063\n",
      "Epoch [6115/10000], Train Loss: 0.8528, Val Loss: 2.5896\n",
      "Epoch [6116/10000], Train Loss: 0.8502, Val Loss: 2.5730\n",
      "Epoch [6117/10000], Train Loss: 0.8477, Val Loss: 2.5866\n",
      "Epoch [6118/10000], Train Loss: 0.8451, Val Loss: 2.5581\n",
      "Epoch [6119/10000], Train Loss: 0.8426, Val Loss: 2.5881\n",
      "Epoch [6120/10000], Train Loss: 0.8401, Val Loss: 2.5502\n",
      "Epoch [6121/10000], Train Loss: 0.8374, Val Loss: 2.5851\n",
      "Epoch [6122/10000], Train Loss: 0.8349, Val Loss: 2.5420\n",
      "Epoch [6123/10000], Train Loss: 0.8328, Val Loss: 2.5906\n",
      "Epoch [6124/10000], Train Loss: 0.8304, Val Loss: 2.5285\n",
      "Epoch [6125/10000], Train Loss: 0.8284, Val Loss: 2.5842\n",
      "Epoch [6126/10000], Train Loss: 0.8256, Val Loss: 2.5005\n",
      "Epoch [6127/10000], Train Loss: 0.8242, Val Loss: 2.5793\n",
      "Epoch [6128/10000], Train Loss: 0.8215, Val Loss: 2.4812\n",
      "Epoch [6129/10000], Train Loss: 0.8198, Val Loss: 2.5739\n",
      "Epoch [6130/10000], Train Loss: 0.8175, Val Loss: 2.4604\n",
      "Epoch [6131/10000], Train Loss: 0.8149, Val Loss: 2.5526\n",
      "Epoch [6132/10000], Train Loss: 0.8125, Val Loss: 2.4552\n",
      "Epoch [6133/10000], Train Loss: 0.8093, Val Loss: 2.5425\n",
      "Epoch [6134/10000], Train Loss: 0.8061, Val Loss: 2.4725\n",
      "Epoch [6135/10000], Train Loss: 0.8030, Val Loss: 2.5232\n",
      "Epoch [6136/10000], Train Loss: 0.7995, Val Loss: 2.4782\n",
      "Epoch [6137/10000], Train Loss: 0.7972, Val Loss: 2.5072\n",
      "Epoch [6138/10000], Train Loss: 0.7937, Val Loss: 2.4765\n",
      "Epoch [6139/10000], Train Loss: 0.7911, Val Loss: 2.4861\n",
      "Epoch [6140/10000], Train Loss: 0.7884, Val Loss: 2.4685\n",
      "Epoch [6141/10000], Train Loss: 0.7864, Val Loss: 2.4703\n",
      "Epoch [6142/10000], Train Loss: 0.7836, Val Loss: 2.4526\n",
      "Epoch [6143/10000], Train Loss: 0.7813, Val Loss: 2.4498\n",
      "Epoch [6144/10000], Train Loss: 0.7786, Val Loss: 2.4364\n",
      "Epoch [6145/10000], Train Loss: 0.7762, Val Loss: 2.4288\n",
      "Epoch [6146/10000], Train Loss: 0.7738, Val Loss: 2.4305\n",
      "Epoch [6147/10000], Train Loss: 0.7711, Val Loss: 2.4263\n",
      "Epoch [6148/10000], Train Loss: 0.7687, Val Loss: 2.4340\n",
      "Epoch [6149/10000], Train Loss: 0.7662, Val Loss: 2.4189\n",
      "Epoch [6150/10000], Train Loss: 0.7636, Val Loss: 2.4245\n",
      "Epoch [6151/10000], Train Loss: 0.7619, Val Loss: 2.4242\n",
      "Epoch [6152/10000], Train Loss: 0.7588, Val Loss: 2.4062\n",
      "Epoch [6153/10000], Train Loss: 0.7567, Val Loss: 2.4185\n",
      "Epoch [6154/10000], Train Loss: 0.7540, Val Loss: 2.3808\n",
      "Epoch [6155/10000], Train Loss: 0.7524, Val Loss: 2.4153\n",
      "Epoch [6156/10000], Train Loss: 0.7497, Val Loss: 2.3558\n",
      "Epoch [6157/10000], Train Loss: 0.7478, Val Loss: 2.4073\n",
      "Epoch [6158/10000], Train Loss: 0.7456, Val Loss: 2.3349\n",
      "Epoch [6159/10000], Train Loss: 0.7433, Val Loss: 2.3901\n",
      "Epoch [6160/10000], Train Loss: 0.7412, Val Loss: 2.3252\n",
      "Epoch [6161/10000], Train Loss: 0.7388, Val Loss: 2.3887\n",
      "Epoch [6162/10000], Train Loss: 0.7364, Val Loss: 2.3317\n",
      "Epoch [6163/10000], Train Loss: 0.7340, Val Loss: 2.3797\n",
      "Epoch [6164/10000], Train Loss: 0.7313, Val Loss: 2.3259\n",
      "Epoch [6165/10000], Train Loss: 0.7294, Val Loss: 2.3793\n",
      "Epoch [6166/10000], Train Loss: 0.7265, Val Loss: 2.3129\n",
      "Epoch [6167/10000], Train Loss: 0.7243, Val Loss: 2.3687\n",
      "Epoch [6168/10000], Train Loss: 0.7217, Val Loss: 2.2968\n",
      "Epoch [6169/10000], Train Loss: 0.7198, Val Loss: 2.3585\n",
      "Epoch [6170/10000], Train Loss: 0.7172, Val Loss: 2.2803\n",
      "Epoch [6171/10000], Train Loss: 0.7151, Val Loss: 2.3406\n",
      "Epoch [6172/10000], Train Loss: 0.7126, Val Loss: 2.2687\n",
      "Epoch [6173/10000], Train Loss: 0.7101, Val Loss: 2.3139\n",
      "Epoch [6174/10000], Train Loss: 0.7076, Val Loss: 2.2698\n",
      "Epoch [6175/10000], Train Loss: 0.7049, Val Loss: 2.3041\n",
      "Epoch [6176/10000], Train Loss: 0.7025, Val Loss: 2.2813\n",
      "Epoch [6177/10000], Train Loss: 0.7000, Val Loss: 2.2888\n",
      "Epoch [6178/10000], Train Loss: 0.6974, Val Loss: 2.2805\n",
      "Epoch [6179/10000], Train Loss: 0.6957, Val Loss: 2.2869\n",
      "Epoch [6180/10000], Train Loss: 0.6928, Val Loss: 2.2676\n",
      "Epoch [6181/10000], Train Loss: 0.6907, Val Loss: 2.2772\n",
      "Epoch [6182/10000], Train Loss: 0.6882, Val Loss: 2.2489\n",
      "Epoch [6183/10000], Train Loss: 0.6865, Val Loss: 2.2695\n",
      "Epoch [6184/10000], Train Loss: 0.6840, Val Loss: 2.2277\n",
      "Epoch [6185/10000], Train Loss: 0.6821, Val Loss: 2.2589\n",
      "Epoch [6186/10000], Train Loss: 0.6798, Val Loss: 2.2093\n",
      "Epoch [6187/10000], Train Loss: 0.6775, Val Loss: 2.2392\n",
      "Epoch [6188/10000], Train Loss: 0.6755, Val Loss: 2.2028\n",
      "Epoch [6189/10000], Train Loss: 0.6731, Val Loss: 2.2378\n",
      "Epoch [6190/10000], Train Loss: 0.6710, Val Loss: 2.2067\n",
      "Epoch [6191/10000], Train Loss: 0.6688, Val Loss: 2.2300\n",
      "Epoch [6192/10000], Train Loss: 0.6664, Val Loss: 2.1999\n",
      "Epoch [6193/10000], Train Loss: 0.6646, Val Loss: 2.2333\n",
      "Epoch [6194/10000], Train Loss: 0.6622, Val Loss: 2.1823\n",
      "Epoch [6195/10000], Train Loss: 0.6603, Val Loss: 2.2302\n",
      "Epoch [6196/10000], Train Loss: 0.6581, Val Loss: 2.1606\n",
      "Epoch [6197/10000], Train Loss: 0.6565, Val Loss: 2.2265\n",
      "Epoch [6198/10000], Train Loss: 0.6545, Val Loss: 2.1389\n",
      "Epoch [6199/10000], Train Loss: 0.6530, Val Loss: 2.2191\n",
      "Epoch [6200/10000], Train Loss: 0.6510, Val Loss: 2.1210\n",
      "Epoch [6201/10000], Train Loss: 0.6489, Val Loss: 2.1987\n",
      "Epoch [6202/10000], Train Loss: 0.6469, Val Loss: 2.1197\n",
      "Epoch [6203/10000], Train Loss: 0.6444, Val Loss: 2.1912\n",
      "Epoch [6204/10000], Train Loss: 0.6421, Val Loss: 2.1288\n",
      "Epoch [6205/10000], Train Loss: 0.6396, Val Loss: 2.1754\n",
      "Epoch [6206/10000], Train Loss: 0.6369, Val Loss: 2.1306\n",
      "Epoch [6207/10000], Train Loss: 0.6348, Val Loss: 2.1688\n",
      "Epoch [6208/10000], Train Loss: 0.6321, Val Loss: 2.1212\n",
      "Epoch [6209/10000], Train Loss: 0.6300, Val Loss: 2.1569\n",
      "Epoch [6210/10000], Train Loss: 0.6275, Val Loss: 2.1083\n",
      "Epoch [6211/10000], Train Loss: 0.6257, Val Loss: 2.1429\n",
      "Epoch [6212/10000], Train Loss: 0.6234, Val Loss: 2.0952\n",
      "Epoch [6213/10000], Train Loss: 0.6215, Val Loss: 2.1275\n",
      "Epoch [6214/10000], Train Loss: 0.6193, Val Loss: 2.0827\n",
      "Epoch [6215/10000], Train Loss: 0.6171, Val Loss: 2.1021\n",
      "Epoch [6216/10000], Train Loss: 0.6150, Val Loss: 2.0845\n",
      "Epoch [6217/10000], Train Loss: 0.6127, Val Loss: 2.0951\n",
      "Epoch [6218/10000], Train Loss: 0.6107, Val Loss: 2.0904\n",
      "Epoch [6219/10000], Train Loss: 0.6086, Val Loss: 2.0851\n",
      "Epoch [6220/10000], Train Loss: 0.6064, Val Loss: 2.0871\n",
      "Epoch [6221/10000], Train Loss: 0.6046, Val Loss: 2.0859\n",
      "Epoch [6222/10000], Train Loss: 0.6024, Val Loss: 2.0699\n",
      "Epoch [6223/10000], Train Loss: 0.6006, Val Loss: 2.0840\n",
      "Epoch [6224/10000], Train Loss: 0.5984, Val Loss: 2.0480\n",
      "Epoch [6225/10000], Train Loss: 0.5967, Val Loss: 2.0793\n",
      "Epoch [6226/10000], Train Loss: 0.5948, Val Loss: 2.0272\n",
      "Epoch [6227/10000], Train Loss: 0.5933, Val Loss: 2.0747\n",
      "Epoch [6228/10000], Train Loss: 0.5914, Val Loss: 2.0056\n",
      "Epoch [6229/10000], Train Loss: 0.5896, Val Loss: 2.0587\n",
      "Epoch [6230/10000], Train Loss: 0.5879, Val Loss: 2.0020\n",
      "Epoch [6231/10000], Train Loss: 0.5858, Val Loss: 2.0568\n",
      "Epoch [6232/10000], Train Loss: 0.5840, Val Loss: 2.0038\n",
      "Epoch [6233/10000], Train Loss: 0.5821, Val Loss: 2.0504\n",
      "Epoch [6234/10000], Train Loss: 0.5799, Val Loss: 1.9994\n",
      "Epoch [6235/10000], Train Loss: 0.5780, Val Loss: 2.0503\n",
      "Epoch [6236/10000], Train Loss: 0.5761, Val Loss: 1.9850\n",
      "Epoch [6237/10000], Train Loss: 0.5745, Val Loss: 2.0479\n",
      "Epoch [6238/10000], Train Loss: 0.5724, Val Loss: 1.9666\n",
      "Epoch [6239/10000], Train Loss: 0.5706, Val Loss: 2.0390\n",
      "Epoch [6240/10000], Train Loss: 0.5689, Val Loss: 1.9536\n",
      "Epoch [6241/10000], Train Loss: 0.5673, Val Loss: 2.0267\n",
      "Epoch [6242/10000], Train Loss: 0.5652, Val Loss: 1.9408\n",
      "Epoch [6243/10000], Train Loss: 0.5631, Val Loss: 2.0012\n",
      "Epoch [6244/10000], Train Loss: 0.5609, Val Loss: 1.9480\n",
      "Epoch [6245/10000], Train Loss: 0.5585, Val Loss: 1.9869\n",
      "Epoch [6246/10000], Train Loss: 0.5564, Val Loss: 1.9589\n",
      "Epoch [6247/10000], Train Loss: 0.5542, Val Loss: 1.9719\n",
      "Epoch [6248/10000], Train Loss: 0.5520, Val Loss: 1.9618\n",
      "Epoch [6249/10000], Train Loss: 0.5500, Val Loss: 1.9654\n",
      "Epoch [6250/10000], Train Loss: 0.5481, Val Loss: 1.9514\n",
      "Epoch [6251/10000], Train Loss: 0.5464, Val Loss: 1.9600\n",
      "Epoch [6252/10000], Train Loss: 0.5443, Val Loss: 1.9336\n",
      "Epoch [6253/10000], Train Loss: 0.5427, Val Loss: 1.9490\n",
      "Epoch [6254/10000], Train Loss: 0.5408, Val Loss: 1.9376\n",
      "Epoch [6255/10000], Train Loss: 0.5388, Val Loss: 1.9463\n",
      "Epoch [6256/10000], Train Loss: 0.5370, Val Loss: 1.9421\n",
      "Epoch [6257/10000], Train Loss: 0.5351, Val Loss: 1.9361\n",
      "Epoch [6258/10000], Train Loss: 0.5338, Val Loss: 1.9441\n",
      "Epoch [6259/10000], Train Loss: 0.5316, Val Loss: 1.9137\n",
      "Epoch [6260/10000], Train Loss: 0.5300, Val Loss: 1.9426\n",
      "Epoch [6261/10000], Train Loss: 0.5283, Val Loss: 1.8962\n",
      "Epoch [6262/10000], Train Loss: 0.5266, Val Loss: 1.9351\n",
      "Epoch [6263/10000], Train Loss: 0.5254, Val Loss: 1.8766\n",
      "Epoch [6264/10000], Train Loss: 0.5241, Val Loss: 1.9313\n",
      "Epoch [6265/10000], Train Loss: 0.5225, Val Loss: 1.8531\n",
      "Epoch [6266/10000], Train Loss: 0.5212, Val Loss: 1.9166\n",
      "Epoch [6267/10000], Train Loss: 0.5197, Val Loss: 1.8527\n",
      "Epoch [6268/10000], Train Loss: 0.5179, Val Loss: 1.9195\n",
      "Epoch [6269/10000], Train Loss: 0.5163, Val Loss: 1.8484\n",
      "Epoch [6270/10000], Train Loss: 0.5143, Val Loss: 1.9060\n",
      "Epoch [6271/10000], Train Loss: 0.5123, Val Loss: 1.8410\n",
      "Epoch [6272/10000], Train Loss: 0.5103, Val Loss: 1.9071\n",
      "Epoch [6273/10000], Train Loss: 0.5087, Val Loss: 1.8388\n",
      "Epoch [6274/10000], Train Loss: 0.5072, Val Loss: 1.8987\n",
      "Epoch [6275/10000], Train Loss: 0.5049, Val Loss: 1.8218\n",
      "Epoch [6276/10000], Train Loss: 0.5032, Val Loss: 1.8783\n",
      "Epoch [6277/10000], Train Loss: 0.5011, Val Loss: 1.8368\n",
      "Epoch [6278/10000], Train Loss: 0.4989, Val Loss: 1.8710\n",
      "Epoch [6279/10000], Train Loss: 0.4972, Val Loss: 1.8473\n",
      "Epoch [6280/10000], Train Loss: 0.4952, Val Loss: 1.8480\n",
      "Epoch [6281/10000], Train Loss: 0.4938, Val Loss: 1.8557\n",
      "Epoch [6282/10000], Train Loss: 0.4918, Val Loss: 1.8273\n",
      "Epoch [6283/10000], Train Loss: 0.4905, Val Loss: 1.8641\n",
      "Epoch [6284/10000], Train Loss: 0.4890, Val Loss: 1.8073\n",
      "Epoch [6285/10000], Train Loss: 0.4876, Val Loss: 1.8563\n",
      "Epoch [6286/10000], Train Loss: 0.4862, Val Loss: 1.8032\n",
      "Epoch [6287/10000], Train Loss: 0.4847, Val Loss: 1.8577\n",
      "Epoch [6288/10000], Train Loss: 0.4833, Val Loss: 1.8018\n",
      "Epoch [6289/10000], Train Loss: 0.4818, Val Loss: 1.8545\n",
      "Epoch [6290/10000], Train Loss: 0.4806, Val Loss: 1.7878\n",
      "Epoch [6291/10000], Train Loss: 0.4789, Val Loss: 1.8452\n",
      "Epoch [6292/10000], Train Loss: 0.4774, Val Loss: 1.7688\n",
      "Epoch [6293/10000], Train Loss: 0.4759, Val Loss: 1.8469\n",
      "Epoch [6294/10000], Train Loss: 0.4746, Val Loss: 1.7696\n",
      "Epoch [6295/10000], Train Loss: 0.4733, Val Loss: 1.8355\n",
      "Epoch [6296/10000], Train Loss: 0.4712, Val Loss: 1.7495\n",
      "Epoch [6297/10000], Train Loss: 0.4694, Val Loss: 1.8071\n",
      "Epoch [6298/10000], Train Loss: 0.4675, Val Loss: 1.7643\n",
      "Epoch [6299/10000], Train Loss: 0.4651, Val Loss: 1.7980\n",
      "Epoch [6300/10000], Train Loss: 0.4636, Val Loss: 1.7774\n",
      "Epoch [6301/10000], Train Loss: 0.4616, Val Loss: 1.7703\n",
      "Epoch [6302/10000], Train Loss: 0.4599, Val Loss: 1.7751\n",
      "Epoch [6303/10000], Train Loss: 0.4585, Val Loss: 1.7604\n",
      "Epoch [6304/10000], Train Loss: 0.4568, Val Loss: 1.7877\n",
      "Epoch [6305/10000], Train Loss: 0.4554, Val Loss: 1.7600\n",
      "Epoch [6306/10000], Train Loss: 0.4541, Val Loss: 1.7926\n",
      "Epoch [6307/10000], Train Loss: 0.4530, Val Loss: 1.7438\n",
      "Epoch [6308/10000], Train Loss: 0.4517, Val Loss: 1.7951\n",
      "Epoch [6309/10000], Train Loss: 0.4508, Val Loss: 1.7170\n",
      "Epoch [6310/10000], Train Loss: 0.4500, Val Loss: 1.7959\n",
      "Epoch [6311/10000], Train Loss: 0.4490, Val Loss: 1.7062\n",
      "Epoch [6312/10000], Train Loss: 0.4477, Val Loss: 1.7868\n",
      "Epoch [6313/10000], Train Loss: 0.4460, Val Loss: 1.7071\n",
      "Epoch [6314/10000], Train Loss: 0.4441, Val Loss: 1.7706\n",
      "Epoch [6315/10000], Train Loss: 0.4420, Val Loss: 1.7115\n",
      "Epoch [6316/10000], Train Loss: 0.4398, Val Loss: 1.7451\n",
      "Epoch [6317/10000], Train Loss: 0.4378, Val Loss: 1.7217\n",
      "Epoch [6318/10000], Train Loss: 0.4360, Val Loss: 1.7275\n",
      "Epoch [6319/10000], Train Loss: 0.4344, Val Loss: 1.7324\n",
      "Epoch [6320/10000], Train Loss: 0.4330, Val Loss: 1.7139\n",
      "Epoch [6321/10000], Train Loss: 0.4319, Val Loss: 1.7451\n",
      "Epoch [6322/10000], Train Loss: 0.4309, Val Loss: 1.6965\n",
      "Epoch [6323/10000], Train Loss: 0.4299, Val Loss: 1.7465\n",
      "Epoch [6324/10000], Train Loss: 0.4288, Val Loss: 1.6753\n",
      "Epoch [6325/10000], Train Loss: 0.4281, Val Loss: 1.7502\n",
      "Epoch [6326/10000], Train Loss: 0.4269, Val Loss: 1.6769\n",
      "Epoch [6327/10000], Train Loss: 0.4260, Val Loss: 1.7450\n",
      "Epoch [6328/10000], Train Loss: 0.4242, Val Loss: 1.6586\n",
      "Epoch [6329/10000], Train Loss: 0.4225, Val Loss: 1.7182\n",
      "Epoch [6330/10000], Train Loss: 0.4207, Val Loss: 1.6724\n",
      "Epoch [6331/10000], Train Loss: 0.4184, Val Loss: 1.7067\n",
      "Epoch [6332/10000], Train Loss: 0.4168, Val Loss: 1.6849\n",
      "Epoch [6333/10000], Train Loss: 0.4150, Val Loss: 1.6797\n",
      "Epoch [6334/10000], Train Loss: 0.4135, Val Loss: 1.6855\n",
      "Epoch [6335/10000], Train Loss: 0.4123, Val Loss: 1.6651\n",
      "Epoch [6336/10000], Train Loss: 0.4110, Val Loss: 1.6989\n",
      "Epoch [6337/10000], Train Loss: 0.4099, Val Loss: 1.6625\n",
      "Epoch [6338/10000], Train Loss: 0.4089, Val Loss: 1.7040\n",
      "Epoch [6339/10000], Train Loss: 0.4079, Val Loss: 1.6471\n",
      "Epoch [6340/10000], Train Loss: 0.4067, Val Loss: 1.7038\n",
      "Epoch [6341/10000], Train Loss: 0.4059, Val Loss: 1.6248\n",
      "Epoch [6342/10000], Train Loss: 0.4049, Val Loss: 1.6986\n",
      "Epoch [6343/10000], Train Loss: 0.4037, Val Loss: 1.6212\n",
      "Epoch [6344/10000], Train Loss: 0.4021, Val Loss: 1.6818\n",
      "Epoch [6345/10000], Train Loss: 0.4004, Val Loss: 1.6295\n",
      "Epoch [6346/10000], Train Loss: 0.3986, Val Loss: 1.6613\n",
      "Epoch [6347/10000], Train Loss: 0.3968, Val Loss: 1.6366\n",
      "Epoch [6348/10000], Train Loss: 0.3952, Val Loss: 1.6376\n",
      "Epoch [6349/10000], Train Loss: 0.3938, Val Loss: 1.6468\n",
      "Epoch [6350/10000], Train Loss: 0.3925, Val Loss: 1.6257\n",
      "Epoch [6351/10000], Train Loss: 0.3913, Val Loss: 1.6516\n",
      "Epoch [6352/10000], Train Loss: 0.3902, Val Loss: 1.6189\n",
      "Epoch [6353/10000], Train Loss: 0.3891, Val Loss: 1.6499\n",
      "Epoch [6354/10000], Train Loss: 0.3881, Val Loss: 1.6234\n",
      "Epoch [6355/10000], Train Loss: 0.3868, Val Loss: 1.6400\n",
      "Epoch [6356/10000], Train Loss: 0.3853, Val Loss: 1.6224\n",
      "Epoch [6357/10000], Train Loss: 0.3838, Val Loss: 1.6156\n",
      "Epoch [6358/10000], Train Loss: 0.3827, Val Loss: 1.6299\n",
      "Epoch [6359/10000], Train Loss: 0.3813, Val Loss: 1.6115\n",
      "Epoch [6360/10000], Train Loss: 0.3807, Val Loss: 1.6323\n",
      "Epoch [6361/10000], Train Loss: 0.3794, Val Loss: 1.5838\n",
      "Epoch [6362/10000], Train Loss: 0.3786, Val Loss: 1.6236\n",
      "Epoch [6363/10000], Train Loss: 0.3777, Val Loss: 1.5831\n",
      "Epoch [6364/10000], Train Loss: 0.3763, Val Loss: 1.6271\n",
      "Epoch [6365/10000], Train Loss: 0.3753, Val Loss: 1.5829\n",
      "Epoch [6366/10000], Train Loss: 0.3738, Val Loss: 1.6133\n",
      "Epoch [6367/10000], Train Loss: 0.3724, Val Loss: 1.5722\n",
      "Epoch [6368/10000], Train Loss: 0.3711, Val Loss: 1.6057\n",
      "Epoch [6369/10000], Train Loss: 0.3695, Val Loss: 1.5836\n",
      "Epoch [6370/10000], Train Loss: 0.3682, Val Loss: 1.5998\n",
      "Epoch [6371/10000], Train Loss: 0.3670, Val Loss: 1.5849\n",
      "Epoch [6372/10000], Train Loss: 0.3661, Val Loss: 1.5922\n",
      "Epoch [6373/10000], Train Loss: 0.3645, Val Loss: 1.5815\n",
      "Epoch [6374/10000], Train Loss: 0.3634, Val Loss: 1.5841\n",
      "Epoch [6375/10000], Train Loss: 0.3622, Val Loss: 1.5747\n",
      "Epoch [6376/10000], Train Loss: 0.3611, Val Loss: 1.5766\n",
      "Epoch [6377/10000], Train Loss: 0.3599, Val Loss: 1.5774\n",
      "Epoch [6378/10000], Train Loss: 0.3588, Val Loss: 1.5737\n",
      "Epoch [6379/10000], Train Loss: 0.3577, Val Loss: 1.5748\n",
      "Epoch [6380/10000], Train Loss: 0.3565, Val Loss: 1.5654\n",
      "Epoch [6381/10000], Train Loss: 0.3556, Val Loss: 1.5763\n",
      "Epoch [6382/10000], Train Loss: 0.3545, Val Loss: 1.5570\n",
      "Epoch [6383/10000], Train Loss: 0.3535, Val Loss: 1.5731\n",
      "Epoch [6384/10000], Train Loss: 0.3524, Val Loss: 1.5363\n",
      "Epoch [6385/10000], Train Loss: 0.3515, Val Loss: 1.5671\n",
      "Epoch [6386/10000], Train Loss: 0.3504, Val Loss: 1.5388\n",
      "Epoch [6387/10000], Train Loss: 0.3493, Val Loss: 1.5674\n",
      "Epoch [6388/10000], Train Loss: 0.3484, Val Loss: 1.5319\n",
      "Epoch [6389/10000], Train Loss: 0.3472, Val Loss: 1.5580\n",
      "Epoch [6390/10000], Train Loss: 0.3463, Val Loss: 1.5323\n",
      "Epoch [6391/10000], Train Loss: 0.3450, Val Loss: 1.5496\n",
      "Epoch [6392/10000], Train Loss: 0.3439, Val Loss: 1.5341\n",
      "Epoch [6393/10000], Train Loss: 0.3426, Val Loss: 1.5282\n",
      "Epoch [6394/10000], Train Loss: 0.3416, Val Loss: 1.5282\n",
      "Epoch [6395/10000], Train Loss: 0.3405, Val Loss: 1.5291\n",
      "Epoch [6396/10000], Train Loss: 0.3393, Val Loss: 1.5331\n",
      "Epoch [6397/10000], Train Loss: 0.3384, Val Loss: 1.5223\n",
      "Epoch [6398/10000], Train Loss: 0.3373, Val Loss: 1.5288\n",
      "Epoch [6399/10000], Train Loss: 0.3364, Val Loss: 1.5124\n",
      "Epoch [6400/10000], Train Loss: 0.3354, Val Loss: 1.5376\n",
      "Epoch [6401/10000], Train Loss: 0.3348, Val Loss: 1.5060\n",
      "Epoch [6402/10000], Train Loss: 0.3342, Val Loss: 1.5424\n",
      "Epoch [6403/10000], Train Loss: 0.3332, Val Loss: 1.4759\n",
      "Epoch [6404/10000], Train Loss: 0.3329, Val Loss: 1.5444\n",
      "Epoch [6405/10000], Train Loss: 0.3321, Val Loss: 1.4764\n",
      "Epoch [6406/10000], Train Loss: 0.3314, Val Loss: 1.5532\n",
      "Epoch [6407/10000], Train Loss: 0.3309, Val Loss: 1.4690\n",
      "Epoch [6408/10000], Train Loss: 0.3300, Val Loss: 1.5459\n",
      "Epoch [6409/10000], Train Loss: 0.3294, Val Loss: 1.4595\n",
      "Epoch [6410/10000], Train Loss: 0.3289, Val Loss: 1.5516\n",
      "Epoch [6411/10000], Train Loss: 0.3282, Val Loss: 1.4644\n",
      "Epoch [6412/10000], Train Loss: 0.3276, Val Loss: 1.5432\n",
      "Epoch [6413/10000], Train Loss: 0.3262, Val Loss: 1.4440\n",
      "Epoch [6414/10000], Train Loss: 0.3255, Val Loss: 1.5372\n",
      "Epoch [6415/10000], Train Loss: 0.3240, Val Loss: 1.4512\n",
      "Epoch [6416/10000], Train Loss: 0.3230, Val Loss: 1.5269\n",
      "Epoch [6417/10000], Train Loss: 0.3212, Val Loss: 1.4445\n",
      "Epoch [6418/10000], Train Loss: 0.3194, Val Loss: 1.4976\n",
      "Epoch [6419/10000], Train Loss: 0.3179, Val Loss: 1.4558\n",
      "Epoch [6420/10000], Train Loss: 0.3161, Val Loss: 1.4823\n",
      "Epoch [6421/10000], Train Loss: 0.3150, Val Loss: 1.4757\n",
      "Epoch [6422/10000], Train Loss: 0.3139, Val Loss: 1.4568\n",
      "Epoch [6423/10000], Train Loss: 0.3130, Val Loss: 1.4779\n",
      "Epoch [6424/10000], Train Loss: 0.3124, Val Loss: 1.4447\n",
      "Epoch [6425/10000], Train Loss: 0.3116, Val Loss: 1.4888\n",
      "Epoch [6426/10000], Train Loss: 0.3110, Val Loss: 1.4442\n",
      "Epoch [6427/10000], Train Loss: 0.3102, Val Loss: 1.4870\n",
      "Epoch [6428/10000], Train Loss: 0.3093, Val Loss: 1.4461\n",
      "Epoch [6429/10000], Train Loss: 0.3081, Val Loss: 1.4699\n",
      "Epoch [6430/10000], Train Loss: 0.3069, Val Loss: 1.4523\n",
      "Epoch [6431/10000], Train Loss: 0.3058, Val Loss: 1.4503\n",
      "Epoch [6432/10000], Train Loss: 0.3048, Val Loss: 1.4566\n",
      "Epoch [6433/10000], Train Loss: 0.3038, Val Loss: 1.4464\n",
      "Epoch [6434/10000], Train Loss: 0.3030, Val Loss: 1.4591\n",
      "Epoch [6435/10000], Train Loss: 0.3022, Val Loss: 1.4370\n",
      "Epoch [6436/10000], Train Loss: 0.3015, Val Loss: 1.4567\n",
      "Epoch [6437/10000], Train Loss: 0.3007, Val Loss: 1.4305\n",
      "Epoch [6438/10000], Train Loss: 0.3000, Val Loss: 1.4635\n",
      "Epoch [6439/10000], Train Loss: 0.2996, Val Loss: 1.4232\n",
      "Epoch [6440/10000], Train Loss: 0.2988, Val Loss: 1.4594\n",
      "Epoch [6441/10000], Train Loss: 0.2980, Val Loss: 1.4008\n",
      "Epoch [6442/10000], Train Loss: 0.2974, Val Loss: 1.4571\n",
      "Epoch [6443/10000], Train Loss: 0.2963, Val Loss: 1.4084\n",
      "Epoch [6444/10000], Train Loss: 0.2954, Val Loss: 1.4516\n",
      "Epoch [6445/10000], Train Loss: 0.2944, Val Loss: 1.4077\n",
      "Epoch [6446/10000], Train Loss: 0.2933, Val Loss: 1.4342\n",
      "Epoch [6447/10000], Train Loss: 0.2924, Val Loss: 1.4094\n",
      "Epoch [6448/10000], Train Loss: 0.2913, Val Loss: 1.4354\n",
      "Epoch [6449/10000], Train Loss: 0.2908, Val Loss: 1.4155\n",
      "Epoch [6450/10000], Train Loss: 0.2900, Val Loss: 1.4224\n",
      "Epoch [6451/10000], Train Loss: 0.2888, Val Loss: 1.3965\n",
      "Epoch [6452/10000], Train Loss: 0.2883, Val Loss: 1.4179\n",
      "Epoch [6453/10000], Train Loss: 0.2872, Val Loss: 1.4062\n",
      "Epoch [6454/10000], Train Loss: 0.2864, Val Loss: 1.4187\n",
      "Epoch [6455/10000], Train Loss: 0.2857, Val Loss: 1.4032\n",
      "Epoch [6456/10000], Train Loss: 0.2846, Val Loss: 1.4032\n",
      "Epoch [6457/10000], Train Loss: 0.2840, Val Loss: 1.3988\n",
      "Epoch [6458/10000], Train Loss: 0.2831, Val Loss: 1.4062\n",
      "Epoch [6459/10000], Train Loss: 0.2822, Val Loss: 1.4077\n",
      "Epoch [6460/10000], Train Loss: 0.2816, Val Loss: 1.3988\n",
      "Epoch [6461/10000], Train Loss: 0.2808, Val Loss: 1.4064\n",
      "Epoch [6462/10000], Train Loss: 0.2799, Val Loss: 1.3871\n",
      "Epoch [6463/10000], Train Loss: 0.2793, Val Loss: 1.4075\n",
      "Epoch [6464/10000], Train Loss: 0.2786, Val Loss: 1.3747\n",
      "Epoch [6465/10000], Train Loss: 0.2780, Val Loss: 1.4105\n",
      "Epoch [6466/10000], Train Loss: 0.2774, Val Loss: 1.3713\n",
      "Epoch [6467/10000], Train Loss: 0.2767, Val Loss: 1.4077\n",
      "Epoch [6468/10000], Train Loss: 0.2761, Val Loss: 1.3670\n",
      "Epoch [6469/10000], Train Loss: 0.2755, Val Loss: 1.4049\n",
      "Epoch [6470/10000], Train Loss: 0.2748, Val Loss: 1.3623\n",
      "Epoch [6471/10000], Train Loss: 0.2742, Val Loss: 1.4114\n",
      "Epoch [6472/10000], Train Loss: 0.2739, Val Loss: 1.3540\n",
      "Epoch [6473/10000], Train Loss: 0.2734, Val Loss: 1.4083\n",
      "Epoch [6474/10000], Train Loss: 0.2730, Val Loss: 1.3352\n",
      "Epoch [6475/10000], Train Loss: 0.2727, Val Loss: 1.4113\n",
      "Epoch [6476/10000], Train Loss: 0.2720, Val Loss: 1.3372\n",
      "Epoch [6477/10000], Train Loss: 0.2715, Val Loss: 1.4105\n",
      "Epoch [6478/10000], Train Loss: 0.2707, Val Loss: 1.3325\n",
      "Epoch [6479/10000], Train Loss: 0.2698, Val Loss: 1.3978\n",
      "Epoch [6480/10000], Train Loss: 0.2690, Val Loss: 1.3338\n",
      "Epoch [6481/10000], Train Loss: 0.2679, Val Loss: 1.4000\n",
      "Epoch [6482/10000], Train Loss: 0.2675, Val Loss: 1.3373\n",
      "Epoch [6483/10000], Train Loss: 0.2665, Val Loss: 1.3848\n",
      "Epoch [6484/10000], Train Loss: 0.2654, Val Loss: 1.3250\n",
      "Epoch [6485/10000], Train Loss: 0.2647, Val Loss: 1.3763\n",
      "Epoch [6486/10000], Train Loss: 0.2634, Val Loss: 1.3392\n",
      "Epoch [6487/10000], Train Loss: 0.2625, Val Loss: 1.3691\n",
      "Epoch [6488/10000], Train Loss: 0.2615, Val Loss: 1.3405\n",
      "Epoch [6489/10000], Train Loss: 0.2605, Val Loss: 1.3491\n",
      "Epoch [6490/10000], Train Loss: 0.2599, Val Loss: 1.3504\n",
      "Epoch [6491/10000], Train Loss: 0.2590, Val Loss: 1.3410\n",
      "Epoch [6492/10000], Train Loss: 0.2588, Val Loss: 1.3607\n",
      "Epoch [6493/10000], Train Loss: 0.2581, Val Loss: 1.3146\n",
      "Epoch [6494/10000], Train Loss: 0.2578, Val Loss: 1.3606\n",
      "Epoch [6495/10000], Train Loss: 0.2574, Val Loss: 1.3147\n",
      "Epoch [6496/10000], Train Loss: 0.2569, Val Loss: 1.3656\n",
      "Epoch [6497/10000], Train Loss: 0.2565, Val Loss: 1.3132\n",
      "Epoch [6498/10000], Train Loss: 0.2558, Val Loss: 1.3566\n",
      "Epoch [6499/10000], Train Loss: 0.2552, Val Loss: 1.3058\n",
      "Epoch [6500/10000], Train Loss: 0.2545, Val Loss: 1.3605\n",
      "Epoch [6501/10000], Train Loss: 0.2540, Val Loss: 1.3104\n",
      "Epoch [6502/10000], Train Loss: 0.2535, Val Loss: 1.3536\n",
      "Epoch [6503/10000], Train Loss: 0.2525, Val Loss: 1.2941\n",
      "Epoch [6504/10000], Train Loss: 0.2520, Val Loss: 1.3466\n",
      "Epoch [6505/10000], Train Loss: 0.2510, Val Loss: 1.3028\n",
      "Epoch [6506/10000], Train Loss: 0.2501, Val Loss: 1.3433\n",
      "Epoch [6507/10000], Train Loss: 0.2493, Val Loss: 1.3073\n",
      "Epoch [6508/10000], Train Loss: 0.2483, Val Loss: 1.3237\n",
      "Epoch [6509/10000], Train Loss: 0.2476, Val Loss: 1.3084\n",
      "Epoch [6510/10000], Train Loss: 0.2468, Val Loss: 1.3201\n",
      "Epoch [6511/10000], Train Loss: 0.2461, Val Loss: 1.3201\n",
      "Epoch [6512/10000], Train Loss: 0.2456, Val Loss: 1.3102\n",
      "Epoch [6513/10000], Train Loss: 0.2449, Val Loss: 1.3242\n",
      "Epoch [6514/10000], Train Loss: 0.2444, Val Loss: 1.2963\n",
      "Epoch [6515/10000], Train Loss: 0.2440, Val Loss: 1.3268\n",
      "Epoch [6516/10000], Train Loss: 0.2437, Val Loss: 1.2845\n",
      "Epoch [6517/10000], Train Loss: 0.2433, Val Loss: 1.3305\n",
      "Epoch [6518/10000], Train Loss: 0.2429, Val Loss: 1.2820\n",
      "Epoch [6519/10000], Train Loss: 0.2425, Val Loss: 1.3276\n",
      "Epoch [6520/10000], Train Loss: 0.2420, Val Loss: 1.2784\n",
      "Epoch [6521/10000], Train Loss: 0.2414, Val Loss: 1.3228\n",
      "Epoch [6522/10000], Train Loss: 0.2408, Val Loss: 1.2769\n",
      "Epoch [6523/10000], Train Loss: 0.2401, Val Loss: 1.3206\n",
      "Epoch [6524/10000], Train Loss: 0.2394, Val Loss: 1.2770\n",
      "Epoch [6525/10000], Train Loss: 0.2387, Val Loss: 1.3194\n",
      "Epoch [6526/10000], Train Loss: 0.2383, Val Loss: 1.2725\n",
      "Epoch [6527/10000], Train Loss: 0.2376, Val Loss: 1.3135\n",
      "Epoch [6528/10000], Train Loss: 0.2370, Val Loss: 1.2615\n",
      "Epoch [6529/10000], Train Loss: 0.2365, Val Loss: 1.3110\n",
      "Epoch [6530/10000], Train Loss: 0.2357, Val Loss: 1.2692\n",
      "Epoch [6531/10000], Train Loss: 0.2350, Val Loss: 1.3022\n",
      "Epoch [6532/10000], Train Loss: 0.2343, Val Loss: 1.2703\n",
      "Epoch [6533/10000], Train Loss: 0.2336, Val Loss: 1.2902\n",
      "Epoch [6534/10000], Train Loss: 0.2329, Val Loss: 1.2728\n",
      "Epoch [6535/10000], Train Loss: 0.2323, Val Loss: 1.2874\n",
      "Epoch [6536/10000], Train Loss: 0.2317, Val Loss: 1.2784\n",
      "Epoch [6537/10000], Train Loss: 0.2310, Val Loss: 1.2783\n",
      "Epoch [6538/10000], Train Loss: 0.2305, Val Loss: 1.2824\n",
      "Epoch [6539/10000], Train Loss: 0.2299, Val Loss: 1.2704\n",
      "Epoch [6540/10000], Train Loss: 0.2295, Val Loss: 1.2827\n",
      "Epoch [6541/10000], Train Loss: 0.2290, Val Loss: 1.2562\n",
      "Epoch [6542/10000], Train Loss: 0.2286, Val Loss: 1.2863\n",
      "Epoch [6543/10000], Train Loss: 0.2282, Val Loss: 1.2542\n",
      "Epoch [6544/10000], Train Loss: 0.2279, Val Loss: 1.2882\n",
      "Epoch [6545/10000], Train Loss: 0.2275, Val Loss: 1.2484\n",
      "Epoch [6546/10000], Train Loss: 0.2271, Val Loss: 1.2848\n",
      "Epoch [6547/10000], Train Loss: 0.2267, Val Loss: 1.2426\n",
      "Epoch [6548/10000], Train Loss: 0.2263, Val Loss: 1.2897\n",
      "Epoch [6549/10000], Train Loss: 0.2259, Val Loss: 1.2403\n",
      "Epoch [6550/10000], Train Loss: 0.2254, Val Loss: 1.2933\n",
      "Epoch [6551/10000], Train Loss: 0.2253, Val Loss: 1.2308\n",
      "Epoch [6552/10000], Train Loss: 0.2251, Val Loss: 1.2922\n",
      "Epoch [6553/10000], Train Loss: 0.2249, Val Loss: 1.2181\n",
      "Epoch [6554/10000], Train Loss: 0.2246, Val Loss: 1.2971\n",
      "Epoch [6555/10000], Train Loss: 0.2242, Val Loss: 1.2214\n",
      "Epoch [6556/10000], Train Loss: 0.2237, Val Loss: 1.2897\n",
      "Epoch [6557/10000], Train Loss: 0.2230, Val Loss: 1.2206\n",
      "Epoch [6558/10000], Train Loss: 0.2224, Val Loss: 1.2790\n",
      "Epoch [6559/10000], Train Loss: 0.2215, Val Loss: 1.2249\n",
      "Epoch [6560/10000], Train Loss: 0.2207, Val Loss: 1.2742\n",
      "Epoch [6561/10000], Train Loss: 0.2198, Val Loss: 1.2304\n",
      "Epoch [6562/10000], Train Loss: 0.2189, Val Loss: 1.2648\n",
      "Epoch [6563/10000], Train Loss: 0.2183, Val Loss: 1.2300\n",
      "Epoch [6564/10000], Train Loss: 0.2177, Val Loss: 1.2571\n",
      "Epoch [6565/10000], Train Loss: 0.2170, Val Loss: 1.2236\n",
      "Epoch [6566/10000], Train Loss: 0.2164, Val Loss: 1.2542\n",
      "Epoch [6567/10000], Train Loss: 0.2158, Val Loss: 1.2303\n",
      "Epoch [6568/10000], Train Loss: 0.2152, Val Loss: 1.2430\n",
      "Epoch [6569/10000], Train Loss: 0.2147, Val Loss: 1.2338\n",
      "Epoch [6570/10000], Train Loss: 0.2142, Val Loss: 1.2328\n",
      "Epoch [6571/10000], Train Loss: 0.2137, Val Loss: 1.2365\n",
      "Epoch [6572/10000], Train Loss: 0.2132, Val Loss: 1.2303\n",
      "Epoch [6573/10000], Train Loss: 0.2128, Val Loss: 1.2399\n",
      "Epoch [6574/10000], Train Loss: 0.2123, Val Loss: 1.2220\n",
      "Epoch [6575/10000], Train Loss: 0.2120, Val Loss: 1.2453\n",
      "Epoch [6576/10000], Train Loss: 0.2116, Val Loss: 1.2161\n",
      "Epoch [6577/10000], Train Loss: 0.2113, Val Loss: 1.2434\n",
      "Epoch [6578/10000], Train Loss: 0.2110, Val Loss: 1.2050\n",
      "Epoch [6579/10000], Train Loss: 0.2107, Val Loss: 1.2450\n",
      "Epoch [6580/10000], Train Loss: 0.2103, Val Loss: 1.2055\n",
      "Epoch [6581/10000], Train Loss: 0.2100, Val Loss: 1.2456\n",
      "Epoch [6582/10000], Train Loss: 0.2096, Val Loss: 1.2009\n",
      "Epoch [6583/10000], Train Loss: 0.2093, Val Loss: 1.2396\n",
      "Epoch [6584/10000], Train Loss: 0.2089, Val Loss: 1.1986\n",
      "Epoch [6585/10000], Train Loss: 0.2084, Val Loss: 1.2424\n",
      "Epoch [6586/10000], Train Loss: 0.2080, Val Loss: 1.1977\n",
      "Epoch [6587/10000], Train Loss: 0.2075, Val Loss: 1.2391\n",
      "Epoch [6588/10000], Train Loss: 0.2070, Val Loss: 1.1938\n",
      "Epoch [6589/10000], Train Loss: 0.2067, Val Loss: 1.2408\n",
      "Epoch [6590/10000], Train Loss: 0.2062, Val Loss: 1.1928\n",
      "Epoch [6591/10000], Train Loss: 0.2059, Val Loss: 1.2380\n",
      "Epoch [6592/10000], Train Loss: 0.2054, Val Loss: 1.1815\n",
      "Epoch [6593/10000], Train Loss: 0.2051, Val Loss: 1.2399\n",
      "Epoch [6594/10000], Train Loss: 0.2049, Val Loss: 1.1837\n",
      "Epoch [6595/10000], Train Loss: 0.2047, Val Loss: 1.2355\n",
      "Epoch [6596/10000], Train Loss: 0.2043, Val Loss: 1.1728\n",
      "Epoch [6597/10000], Train Loss: 0.2040, Val Loss: 1.2294\n",
      "Epoch [6598/10000], Train Loss: 0.2035, Val Loss: 1.1760\n",
      "Epoch [6599/10000], Train Loss: 0.2030, Val Loss: 1.2277\n",
      "Epoch [6600/10000], Train Loss: 0.2025, Val Loss: 1.1772\n",
      "Epoch [6601/10000], Train Loss: 0.2018, Val Loss: 1.2151\n",
      "Epoch [6602/10000], Train Loss: 0.2012, Val Loss: 1.1762\n",
      "Epoch [6603/10000], Train Loss: 0.2005, Val Loss: 1.2142\n",
      "Epoch [6604/10000], Train Loss: 0.1999, Val Loss: 1.1814\n",
      "Epoch [6605/10000], Train Loss: 0.1993, Val Loss: 1.2082\n",
      "Epoch [6606/10000], Train Loss: 0.1986, Val Loss: 1.1813\n",
      "Epoch [6607/10000], Train Loss: 0.1981, Val Loss: 1.2012\n",
      "Epoch [6608/10000], Train Loss: 0.1976, Val Loss: 1.1886\n",
      "Epoch [6609/10000], Train Loss: 0.1971, Val Loss: 1.1994\n",
      "Epoch [6610/10000], Train Loss: 0.1967, Val Loss: 1.1915\n",
      "Epoch [6611/10000], Train Loss: 0.1963, Val Loss: 1.1956\n",
      "Epoch [6612/10000], Train Loss: 0.1959, Val Loss: 1.1911\n",
      "Epoch [6613/10000], Train Loss: 0.1954, Val Loss: 1.1908\n",
      "Epoch [6614/10000], Train Loss: 0.1950, Val Loss: 1.1846\n",
      "Epoch [6615/10000], Train Loss: 0.1947, Val Loss: 1.1905\n",
      "Epoch [6616/10000], Train Loss: 0.1942, Val Loss: 1.1850\n",
      "Epoch [6617/10000], Train Loss: 0.1939, Val Loss: 1.1868\n",
      "Epoch [6618/10000], Train Loss: 0.1935, Val Loss: 1.1819\n",
      "Epoch [6619/10000], Train Loss: 0.1931, Val Loss: 1.1816\n",
      "Epoch [6620/10000], Train Loss: 0.1927, Val Loss: 1.1787\n",
      "Epoch [6621/10000], Train Loss: 0.1923, Val Loss: 1.1831\n",
      "Epoch [6622/10000], Train Loss: 0.1919, Val Loss: 1.1761\n",
      "Epoch [6623/10000], Train Loss: 0.1915, Val Loss: 1.1800\n",
      "Epoch [6624/10000], Train Loss: 0.1912, Val Loss: 1.1778\n",
      "Epoch [6625/10000], Train Loss: 0.1908, Val Loss: 1.1748\n",
      "Epoch [6626/10000], Train Loss: 0.1904, Val Loss: 1.1764\n",
      "Epoch [6627/10000], Train Loss: 0.1900, Val Loss: 1.1636\n",
      "Epoch [6628/10000], Train Loss: 0.1897, Val Loss: 1.1794\n",
      "Epoch [6629/10000], Train Loss: 0.1893, Val Loss: 1.1638\n",
      "Epoch [6630/10000], Train Loss: 0.1890, Val Loss: 1.1810\n",
      "Epoch [6631/10000], Train Loss: 0.1887, Val Loss: 1.1575\n",
      "Epoch [6632/10000], Train Loss: 0.1884, Val Loss: 1.1794\n",
      "Epoch [6633/10000], Train Loss: 0.1882, Val Loss: 1.1533\n",
      "Epoch [6634/10000], Train Loss: 0.1879, Val Loss: 1.1861\n",
      "Epoch [6635/10000], Train Loss: 0.1877, Val Loss: 1.1491\n",
      "Epoch [6636/10000], Train Loss: 0.1875, Val Loss: 1.1878\n",
      "Epoch [6637/10000], Train Loss: 0.1875, Val Loss: 1.1410\n",
      "Epoch [6638/10000], Train Loss: 0.1875, Val Loss: 1.1991\n",
      "Epoch [6639/10000], Train Loss: 0.1879, Val Loss: 1.1325\n",
      "Epoch [6640/10000], Train Loss: 0.1884, Val Loss: 1.2093\n",
      "Epoch [6641/10000], Train Loss: 0.1891, Val Loss: 1.1128\n",
      "Epoch [6642/10000], Train Loss: 0.1902, Val Loss: 1.2277\n",
      "Epoch [6643/10000], Train Loss: 0.1917, Val Loss: 1.1070\n",
      "Epoch [6644/10000], Train Loss: 0.1934, Val Loss: 1.2377\n",
      "Epoch [6645/10000], Train Loss: 0.1946, Val Loss: 1.0938\n",
      "Epoch [6646/10000], Train Loss: 0.1952, Val Loss: 1.2343\n",
      "Epoch [6647/10000], Train Loss: 0.1945, Val Loss: 1.0990\n",
      "Epoch [6648/10000], Train Loss: 0.1930, Val Loss: 1.2201\n",
      "Epoch [6649/10000], Train Loss: 0.1901, Val Loss: 1.1133\n",
      "Epoch [6650/10000], Train Loss: 0.1864, Val Loss: 1.1754\n",
      "Epoch [6651/10000], Train Loss: 0.1832, Val Loss: 1.1398\n",
      "Epoch [6652/10000], Train Loss: 0.1812, Val Loss: 1.1432\n",
      "Epoch [6653/10000], Train Loss: 0.1808, Val Loss: 1.1720\n",
      "Epoch [6654/10000], Train Loss: 0.1815, Val Loss: 1.1192\n",
      "Epoch [6655/10000], Train Loss: 0.1826, Val Loss: 1.1875\n",
      "Epoch [6656/10000], Train Loss: 0.1833, Val Loss: 1.1106\n",
      "Epoch [6657/10000], Train Loss: 0.1832, Val Loss: 1.1925\n",
      "Epoch [6658/10000], Train Loss: 0.1826, Val Loss: 1.1180\n",
      "Epoch [6659/10000], Train Loss: 0.1812, Val Loss: 1.1683\n",
      "Epoch [6660/10000], Train Loss: 0.1795, Val Loss: 1.1285\n",
      "Epoch [6661/10000], Train Loss: 0.1783, Val Loss: 1.1447\n",
      "Epoch [6662/10000], Train Loss: 0.1776, Val Loss: 1.1551\n",
      "Epoch [6663/10000], Train Loss: 0.1776, Val Loss: 1.1256\n",
      "Epoch [6664/10000], Train Loss: 0.1778, Val Loss: 1.1655\n",
      "Epoch [6665/10000], Train Loss: 0.1780, Val Loss: 1.1119\n",
      "Epoch [6666/10000], Train Loss: 0.1779, Val Loss: 1.1661\n",
      "Epoch [6667/10000], Train Loss: 0.1773, Val Loss: 1.1208\n",
      "Epoch [6668/10000], Train Loss: 0.1766, Val Loss: 1.1525\n",
      "Epoch [6669/10000], Train Loss: 0.1757, Val Loss: 1.1290\n",
      "Epoch [6670/10000], Train Loss: 0.1751, Val Loss: 1.1367\n",
      "Epoch [6671/10000], Train Loss: 0.1746, Val Loss: 1.1399\n",
      "Epoch [6672/10000], Train Loss: 0.1743, Val Loss: 1.1257\n",
      "Epoch [6673/10000], Train Loss: 0.1741, Val Loss: 1.1395\n",
      "Epoch [6674/10000], Train Loss: 0.1739, Val Loss: 1.1199\n",
      "Epoch [6675/10000], Train Loss: 0.1737, Val Loss: 1.1422\n",
      "Epoch [6676/10000], Train Loss: 0.1733, Val Loss: 1.1203\n",
      "Epoch [6677/10000], Train Loss: 0.1730, Val Loss: 1.1372\n",
      "Epoch [6678/10000], Train Loss: 0.1725, Val Loss: 1.1210\n",
      "Epoch [6679/10000], Train Loss: 0.1721, Val Loss: 1.1282\n",
      "Epoch [6680/10000], Train Loss: 0.1718, Val Loss: 1.1287\n",
      "Epoch [6681/10000], Train Loss: 0.1714, Val Loss: 1.1236\n",
      "Epoch [6682/10000], Train Loss: 0.1712, Val Loss: 1.1306\n",
      "Epoch [6683/10000], Train Loss: 0.1709, Val Loss: 1.1180\n",
      "Epoch [6684/10000], Train Loss: 0.1706, Val Loss: 1.1315\n",
      "Epoch [6685/10000], Train Loss: 0.1703, Val Loss: 1.1183\n",
      "Epoch [6686/10000], Train Loss: 0.1700, Val Loss: 1.1315\n",
      "Epoch [6687/10000], Train Loss: 0.1697, Val Loss: 1.1183\n",
      "Epoch [6688/10000], Train Loss: 0.1693, Val Loss: 1.1302\n",
      "Epoch [6689/10000], Train Loss: 0.1691, Val Loss: 1.1182\n",
      "Epoch [6690/10000], Train Loss: 0.1688, Val Loss: 1.1252\n",
      "Epoch [6691/10000], Train Loss: 0.1684, Val Loss: 1.1134\n",
      "Epoch [6692/10000], Train Loss: 0.1681, Val Loss: 1.1241\n",
      "Epoch [6693/10000], Train Loss: 0.1678, Val Loss: 1.1170\n",
      "Epoch [6694/10000], Train Loss: 0.1675, Val Loss: 1.1184\n",
      "Epoch [6695/10000], Train Loss: 0.1672, Val Loss: 1.1177\n",
      "Epoch [6696/10000], Train Loss: 0.1669, Val Loss: 1.1115\n",
      "Epoch [6697/10000], Train Loss: 0.1666, Val Loss: 1.1182\n",
      "Epoch [6698/10000], Train Loss: 0.1663, Val Loss: 1.1127\n",
      "Epoch [6699/10000], Train Loss: 0.1660, Val Loss: 1.1167\n",
      "Epoch [6700/10000], Train Loss: 0.1657, Val Loss: 1.1095\n",
      "Epoch [6701/10000], Train Loss: 0.1654, Val Loss: 1.1150\n",
      "Epoch [6702/10000], Train Loss: 0.1651, Val Loss: 1.1099\n",
      "Epoch [6703/10000], Train Loss: 0.1648, Val Loss: 1.1152\n",
      "Epoch [6704/10000], Train Loss: 0.1645, Val Loss: 1.1106\n",
      "Epoch [6705/10000], Train Loss: 0.1642, Val Loss: 1.1114\n",
      "Epoch [6706/10000], Train Loss: 0.1639, Val Loss: 1.1146\n",
      "Epoch [6707/10000], Train Loss: 0.1637, Val Loss: 1.1079\n",
      "Epoch [6708/10000], Train Loss: 0.1634, Val Loss: 1.1135\n",
      "Epoch [6709/10000], Train Loss: 0.1632, Val Loss: 1.0988\n",
      "Epoch [6710/10000], Train Loss: 0.1629, Val Loss: 1.1162\n",
      "Epoch [6711/10000], Train Loss: 0.1626, Val Loss: 1.0992\n",
      "Epoch [6712/10000], Train Loss: 0.1624, Val Loss: 1.1149\n",
      "Epoch [6713/10000], Train Loss: 0.1621, Val Loss: 1.0967\n",
      "Epoch [6714/10000], Train Loss: 0.1618, Val Loss: 1.1085\n",
      "Epoch [6715/10000], Train Loss: 0.1615, Val Loss: 1.0975\n",
      "Epoch [6716/10000], Train Loss: 0.1612, Val Loss: 1.1094\n",
      "Epoch [6717/10000], Train Loss: 0.1609, Val Loss: 1.0973\n",
      "Epoch [6718/10000], Train Loss: 0.1606, Val Loss: 1.1041\n",
      "Epoch [6719/10000], Train Loss: 0.1603, Val Loss: 1.0973\n",
      "Epoch [6720/10000], Train Loss: 0.1600, Val Loss: 1.1024\n",
      "Epoch [6721/10000], Train Loss: 0.1597, Val Loss: 1.1009\n",
      "Epoch [6722/10000], Train Loss: 0.1594, Val Loss: 1.0999\n",
      "Epoch [6723/10000], Train Loss: 0.1591, Val Loss: 1.0999\n",
      "Epoch [6724/10000], Train Loss: 0.1589, Val Loss: 1.1014\n",
      "Epoch [6725/10000], Train Loss: 0.1586, Val Loss: 1.0988\n",
      "Epoch [6726/10000], Train Loss: 0.1583, Val Loss: 1.0992\n",
      "Epoch [6727/10000], Train Loss: 0.1581, Val Loss: 1.0912\n",
      "Epoch [6728/10000], Train Loss: 0.1578, Val Loss: 1.1005\n",
      "Epoch [6729/10000], Train Loss: 0.1575, Val Loss: 1.0920\n",
      "Epoch [6730/10000], Train Loss: 0.1573, Val Loss: 1.0998\n",
      "Epoch [6731/10000], Train Loss: 0.1570, Val Loss: 1.0885\n",
      "Epoch [6732/10000], Train Loss: 0.1568, Val Loss: 1.0949\n",
      "Epoch [6733/10000], Train Loss: 0.1565, Val Loss: 1.0877\n",
      "Epoch [6734/10000], Train Loss: 0.1562, Val Loss: 1.0976\n",
      "Epoch [6735/10000], Train Loss: 0.1560, Val Loss: 1.0855\n",
      "Epoch [6736/10000], Train Loss: 0.1557, Val Loss: 1.0947\n",
      "Epoch [6737/10000], Train Loss: 0.1554, Val Loss: 1.0830\n",
      "Epoch [6738/10000], Train Loss: 0.1552, Val Loss: 1.0958\n",
      "Epoch [6739/10000], Train Loss: 0.1549, Val Loss: 1.0839\n",
      "Epoch [6740/10000], Train Loss: 0.1547, Val Loss: 1.0957\n",
      "Epoch [6741/10000], Train Loss: 0.1544, Val Loss: 1.0808\n",
      "Epoch [6742/10000], Train Loss: 0.1542, Val Loss: 1.0991\n",
      "Epoch [6743/10000], Train Loss: 0.1540, Val Loss: 1.0782\n",
      "Epoch [6744/10000], Train Loss: 0.1538, Val Loss: 1.0993\n",
      "Epoch [6745/10000], Train Loss: 0.1537, Val Loss: 1.0692\n",
      "Epoch [6746/10000], Train Loss: 0.1536, Val Loss: 1.1030\n",
      "Epoch [6747/10000], Train Loss: 0.1534, Val Loss: 1.0678\n",
      "Epoch [6748/10000], Train Loss: 0.1533, Val Loss: 1.1054\n",
      "Epoch [6749/10000], Train Loss: 0.1533, Val Loss: 1.0618\n",
      "Epoch [6750/10000], Train Loss: 0.1532, Val Loss: 1.1049\n",
      "Epoch [6751/10000], Train Loss: 0.1533, Val Loss: 1.0580\n",
      "Epoch [6752/10000], Train Loss: 0.1533, Val Loss: 1.1124\n",
      "Epoch [6753/10000], Train Loss: 0.1535, Val Loss: 1.0518\n",
      "Epoch [6754/10000], Train Loss: 0.1537, Val Loss: 1.1158\n",
      "Epoch [6755/10000], Train Loss: 0.1539, Val Loss: 1.0452\n",
      "Epoch [6756/10000], Train Loss: 0.1542, Val Loss: 1.1259\n",
      "Epoch [6757/10000], Train Loss: 0.1548, Val Loss: 1.0405\n",
      "Epoch [6758/10000], Train Loss: 0.1554, Val Loss: 1.1304\n",
      "Epoch [6759/10000], Train Loss: 0.1558, Val Loss: 1.0304\n",
      "Epoch [6760/10000], Train Loss: 0.1561, Val Loss: 1.1378\n",
      "Epoch [6761/10000], Train Loss: 0.1562, Val Loss: 1.0303\n",
      "Epoch [6762/10000], Train Loss: 0.1564, Val Loss: 1.1349\n",
      "Epoch [6763/10000], Train Loss: 0.1559, Val Loss: 1.0269\n",
      "Epoch [6764/10000], Train Loss: 0.1552, Val Loss: 1.1229\n",
      "Epoch [6765/10000], Train Loss: 0.1537, Val Loss: 1.0400\n",
      "Epoch [6766/10000], Train Loss: 0.1519, Val Loss: 1.1025\n",
      "Epoch [6767/10000], Train Loss: 0.1500, Val Loss: 1.0543\n",
      "Epoch [6768/10000], Train Loss: 0.1484, Val Loss: 1.0740\n",
      "Epoch [6769/10000], Train Loss: 0.1474, Val Loss: 1.0733\n",
      "Epoch [6770/10000], Train Loss: 0.1470, Val Loss: 1.0586\n",
      "Epoch [6771/10000], Train Loss: 0.1471, Val Loss: 1.0897\n",
      "Epoch [6772/10000], Train Loss: 0.1475, Val Loss: 1.0453\n",
      "Epoch [6773/10000], Train Loss: 0.1478, Val Loss: 1.0956\n",
      "Epoch [6774/10000], Train Loss: 0.1480, Val Loss: 1.0446\n",
      "Epoch [6775/10000], Train Loss: 0.1479, Val Loss: 1.0957\n",
      "Epoch [6776/10000], Train Loss: 0.1474, Val Loss: 1.0488\n",
      "Epoch [6777/10000], Train Loss: 0.1468, Val Loss: 1.0854\n",
      "Epoch [6778/10000], Train Loss: 0.1460, Val Loss: 1.0553\n",
      "Epoch [6779/10000], Train Loss: 0.1453, Val Loss: 1.0789\n",
      "Epoch [6780/10000], Train Loss: 0.1448, Val Loss: 1.0636\n",
      "Epoch [6781/10000], Train Loss: 0.1444, Val Loss: 1.0659\n",
      "Epoch [6782/10000], Train Loss: 0.1442, Val Loss: 1.0649\n",
      "Epoch [6783/10000], Train Loss: 0.1440, Val Loss: 1.0599\n",
      "Epoch [6784/10000], Train Loss: 0.1438, Val Loss: 1.0741\n",
      "Epoch [6785/10000], Train Loss: 0.1437, Val Loss: 1.0525\n",
      "Epoch [6786/10000], Train Loss: 0.1435, Val Loss: 1.0737\n",
      "Epoch [6787/10000], Train Loss: 0.1434, Val Loss: 1.0466\n",
      "Epoch [6788/10000], Train Loss: 0.1431, Val Loss: 1.0741\n",
      "Epoch [6789/10000], Train Loss: 0.1428, Val Loss: 1.0508\n",
      "Epoch [6790/10000], Train Loss: 0.1425, Val Loss: 1.0680\n",
      "Epoch [6791/10000], Train Loss: 0.1422, Val Loss: 1.0513\n",
      "Epoch [6792/10000], Train Loss: 0.1419, Val Loss: 1.0619\n",
      "Epoch [6793/10000], Train Loss: 0.1416, Val Loss: 1.0579\n",
      "Epoch [6794/10000], Train Loss: 0.1413, Val Loss: 1.0584\n",
      "Epoch [6795/10000], Train Loss: 0.1411, Val Loss: 1.0604\n",
      "Epoch [6796/10000], Train Loss: 0.1409, Val Loss: 1.0525\n",
      "Epoch [6797/10000], Train Loss: 0.1407, Val Loss: 1.0637\n",
      "Epoch [6798/10000], Train Loss: 0.1405, Val Loss: 1.0525\n",
      "Epoch [6799/10000], Train Loss: 0.1403, Val Loss: 1.0643\n",
      "Epoch [6800/10000], Train Loss: 0.1400, Val Loss: 1.0508\n",
      "Epoch [6801/10000], Train Loss: 0.1398, Val Loss: 1.0621\n",
      "Epoch [6802/10000], Train Loss: 0.1396, Val Loss: 1.0517\n",
      "Epoch [6803/10000], Train Loss: 0.1394, Val Loss: 1.0624\n",
      "Epoch [6804/10000], Train Loss: 0.1391, Val Loss: 1.0509\n",
      "Epoch [6805/10000], Train Loss: 0.1389, Val Loss: 1.0592\n",
      "Epoch [6806/10000], Train Loss: 0.1386, Val Loss: 1.0508\n",
      "Epoch [6807/10000], Train Loss: 0.1384, Val Loss: 1.0610\n",
      "Epoch [6808/10000], Train Loss: 0.1383, Val Loss: 1.0491\n",
      "Epoch [6809/10000], Train Loss: 0.1380, Val Loss: 1.0569\n",
      "Epoch [6810/10000], Train Loss: 0.1378, Val Loss: 1.0424\n",
      "Epoch [6811/10000], Train Loss: 0.1376, Val Loss: 1.0595\n",
      "Epoch [6812/10000], Train Loss: 0.1374, Val Loss: 1.0442\n",
      "Epoch [6813/10000], Train Loss: 0.1372, Val Loss: 1.0562\n",
      "Epoch [6814/10000], Train Loss: 0.1369, Val Loss: 1.0422\n",
      "Epoch [6815/10000], Train Loss: 0.1367, Val Loss: 1.0515\n",
      "Epoch [6816/10000], Train Loss: 0.1365, Val Loss: 1.0451\n",
      "Epoch [6817/10000], Train Loss: 0.1363, Val Loss: 1.0532\n",
      "Epoch [6818/10000], Train Loss: 0.1360, Val Loss: 1.0426\n",
      "Epoch [6819/10000], Train Loss: 0.1358, Val Loss: 1.0502\n",
      "Epoch [6820/10000], Train Loss: 0.1356, Val Loss: 1.0429\n",
      "Epoch [6821/10000], Train Loss: 0.1353, Val Loss: 1.0517\n",
      "Epoch [6822/10000], Train Loss: 0.1351, Val Loss: 1.0440\n",
      "Epoch [6823/10000], Train Loss: 0.1349, Val Loss: 1.0494\n",
      "Epoch [6824/10000], Train Loss: 0.1347, Val Loss: 1.0423\n",
      "Epoch [6825/10000], Train Loss: 0.1345, Val Loss: 1.0510\n",
      "Epoch [6826/10000], Train Loss: 0.1342, Val Loss: 1.0431\n",
      "Epoch [6827/10000], Train Loss: 0.1340, Val Loss: 1.0504\n",
      "Epoch [6828/10000], Train Loss: 0.1338, Val Loss: 1.0419\n",
      "Epoch [6829/10000], Train Loss: 0.1336, Val Loss: 1.0485\n",
      "Epoch [6830/10000], Train Loss: 0.1334, Val Loss: 1.0434\n",
      "Epoch [6831/10000], Train Loss: 0.1332, Val Loss: 1.0487\n",
      "Epoch [6832/10000], Train Loss: 0.1330, Val Loss: 1.0413\n",
      "Epoch [6833/10000], Train Loss: 0.1327, Val Loss: 1.0501\n",
      "Epoch [6834/10000], Train Loss: 0.1326, Val Loss: 1.0376\n",
      "Epoch [6835/10000], Train Loss: 0.1324, Val Loss: 1.0500\n",
      "Epoch [6836/10000], Train Loss: 0.1323, Val Loss: 1.0301\n",
      "Epoch [6837/10000], Train Loss: 0.1322, Val Loss: 1.0544\n",
      "Epoch [6838/10000], Train Loss: 0.1321, Val Loss: 1.0265\n",
      "Epoch [6839/10000], Train Loss: 0.1320, Val Loss: 1.0569\n",
      "Epoch [6840/10000], Train Loss: 0.1320, Val Loss: 1.0204\n",
      "Epoch [6841/10000], Train Loss: 0.1320, Val Loss: 1.0594\n",
      "Epoch [6842/10000], Train Loss: 0.1321, Val Loss: 1.0162\n",
      "Epoch [6843/10000], Train Loss: 0.1323, Val Loss: 1.0675\n",
      "Epoch [6844/10000], Train Loss: 0.1326, Val Loss: 1.0084\n",
      "Epoch [6845/10000], Train Loss: 0.1331, Val Loss: 1.0756\n",
      "Epoch [6846/10000], Train Loss: 0.1338, Val Loss: 1.0011\n",
      "Epoch [6847/10000], Train Loss: 0.1347, Val Loss: 1.0886\n",
      "Epoch [6848/10000], Train Loss: 0.1358, Val Loss: 0.9916\n",
      "Epoch [6849/10000], Train Loss: 0.1376, Val Loss: 1.1089\n",
      "Epoch [6850/10000], Train Loss: 0.1399, Val Loss: 0.9773\n",
      "Epoch [6851/10000], Train Loss: 0.1437, Val Loss: 1.1357\n",
      "Epoch [6852/10000], Train Loss: 0.1471, Val Loss: 0.9644\n",
      "Epoch [6853/10000], Train Loss: 0.1516, Val Loss: 1.1547\n",
      "Epoch [6854/10000], Train Loss: 0.1528, Val Loss: 0.9627\n",
      "Epoch [6855/10000], Train Loss: 0.1526, Val Loss: 1.1325\n",
      "Epoch [6856/10000], Train Loss: 0.1465, Val Loss: 0.9829\n",
      "Epoch [6857/10000], Train Loss: 0.1389, Val Loss: 1.0675\n",
      "Epoch [6858/10000], Train Loss: 0.1312, Val Loss: 1.0319\n",
      "Epoch [6859/10000], Train Loss: 0.1276, Val Loss: 1.0047\n",
      "Epoch [6860/10000], Train Loss: 0.1290, Val Loss: 1.0825\n",
      "Epoch [6861/10000], Train Loss: 0.1328, Val Loss: 0.9864\n",
      "Epoch [6862/10000], Train Loss: 0.1354, Val Loss: 1.0860\n",
      "Epoch [6863/10000], Train Loss: 0.1347, Val Loss: 0.9969\n",
      "Epoch [6864/10000], Train Loss: 0.1319, Val Loss: 1.0526\n",
      "Epoch [6865/10000], Train Loss: 0.1283, Val Loss: 1.0292\n",
      "Epoch [6866/10000], Train Loss: 0.1263, Val Loss: 1.0120\n",
      "Epoch [6867/10000], Train Loss: 0.1266, Val Loss: 1.0623\n",
      "Epoch [6868/10000], Train Loss: 0.1282, Val Loss: 0.9992\n",
      "Epoch [6869/10000], Train Loss: 0.1294, Val Loss: 1.0632\n",
      "Epoch [6870/10000], Train Loss: 0.1289, Val Loss: 1.0117\n",
      "Epoch [6871/10000], Train Loss: 0.1271, Val Loss: 1.0364\n",
      "Epoch [6872/10000], Train Loss: 0.1254, Val Loss: 1.0351\n",
      "Epoch [6873/10000], Train Loss: 0.1247, Val Loss: 1.0146\n",
      "Epoch [6874/10000], Train Loss: 0.1251, Val Loss: 1.0499\n",
      "Epoch [6875/10000], Train Loss: 0.1259, Val Loss: 1.0102\n",
      "Epoch [6876/10000], Train Loss: 0.1261, Val Loss: 1.0489\n",
      "Epoch [6877/10000], Train Loss: 0.1255, Val Loss: 1.0145\n",
      "Epoch [6878/10000], Train Loss: 0.1244, Val Loss: 1.0319\n",
      "Epoch [6879/10000], Train Loss: 0.1235, Val Loss: 1.0262\n",
      "Epoch [6880/10000], Train Loss: 0.1233, Val Loss: 1.0168\n",
      "Epoch [6881/10000], Train Loss: 0.1236, Val Loss: 1.0404\n",
      "Epoch [6882/10000], Train Loss: 0.1238, Val Loss: 1.0080\n",
      "Epoch [6883/10000], Train Loss: 0.1237, Val Loss: 1.0380\n",
      "Epoch [6884/10000], Train Loss: 0.1231, Val Loss: 1.0121\n",
      "Epoch [6885/10000], Train Loss: 0.1225, Val Loss: 1.0262\n",
      "Epoch [6886/10000], Train Loss: 0.1221, Val Loss: 1.0261\n",
      "Epoch [6887/10000], Train Loss: 0.1220, Val Loss: 1.0124\n",
      "Epoch [6888/10000], Train Loss: 0.1220, Val Loss: 1.0332\n",
      "Epoch [6889/10000], Train Loss: 0.1220, Val Loss: 1.0095\n",
      "Epoch [6890/10000], Train Loss: 0.1218, Val Loss: 1.0322\n",
      "Epoch [6891/10000], Train Loss: 0.1214, Val Loss: 1.0145\n",
      "Epoch [6892/10000], Train Loss: 0.1210, Val Loss: 1.0223\n",
      "Epoch [6893/10000], Train Loss: 0.1207, Val Loss: 1.0235\n",
      "Epoch [6894/10000], Train Loss: 0.1206, Val Loss: 1.0137\n",
      "Epoch [6895/10000], Train Loss: 0.1205, Val Loss: 1.0307\n",
      "Epoch [6896/10000], Train Loss: 0.1204, Val Loss: 1.0105\n",
      "Epoch [6897/10000], Train Loss: 0.1202, Val Loss: 1.0278\n",
      "Epoch [6898/10000], Train Loss: 0.1199, Val Loss: 1.0153\n",
      "Epoch [6899/10000], Train Loss: 0.1196, Val Loss: 1.0202\n",
      "Epoch [6900/10000], Train Loss: 0.1194, Val Loss: 1.0228\n",
      "Epoch [6901/10000], Train Loss: 0.1192, Val Loss: 1.0128\n",
      "Epoch [6902/10000], Train Loss: 0.1191, Val Loss: 1.0255\n",
      "Epoch [6903/10000], Train Loss: 0.1190, Val Loss: 1.0123\n",
      "Epoch [6904/10000], Train Loss: 0.1188, Val Loss: 1.0232\n",
      "Epoch [6905/10000], Train Loss: 0.1186, Val Loss: 1.0151\n",
      "Epoch [6906/10000], Train Loss: 0.1183, Val Loss: 1.0177\n",
      "Epoch [6907/10000], Train Loss: 0.1181, Val Loss: 1.0187\n",
      "Epoch [6908/10000], Train Loss: 0.1179, Val Loss: 1.0139\n",
      "Epoch [6909/10000], Train Loss: 0.1178, Val Loss: 1.0209\n",
      "Epoch [6910/10000], Train Loss: 0.1176, Val Loss: 1.0119\n",
      "Epoch [6911/10000], Train Loss: 0.1174, Val Loss: 1.0196\n",
      "Epoch [6912/10000], Train Loss: 0.1172, Val Loss: 1.0134\n",
      "Epoch [6913/10000], Train Loss: 0.1170, Val Loss: 1.0167\n",
      "Epoch [6914/10000], Train Loss: 0.1168, Val Loss: 1.0155\n",
      "Epoch [6915/10000], Train Loss: 0.1166, Val Loss: 1.0133\n",
      "Epoch [6916/10000], Train Loss: 0.1165, Val Loss: 1.0167\n",
      "Epoch [6917/10000], Train Loss: 0.1163, Val Loss: 1.0121\n",
      "Epoch [6918/10000], Train Loss: 0.1161, Val Loss: 1.0165\n",
      "Epoch [6919/10000], Train Loss: 0.1159, Val Loss: 1.0117\n",
      "Epoch [6920/10000], Train Loss: 0.1157, Val Loss: 1.0150\n",
      "Epoch [6921/10000], Train Loss: 0.1156, Val Loss: 1.0123\n",
      "Epoch [6922/10000], Train Loss: 0.1154, Val Loss: 1.0135\n",
      "Epoch [6923/10000], Train Loss: 0.1152, Val Loss: 1.0134\n",
      "Epoch [6924/10000], Train Loss: 0.1150, Val Loss: 1.0114\n",
      "Epoch [6925/10000], Train Loss: 0.1148, Val Loss: 1.0141\n",
      "Epoch [6926/10000], Train Loss: 0.1147, Val Loss: 1.0104\n",
      "Epoch [6927/10000], Train Loss: 0.1145, Val Loss: 1.0139\n",
      "Epoch [6928/10000], Train Loss: 0.1143, Val Loss: 1.0104\n",
      "Epoch [6929/10000], Train Loss: 0.1141, Val Loss: 1.0125\n",
      "Epoch [6930/10000], Train Loss: 0.1139, Val Loss: 1.0110\n",
      "Epoch [6931/10000], Train Loss: 0.1138, Val Loss: 1.0111\n",
      "Epoch [6932/10000], Train Loss: 0.1136, Val Loss: 1.0117\n",
      "Epoch [6933/10000], Train Loss: 0.1134, Val Loss: 1.0097\n",
      "Epoch [6934/10000], Train Loss: 0.1132, Val Loss: 1.0118\n",
      "Epoch [6935/10000], Train Loss: 0.1130, Val Loss: 1.0090\n",
      "Epoch [6936/10000], Train Loss: 0.1129, Val Loss: 1.0114\n",
      "Epoch [6937/10000], Train Loss: 0.1127, Val Loss: 1.0089\n",
      "Epoch [6938/10000], Train Loss: 0.1125, Val Loss: 1.0101\n",
      "Epoch [6939/10000], Train Loss: 0.1123, Val Loss: 1.0093\n",
      "Epoch [6940/10000], Train Loss: 0.1122, Val Loss: 1.0089\n",
      "Epoch [6941/10000], Train Loss: 0.1120, Val Loss: 1.0095\n",
      "Epoch [6942/10000], Train Loss: 0.1118, Val Loss: 1.0079\n",
      "Epoch [6943/10000], Train Loss: 0.1116, Val Loss: 1.0092\n",
      "Epoch [6944/10000], Train Loss: 0.1115, Val Loss: 1.0074\n",
      "Epoch [6945/10000], Train Loss: 0.1113, Val Loss: 1.0087\n",
      "Epoch [6946/10000], Train Loss: 0.1111, Val Loss: 1.0072\n",
      "Epoch [6947/10000], Train Loss: 0.1109, Val Loss: 1.0079\n",
      "Epoch [6948/10000], Train Loss: 0.1108, Val Loss: 1.0071\n",
      "Epoch [6949/10000], Train Loss: 0.1106, Val Loss: 1.0071\n",
      "Epoch [6950/10000], Train Loss: 0.1104, Val Loss: 1.0070\n",
      "Epoch [6951/10000], Train Loss: 0.1102, Val Loss: 1.0063\n",
      "Epoch [6952/10000], Train Loss: 0.1101, Val Loss: 1.0067\n",
      "Epoch [6953/10000], Train Loss: 0.1099, Val Loss: 1.0057\n",
      "Epoch [6954/10000], Train Loss: 0.1097, Val Loss: 1.0063\n",
      "Epoch [6955/10000], Train Loss: 0.1096, Val Loss: 1.0053\n",
      "Epoch [6956/10000], Train Loss: 0.1094, Val Loss: 1.0057\n",
      "Epoch [6957/10000], Train Loss: 0.1092, Val Loss: 1.0049\n",
      "Epoch [6958/10000], Train Loss: 0.1090, Val Loss: 1.0052\n",
      "Epoch [6959/10000], Train Loss: 0.1089, Val Loss: 1.0046\n",
      "Epoch [6960/10000], Train Loss: 0.1087, Val Loss: 1.0046\n",
      "Epoch [6961/10000], Train Loss: 0.1085, Val Loss: 1.0043\n",
      "Epoch [6962/10000], Train Loss: 0.1084, Val Loss: 1.0040\n",
      "Epoch [6963/10000], Train Loss: 0.1082, Val Loss: 1.0041\n",
      "Epoch [6964/10000], Train Loss: 0.1080, Val Loss: 1.0034\n",
      "Epoch [6965/10000], Train Loss: 0.1078, Val Loss: 1.0037\n",
      "Epoch [6966/10000], Train Loss: 0.1077, Val Loss: 1.0029\n",
      "Epoch [6967/10000], Train Loss: 0.1075, Val Loss: 1.0033\n",
      "Epoch [6968/10000], Train Loss: 0.1073, Val Loss: 1.0025\n",
      "Epoch [6969/10000], Train Loss: 0.1072, Val Loss: 1.0028\n",
      "Epoch [6970/10000], Train Loss: 0.1070, Val Loss: 1.0022\n",
      "Epoch [6971/10000], Train Loss: 0.1068, Val Loss: 1.0023\n",
      "Epoch [6972/10000], Train Loss: 0.1067, Val Loss: 1.0019\n",
      "Epoch [6973/10000], Train Loss: 0.1065, Val Loss: 1.0017\n",
      "Epoch [6974/10000], Train Loss: 0.1063, Val Loss: 1.0015\n",
      "Epoch [6975/10000], Train Loss: 0.1062, Val Loss: 1.0012\n",
      "Epoch [6976/10000], Train Loss: 0.1060, Val Loss: 1.0012\n",
      "Epoch [6977/10000], Train Loss: 0.1058, Val Loss: 1.0007\n",
      "Epoch [6978/10000], Train Loss: 0.1057, Val Loss: 1.0007\n",
      "Epoch [6979/10000], Train Loss: 0.1055, Val Loss: 1.0003\n",
      "Epoch [6980/10000], Train Loss: 0.1053, Val Loss: 1.0004\n",
      "Epoch [6981/10000], Train Loss: 0.1052, Val Loss: 0.9999\n",
      "Epoch [6982/10000], Train Loss: 0.1050, Val Loss: 1.0000\n",
      "Epoch [6983/10000], Train Loss: 0.1048, Val Loss: 0.9995\n",
      "Epoch [6984/10000], Train Loss: 0.1047, Val Loss: 0.9995\n",
      "Epoch [6985/10000], Train Loss: 0.1045, Val Loss: 0.9991\n",
      "Epoch [6986/10000], Train Loss: 0.1043, Val Loss: 0.9991\n",
      "Epoch [6987/10000], Train Loss: 0.1042, Val Loss: 0.9987\n",
      "Epoch [6988/10000], Train Loss: 0.1040, Val Loss: 0.9987\n",
      "Epoch [6989/10000], Train Loss: 0.1039, Val Loss: 0.9983\n",
      "Epoch [6990/10000], Train Loss: 0.1037, Val Loss: 0.9984\n",
      "Epoch [6991/10000], Train Loss: 0.1035, Val Loss: 0.9979\n",
      "Epoch [6992/10000], Train Loss: 0.1034, Val Loss: 0.9979\n",
      "Epoch [6993/10000], Train Loss: 0.1032, Val Loss: 0.9976\n",
      "Epoch [6994/10000], Train Loss: 0.1030, Val Loss: 0.9975\n",
      "Epoch [6995/10000], Train Loss: 0.1029, Val Loss: 0.9972\n",
      "Epoch [6996/10000], Train Loss: 0.1027, Val Loss: 0.9972\n",
      "Epoch [6997/10000], Train Loss: 0.1026, Val Loss: 0.9969\n",
      "Epoch [6998/10000], Train Loss: 0.1024, Val Loss: 0.9968\n",
      "Epoch [6999/10000], Train Loss: 0.1022, Val Loss: 0.9965\n",
      "Epoch [7000/10000], Train Loss: 0.1021, Val Loss: 0.9964\n",
      "Epoch [7001/10000], Train Loss: 0.1019, Val Loss: 0.9961\n",
      "Epoch [7002/10000], Train Loss: 0.1017, Val Loss: 0.9960\n",
      "Epoch [7003/10000], Train Loss: 0.1016, Val Loss: 0.9957\n",
      "Epoch [7004/10000], Train Loss: 0.1014, Val Loss: 0.9957\n",
      "Epoch [7005/10000], Train Loss: 0.1013, Val Loss: 0.9953\n",
      "Epoch [7006/10000], Train Loss: 0.1011, Val Loss: 0.9954\n",
      "Epoch [7007/10000], Train Loss: 0.1009, Val Loss: 0.9950\n",
      "Epoch [7008/10000], Train Loss: 0.1008, Val Loss: 0.9949\n",
      "Epoch [7009/10000], Train Loss: 0.1006, Val Loss: 0.9943\n",
      "Epoch [7010/10000], Train Loss: 0.1005, Val Loss: 0.9941\n",
      "Epoch [7011/10000], Train Loss: 0.1003, Val Loss: 0.9933\n",
      "Epoch [7012/10000], Train Loss: 0.1001, Val Loss: 0.9932\n",
      "Epoch [7013/10000], Train Loss: 0.1000, Val Loss: 0.9924\n",
      "Epoch [7014/10000], Train Loss: 0.0998, Val Loss: 0.9924\n",
      "Epoch [7015/10000], Train Loss: 0.0997, Val Loss: 0.9916\n",
      "Epoch [7016/10000], Train Loss: 0.0995, Val Loss: 0.9915\n",
      "Epoch [7017/10000], Train Loss: 0.0994, Val Loss: 0.9906\n",
      "Epoch [7018/10000], Train Loss: 0.0992, Val Loss: 0.9907\n",
      "Epoch [7019/10000], Train Loss: 0.0990, Val Loss: 0.9896\n",
      "Epoch [7020/10000], Train Loss: 0.0989, Val Loss: 0.9900\n",
      "Epoch [7021/10000], Train Loss: 0.0987, Val Loss: 0.9886\n",
      "Epoch [7022/10000], Train Loss: 0.0986, Val Loss: 0.9892\n",
      "Epoch [7023/10000], Train Loss: 0.0984, Val Loss: 0.9876\n",
      "Epoch [7024/10000], Train Loss: 0.0983, Val Loss: 0.9885\n",
      "Epoch [7025/10000], Train Loss: 0.0981, Val Loss: 0.9865\n",
      "Epoch [7026/10000], Train Loss: 0.0979, Val Loss: 0.9880\n",
      "Epoch [7027/10000], Train Loss: 0.0978, Val Loss: 0.9853\n",
      "Epoch [7028/10000], Train Loss: 0.0976, Val Loss: 0.9876\n",
      "Epoch [7029/10000], Train Loss: 0.0975, Val Loss: 0.9839\n",
      "Epoch [7030/10000], Train Loss: 0.0973, Val Loss: 0.9875\n",
      "Epoch [7031/10000], Train Loss: 0.0972, Val Loss: 0.9822\n",
      "Epoch [7032/10000], Train Loss: 0.0970, Val Loss: 0.9877\n",
      "Epoch [7033/10000], Train Loss: 0.0969, Val Loss: 0.9801\n",
      "Epoch [7034/10000], Train Loss: 0.0968, Val Loss: 0.9885\n",
      "Epoch [7035/10000], Train Loss: 0.0966, Val Loss: 0.9772\n",
      "Epoch [7036/10000], Train Loss: 0.0965, Val Loss: 0.9904\n",
      "Epoch [7037/10000], Train Loss: 0.0964, Val Loss: 0.9731\n",
      "Epoch [7038/10000], Train Loss: 0.0964, Val Loss: 0.9941\n",
      "Epoch [7039/10000], Train Loss: 0.0964, Val Loss: 0.9674\n",
      "Epoch [7040/10000], Train Loss: 0.0965, Val Loss: 1.0007\n",
      "Epoch [7041/10000], Train Loss: 0.0967, Val Loss: 0.9589\n",
      "Epoch [7042/10000], Train Loss: 0.0972, Val Loss: 1.0133\n",
      "Epoch [7043/10000], Train Loss: 0.0983, Val Loss: 0.9429\n",
      "Epoch [7044/10000], Train Loss: 0.1005, Val Loss: 1.0422\n",
      "Epoch [7045/10000], Train Loss: 0.1042, Val Loss: 0.9166\n",
      "Epoch [7046/10000], Train Loss: 0.1121, Val Loss: 1.1053\n",
      "Epoch [7047/10000], Train Loss: 0.1237, Val Loss: 0.8915\n",
      "Epoch [7048/10000], Train Loss: 0.1447, Val Loss: 1.1998\n",
      "Epoch [7049/10000], Train Loss: 0.1649, Val Loss: 0.8886\n",
      "Epoch [7050/10000], Train Loss: 0.1837, Val Loss: 1.2000\n",
      "Epoch [7051/10000], Train Loss: 0.1687, Val Loss: 0.9077\n",
      "Epoch [7052/10000], Train Loss: 0.1347, Val Loss: 1.0162\n",
      "Epoch [7053/10000], Train Loss: 0.0997, Val Loss: 1.0222\n",
      "Epoch [7054/10000], Train Loss: 0.0976, Val Loss: 0.9095\n",
      "Epoch [7055/10000], Train Loss: 0.1209, Val Loss: 1.1204\n",
      "Epoch [7056/10000], Train Loss: 0.1334, Val Loss: 0.9159\n",
      "Epoch [7057/10000], Train Loss: 0.1231, Val Loss: 1.0198\n",
      "Epoch [7058/10000], Train Loss: 0.0993, Val Loss: 1.0043\n",
      "Epoch [7059/10000], Train Loss: 0.0950, Val Loss: 0.9189\n",
      "Epoch [7060/10000], Train Loss: 0.1109, Val Loss: 1.0747\n",
      "Epoch [7061/10000], Train Loss: 0.1177, Val Loss: 0.9216\n",
      "Epoch [7062/10000], Train Loss: 0.1076, Val Loss: 0.9925\n",
      "Epoch [7063/10000], Train Loss: 0.0938, Val Loss: 1.0002\n",
      "Epoch [7064/10000], Train Loss: 0.0957, Val Loss: 0.9209\n",
      "Epoch [7065/10000], Train Loss: 0.1058, Val Loss: 1.0427\n",
      "Epoch [7066/10000], Train Loss: 0.1056, Val Loss: 0.9303\n",
      "Epoch [7067/10000], Train Loss: 0.0968, Val Loss: 0.9704\n",
      "Epoch [7068/10000], Train Loss: 0.0917, Val Loss: 1.0069\n",
      "Epoch [7069/10000], Train Loss: 0.0961, Val Loss: 0.9214\n",
      "Epoch [7070/10000], Train Loss: 0.1004, Val Loss: 1.0132\n",
      "Epoch [7071/10000], Train Loss: 0.0968, Val Loss: 0.9547\n",
      "Epoch [7072/10000], Train Loss: 0.0916, Val Loss: 0.9467\n",
      "Epoch [7073/10000], Train Loss: 0.0922, Val Loss: 1.0085\n",
      "Epoch [7074/10000], Train Loss: 0.0959, Val Loss: 0.9288\n",
      "Epoch [7075/10000], Train Loss: 0.0960, Val Loss: 0.9898\n",
      "Epoch [7076/10000], Train Loss: 0.0922, Val Loss: 0.9685\n",
      "Epoch [7077/10000], Train Loss: 0.0904, Val Loss: 0.9386\n",
      "Epoch [7078/10000], Train Loss: 0.0924, Val Loss: 1.0007\n",
      "Epoch [7079/10000], Train Loss: 0.0938, Val Loss: 0.9391\n",
      "Epoch [7080/10000], Train Loss: 0.0923, Val Loss: 0.9709\n",
      "Epoch [7081/10000], Train Loss: 0.0901, Val Loss: 0.9763\n",
      "Epoch [7082/10000], Train Loss: 0.0901, Val Loss: 0.9403\n",
      "Epoch [7083/10000], Train Loss: 0.0915, Val Loss: 0.9876\n",
      "Epoch [7084/10000], Train Loss: 0.0914, Val Loss: 0.9500\n",
      "Epoch [7085/10000], Train Loss: 0.0899, Val Loss: 0.9619\n",
      "Epoch [7086/10000], Train Loss: 0.0891, Val Loss: 0.9765\n",
      "Epoch [7087/10000], Train Loss: 0.0896, Val Loss: 0.9438\n",
      "Epoch [7088/10000], Train Loss: 0.0902, Val Loss: 0.9794\n",
      "Epoch [7089/10000], Train Loss: 0.0896, Val Loss: 0.9555\n",
      "Epoch [7090/10000], Train Loss: 0.0886, Val Loss: 0.9539\n",
      "Epoch [7091/10000], Train Loss: 0.0885, Val Loss: 0.9748\n",
      "Epoch [7092/10000], Train Loss: 0.0889, Val Loss: 0.9455\n",
      "Epoch [7093/10000], Train Loss: 0.0889, Val Loss: 0.9687\n",
      "Epoch [7094/10000], Train Loss: 0.0882, Val Loss: 0.9585\n",
      "Epoch [7095/10000], Train Loss: 0.0877, Val Loss: 0.9497\n",
      "Epoch [7096/10000], Train Loss: 0.0879, Val Loss: 0.9706\n",
      "Epoch [7097/10000], Train Loss: 0.0880, Val Loss: 0.9467\n",
      "Epoch [7098/10000], Train Loss: 0.0877, Val Loss: 0.9617\n",
      "Epoch [7099/10000], Train Loss: 0.0872, Val Loss: 0.9603\n",
      "Epoch [7100/10000], Train Loss: 0.0871, Val Loss: 0.9465\n",
      "Epoch [7101/10000], Train Loss: 0.0872, Val Loss: 0.9668\n",
      "Epoch [7102/10000], Train Loss: 0.0871, Val Loss: 0.9496\n",
      "Epoch [7103/10000], Train Loss: 0.0868, Val Loss: 0.9551\n",
      "Epoch [7104/10000], Train Loss: 0.0865, Val Loss: 0.9605\n",
      "Epoch [7105/10000], Train Loss: 0.0864, Val Loss: 0.9467\n",
      "Epoch [7106/10000], Train Loss: 0.0864, Val Loss: 0.9615\n",
      "Epoch [7107/10000], Train Loss: 0.0862, Val Loss: 0.9511\n",
      "Epoch [7108/10000], Train Loss: 0.0860, Val Loss: 0.9515\n",
      "Epoch [7109/10000], Train Loss: 0.0858, Val Loss: 0.9588\n",
      "Epoch [7110/10000], Train Loss: 0.0857, Val Loss: 0.9466\n",
      "Epoch [7111/10000], Train Loss: 0.0856, Val Loss: 0.9570\n",
      "Epoch [7112/10000], Train Loss: 0.0854, Val Loss: 0.9516\n",
      "Epoch [7113/10000], Train Loss: 0.0852, Val Loss: 0.9489\n",
      "Epoch [7114/10000], Train Loss: 0.0851, Val Loss: 0.9560\n",
      "Epoch [7115/10000], Train Loss: 0.0850, Val Loss: 0.9470\n",
      "Epoch [7116/10000], Train Loss: 0.0849, Val Loss: 0.9532\n",
      "Epoch [7117/10000], Train Loss: 0.0847, Val Loss: 0.9504\n",
      "Epoch [7118/10000], Train Loss: 0.0845, Val Loss: 0.9476\n",
      "Epoch [7119/10000], Train Loss: 0.0844, Val Loss: 0.9534\n",
      "Epoch [7120/10000], Train Loss: 0.0843, Val Loss: 0.9461\n",
      "Epoch [7121/10000], Train Loss: 0.0842, Val Loss: 0.9505\n",
      "Epoch [7122/10000], Train Loss: 0.0840, Val Loss: 0.9491\n",
      "Epoch [7123/10000], Train Loss: 0.0839, Val Loss: 0.9459\n",
      "Epoch [7124/10000], Train Loss: 0.0837, Val Loss: 0.9508\n",
      "Epoch [7125/10000], Train Loss: 0.0836, Val Loss: 0.9452\n",
      "Epoch [7126/10000], Train Loss: 0.0835, Val Loss: 0.9480\n",
      "Epoch [7127/10000], Train Loss: 0.0833, Val Loss: 0.9473\n",
      "Epoch [7128/10000], Train Loss: 0.0832, Val Loss: 0.9445\n",
      "Epoch [7129/10000], Train Loss: 0.0831, Val Loss: 0.9484\n",
      "Epoch [7130/10000], Train Loss: 0.0829, Val Loss: 0.9438\n",
      "Epoch [7131/10000], Train Loss: 0.0828, Val Loss: 0.9458\n",
      "Epoch [7132/10000], Train Loss: 0.0826, Val Loss: 0.9459\n",
      "Epoch [7133/10000], Train Loss: 0.0825, Val Loss: 0.9429\n",
      "Epoch [7134/10000], Train Loss: 0.0824, Val Loss: 0.9461\n",
      "Epoch [7135/10000], Train Loss: 0.0823, Val Loss: 0.9428\n",
      "Epoch [7136/10000], Train Loss: 0.0821, Val Loss: 0.9439\n",
      "Epoch [7137/10000], Train Loss: 0.0820, Val Loss: 0.9441\n",
      "Epoch [7138/10000], Train Loss: 0.0818, Val Loss: 0.9417\n",
      "Epoch [7139/10000], Train Loss: 0.0817, Val Loss: 0.9441\n",
      "Epoch [7140/10000], Train Loss: 0.0816, Val Loss: 0.9415\n",
      "Epoch [7141/10000], Train Loss: 0.0814, Val Loss: 0.9422\n",
      "Epoch [7142/10000], Train Loss: 0.0813, Val Loss: 0.9424\n",
      "Epoch [7143/10000], Train Loss: 0.0812, Val Loss: 0.9404\n",
      "Epoch [7144/10000], Train Loss: 0.0810, Val Loss: 0.9421\n",
      "Epoch [7145/10000], Train Loss: 0.0809, Val Loss: 0.9401\n",
      "Epoch [7146/10000], Train Loss: 0.0808, Val Loss: 0.9406\n",
      "Epoch [7147/10000], Train Loss: 0.0806, Val Loss: 0.9405\n",
      "Epoch [7148/10000], Train Loss: 0.0805, Val Loss: 0.9391\n",
      "Epoch [7149/10000], Train Loss: 0.0804, Val Loss: 0.9403\n",
      "Epoch [7150/10000], Train Loss: 0.0803, Val Loss: 0.9386\n",
      "Epoch [7151/10000], Train Loss: 0.0801, Val Loss: 0.9390\n",
      "Epoch [7152/10000], Train Loss: 0.0800, Val Loss: 0.9388\n",
      "Epoch [7153/10000], Train Loss: 0.0799, Val Loss: 0.9376\n",
      "Epoch [7154/10000], Train Loss: 0.0797, Val Loss: 0.9386\n",
      "Epoch [7155/10000], Train Loss: 0.0796, Val Loss: 0.9371\n",
      "Epoch [7156/10000], Train Loss: 0.0795, Val Loss: 0.9374\n",
      "Epoch [7157/10000], Train Loss: 0.0793, Val Loss: 0.9371\n",
      "Epoch [7158/10000], Train Loss: 0.0792, Val Loss: 0.9361\n",
      "Epoch [7159/10000], Train Loss: 0.0791, Val Loss: 0.9368\n",
      "Epoch [7160/10000], Train Loss: 0.0789, Val Loss: 0.9355\n",
      "Epoch [7161/10000], Train Loss: 0.0788, Val Loss: 0.9358\n",
      "Epoch [7162/10000], Train Loss: 0.0787, Val Loss: 0.9354\n",
      "Epoch [7163/10000], Train Loss: 0.0785, Val Loss: 0.9346\n",
      "Epoch [7164/10000], Train Loss: 0.0784, Val Loss: 0.9350\n",
      "Epoch [7165/10000], Train Loss: 0.0783, Val Loss: 0.9339\n",
      "Epoch [7166/10000], Train Loss: 0.0782, Val Loss: 0.9342\n",
      "Epoch [7167/10000], Train Loss: 0.0780, Val Loss: 0.9337\n",
      "Epoch [7168/10000], Train Loss: 0.0779, Val Loss: 0.9331\n",
      "Epoch [7169/10000], Train Loss: 0.0778, Val Loss: 0.9333\n",
      "Epoch [7170/10000], Train Loss: 0.0776, Val Loss: 0.9324\n",
      "Epoch [7171/10000], Train Loss: 0.0775, Val Loss: 0.9326\n",
      "Epoch [7172/10000], Train Loss: 0.0774, Val Loss: 0.9320\n",
      "Epoch [7173/10000], Train Loss: 0.0773, Val Loss: 0.9316\n",
      "Epoch [7174/10000], Train Loss: 0.0771, Val Loss: 0.9316\n",
      "Epoch [7175/10000], Train Loss: 0.0770, Val Loss: 0.9308\n",
      "Epoch [7176/10000], Train Loss: 0.0769, Val Loss: 0.9309\n",
      "Epoch [7177/10000], Train Loss: 0.0767, Val Loss: 0.9304\n",
      "Epoch [7178/10000], Train Loss: 0.0766, Val Loss: 0.9301\n",
      "Epoch [7179/10000], Train Loss: 0.0765, Val Loss: 0.9299\n",
      "Epoch [7180/10000], Train Loss: 0.0764, Val Loss: 0.9293\n",
      "Epoch [7181/10000], Train Loss: 0.0762, Val Loss: 0.9293\n",
      "Epoch [7182/10000], Train Loss: 0.0761, Val Loss: 0.9287\n",
      "Epoch [7183/10000], Train Loss: 0.0760, Val Loss: 0.9285\n",
      "Epoch [7184/10000], Train Loss: 0.0759, Val Loss: 0.9282\n",
      "Epoch [7185/10000], Train Loss: 0.0757, Val Loss: 0.9278\n",
      "Epoch [7186/10000], Train Loss: 0.0756, Val Loss: 0.9276\n",
      "Epoch [7187/10000], Train Loss: 0.0755, Val Loss: 0.9271\n",
      "Epoch [7188/10000], Train Loss: 0.0754, Val Loss: 0.9269\n",
      "Epoch [7189/10000], Train Loss: 0.0752, Val Loss: 0.9266\n",
      "Epoch [7190/10000], Train Loss: 0.0751, Val Loss: 0.9262\n",
      "Epoch [7191/10000], Train Loss: 0.0750, Val Loss: 0.9260\n",
      "Epoch [7192/10000], Train Loss: 0.0749, Val Loss: 0.9255\n",
      "Epoch [7193/10000], Train Loss: 0.0747, Val Loss: 0.9254\n",
      "Epoch [7194/10000], Train Loss: 0.0746, Val Loss: 0.9250\n",
      "Epoch [7195/10000], Train Loss: 0.0745, Val Loss: 0.9247\n",
      "Epoch [7196/10000], Train Loss: 0.0744, Val Loss: 0.9244\n",
      "Epoch [7197/10000], Train Loss: 0.0742, Val Loss: 0.9240\n",
      "Epoch [7198/10000], Train Loss: 0.0741, Val Loss: 0.9238\n",
      "Epoch [7199/10000], Train Loss: 0.0740, Val Loss: 0.9234\n",
      "Epoch [7200/10000], Train Loss: 0.0739, Val Loss: 0.9231\n",
      "Epoch [7201/10000], Train Loss: 0.0737, Val Loss: 0.9228\n",
      "Epoch [7202/10000], Train Loss: 0.0736, Val Loss: 0.9224\n",
      "Epoch [7203/10000], Train Loss: 0.0735, Val Loss: 0.9222\n",
      "Epoch [7204/10000], Train Loss: 0.0734, Val Loss: 0.9218\n",
      "Epoch [7205/10000], Train Loss: 0.0732, Val Loss: 0.9216\n",
      "Epoch [7206/10000], Train Loss: 0.0731, Val Loss: 0.9212\n",
      "Epoch [7207/10000], Train Loss: 0.0730, Val Loss: 0.9209\n",
      "Epoch [7208/10000], Train Loss: 0.0729, Val Loss: 0.9206\n",
      "Epoch [7209/10000], Train Loss: 0.0727, Val Loss: 0.9202\n",
      "Epoch [7210/10000], Train Loss: 0.0726, Val Loss: 0.9200\n",
      "Epoch [7211/10000], Train Loss: 0.0725, Val Loss: 0.9196\n",
      "Epoch [7212/10000], Train Loss: 0.0724, Val Loss: 0.9193\n",
      "Epoch [7213/10000], Train Loss: 0.0723, Val Loss: 0.9191\n",
      "Epoch [7214/10000], Train Loss: 0.0721, Val Loss: 0.9187\n",
      "Epoch [7215/10000], Train Loss: 0.0720, Val Loss: 0.9185\n",
      "Epoch [7216/10000], Train Loss: 0.0719, Val Loss: 0.9181\n",
      "Epoch [7217/10000], Train Loss: 0.0718, Val Loss: 0.9178\n",
      "Epoch [7218/10000], Train Loss: 0.0716, Val Loss: 0.9175\n",
      "Epoch [7219/10000], Train Loss: 0.0715, Val Loss: 0.9172\n",
      "Epoch [7220/10000], Train Loss: 0.0714, Val Loss: 0.9169\n",
      "Epoch [7221/10000], Train Loss: 0.0713, Val Loss: 0.9166\n",
      "Epoch [7222/10000], Train Loss: 0.0712, Val Loss: 0.9163\n",
      "Epoch [7223/10000], Train Loss: 0.0710, Val Loss: 0.9159\n",
      "Epoch [7224/10000], Train Loss: 0.0709, Val Loss: 0.9157\n",
      "Epoch [7225/10000], Train Loss: 0.0708, Val Loss: 0.9153\n",
      "Epoch [7226/10000], Train Loss: 0.0707, Val Loss: 0.9151\n",
      "Epoch [7227/10000], Train Loss: 0.0706, Val Loss: 0.9148\n",
      "Epoch [7228/10000], Train Loss: 0.0704, Val Loss: 0.9144\n",
      "Epoch [7229/10000], Train Loss: 0.0703, Val Loss: 0.9142\n",
      "Epoch [7230/10000], Train Loss: 0.0702, Val Loss: 0.9138\n",
      "Epoch [7231/10000], Train Loss: 0.0701, Val Loss: 0.9135\n",
      "Epoch [7232/10000], Train Loss: 0.0700, Val Loss: 0.9133\n",
      "Epoch [7233/10000], Train Loss: 0.0698, Val Loss: 0.9129\n",
      "Epoch [7234/10000], Train Loss: 0.0697, Val Loss: 0.9126\n",
      "Epoch [7235/10000], Train Loss: 0.0696, Val Loss: 0.9124\n",
      "Epoch [7236/10000], Train Loss: 0.0695, Val Loss: 0.9120\n",
      "Epoch [7237/10000], Train Loss: 0.0694, Val Loss: 0.9117\n",
      "Epoch [7238/10000], Train Loss: 0.0693, Val Loss: 0.9115\n",
      "Epoch [7239/10000], Train Loss: 0.0691, Val Loss: 0.9111\n",
      "Epoch [7240/10000], Train Loss: 0.0690, Val Loss: 0.9109\n",
      "Epoch [7241/10000], Train Loss: 0.0689, Val Loss: 0.9105\n",
      "Epoch [7242/10000], Train Loss: 0.0688, Val Loss: 0.9102\n",
      "Epoch [7243/10000], Train Loss: 0.0687, Val Loss: 0.9100\n",
      "Epoch [7244/10000], Train Loss: 0.0685, Val Loss: 0.9097\n",
      "Epoch [7245/10000], Train Loss: 0.0684, Val Loss: 0.9094\n",
      "Epoch [7246/10000], Train Loss: 0.0683, Val Loss: 0.9090\n",
      "Epoch [7247/10000], Train Loss: 0.0682, Val Loss: 0.9088\n",
      "Epoch [7248/10000], Train Loss: 0.0681, Val Loss: 0.9085\n",
      "Epoch [7249/10000], Train Loss: 0.0680, Val Loss: 0.9082\n",
      "Epoch [7250/10000], Train Loss: 0.0678, Val Loss: 0.9079\n",
      "Epoch [7251/10000], Train Loss: 0.0677, Val Loss: 0.9076\n",
      "Epoch [7252/10000], Train Loss: 0.0676, Val Loss: 0.9073\n",
      "Epoch [7253/10000], Train Loss: 0.0675, Val Loss: 0.9070\n",
      "Epoch [7254/10000], Train Loss: 0.0674, Val Loss: 0.9067\n",
      "Epoch [7255/10000], Train Loss: 0.0673, Val Loss: 0.9064\n",
      "Epoch [7256/10000], Train Loss: 0.0671, Val Loss: 0.9061\n",
      "Epoch [7257/10000], Train Loss: 0.0670, Val Loss: 0.9058\n",
      "Epoch [7258/10000], Train Loss: 0.0669, Val Loss: 0.9056\n",
      "Epoch [7259/10000], Train Loss: 0.0668, Val Loss: 0.9052\n",
      "Epoch [7260/10000], Train Loss: 0.0667, Val Loss: 0.9050\n",
      "Epoch [7261/10000], Train Loss: 0.0666, Val Loss: 0.9046\n",
      "Epoch [7262/10000], Train Loss: 0.0665, Val Loss: 0.9044\n",
      "Epoch [7263/10000], Train Loss: 0.0663, Val Loss: 0.9041\n",
      "Epoch [7264/10000], Train Loss: 0.0662, Val Loss: 0.9038\n",
      "Epoch [7265/10000], Train Loss: 0.0661, Val Loss: 0.9035\n",
      "Epoch [7266/10000], Train Loss: 0.0660, Val Loss: 0.9032\n",
      "Epoch [7267/10000], Train Loss: 0.0659, Val Loss: 0.9030\n",
      "Epoch [7268/10000], Train Loss: 0.0658, Val Loss: 0.9027\n",
      "Epoch [7269/10000], Train Loss: 0.0657, Val Loss: 0.9024\n",
      "Epoch [7270/10000], Train Loss: 0.0655, Val Loss: 0.9021\n",
      "Epoch [7271/10000], Train Loss: 0.0654, Val Loss: 0.9018\n",
      "Epoch [7272/10000], Train Loss: 0.0653, Val Loss: 0.9015\n",
      "Epoch [7273/10000], Train Loss: 0.0652, Val Loss: 0.9012\n",
      "Epoch [7274/10000], Train Loss: 0.0651, Val Loss: 0.9010\n",
      "Epoch [7275/10000], Train Loss: 0.0650, Val Loss: 0.9007\n",
      "Epoch [7276/10000], Train Loss: 0.0649, Val Loss: 0.9004\n",
      "Epoch [7277/10000], Train Loss: 0.0647, Val Loss: 0.9001\n",
      "Epoch [7278/10000], Train Loss: 0.0646, Val Loss: 0.8998\n",
      "Epoch [7279/10000], Train Loss: 0.0645, Val Loss: 0.8995\n",
      "Epoch [7280/10000], Train Loss: 0.0644, Val Loss: 0.8993\n",
      "Epoch [7281/10000], Train Loss: 0.0643, Val Loss: 0.8990\n",
      "Epoch [7282/10000], Train Loss: 0.0642, Val Loss: 0.8987\n",
      "Epoch [7283/10000], Train Loss: 0.0641, Val Loss: 0.8984\n",
      "Epoch [7284/10000], Train Loss: 0.0640, Val Loss: 0.8982\n",
      "Epoch [7285/10000], Train Loss: 0.0638, Val Loss: 0.8978\n",
      "Epoch [7286/10000], Train Loss: 0.0637, Val Loss: 0.8976\n",
      "Epoch [7287/10000], Train Loss: 0.0636, Val Loss: 0.8973\n",
      "Epoch [7288/10000], Train Loss: 0.0635, Val Loss: 0.8970\n",
      "Epoch [7289/10000], Train Loss: 0.0634, Val Loss: 0.8967\n",
      "Epoch [7290/10000], Train Loss: 0.0633, Val Loss: 0.8965\n",
      "Epoch [7291/10000], Train Loss: 0.0632, Val Loss: 0.8962\n",
      "Epoch [7292/10000], Train Loss: 0.0631, Val Loss: 0.8959\n",
      "Epoch [7293/10000], Train Loss: 0.0630, Val Loss: 0.8956\n",
      "Epoch [7294/10000], Train Loss: 0.0628, Val Loss: 0.8954\n",
      "Epoch [7295/10000], Train Loss: 0.0627, Val Loss: 0.8951\n",
      "Epoch [7296/10000], Train Loss: 0.0626, Val Loss: 0.8948\n",
      "Epoch [7297/10000], Train Loss: 0.0625, Val Loss: 0.8945\n",
      "Epoch [7298/10000], Train Loss: 0.0624, Val Loss: 0.8942\n",
      "Epoch [7299/10000], Train Loss: 0.0623, Val Loss: 0.8940\n",
      "Epoch [7300/10000], Train Loss: 0.0622, Val Loss: 0.8937\n",
      "Epoch [7301/10000], Train Loss: 0.0621, Val Loss: 0.8934\n",
      "Epoch [7302/10000], Train Loss: 0.0620, Val Loss: 0.8932\n",
      "Epoch [7303/10000], Train Loss: 0.0619, Val Loss: 0.8929\n",
      "Epoch [7304/10000], Train Loss: 0.0617, Val Loss: 0.8926\n",
      "Epoch [7305/10000], Train Loss: 0.0616, Val Loss: 0.8924\n",
      "Epoch [7306/10000], Train Loss: 0.0615, Val Loss: 0.8920\n",
      "Epoch [7307/10000], Train Loss: 0.0614, Val Loss: 0.8918\n",
      "Epoch [7308/10000], Train Loss: 0.0613, Val Loss: 0.8914\n",
      "Epoch [7309/10000], Train Loss: 0.0612, Val Loss: 0.8913\n",
      "Epoch [7310/10000], Train Loss: 0.0611, Val Loss: 0.8909\n",
      "Epoch [7311/10000], Train Loss: 0.0610, Val Loss: 0.8907\n",
      "Epoch [7312/10000], Train Loss: 0.0609, Val Loss: 0.8904\n",
      "Epoch [7313/10000], Train Loss: 0.0608, Val Loss: 0.8902\n",
      "Epoch [7314/10000], Train Loss: 0.0607, Val Loss: 0.8899\n",
      "Epoch [7315/10000], Train Loss: 0.0606, Val Loss: 0.8896\n",
      "Epoch [7316/10000], Train Loss: 0.0604, Val Loss: 0.8894\n",
      "Epoch [7317/10000], Train Loss: 0.0603, Val Loss: 0.8891\n",
      "Epoch [7318/10000], Train Loss: 0.0602, Val Loss: 0.8888\n",
      "Epoch [7319/10000], Train Loss: 0.0601, Val Loss: 0.8885\n",
      "Epoch [7320/10000], Train Loss: 0.0600, Val Loss: 0.8883\n",
      "Epoch [7321/10000], Train Loss: 0.0599, Val Loss: 0.8880\n",
      "Epoch [7322/10000], Train Loss: 0.0598, Val Loss: 0.8878\n",
      "Epoch [7323/10000], Train Loss: 0.0597, Val Loss: 0.8875\n",
      "Epoch [7324/10000], Train Loss: 0.0596, Val Loss: 0.8873\n",
      "Epoch [7325/10000], Train Loss: 0.0595, Val Loss: 0.8869\n",
      "Epoch [7326/10000], Train Loss: 0.0594, Val Loss: 0.8867\n",
      "Epoch [7327/10000], Train Loss: 0.0593, Val Loss: 0.8864\n",
      "Epoch [7328/10000], Train Loss: 0.0592, Val Loss: 0.8862\n",
      "Epoch [7329/10000], Train Loss: 0.0591, Val Loss: 0.8859\n",
      "Epoch [7330/10000], Train Loss: 0.0590, Val Loss: 0.8856\n",
      "Epoch [7331/10000], Train Loss: 0.0588, Val Loss: 0.8854\n",
      "Epoch [7332/10000], Train Loss: 0.0587, Val Loss: 0.8851\n",
      "Epoch [7333/10000], Train Loss: 0.0586, Val Loss: 0.8848\n",
      "Epoch [7334/10000], Train Loss: 0.0585, Val Loss: 0.8846\n",
      "Epoch [7335/10000], Train Loss: 0.0584, Val Loss: 0.8843\n",
      "Epoch [7336/10000], Train Loss: 0.0583, Val Loss: 0.8840\n",
      "Epoch [7337/10000], Train Loss: 0.0582, Val Loss: 0.8838\n",
      "Epoch [7338/10000], Train Loss: 0.0581, Val Loss: 0.8835\n",
      "Epoch [7339/10000], Train Loss: 0.0580, Val Loss: 0.8833\n",
      "Epoch [7340/10000], Train Loss: 0.0579, Val Loss: 0.8830\n",
      "Epoch [7341/10000], Train Loss: 0.0578, Val Loss: 0.8828\n",
      "Epoch [7342/10000], Train Loss: 0.0577, Val Loss: 0.8825\n",
      "Epoch [7343/10000], Train Loss: 0.0576, Val Loss: 0.8823\n",
      "Epoch [7344/10000], Train Loss: 0.0575, Val Loss: 0.8819\n",
      "Epoch [7345/10000], Train Loss: 0.0574, Val Loss: 0.8818\n",
      "Epoch [7346/10000], Train Loss: 0.0573, Val Loss: 0.8814\n",
      "Epoch [7347/10000], Train Loss: 0.0572, Val Loss: 0.8813\n",
      "Epoch [7348/10000], Train Loss: 0.0571, Val Loss: 0.8809\n",
      "Epoch [7349/10000], Train Loss: 0.0570, Val Loss: 0.8808\n",
      "Epoch [7350/10000], Train Loss: 0.0569, Val Loss: 0.8804\n",
      "Epoch [7351/10000], Train Loss: 0.0568, Val Loss: 0.8803\n",
      "Epoch [7352/10000], Train Loss: 0.0567, Val Loss: 0.8798\n",
      "Epoch [7353/10000], Train Loss: 0.0566, Val Loss: 0.8798\n",
      "Epoch [7354/10000], Train Loss: 0.0565, Val Loss: 0.8793\n",
      "Epoch [7355/10000], Train Loss: 0.0564, Val Loss: 0.8793\n",
      "Epoch [7356/10000], Train Loss: 0.0563, Val Loss: 0.8788\n",
      "Epoch [7357/10000], Train Loss: 0.0562, Val Loss: 0.8788\n",
      "Epoch [7358/10000], Train Loss: 0.0560, Val Loss: 0.8783\n",
      "Epoch [7359/10000], Train Loss: 0.0559, Val Loss: 0.8783\n",
      "Epoch [7360/10000], Train Loss: 0.0558, Val Loss: 0.8777\n",
      "Epoch [7361/10000], Train Loss: 0.0557, Val Loss: 0.8778\n",
      "Epoch [7362/10000], Train Loss: 0.0556, Val Loss: 0.8772\n",
      "Epoch [7363/10000], Train Loss: 0.0555, Val Loss: 0.8773\n",
      "Epoch [7364/10000], Train Loss: 0.0554, Val Loss: 0.8767\n",
      "Epoch [7365/10000], Train Loss: 0.0553, Val Loss: 0.8769\n",
      "Epoch [7366/10000], Train Loss: 0.0552, Val Loss: 0.8761\n",
      "Epoch [7367/10000], Train Loss: 0.0551, Val Loss: 0.8765\n",
      "Epoch [7368/10000], Train Loss: 0.0550, Val Loss: 0.8754\n",
      "Epoch [7369/10000], Train Loss: 0.0549, Val Loss: 0.8762\n",
      "Epoch [7370/10000], Train Loss: 0.0548, Val Loss: 0.8748\n",
      "Epoch [7371/10000], Train Loss: 0.0547, Val Loss: 0.8759\n",
      "Epoch [7372/10000], Train Loss: 0.0546, Val Loss: 0.8740\n",
      "Epoch [7373/10000], Train Loss: 0.0545, Val Loss: 0.8757\n",
      "Epoch [7374/10000], Train Loss: 0.0544, Val Loss: 0.8732\n",
      "Epoch [7375/10000], Train Loss: 0.0543, Val Loss: 0.8756\n",
      "Epoch [7376/10000], Train Loss: 0.0542, Val Loss: 0.8721\n",
      "Epoch [7377/10000], Train Loss: 0.0541, Val Loss: 0.8758\n",
      "Epoch [7378/10000], Train Loss: 0.0541, Val Loss: 0.8707\n",
      "Epoch [7379/10000], Train Loss: 0.0540, Val Loss: 0.8764\n",
      "Epoch [7380/10000], Train Loss: 0.0539, Val Loss: 0.8686\n",
      "Epoch [7381/10000], Train Loss: 0.0538, Val Loss: 0.8783\n",
      "Epoch [7382/10000], Train Loss: 0.0537, Val Loss: 0.8649\n",
      "Epoch [7383/10000], Train Loss: 0.0537, Val Loss: 0.8823\n",
      "Epoch [7384/10000], Train Loss: 0.0537, Val Loss: 0.8584\n",
      "Epoch [7385/10000], Train Loss: 0.0539, Val Loss: 0.8909\n",
      "Epoch [7386/10000], Train Loss: 0.0542, Val Loss: 0.8469\n",
      "Epoch [7387/10000], Train Loss: 0.0551, Val Loss: 0.9091\n",
      "Epoch [7388/10000], Train Loss: 0.0565, Val Loss: 0.8277\n",
      "Epoch [7389/10000], Train Loss: 0.0598, Val Loss: 0.9482\n",
      "Epoch [7390/10000], Train Loss: 0.0654, Val Loss: 0.8005\n",
      "Epoch [7391/10000], Train Loss: 0.0770, Val Loss: 1.0277\n",
      "Epoch [7392/10000], Train Loss: 0.0939, Val Loss: 0.7808\n",
      "Epoch [7393/10000], Train Loss: 0.1232, Val Loss: 1.1431\n",
      "Epoch [7394/10000], Train Loss: 0.1496, Val Loss: 0.7856\n",
      "Epoch [7395/10000], Train Loss: 0.1708, Val Loss: 1.1311\n",
      "Epoch [7396/10000], Train Loss: 0.1459, Val Loss: 0.7986\n",
      "Epoch [7397/10000], Train Loss: 0.0984, Val Loss: 0.9107\n",
      "Epoch [7398/10000], Train Loss: 0.0566, Val Loss: 0.9362\n",
      "Epoch [7399/10000], Train Loss: 0.0603, Val Loss: 0.7973\n",
      "Epoch [7400/10000], Train Loss: 0.0930, Val Loss: 1.0476\n",
      "Epoch [7401/10000], Train Loss: 0.1054, Val Loss: 0.7977\n",
      "Epoch [7402/10000], Train Loss: 0.0872, Val Loss: 0.9165\n",
      "Epoch [7403/10000], Train Loss: 0.0570, Val Loss: 0.9096\n",
      "Epoch [7404/10000], Train Loss: 0.0555, Val Loss: 0.8021\n",
      "Epoch [7405/10000], Train Loss: 0.0761, Val Loss: 0.9914\n",
      "Epoch [7406/10000], Train Loss: 0.0820, Val Loss: 0.8113\n",
      "Epoch [7407/10000], Train Loss: 0.0679, Val Loss: 0.8860\n",
      "Epoch [7408/10000], Train Loss: 0.0523, Val Loss: 0.9137\n",
      "Epoch [7409/10000], Train Loss: 0.0568, Val Loss: 0.8077\n",
      "Epoch [7410/10000], Train Loss: 0.0695, Val Loss: 0.9500\n",
      "Epoch [7411/10000], Train Loss: 0.0672, Val Loss: 0.8287\n",
      "Epoch [7412/10000], Train Loss: 0.0561, Val Loss: 0.8611\n",
      "Epoch [7413/10000], Train Loss: 0.0511, Val Loss: 0.9174\n",
      "Epoch [7414/10000], Train Loss: 0.0576, Val Loss: 0.8079\n",
      "Epoch [7415/10000], Train Loss: 0.0636, Val Loss: 0.9222\n",
      "Epoch [7416/10000], Train Loss: 0.0584, Val Loss: 0.8474\n",
      "Epoch [7417/10000], Train Loss: 0.0515, Val Loss: 0.8424\n",
      "Epoch [7418/10000], Train Loss: 0.0516, Val Loss: 0.9142\n",
      "Epoch [7419/10000], Train Loss: 0.0562, Val Loss: 0.8186\n",
      "Epoch [7420/10000], Train Loss: 0.0575, Val Loss: 0.8955\n",
      "Epoch [7421/10000], Train Loss: 0.0530, Val Loss: 0.8665\n",
      "Epoch [7422/10000], Train Loss: 0.0500, Val Loss: 0.8339\n",
      "Epoch [7423/10000], Train Loss: 0.0522, Val Loss: 0.9096\n",
      "Epoch [7424/10000], Train Loss: 0.0545, Val Loss: 0.8320\n",
      "Epoch [7425/10000], Train Loss: 0.0535, Val Loss: 0.8772\n",
      "Epoch [7426/10000], Train Loss: 0.0503, Val Loss: 0.8801\n",
      "Epoch [7427/10000], Train Loss: 0.0499, Val Loss: 0.8343\n",
      "Epoch [7428/10000], Train Loss: 0.0517, Val Loss: 0.8987\n",
      "Epoch [7429/10000], Train Loss: 0.0522, Val Loss: 0.8475\n",
      "Epoch [7430/10000], Train Loss: 0.0507, Val Loss: 0.8635\n",
      "Epoch [7431/10000], Train Loss: 0.0493, Val Loss: 0.8835\n",
      "Epoch [7432/10000], Train Loss: 0.0496, Val Loss: 0.8398\n",
      "Epoch [7433/10000], Train Loss: 0.0507, Val Loss: 0.8862\n",
      "Epoch [7434/10000], Train Loss: 0.0504, Val Loss: 0.8560\n",
      "Epoch [7435/10000], Train Loss: 0.0493, Val Loss: 0.8575\n",
      "Epoch [7436/10000], Train Loss: 0.0487, Val Loss: 0.8802\n",
      "Epoch [7437/10000], Train Loss: 0.0491, Val Loss: 0.8453\n",
      "Epoch [7438/10000], Train Loss: 0.0496, Val Loss: 0.8765\n",
      "Epoch [7439/10000], Train Loss: 0.0492, Val Loss: 0.8603\n",
      "Epoch [7440/10000], Train Loss: 0.0485, Val Loss: 0.8555\n",
      "Epoch [7441/10000], Train Loss: 0.0483, Val Loss: 0.8757\n",
      "Epoch [7442/10000], Train Loss: 0.0485, Val Loss: 0.8499\n",
      "Epoch [7443/10000], Train Loss: 0.0486, Val Loss: 0.8701\n",
      "Epoch [7444/10000], Train Loss: 0.0483, Val Loss: 0.8617\n",
      "Epoch [7445/10000], Train Loss: 0.0479, Val Loss: 0.8550\n",
      "Epoch [7446/10000], Train Loss: 0.0478, Val Loss: 0.8718\n",
      "Epoch [7447/10000], Train Loss: 0.0479, Val Loss: 0.8521\n",
      "Epoch [7448/10000], Train Loss: 0.0479, Val Loss: 0.8659\n",
      "Epoch [7449/10000], Train Loss: 0.0476, Val Loss: 0.8623\n",
      "Epoch [7450/10000], Train Loss: 0.0474, Val Loss: 0.8540\n",
      "Epoch [7451/10000], Train Loss: 0.0474, Val Loss: 0.8687\n",
      "Epoch [7452/10000], Train Loss: 0.0474, Val Loss: 0.8540\n",
      "Epoch [7453/10000], Train Loss: 0.0473, Val Loss: 0.8620\n",
      "Epoch [7454/10000], Train Loss: 0.0471, Val Loss: 0.8624\n",
      "Epoch [7455/10000], Train Loss: 0.0469, Val Loss: 0.8537\n",
      "Epoch [7456/10000], Train Loss: 0.0469, Val Loss: 0.8659\n",
      "Epoch [7457/10000], Train Loss: 0.0469, Val Loss: 0.8549\n",
      "Epoch [7458/10000], Train Loss: 0.0467, Val Loss: 0.8592\n",
      "Epoch [7459/10000], Train Loss: 0.0466, Val Loss: 0.8621\n",
      "Epoch [7460/10000], Train Loss: 0.0465, Val Loss: 0.8532\n",
      "Epoch [7461/10000], Train Loss: 0.0464, Val Loss: 0.8629\n",
      "Epoch [7462/10000], Train Loss: 0.0464, Val Loss: 0.8557\n",
      "Epoch [7463/10000], Train Loss: 0.0462, Val Loss: 0.8568\n",
      "Epoch [7464/10000], Train Loss: 0.0461, Val Loss: 0.8605\n",
      "Epoch [7465/10000], Train Loss: 0.0460, Val Loss: 0.8530\n",
      "Epoch [7466/10000], Train Loss: 0.0460, Val Loss: 0.8599\n",
      "Epoch [7467/10000], Train Loss: 0.0459, Val Loss: 0.8552\n",
      "Epoch [7468/10000], Train Loss: 0.0458, Val Loss: 0.8549\n",
      "Epoch [7469/10000], Train Loss: 0.0457, Val Loss: 0.8586\n",
      "Epoch [7470/10000], Train Loss: 0.0456, Val Loss: 0.8524\n",
      "Epoch [7471/10000], Train Loss: 0.0455, Val Loss: 0.8573\n",
      "Epoch [7472/10000], Train Loss: 0.0454, Val Loss: 0.8546\n",
      "Epoch [7473/10000], Train Loss: 0.0453, Val Loss: 0.8534\n",
      "Epoch [7474/10000], Train Loss: 0.0453, Val Loss: 0.8565\n",
      "Epoch [7475/10000], Train Loss: 0.0452, Val Loss: 0.8520\n",
      "Epoch [7476/10000], Train Loss: 0.0451, Val Loss: 0.8552\n",
      "Epoch [7477/10000], Train Loss: 0.0450, Val Loss: 0.8535\n",
      "Epoch [7478/10000], Train Loss: 0.0449, Val Loss: 0.8524\n",
      "Epoch [7479/10000], Train Loss: 0.0448, Val Loss: 0.8548\n",
      "Epoch [7480/10000], Train Loss: 0.0447, Val Loss: 0.8513\n",
      "Epoch [7481/10000], Train Loss: 0.0447, Val Loss: 0.8536\n",
      "Epoch [7482/10000], Train Loss: 0.0446, Val Loss: 0.8524\n",
      "Epoch [7483/10000], Train Loss: 0.0445, Val Loss: 0.8515\n",
      "Epoch [7484/10000], Train Loss: 0.0444, Val Loss: 0.8531\n",
      "Epoch [7485/10000], Train Loss: 0.0443, Val Loss: 0.8507\n",
      "Epoch [7486/10000], Train Loss: 0.0442, Val Loss: 0.8523\n",
      "Epoch [7487/10000], Train Loss: 0.0441, Val Loss: 0.8512\n",
      "Epoch [7488/10000], Train Loss: 0.0441, Val Loss: 0.8507\n",
      "Epoch [7489/10000], Train Loss: 0.0440, Val Loss: 0.8518\n",
      "Epoch [7490/10000], Train Loss: 0.0439, Val Loss: 0.8499\n",
      "Epoch [7491/10000], Train Loss: 0.0438, Val Loss: 0.8512\n",
      "Epoch [7492/10000], Train Loss: 0.0437, Val Loss: 0.8502\n",
      "Epoch [7493/10000], Train Loss: 0.0436, Val Loss: 0.8498\n",
      "Epoch [7494/10000], Train Loss: 0.0436, Val Loss: 0.8506\n",
      "Epoch [7495/10000], Train Loss: 0.0435, Val Loss: 0.8491\n",
      "Epoch [7496/10000], Train Loss: 0.0434, Val Loss: 0.8501\n",
      "Epoch [7497/10000], Train Loss: 0.0433, Val Loss: 0.8492\n",
      "Epoch [7498/10000], Train Loss: 0.0432, Val Loss: 0.8489\n",
      "Epoch [7499/10000], Train Loss: 0.0431, Val Loss: 0.8495\n",
      "Epoch [7500/10000], Train Loss: 0.0431, Val Loss: 0.8482\n",
      "Epoch [7501/10000], Train Loss: 0.0430, Val Loss: 0.8490\n",
      "Epoch [7502/10000], Train Loss: 0.0429, Val Loss: 0.8482\n",
      "Epoch [7503/10000], Train Loss: 0.0428, Val Loss: 0.8480\n",
      "Epoch [7504/10000], Train Loss: 0.0427, Val Loss: 0.8484\n",
      "Epoch [7505/10000], Train Loss: 0.0426, Val Loss: 0.8473\n",
      "Epoch [7506/10000], Train Loss: 0.0426, Val Loss: 0.8479\n",
      "Epoch [7507/10000], Train Loss: 0.0425, Val Loss: 0.8472\n",
      "Epoch [7508/10000], Train Loss: 0.0424, Val Loss: 0.8471\n",
      "Epoch [7509/10000], Train Loss: 0.0423, Val Loss: 0.8473\n",
      "Epoch [7510/10000], Train Loss: 0.0422, Val Loss: 0.8465\n",
      "Epoch [7511/10000], Train Loss: 0.0422, Val Loss: 0.8469\n",
      "Epoch [7512/10000], Train Loss: 0.0421, Val Loss: 0.8463\n",
      "Epoch [7513/10000], Train Loss: 0.0420, Val Loss: 0.8462\n",
      "Epoch [7514/10000], Train Loss: 0.0419, Val Loss: 0.8462\n",
      "Epoch [7515/10000], Train Loss: 0.0418, Val Loss: 0.8457\n",
      "Epoch [7516/10000], Train Loss: 0.0417, Val Loss: 0.8459\n",
      "Epoch [7517/10000], Train Loss: 0.0417, Val Loss: 0.8454\n",
      "Epoch [7518/10000], Train Loss: 0.0416, Val Loss: 0.8454\n",
      "Epoch [7519/10000], Train Loss: 0.0415, Val Loss: 0.8452\n",
      "Epoch [7520/10000], Train Loss: 0.0414, Val Loss: 0.8448\n",
      "Epoch [7521/10000], Train Loss: 0.0413, Val Loss: 0.8449\n",
      "Epoch [7522/10000], Train Loss: 0.0413, Val Loss: 0.8445\n",
      "Epoch [7523/10000], Train Loss: 0.0412, Val Loss: 0.8444\n",
      "Epoch [7524/10000], Train Loss: 0.0411, Val Loss: 0.8442\n",
      "Epoch [7525/10000], Train Loss: 0.0410, Val Loss: 0.8440\n",
      "Epoch [7526/10000], Train Loss: 0.0409, Val Loss: 0.8439\n",
      "Epoch [7527/10000], Train Loss: 0.0409, Val Loss: 0.8436\n",
      "Epoch [7528/10000], Train Loss: 0.0408, Val Loss: 0.8435\n",
      "Epoch [7529/10000], Train Loss: 0.0407, Val Loss: 0.8433\n",
      "Epoch [7530/10000], Train Loss: 0.0406, Val Loss: 0.8431\n",
      "Epoch [7531/10000], Train Loss: 0.0405, Val Loss: 0.8430\n",
      "Epoch [7532/10000], Train Loss: 0.0405, Val Loss: 0.8427\n",
      "Epoch [7533/10000], Train Loss: 0.0404, Val Loss: 0.8426\n",
      "Epoch [7534/10000], Train Loss: 0.0403, Val Loss: 0.8423\n",
      "Epoch [7535/10000], Train Loss: 0.0402, Val Loss: 0.8422\n",
      "Epoch [7536/10000], Train Loss: 0.0402, Val Loss: 0.8420\n",
      "Epoch [7537/10000], Train Loss: 0.0401, Val Loss: 0.8418\n",
      "Epoch [7538/10000], Train Loss: 0.0400, Val Loss: 0.8416\n",
      "Epoch [7539/10000], Train Loss: 0.0399, Val Loss: 0.8414\n",
      "Epoch [7540/10000], Train Loss: 0.0398, Val Loss: 0.8412\n",
      "Epoch [7541/10000], Train Loss: 0.0398, Val Loss: 0.8411\n",
      "Epoch [7542/10000], Train Loss: 0.0397, Val Loss: 0.8408\n",
      "Epoch [7543/10000], Train Loss: 0.0396, Val Loss: 0.8407\n",
      "Epoch [7544/10000], Train Loss: 0.0395, Val Loss: 0.8405\n",
      "Epoch [7545/10000], Train Loss: 0.0394, Val Loss: 0.8402\n",
      "Epoch [7546/10000], Train Loss: 0.0394, Val Loss: 0.8403\n",
      "Epoch [7547/10000], Train Loss: 0.0393, Val Loss: 0.8396\n",
      "Epoch [7548/10000], Train Loss: 0.0392, Val Loss: 0.8400\n",
      "Epoch [7549/10000], Train Loss: 0.0391, Val Loss: 0.8392\n",
      "Epoch [7550/10000], Train Loss: 0.0391, Val Loss: 0.8397\n",
      "Epoch [7551/10000], Train Loss: 0.0390, Val Loss: 0.8388\n",
      "Epoch [7552/10000], Train Loss: 0.0389, Val Loss: 0.8393\n",
      "Epoch [7553/10000], Train Loss: 0.0388, Val Loss: 0.8387\n",
      "Epoch [7554/10000], Train Loss: 0.0388, Val Loss: 0.8386\n",
      "Epoch [7555/10000], Train Loss: 0.0387, Val Loss: 0.8386\n",
      "Epoch [7556/10000], Train Loss: 0.0386, Val Loss: 0.8381\n",
      "Epoch [7557/10000], Train Loss: 0.0385, Val Loss: 0.8383\n",
      "Epoch [7558/10000], Train Loss: 0.0384, Val Loss: 0.8377\n",
      "Epoch [7559/10000], Train Loss: 0.0384, Val Loss: 0.8379\n",
      "Epoch [7560/10000], Train Loss: 0.0383, Val Loss: 0.8376\n",
      "Epoch [7561/10000], Train Loss: 0.0382, Val Loss: 0.8373\n",
      "Epoch [7562/10000], Train Loss: 0.0381, Val Loss: 0.8374\n",
      "Epoch [7563/10000], Train Loss: 0.0381, Val Loss: 0.8368\n",
      "Epoch [7564/10000], Train Loss: 0.0380, Val Loss: 0.8372\n",
      "Epoch [7565/10000], Train Loss: 0.0379, Val Loss: 0.8362\n",
      "Epoch [7566/10000], Train Loss: 0.0378, Val Loss: 0.8370\n",
      "Epoch [7567/10000], Train Loss: 0.0378, Val Loss: 0.8358\n",
      "Epoch [7568/10000], Train Loss: 0.0377, Val Loss: 0.8366\n",
      "Epoch [7569/10000], Train Loss: 0.0376, Val Loss: 0.8355\n",
      "Epoch [7570/10000], Train Loss: 0.0375, Val Loss: 0.8361\n",
      "Epoch [7571/10000], Train Loss: 0.0375, Val Loss: 0.8353\n",
      "Epoch [7572/10000], Train Loss: 0.0374, Val Loss: 0.8357\n",
      "Epoch [7573/10000], Train Loss: 0.0373, Val Loss: 0.8350\n",
      "Epoch [7574/10000], Train Loss: 0.0372, Val Loss: 0.8353\n",
      "Epoch [7575/10000], Train Loss: 0.0372, Val Loss: 0.8348\n",
      "Epoch [7576/10000], Train Loss: 0.0371, Val Loss: 0.8347\n",
      "Epoch [7577/10000], Train Loss: 0.0370, Val Loss: 0.8347\n",
      "Epoch [7578/10000], Train Loss: 0.0369, Val Loss: 0.8343\n",
      "Epoch [7579/10000], Train Loss: 0.0369, Val Loss: 0.8344\n",
      "Epoch [7580/10000], Train Loss: 0.0368, Val Loss: 0.8337\n",
      "Epoch [7581/10000], Train Loss: 0.0367, Val Loss: 0.8343\n",
      "Epoch [7582/10000], Train Loss: 0.0366, Val Loss: 0.8332\n",
      "Epoch [7583/10000], Train Loss: 0.0366, Val Loss: 0.8340\n",
      "Epoch [7584/10000], Train Loss: 0.0365, Val Loss: 0.8328\n",
      "Epoch [7585/10000], Train Loss: 0.0364, Val Loss: 0.8338\n",
      "Epoch [7586/10000], Train Loss: 0.0364, Val Loss: 0.8323\n",
      "Epoch [7587/10000], Train Loss: 0.0363, Val Loss: 0.8334\n",
      "Epoch [7588/10000], Train Loss: 0.0362, Val Loss: 0.8321\n",
      "Epoch [7589/10000], Train Loss: 0.0361, Val Loss: 0.8329\n",
      "Epoch [7590/10000], Train Loss: 0.0361, Val Loss: 0.8319\n",
      "Epoch [7591/10000], Train Loss: 0.0360, Val Loss: 0.8326\n",
      "Epoch [7592/10000], Train Loss: 0.0359, Val Loss: 0.8315\n",
      "Epoch [7593/10000], Train Loss: 0.0358, Val Loss: 0.8322\n",
      "Epoch [7594/10000], Train Loss: 0.0358, Val Loss: 0.8313\n",
      "Epoch [7595/10000], Train Loss: 0.0357, Val Loss: 0.8318\n",
      "Epoch [7596/10000], Train Loss: 0.0356, Val Loss: 0.8311\n",
      "Epoch [7597/10000], Train Loss: 0.0356, Val Loss: 0.8313\n",
      "Epoch [7598/10000], Train Loss: 0.0355, Val Loss: 0.8310\n",
      "Epoch [7599/10000], Train Loss: 0.0354, Val Loss: 0.8308\n",
      "Epoch [7600/10000], Train Loss: 0.0353, Val Loss: 0.8308\n",
      "Epoch [7601/10000], Train Loss: 0.0353, Val Loss: 0.8301\n",
      "Epoch [7602/10000], Train Loss: 0.0352, Val Loss: 0.8309\n",
      "Epoch [7603/10000], Train Loss: 0.0351, Val Loss: 0.8295\n",
      "Epoch [7604/10000], Train Loss: 0.0351, Val Loss: 0.8308\n",
      "Epoch [7605/10000], Train Loss: 0.0350, Val Loss: 0.8289\n",
      "Epoch [7606/10000], Train Loss: 0.0349, Val Loss: 0.8307\n",
      "Epoch [7607/10000], Train Loss: 0.0348, Val Loss: 0.8283\n",
      "Epoch [7608/10000], Train Loss: 0.0348, Val Loss: 0.8304\n",
      "Epoch [7609/10000], Train Loss: 0.0347, Val Loss: 0.8280\n",
      "Epoch [7610/10000], Train Loss: 0.0346, Val Loss: 0.8300\n",
      "Epoch [7611/10000], Train Loss: 0.0346, Val Loss: 0.8278\n",
      "Epoch [7612/10000], Train Loss: 0.0345, Val Loss: 0.8296\n",
      "Epoch [7613/10000], Train Loss: 0.0344, Val Loss: 0.8275\n",
      "Epoch [7614/10000], Train Loss: 0.0343, Val Loss: 0.8291\n",
      "Epoch [7615/10000], Train Loss: 0.0343, Val Loss: 0.8273\n",
      "Epoch [7616/10000], Train Loss: 0.0342, Val Loss: 0.8286\n",
      "Epoch [7617/10000], Train Loss: 0.0341, Val Loss: 0.8271\n",
      "Epoch [7618/10000], Train Loss: 0.0341, Val Loss: 0.8283\n",
      "Epoch [7619/10000], Train Loss: 0.0340, Val Loss: 0.8267\n",
      "Epoch [7620/10000], Train Loss: 0.0339, Val Loss: 0.8280\n",
      "Epoch [7621/10000], Train Loss: 0.0339, Val Loss: 0.8264\n",
      "Epoch [7622/10000], Train Loss: 0.0338, Val Loss: 0.8277\n",
      "Epoch [7623/10000], Train Loss: 0.0337, Val Loss: 0.8260\n",
      "Epoch [7624/10000], Train Loss: 0.0336, Val Loss: 0.8275\n",
      "Epoch [7625/10000], Train Loss: 0.0336, Val Loss: 0.8255\n",
      "Epoch [7626/10000], Train Loss: 0.0335, Val Loss: 0.8273\n",
      "Epoch [7627/10000], Train Loss: 0.0334, Val Loss: 0.8251\n",
      "Epoch [7628/10000], Train Loss: 0.0334, Val Loss: 0.8271\n",
      "Epoch [7629/10000], Train Loss: 0.0333, Val Loss: 0.8246\n",
      "Epoch [7630/10000], Train Loss: 0.0332, Val Loss: 0.8270\n",
      "Epoch [7631/10000], Train Loss: 0.0332, Val Loss: 0.8242\n",
      "Epoch [7632/10000], Train Loss: 0.0331, Val Loss: 0.8267\n",
      "Epoch [7633/10000], Train Loss: 0.0330, Val Loss: 0.8239\n",
      "Epoch [7634/10000], Train Loss: 0.0330, Val Loss: 0.8264\n",
      "Epoch [7635/10000], Train Loss: 0.0329, Val Loss: 0.8235\n",
      "Epoch [7636/10000], Train Loss: 0.0328, Val Loss: 0.8262\n",
      "Epoch [7637/10000], Train Loss: 0.0328, Val Loss: 0.8231\n",
      "Epoch [7638/10000], Train Loss: 0.0327, Val Loss: 0.8259\n",
      "Epoch [7639/10000], Train Loss: 0.0326, Val Loss: 0.8227\n",
      "Epoch [7640/10000], Train Loss: 0.0326, Val Loss: 0.8257\n",
      "Epoch [7641/10000], Train Loss: 0.0325, Val Loss: 0.8222\n",
      "Epoch [7642/10000], Train Loss: 0.0324, Val Loss: 0.8256\n",
      "Epoch [7643/10000], Train Loss: 0.0324, Val Loss: 0.8217\n",
      "Epoch [7644/10000], Train Loss: 0.0323, Val Loss: 0.8255\n",
      "Epoch [7645/10000], Train Loss: 0.0322, Val Loss: 0.8212\n",
      "Epoch [7646/10000], Train Loss: 0.0322, Val Loss: 0.8254\n",
      "Epoch [7647/10000], Train Loss: 0.0321, Val Loss: 0.8206\n",
      "Epoch [7648/10000], Train Loss: 0.0320, Val Loss: 0.8253\n",
      "Epoch [7649/10000], Train Loss: 0.0320, Val Loss: 0.8201\n",
      "Epoch [7650/10000], Train Loss: 0.0319, Val Loss: 0.8253\n",
      "Epoch [7651/10000], Train Loss: 0.0318, Val Loss: 0.8195\n",
      "Epoch [7652/10000], Train Loss: 0.0318, Val Loss: 0.8253\n",
      "Epoch [7653/10000], Train Loss: 0.0317, Val Loss: 0.8188\n",
      "Epoch [7654/10000], Train Loss: 0.0316, Val Loss: 0.8254\n",
      "Epoch [7655/10000], Train Loss: 0.0316, Val Loss: 0.8180\n",
      "Epoch [7656/10000], Train Loss: 0.0315, Val Loss: 0.8257\n",
      "Epoch [7657/10000], Train Loss: 0.0315, Val Loss: 0.8171\n",
      "Epoch [7658/10000], Train Loss: 0.0314, Val Loss: 0.8260\n",
      "Epoch [7659/10000], Train Loss: 0.0313, Val Loss: 0.8160\n",
      "Epoch [7660/10000], Train Loss: 0.0313, Val Loss: 0.8265\n",
      "Epoch [7661/10000], Train Loss: 0.0312, Val Loss: 0.8148\n",
      "Epoch [7662/10000], Train Loss: 0.0312, Val Loss: 0.8273\n",
      "Epoch [7663/10000], Train Loss: 0.0311, Val Loss: 0.8134\n",
      "Epoch [7664/10000], Train Loss: 0.0311, Val Loss: 0.8283\n",
      "Epoch [7665/10000], Train Loss: 0.0310, Val Loss: 0.8116\n",
      "Epoch [7666/10000], Train Loss: 0.0310, Val Loss: 0.8298\n",
      "Epoch [7667/10000], Train Loss: 0.0310, Val Loss: 0.8093\n",
      "Epoch [7668/10000], Train Loss: 0.0310, Val Loss: 0.8319\n",
      "Epoch [7669/10000], Train Loss: 0.0310, Val Loss: 0.8065\n",
      "Epoch [7670/10000], Train Loss: 0.0310, Val Loss: 0.8348\n",
      "Epoch [7671/10000], Train Loss: 0.0310, Val Loss: 0.8029\n",
      "Epoch [7672/10000], Train Loss: 0.0311, Val Loss: 0.8388\n",
      "Epoch [7673/10000], Train Loss: 0.0312, Val Loss: 0.7982\n",
      "Epoch [7674/10000], Train Loss: 0.0315, Val Loss: 0.8445\n",
      "Epoch [7675/10000], Train Loss: 0.0317, Val Loss: 0.7921\n",
      "Epoch [7676/10000], Train Loss: 0.0321, Val Loss: 0.8524\n",
      "Epoch [7677/10000], Train Loss: 0.0326, Val Loss: 0.7844\n",
      "Epoch [7678/10000], Train Loss: 0.0333, Val Loss: 0.8635\n",
      "Epoch [7679/10000], Train Loss: 0.0342, Val Loss: 0.7748\n",
      "Epoch [7680/10000], Train Loss: 0.0356, Val Loss: 0.8784\n",
      "Epoch [7681/10000], Train Loss: 0.0370, Val Loss: 0.7638\n",
      "Epoch [7682/10000], Train Loss: 0.0393, Val Loss: 0.8974\n",
      "Epoch [7683/10000], Train Loss: 0.0414, Val Loss: 0.7528\n",
      "Epoch [7684/10000], Train Loss: 0.0446, Val Loss: 0.9160\n",
      "Epoch [7685/10000], Train Loss: 0.0466, Val Loss: 0.7462\n",
      "Epoch [7686/10000], Train Loss: 0.0492, Val Loss: 0.9260\n",
      "Epoch [7687/10000], Train Loss: 0.0491, Val Loss: 0.7466\n",
      "Epoch [7688/10000], Train Loss: 0.0487, Val Loss: 0.9144\n",
      "Epoch [7689/10000], Train Loss: 0.0450, Val Loss: 0.7599\n",
      "Epoch [7690/10000], Train Loss: 0.0411, Val Loss: 0.8792\n",
      "Epoch [7691/10000], Train Loss: 0.0358, Val Loss: 0.7886\n",
      "Epoch [7692/10000], Train Loss: 0.0320, Val Loss: 0.8346\n",
      "Epoch [7693/10000], Train Loss: 0.0297, Val Loss: 0.8283\n",
      "Epoch [7694/10000], Train Loss: 0.0295, Val Loss: 0.7973\n",
      "Epoch [7695/10000], Train Loss: 0.0309, Val Loss: 0.8567\n",
      "Epoch [7696/10000], Train Loss: 0.0326, Val Loss: 0.7792\n",
      "Epoch [7697/10000], Train Loss: 0.0342, Val Loss: 0.8682\n",
      "Epoch [7698/10000], Train Loss: 0.0345, Val Loss: 0.7765\n",
      "Epoch [7699/10000], Train Loss: 0.0342, Val Loss: 0.8587\n",
      "Epoch [7700/10000], Train Loss: 0.0327, Val Loss: 0.7880\n",
      "Epoch [7701/10000], Train Loss: 0.0312, Val Loss: 0.8368\n",
      "Epoch [7702/10000], Train Loss: 0.0297, Val Loss: 0.8096\n",
      "Epoch [7703/10000], Train Loss: 0.0287, Val Loss: 0.8116\n",
      "Epoch [7704/10000], Train Loss: 0.0285, Val Loss: 0.8314\n",
      "Epoch [7705/10000], Train Loss: 0.0289, Val Loss: 0.7955\n",
      "Epoch [7706/10000], Train Loss: 0.0295, Val Loss: 0.8452\n",
      "Epoch [7707/10000], Train Loss: 0.0300, Val Loss: 0.7879\n",
      "Epoch [7708/10000], Train Loss: 0.0304, Val Loss: 0.8485\n",
      "Epoch [7709/10000], Train Loss: 0.0303, Val Loss: 0.7904\n",
      "Epoch [7710/10000], Train Loss: 0.0300, Val Loss: 0.8403\n",
      "Epoch [7711/10000], Train Loss: 0.0294, Val Loss: 0.7998\n",
      "Epoch [7712/10000], Train Loss: 0.0289, Val Loss: 0.8284\n",
      "Epoch [7713/10000], Train Loss: 0.0284, Val Loss: 0.8125\n",
      "Epoch [7714/10000], Train Loss: 0.0281, Val Loss: 0.8138\n",
      "Epoch [7715/10000], Train Loss: 0.0280, Val Loss: 0.8265\n",
      "Epoch [7716/10000], Train Loss: 0.0281, Val Loss: 0.8027\n",
      "Epoch [7717/10000], Train Loss: 0.0283, Val Loss: 0.8350\n",
      "Epoch [7718/10000], Train Loss: 0.0284, Val Loss: 0.7976\n",
      "Epoch [7719/10000], Train Loss: 0.0286, Val Loss: 0.8383\n",
      "Epoch [7720/10000], Train Loss: 0.0286, Val Loss: 0.7967\n",
      "Epoch [7721/10000], Train Loss: 0.0286, Val Loss: 0.8368\n",
      "Epoch [7722/10000], Train Loss: 0.0284, Val Loss: 0.7993\n",
      "Epoch [7723/10000], Train Loss: 0.0283, Val Loss: 0.8318\n",
      "Epoch [7724/10000], Train Loss: 0.0280, Val Loss: 0.8042\n",
      "Epoch [7725/10000], Train Loss: 0.0279, Val Loss: 0.8251\n",
      "Epoch [7726/10000], Train Loss: 0.0277, Val Loss: 0.8103\n",
      "Epoch [7727/10000], Train Loss: 0.0276, Val Loss: 0.8180\n",
      "Epoch [7728/10000], Train Loss: 0.0276, Val Loss: 0.8159\n",
      "Epoch [7729/10000], Train Loss: 0.0277, Val Loss: 0.8123\n",
      "Epoch [7730/10000], Train Loss: 0.0277, Val Loss: 0.8201\n",
      "Epoch [7731/10000], Train Loss: 0.0279, Val Loss: 0.8086\n",
      "Epoch [7732/10000], Train Loss: 0.0280, Val Loss: 0.8224\n",
      "Epoch [7733/10000], Train Loss: 0.0282, Val Loss: 0.8070\n",
      "Epoch [7734/10000], Train Loss: 0.0284, Val Loss: 0.8232\n",
      "Epoch [7735/10000], Train Loss: 0.0285, Val Loss: 0.8070\n",
      "Epoch [7736/10000], Train Loss: 0.0288, Val Loss: 0.8228\n",
      "Epoch [7737/10000], Train Loss: 0.0289, Val Loss: 0.8080\n",
      "Epoch [7738/10000], Train Loss: 0.0292, Val Loss: 0.8216\n",
      "Epoch [7739/10000], Train Loss: 0.0294, Val Loss: 0.8098\n",
      "Epoch [7740/10000], Train Loss: 0.0295, Val Loss: 0.8195\n",
      "Epoch [7741/10000], Train Loss: 0.0296, Val Loss: 0.8119\n",
      "Epoch [7742/10000], Train Loss: 0.0296, Val Loss: 0.8168\n",
      "Epoch [7743/10000], Train Loss: 0.0294, Val Loss: 0.8138\n",
      "Epoch [7744/10000], Train Loss: 0.0291, Val Loss: 0.8134\n",
      "Epoch [7745/10000], Train Loss: 0.0286, Val Loss: 0.8153\n",
      "Epoch [7746/10000], Train Loss: 0.0281, Val Loss: 0.8097\n",
      "Epoch [7747/10000], Train Loss: 0.0276, Val Loss: 0.8170\n",
      "Epoch [7748/10000], Train Loss: 0.0270, Val Loss: 0.8056\n",
      "Epoch [7749/10000], Train Loss: 0.0266, Val Loss: 0.8183\n",
      "Epoch [7750/10000], Train Loss: 0.0262, Val Loss: 0.8032\n",
      "Epoch [7751/10000], Train Loss: 0.0259, Val Loss: 0.8189\n",
      "Epoch [7752/10000], Train Loss: 0.0258, Val Loss: 0.8021\n",
      "Epoch [7753/10000], Train Loss: 0.0257, Val Loss: 0.8186\n",
      "Epoch [7754/10000], Train Loss: 0.0257, Val Loss: 0.8018\n",
      "Epoch [7755/10000], Train Loss: 0.0258, Val Loss: 0.8184\n",
      "Epoch [7756/10000], Train Loss: 0.0258, Val Loss: 0.8017\n",
      "Epoch [7757/10000], Train Loss: 0.0259, Val Loss: 0.8182\n",
      "Epoch [7758/10000], Train Loss: 0.0259, Val Loss: 0.8012\n",
      "Epoch [7759/10000], Train Loss: 0.0260, Val Loss: 0.8187\n",
      "Epoch [7760/10000], Train Loss: 0.0260, Val Loss: 0.7998\n",
      "Epoch [7761/10000], Train Loss: 0.0260, Val Loss: 0.8193\n",
      "Epoch [7762/10000], Train Loss: 0.0259, Val Loss: 0.7984\n",
      "Epoch [7763/10000], Train Loss: 0.0258, Val Loss: 0.8201\n",
      "Epoch [7764/10000], Train Loss: 0.0258, Val Loss: 0.7962\n",
      "Epoch [7765/10000], Train Loss: 0.0257, Val Loss: 0.8221\n",
      "Epoch [7766/10000], Train Loss: 0.0256, Val Loss: 0.7931\n",
      "Epoch [7767/10000], Train Loss: 0.0256, Val Loss: 0.8249\n",
      "Epoch [7768/10000], Train Loss: 0.0256, Val Loss: 0.7894\n",
      "Epoch [7769/10000], Train Loss: 0.0257, Val Loss: 0.8289\n",
      "Epoch [7770/10000], Train Loss: 0.0257, Val Loss: 0.7845\n",
      "Epoch [7771/10000], Train Loss: 0.0259, Val Loss: 0.8350\n",
      "Epoch [7772/10000], Train Loss: 0.0261, Val Loss: 0.7780\n",
      "Epoch [7773/10000], Train Loss: 0.0266, Val Loss: 0.8434\n",
      "Epoch [7774/10000], Train Loss: 0.0270, Val Loss: 0.7701\n",
      "Epoch [7775/10000], Train Loss: 0.0278, Val Loss: 0.8550\n",
      "Epoch [7776/10000], Train Loss: 0.0287, Val Loss: 0.7601\n",
      "Epoch [7777/10000], Train Loss: 0.0302, Val Loss: 0.8711\n",
      "Epoch [7778/10000], Train Loss: 0.0317, Val Loss: 0.7483\n",
      "Epoch [7779/10000], Train Loss: 0.0340, Val Loss: 0.8915\n",
      "Epoch [7780/10000], Train Loss: 0.0363, Val Loss: 0.7363\n",
      "Epoch [7781/10000], Train Loss: 0.0396, Val Loss: 0.9119\n",
      "Epoch [7782/10000], Train Loss: 0.0418, Val Loss: 0.7285\n",
      "Epoch [7783/10000], Train Loss: 0.0445, Val Loss: 0.9233\n",
      "Epoch [7784/10000], Train Loss: 0.0446, Val Loss: 0.7288\n",
      "Epoch [7785/10000], Train Loss: 0.0443, Val Loss: 0.9113\n",
      "Epoch [7786/10000], Train Loss: 0.0406, Val Loss: 0.7433\n",
      "Epoch [7787/10000], Train Loss: 0.0364, Val Loss: 0.8726\n",
      "Epoch [7788/10000], Train Loss: 0.0309, Val Loss: 0.7753\n",
      "Epoch [7789/10000], Train Loss: 0.0269, Val Loss: 0.8227\n",
      "Epoch [7790/10000], Train Loss: 0.0245, Val Loss: 0.8190\n",
      "Epoch [7791/10000], Train Loss: 0.0243, Val Loss: 0.7822\n",
      "Epoch [7792/10000], Train Loss: 0.0255, Val Loss: 0.8496\n",
      "Epoch [7793/10000], Train Loss: 0.0271, Val Loss: 0.7628\n",
      "Epoch [7794/10000], Train Loss: 0.0286, Val Loss: 0.8613\n",
      "Epoch [7795/10000], Train Loss: 0.0288, Val Loss: 0.7612\n",
      "Epoch [7796/10000], Train Loss: 0.0284, Val Loss: 0.8500\n",
      "Epoch [7797/10000], Train Loss: 0.0269, Val Loss: 0.7786\n",
      "Epoch [7798/10000], Train Loss: 0.0251, Val Loss: 0.8205\n",
      "Epoch [7799/10000], Train Loss: 0.0237, Val Loss: 0.8041\n",
      "Epoch [7800/10000], Train Loss: 0.0232, Val Loss: 0.7954\n",
      "Epoch [7801/10000], Train Loss: 0.0235, Val Loss: 0.8271\n",
      "Epoch [7802/10000], Train Loss: 0.0242, Val Loss: 0.7793\n",
      "Epoch [7803/10000], Train Loss: 0.0250, Val Loss: 0.8392\n",
      "Epoch [7804/10000], Train Loss: 0.0253, Val Loss: 0.7750\n",
      "Epoch [7805/10000], Train Loss: 0.0255, Val Loss: 0.8373\n",
      "Epoch [7806/10000], Train Loss: 0.0250, Val Loss: 0.7815\n",
      "Epoch [7807/10000], Train Loss: 0.0245, Val Loss: 0.8267\n",
      "Epoch [7808/10000], Train Loss: 0.0238, Val Loss: 0.7921\n",
      "Epoch [7809/10000], Train Loss: 0.0233, Val Loss: 0.8134\n",
      "Epoch [7810/10000], Train Loss: 0.0229, Val Loss: 0.8060\n",
      "Epoch [7811/10000], Train Loss: 0.0227, Val Loss: 0.7991\n",
      "Epoch [7812/10000], Train Loss: 0.0227, Val Loss: 0.8184\n",
      "Epoch [7813/10000], Train Loss: 0.0229, Val Loss: 0.7901\n",
      "Epoch [7814/10000], Train Loss: 0.0230, Val Loss: 0.8238\n",
      "Epoch [7815/10000], Train Loss: 0.0231, Val Loss: 0.7875\n",
      "Epoch [7816/10000], Train Loss: 0.0231, Val Loss: 0.8240\n",
      "Epoch [7817/10000], Train Loss: 0.0230, Val Loss: 0.7883\n",
      "Epoch [7818/10000], Train Loss: 0.0228, Val Loss: 0.8199\n",
      "Epoch [7819/10000], Train Loss: 0.0226, Val Loss: 0.7932\n",
      "Epoch [7820/10000], Train Loss: 0.0224, Val Loss: 0.8125\n",
      "Epoch [7821/10000], Train Loss: 0.0221, Val Loss: 0.7993\n",
      "Epoch [7822/10000], Train Loss: 0.0220, Val Loss: 0.8058\n",
      "Epoch [7823/10000], Train Loss: 0.0219, Val Loss: 0.8047\n",
      "Epoch [7824/10000], Train Loss: 0.0218, Val Loss: 0.7995\n",
      "Epoch [7825/10000], Train Loss: 0.0218, Val Loss: 0.8096\n",
      "Epoch [7826/10000], Train Loss: 0.0218, Val Loss: 0.7953\n",
      "Epoch [7827/10000], Train Loss: 0.0218, Val Loss: 0.8114\n",
      "Epoch [7828/10000], Train Loss: 0.0218, Val Loss: 0.7937\n",
      "Epoch [7829/10000], Train Loss: 0.0218, Val Loss: 0.8116\n",
      "Epoch [7830/10000], Train Loss: 0.0217, Val Loss: 0.7936\n",
      "Epoch [7831/10000], Train Loss: 0.0216, Val Loss: 0.8105\n",
      "Epoch [7832/10000], Train Loss: 0.0216, Val Loss: 0.7949\n",
      "Epoch [7833/10000], Train Loss: 0.0215, Val Loss: 0.8081\n",
      "Epoch [7834/10000], Train Loss: 0.0214, Val Loss: 0.7975\n",
      "Epoch [7835/10000], Train Loss: 0.0214, Val Loss: 0.8046\n",
      "Epoch [7836/10000], Train Loss: 0.0213, Val Loss: 0.8003\n",
      "Epoch [7837/10000], Train Loss: 0.0212, Val Loss: 0.8017\n",
      "Epoch [7838/10000], Train Loss: 0.0212, Val Loss: 0.8026\n",
      "Epoch [7839/10000], Train Loss: 0.0212, Val Loss: 0.7991\n",
      "Epoch [7840/10000], Train Loss: 0.0212, Val Loss: 0.8041\n",
      "Epoch [7841/10000], Train Loss: 0.0212, Val Loss: 0.7972\n",
      "Epoch [7842/10000], Train Loss: 0.0212, Val Loss: 0.8054\n",
      "Epoch [7843/10000], Train Loss: 0.0212, Val Loss: 0.7955\n",
      "Epoch [7844/10000], Train Loss: 0.0213, Val Loss: 0.8069\n",
      "Epoch [7845/10000], Train Loss: 0.0214, Val Loss: 0.7936\n",
      "Epoch [7846/10000], Train Loss: 0.0217, Val Loss: 0.8094\n",
      "Epoch [7847/10000], Train Loss: 0.0220, Val Loss: 0.7916\n",
      "Epoch [7848/10000], Train Loss: 0.0225, Val Loss: 0.8126\n",
      "Epoch [7849/10000], Train Loss: 0.0232, Val Loss: 0.7903\n",
      "Epoch [7850/10000], Train Loss: 0.0242, Val Loss: 0.8170\n",
      "Epoch [7851/10000], Train Loss: 0.0255, Val Loss: 0.7902\n",
      "Epoch [7852/10000], Train Loss: 0.0272, Val Loss: 0.8228\n",
      "Epoch [7853/10000], Train Loss: 0.0290, Val Loss: 0.7913\n",
      "Epoch [7854/10000], Train Loss: 0.0311, Val Loss: 0.8284\n",
      "Epoch [7855/10000], Train Loss: 0.0324, Val Loss: 0.7912\n",
      "Epoch [7856/10000], Train Loss: 0.0334, Val Loss: 0.8304\n",
      "Epoch [7857/10000], Train Loss: 0.0323, Val Loss: 0.7864\n",
      "Epoch [7858/10000], Train Loss: 0.0303, Val Loss: 0.8261\n",
      "Epoch [7859/10000], Train Loss: 0.0268, Val Loss: 0.7803\n",
      "Epoch [7860/10000], Train Loss: 0.0237, Val Loss: 0.8191\n",
      "Epoch [7861/10000], Train Loss: 0.0213, Val Loss: 0.7808\n",
      "Epoch [7862/10000], Train Loss: 0.0206, Val Loss: 0.8141\n",
      "Epoch [7863/10000], Train Loss: 0.0212, Val Loss: 0.7884\n",
      "Epoch [7864/10000], Train Loss: 0.0224, Val Loss: 0.8087\n",
      "Epoch [7865/10000], Train Loss: 0.0237, Val Loss: 0.7944\n",
      "Epoch [7866/10000], Train Loss: 0.0243, Val Loss: 0.8047\n",
      "Epoch [7867/10000], Train Loss: 0.0239, Val Loss: 0.7942\n",
      "Epoch [7868/10000], Train Loss: 0.0227, Val Loss: 0.8004\n",
      "Epoch [7869/10000], Train Loss: 0.0213, Val Loss: 0.7916\n",
      "Epoch [7870/10000], Train Loss: 0.0201, Val Loss: 0.7988\n",
      "Epoch [7871/10000], Train Loss: 0.0196, Val Loss: 0.7902\n",
      "Epoch [7872/10000], Train Loss: 0.0198, Val Loss: 0.8002\n",
      "Epoch [7873/10000], Train Loss: 0.0203, Val Loss: 0.7904\n",
      "Epoch [7874/10000], Train Loss: 0.0209, Val Loss: 0.8017\n",
      "Epoch [7875/10000], Train Loss: 0.0212, Val Loss: 0.7903\n",
      "Epoch [7876/10000], Train Loss: 0.0212, Val Loss: 0.8023\n",
      "Epoch [7877/10000], Train Loss: 0.0207, Val Loss: 0.7881\n",
      "Epoch [7878/10000], Train Loss: 0.0202, Val Loss: 0.8040\n",
      "Epoch [7879/10000], Train Loss: 0.0197, Val Loss: 0.7850\n",
      "Epoch [7880/10000], Train Loss: 0.0195, Val Loss: 0.8072\n",
      "Epoch [7881/10000], Train Loss: 0.0195, Val Loss: 0.7819\n",
      "Epoch [7882/10000], Train Loss: 0.0197, Val Loss: 0.8128\n",
      "Epoch [7883/10000], Train Loss: 0.0200, Val Loss: 0.7773\n",
      "Epoch [7884/10000], Train Loss: 0.0203, Val Loss: 0.8197\n",
      "Epoch [7885/10000], Train Loss: 0.0206, Val Loss: 0.7710\n",
      "Epoch [7886/10000], Train Loss: 0.0208, Val Loss: 0.8281\n",
      "Epoch [7887/10000], Train Loss: 0.0211, Val Loss: 0.7625\n",
      "Epoch [7888/10000], Train Loss: 0.0216, Val Loss: 0.8402\n",
      "Epoch [7889/10000], Train Loss: 0.0223, Val Loss: 0.7510\n",
      "Epoch [7890/10000], Train Loss: 0.0238, Val Loss: 0.8578\n",
      "Epoch [7891/10000], Train Loss: 0.0254, Val Loss: 0.7379\n",
      "Epoch [7892/10000], Train Loss: 0.0281, Val Loss: 0.8811\n",
      "Epoch [7893/10000], Train Loss: 0.0306, Val Loss: 0.7244\n",
      "Epoch [7894/10000], Train Loss: 0.0345, Val Loss: 0.9069\n",
      "Epoch [7895/10000], Train Loss: 0.0373, Val Loss: 0.7134\n",
      "Epoch [7896/10000], Train Loss: 0.0414, Val Loss: 0.9258\n",
      "Epoch [7897/10000], Train Loss: 0.0427, Val Loss: 0.7104\n",
      "Epoch [7898/10000], Train Loss: 0.0441, Val Loss: 0.9213\n",
      "Epoch [7899/10000], Train Loss: 0.0411, Val Loss: 0.7205\n",
      "Epoch [7900/10000], Train Loss: 0.0374, Val Loss: 0.8842\n",
      "Epoch [7901/10000], Train Loss: 0.0307, Val Loss: 0.7501\n",
      "Epoch [7902/10000], Train Loss: 0.0248, Val Loss: 0.8238\n",
      "Epoch [7903/10000], Train Loss: 0.0203, Val Loss: 0.7978\n",
      "Epoch [7904/10000], Train Loss: 0.0189, Val Loss: 0.7703\n",
      "Epoch [7905/10000], Train Loss: 0.0201, Val Loss: 0.8398\n",
      "Epoch [7906/10000], Train Loss: 0.0224, Val Loss: 0.7453\n",
      "Epoch [7907/10000], Train Loss: 0.0244, Val Loss: 0.8542\n",
      "Epoch [7908/10000], Train Loss: 0.0249, Val Loss: 0.7413\n",
      "Epoch [7909/10000], Train Loss: 0.0247, Val Loss: 0.8454\n",
      "Epoch [7910/10000], Train Loss: 0.0229, Val Loss: 0.7571\n",
      "Epoch [7911/10000], Train Loss: 0.0210, Val Loss: 0.8148\n",
      "Epoch [7912/10000], Train Loss: 0.0192, Val Loss: 0.7868\n",
      "Epoch [7913/10000], Train Loss: 0.0181, Val Loss: 0.7841\n",
      "Epoch [7914/10000], Train Loss: 0.0180, Val Loss: 0.8136\n",
      "Epoch [7915/10000], Train Loss: 0.0187, Val Loss: 0.7653\n",
      "Epoch [7916/10000], Train Loss: 0.0195, Val Loss: 0.8299\n",
      "Epoch [7917/10000], Train Loss: 0.0201, Val Loss: 0.7586\n",
      "Epoch [7918/10000], Train Loss: 0.0203, Val Loss: 0.8294\n",
      "Epoch [7919/10000], Train Loss: 0.0198, Val Loss: 0.7675\n",
      "Epoch [7920/10000], Train Loss: 0.0192, Val Loss: 0.8144\n",
      "Epoch [7921/10000], Train Loss: 0.0184, Val Loss: 0.7830\n",
      "Epoch [7922/10000], Train Loss: 0.0177, Val Loss: 0.7980\n",
      "Epoch [7923/10000], Train Loss: 0.0174, Val Loss: 0.7988\n",
      "Epoch [7924/10000], Train Loss: 0.0174, Val Loss: 0.7821\n",
      "Epoch [7925/10000], Train Loss: 0.0176, Val Loss: 0.8129\n",
      "Epoch [7926/10000], Train Loss: 0.0179, Val Loss: 0.7722\n",
      "Epoch [7927/10000], Train Loss: 0.0182, Val Loss: 0.8180\n",
      "Epoch [7928/10000], Train Loss: 0.0183, Val Loss: 0.7714\n",
      "Epoch [7929/10000], Train Loss: 0.0183, Val Loss: 0.8161\n",
      "Epoch [7930/10000], Train Loss: 0.0181, Val Loss: 0.7739\n",
      "Epoch [7931/10000], Train Loss: 0.0178, Val Loss: 0.8105\n",
      "Epoch [7932/10000], Train Loss: 0.0175, Val Loss: 0.7808\n",
      "Epoch [7933/10000], Train Loss: 0.0173, Val Loss: 0.8008\n",
      "Epoch [7934/10000], Train Loss: 0.0171, Val Loss: 0.7899\n",
      "Epoch [7935/10000], Train Loss: 0.0170, Val Loss: 0.7923\n",
      "Epoch [7936/10000], Train Loss: 0.0169, Val Loss: 0.7968\n",
      "Epoch [7937/10000], Train Loss: 0.0169, Val Loss: 0.7862\n",
      "Epoch [7938/10000], Train Loss: 0.0169, Val Loss: 0.8015\n",
      "Epoch [7939/10000], Train Loss: 0.0169, Val Loss: 0.7829\n",
      "Epoch [7940/10000], Train Loss: 0.0169, Val Loss: 0.8024\n",
      "Epoch [7941/10000], Train Loss: 0.0168, Val Loss: 0.7833\n",
      "Epoch [7942/10000], Train Loss: 0.0168, Val Loss: 0.8009\n",
      "Epoch [7943/10000], Train Loss: 0.0167, Val Loss: 0.7849\n",
      "Epoch [7944/10000], Train Loss: 0.0167, Val Loss: 0.7990\n",
      "Epoch [7945/10000], Train Loss: 0.0166, Val Loss: 0.7867\n",
      "Epoch [7946/10000], Train Loss: 0.0166, Val Loss: 0.7966\n",
      "Epoch [7947/10000], Train Loss: 0.0165, Val Loss: 0.7896\n",
      "Epoch [7948/10000], Train Loss: 0.0164, Val Loss: 0.7932\n",
      "Epoch [7949/10000], Train Loss: 0.0164, Val Loss: 0.7915\n",
      "Epoch [7950/10000], Train Loss: 0.0163, Val Loss: 0.7908\n",
      "Epoch [7951/10000], Train Loss: 0.0163, Val Loss: 0.7930\n",
      "Epoch [7952/10000], Train Loss: 0.0162, Val Loss: 0.7887\n",
      "Epoch [7953/10000], Train Loss: 0.0162, Val Loss: 0.7938\n",
      "Epoch [7954/10000], Train Loss: 0.0161, Val Loss: 0.7878\n",
      "Epoch [7955/10000], Train Loss: 0.0161, Val Loss: 0.7933\n",
      "Epoch [7956/10000], Train Loss: 0.0160, Val Loss: 0.7879\n",
      "Epoch [7957/10000], Train Loss: 0.0160, Val Loss: 0.7926\n",
      "Epoch [7958/10000], Train Loss: 0.0160, Val Loss: 0.7875\n",
      "Epoch [7959/10000], Train Loss: 0.0159, Val Loss: 0.7925\n",
      "Epoch [7960/10000], Train Loss: 0.0159, Val Loss: 0.7871\n",
      "Epoch [7961/10000], Train Loss: 0.0159, Val Loss: 0.7924\n",
      "Epoch [7962/10000], Train Loss: 0.0159, Val Loss: 0.7862\n",
      "Epoch [7963/10000], Train Loss: 0.0158, Val Loss: 0.7930\n",
      "Epoch [7964/10000], Train Loss: 0.0158, Val Loss: 0.7846\n",
      "Epoch [7965/10000], Train Loss: 0.0158, Val Loss: 0.7940\n",
      "Epoch [7966/10000], Train Loss: 0.0157, Val Loss: 0.7830\n",
      "Epoch [7967/10000], Train Loss: 0.0157, Val Loss: 0.7954\n",
      "Epoch [7968/10000], Train Loss: 0.0157, Val Loss: 0.7807\n",
      "Epoch [7969/10000], Train Loss: 0.0157, Val Loss: 0.7978\n",
      "Epoch [7970/10000], Train Loss: 0.0157, Val Loss: 0.7773\n",
      "Epoch [7971/10000], Train Loss: 0.0158, Val Loss: 0.8011\n",
      "Epoch [7972/10000], Train Loss: 0.0158, Val Loss: 0.7734\n",
      "Epoch [7973/10000], Train Loss: 0.0159, Val Loss: 0.8054\n",
      "Epoch [7974/10000], Train Loss: 0.0160, Val Loss: 0.7683\n",
      "Epoch [7975/10000], Train Loss: 0.0162, Val Loss: 0.8113\n",
      "Epoch [7976/10000], Train Loss: 0.0165, Val Loss: 0.7622\n",
      "Epoch [7977/10000], Train Loss: 0.0168, Val Loss: 0.8188\n",
      "Epoch [7978/10000], Train Loss: 0.0172, Val Loss: 0.7552\n",
      "Epoch [7979/10000], Train Loss: 0.0178, Val Loss: 0.8282\n",
      "Epoch [7980/10000], Train Loss: 0.0184, Val Loss: 0.7473\n",
      "Epoch [7981/10000], Train Loss: 0.0194, Val Loss: 0.8397\n",
      "Epoch [7982/10000], Train Loss: 0.0201, Val Loss: 0.7388\n",
      "Epoch [7983/10000], Train Loss: 0.0215, Val Loss: 0.8524\n",
      "Epoch [7984/10000], Train Loss: 0.0224, Val Loss: 0.7307\n",
      "Epoch [7985/10000], Train Loss: 0.0241, Val Loss: 0.8649\n",
      "Epoch [7986/10000], Train Loss: 0.0250, Val Loss: 0.7241\n",
      "Epoch [7987/10000], Train Loss: 0.0266, Val Loss: 0.8738\n",
      "Epoch [7988/10000], Train Loss: 0.0269, Val Loss: 0.7212\n",
      "Epoch [7989/10000], Train Loss: 0.0277, Val Loss: 0.8742\n",
      "Epoch [7990/10000], Train Loss: 0.0268, Val Loss: 0.7242\n",
      "Epoch [7991/10000], Train Loss: 0.0261, Val Loss: 0.8625\n",
      "Epoch [7992/10000], Train Loss: 0.0239, Val Loss: 0.7357\n",
      "Epoch [7993/10000], Train Loss: 0.0218, Val Loss: 0.8361\n",
      "Epoch [7994/10000], Train Loss: 0.0193, Val Loss: 0.7555\n",
      "Epoch [7995/10000], Train Loss: 0.0176, Val Loss: 0.8056\n",
      "Epoch [7996/10000], Train Loss: 0.0165, Val Loss: 0.7810\n",
      "Epoch [7997/10000], Train Loss: 0.0164, Val Loss: 0.7779\n",
      "Epoch [7998/10000], Train Loss: 0.0170, Val Loss: 0.8036\n",
      "Epoch [7999/10000], Train Loss: 0.0178, Val Loss: 0.7625\n",
      "Epoch [8000/10000], Train Loss: 0.0186, Val Loss: 0.8159\n",
      "Epoch [8001/10000], Train Loss: 0.0189, Val Loss: 0.7575\n",
      "Epoch [8002/10000], Train Loss: 0.0188, Val Loss: 0.8157\n",
      "Epoch [8003/10000], Train Loss: 0.0179, Val Loss: 0.7591\n",
      "Epoch [8004/10000], Train Loss: 0.0172, Val Loss: 0.8108\n",
      "Epoch [8005/10000], Train Loss: 0.0162, Val Loss: 0.7662\n",
      "Epoch [8006/10000], Train Loss: 0.0155, Val Loss: 0.8006\n",
      "Epoch [8007/10000], Train Loss: 0.0147, Val Loss: 0.7774\n",
      "Epoch [8008/10000], Train Loss: 0.0143, Val Loss: 0.7892\n",
      "Epoch [8009/10000], Train Loss: 0.0142, Val Loss: 0.7878\n",
      "Epoch [8010/10000], Train Loss: 0.0143, Val Loss: 0.7796\n",
      "Epoch [8011/10000], Train Loss: 0.0145, Val Loss: 0.7961\n",
      "Epoch [8012/10000], Train Loss: 0.0148, Val Loss: 0.7725\n",
      "Epoch [8013/10000], Train Loss: 0.0151, Val Loss: 0.8011\n",
      "Epoch [8014/10000], Train Loss: 0.0153, Val Loss: 0.7697\n",
      "Epoch [8015/10000], Train Loss: 0.0155, Val Loss: 0.8037\n",
      "Epoch [8016/10000], Train Loss: 0.0156, Val Loss: 0.7679\n",
      "Epoch [8017/10000], Train Loss: 0.0156, Val Loss: 0.8053\n",
      "Epoch [8018/10000], Train Loss: 0.0155, Val Loss: 0.7671\n",
      "Epoch [8019/10000], Train Loss: 0.0154, Val Loss: 0.8055\n",
      "Epoch [8020/10000], Train Loss: 0.0152, Val Loss: 0.7677\n",
      "Epoch [8021/10000], Train Loss: 0.0150, Val Loss: 0.8039\n",
      "Epoch [8022/10000], Train Loss: 0.0147, Val Loss: 0.7689\n",
      "Epoch [8023/10000], Train Loss: 0.0145, Val Loss: 0.8023\n",
      "Epoch [8024/10000], Train Loss: 0.0143, Val Loss: 0.7702\n",
      "Epoch [8025/10000], Train Loss: 0.0141, Val Loss: 0.7994\n",
      "Epoch [8026/10000], Train Loss: 0.0139, Val Loss: 0.7727\n",
      "Epoch [8027/10000], Train Loss: 0.0138, Val Loss: 0.7965\n",
      "Epoch [8028/10000], Train Loss: 0.0137, Val Loss: 0.7744\n",
      "Epoch [8029/10000], Train Loss: 0.0137, Val Loss: 0.7944\n",
      "Epoch [8030/10000], Train Loss: 0.0136, Val Loss: 0.7765\n",
      "Epoch [8031/10000], Train Loss: 0.0135, Val Loss: 0.7913\n",
      "Epoch [8032/10000], Train Loss: 0.0135, Val Loss: 0.7791\n",
      "Epoch [8033/10000], Train Loss: 0.0135, Val Loss: 0.7884\n",
      "Epoch [8034/10000], Train Loss: 0.0135, Val Loss: 0.7810\n",
      "Epoch [8035/10000], Train Loss: 0.0135, Val Loss: 0.7864\n",
      "Epoch [8036/10000], Train Loss: 0.0135, Val Loss: 0.7832\n",
      "Epoch [8037/10000], Train Loss: 0.0136, Val Loss: 0.7843\n",
      "Epoch [8038/10000], Train Loss: 0.0137, Val Loss: 0.7847\n",
      "Epoch [8039/10000], Train Loss: 0.0137, Val Loss: 0.7837\n",
      "Epoch [8040/10000], Train Loss: 0.0138, Val Loss: 0.7850\n",
      "Epoch [8041/10000], Train Loss: 0.0139, Val Loss: 0.7830\n",
      "Epoch [8042/10000], Train Loss: 0.0140, Val Loss: 0.7864\n",
      "Epoch [8043/10000], Train Loss: 0.0142, Val Loss: 0.7817\n",
      "Epoch [8044/10000], Train Loss: 0.0143, Val Loss: 0.7880\n",
      "Epoch [8045/10000], Train Loss: 0.0145, Val Loss: 0.7808\n",
      "Epoch [8046/10000], Train Loss: 0.0147, Val Loss: 0.7898\n",
      "Epoch [8047/10000], Train Loss: 0.0149, Val Loss: 0.7791\n",
      "Epoch [8048/10000], Train Loss: 0.0151, Val Loss: 0.7926\n",
      "Epoch [8049/10000], Train Loss: 0.0153, Val Loss: 0.7769\n",
      "Epoch [8050/10000], Train Loss: 0.0155, Val Loss: 0.7952\n",
      "Epoch [8051/10000], Train Loss: 0.0156, Val Loss: 0.7742\n",
      "Epoch [8052/10000], Train Loss: 0.0157, Val Loss: 0.7985\n",
      "Epoch [8053/10000], Train Loss: 0.0156, Val Loss: 0.7698\n",
      "Epoch [8054/10000], Train Loss: 0.0156, Val Loss: 0.8024\n",
      "Epoch [8055/10000], Train Loss: 0.0153, Val Loss: 0.7644\n",
      "Epoch [8056/10000], Train Loss: 0.0153, Val Loss: 0.8070\n",
      "Epoch [8057/10000], Train Loss: 0.0150, Val Loss: 0.7576\n",
      "Epoch [8058/10000], Train Loss: 0.0150, Val Loss: 0.8137\n",
      "Epoch [8059/10000], Train Loss: 0.0149, Val Loss: 0.7488\n",
      "Epoch [8060/10000], Train Loss: 0.0153, Val Loss: 0.8241\n",
      "Epoch [8061/10000], Train Loss: 0.0158, Val Loss: 0.7379\n",
      "Epoch [8062/10000], Train Loss: 0.0170, Val Loss: 0.8400\n",
      "Epoch [8063/10000], Train Loss: 0.0184, Val Loss: 0.7245\n",
      "Epoch [8064/10000], Train Loss: 0.0210, Val Loss: 0.8647\n",
      "Epoch [8065/10000], Train Loss: 0.0240, Val Loss: 0.7085\n",
      "Epoch [8066/10000], Train Loss: 0.0288, Val Loss: 0.8993\n",
      "Epoch [8067/10000], Train Loss: 0.0338, Val Loss: 0.6928\n",
      "Epoch [8068/10000], Train Loss: 0.0408, Val Loss: 0.9370\n",
      "Epoch [8069/10000], Train Loss: 0.0462, Val Loss: 0.6822\n",
      "Epoch [8070/10000], Train Loss: 0.0518, Val Loss: 0.9548\n",
      "Epoch [8071/10000], Train Loss: 0.0514, Val Loss: 0.6849\n",
      "Epoch [8072/10000], Train Loss: 0.0471, Val Loss: 0.9118\n",
      "Epoch [8073/10000], Train Loss: 0.0361, Val Loss: 0.7141\n",
      "Epoch [8074/10000], Train Loss: 0.0247, Val Loss: 0.8236\n",
      "Epoch [8075/10000], Train Loss: 0.0153, Val Loss: 0.7834\n",
      "Epoch [8076/10000], Train Loss: 0.0121, Val Loss: 0.7427\n",
      "Epoch [8077/10000], Train Loss: 0.0150, Val Loss: 0.8536\n",
      "Epoch [8078/10000], Train Loss: 0.0205, Val Loss: 0.7131\n",
      "Epoch [8079/10000], Train Loss: 0.0249, Val Loss: 0.8727\n",
      "Epoch [8080/10000], Train Loss: 0.0253, Val Loss: 0.7166\n",
      "Epoch [8081/10000], Train Loss: 0.0231, Val Loss: 0.8440\n",
      "Epoch [8082/10000], Train Loss: 0.0181, Val Loss: 0.7509\n",
      "Epoch [8083/10000], Train Loss: 0.0140, Val Loss: 0.7886\n",
      "Epoch [8084/10000], Train Loss: 0.0119, Val Loss: 0.8027\n",
      "Epoch [8085/10000], Train Loss: 0.0124, Val Loss: 0.7502\n",
      "Epoch [8086/10000], Train Loss: 0.0145, Val Loss: 0.8325\n",
      "Epoch [8087/10000], Train Loss: 0.0163, Val Loss: 0.7390\n",
      "Epoch [8088/10000], Train Loss: 0.0170, Val Loss: 0.8338\n",
      "Epoch [8089/10000], Train Loss: 0.0160, Val Loss: 0.7472\n",
      "Epoch [8090/10000], Train Loss: 0.0143, Val Loss: 0.8066\n",
      "Epoch [8091/10000], Train Loss: 0.0124, Val Loss: 0.7794\n",
      "Epoch [8092/10000], Train Loss: 0.0115, Val Loss: 0.7713\n",
      "Epoch [8093/10000], Train Loss: 0.0117, Val Loss: 0.8073\n",
      "Epoch [8094/10000], Train Loss: 0.0126, Val Loss: 0.7545\n",
      "Epoch [8095/10000], Train Loss: 0.0136, Val Loss: 0.8201\n",
      "Epoch [8096/10000], Train Loss: 0.0139, Val Loss: 0.7501\n",
      "Epoch [8097/10000], Train Loss: 0.0137, Val Loss: 0.8142\n",
      "Epoch [8098/10000], Train Loss: 0.0129, Val Loss: 0.7636\n",
      "Epoch [8099/10000], Train Loss: 0.0120, Val Loss: 0.7922\n",
      "Epoch [8100/10000], Train Loss: 0.0114, Val Loss: 0.7851\n",
      "Epoch [8101/10000], Train Loss: 0.0113, Val Loss: 0.7736\n",
      "Epoch [8102/10000], Train Loss: 0.0115, Val Loss: 0.7987\n",
      "Epoch [8103/10000], Train Loss: 0.0119, Val Loss: 0.7642\n",
      "Epoch [8104/10000], Train Loss: 0.0122, Val Loss: 0.8031\n",
      "Epoch [8105/10000], Train Loss: 0.0121, Val Loss: 0.7627\n",
      "Epoch [8106/10000], Train Loss: 0.0119, Val Loss: 0.7966\n",
      "Epoch [8107/10000], Train Loss: 0.0115, Val Loss: 0.7721\n",
      "Epoch [8108/10000], Train Loss: 0.0112, Val Loss: 0.7839\n",
      "Epoch [8109/10000], Train Loss: 0.0110, Val Loss: 0.7823\n",
      "Epoch [8110/10000], Train Loss: 0.0110, Val Loss: 0.7754\n",
      "Epoch [8111/10000], Train Loss: 0.0111, Val Loss: 0.7896\n",
      "Epoch [8112/10000], Train Loss: 0.0112, Val Loss: 0.7699\n",
      "Epoch [8113/10000], Train Loss: 0.0113, Val Loss: 0.7925\n",
      "Epoch [8114/10000], Train Loss: 0.0113, Val Loss: 0.7709\n",
      "Epoch [8115/10000], Train Loss: 0.0112, Val Loss: 0.7877\n",
      "Epoch [8116/10000], Train Loss: 0.0110, Val Loss: 0.7778\n",
      "Epoch [8117/10000], Train Loss: 0.0108, Val Loss: 0.7796\n",
      "Epoch [8118/10000], Train Loss: 0.0108, Val Loss: 0.7842\n",
      "Epoch [8119/10000], Train Loss: 0.0107, Val Loss: 0.7735\n",
      "Epoch [8120/10000], Train Loss: 0.0108, Val Loss: 0.7891\n",
      "Epoch [8121/10000], Train Loss: 0.0108, Val Loss: 0.7684\n",
      "Epoch [8122/10000], Train Loss: 0.0108, Val Loss: 0.7915\n",
      "Epoch [8123/10000], Train Loss: 0.0108, Val Loss: 0.7680\n",
      "Epoch [8124/10000], Train Loss: 0.0108, Val Loss: 0.7894\n",
      "Epoch [8125/10000], Train Loss: 0.0107, Val Loss: 0.7701\n",
      "Epoch [8126/10000], Train Loss: 0.0107, Val Loss: 0.7869\n",
      "Epoch [8127/10000], Train Loss: 0.0106, Val Loss: 0.7720\n",
      "Epoch [8128/10000], Train Loss: 0.0106, Val Loss: 0.7837\n",
      "Epoch [8129/10000], Train Loss: 0.0105, Val Loss: 0.7754\n",
      "Epoch [8130/10000], Train Loss: 0.0105, Val Loss: 0.7805\n",
      "Epoch [8131/10000], Train Loss: 0.0105, Val Loss: 0.7767\n",
      "Epoch [8132/10000], Train Loss: 0.0106, Val Loss: 0.7799\n",
      "Epoch [8133/10000], Train Loss: 0.0106, Val Loss: 0.7763\n",
      "Epoch [8134/10000], Train Loss: 0.0106, Val Loss: 0.7800\n",
      "Epoch [8135/10000], Train Loss: 0.0106, Val Loss: 0.7751\n",
      "Epoch [8136/10000], Train Loss: 0.0106, Val Loss: 0.7816\n",
      "Epoch [8137/10000], Train Loss: 0.0106, Val Loss: 0.7720\n",
      "Epoch [8138/10000], Train Loss: 0.0107, Val Loss: 0.7848\n",
      "Epoch [8139/10000], Train Loss: 0.0107, Val Loss: 0.7685\n",
      "Epoch [8140/10000], Train Loss: 0.0108, Val Loss: 0.7880\n",
      "Epoch [8141/10000], Train Loss: 0.0109, Val Loss: 0.7653\n",
      "Epoch [8142/10000], Train Loss: 0.0110, Val Loss: 0.7914\n",
      "Epoch [8143/10000], Train Loss: 0.0111, Val Loss: 0.7620\n",
      "Epoch [8144/10000], Train Loss: 0.0113, Val Loss: 0.7947\n",
      "Epoch [8145/10000], Train Loss: 0.0113, Val Loss: 0.7598\n",
      "Epoch [8146/10000], Train Loss: 0.0115, Val Loss: 0.7967\n",
      "Epoch [8147/10000], Train Loss: 0.0116, Val Loss: 0.7584\n",
      "Epoch [8148/10000], Train Loss: 0.0118, Val Loss: 0.7984\n",
      "Epoch [8149/10000], Train Loss: 0.0119, Val Loss: 0.7573\n",
      "Epoch [8150/10000], Train Loss: 0.0121, Val Loss: 0.7990\n",
      "Epoch [8151/10000], Train Loss: 0.0121, Val Loss: 0.7574\n",
      "Epoch [8152/10000], Train Loss: 0.0122, Val Loss: 0.7984\n",
      "Epoch [8153/10000], Train Loss: 0.0122, Val Loss: 0.7578\n",
      "Epoch [8154/10000], Train Loss: 0.0122, Val Loss: 0.7973\n",
      "Epoch [8155/10000], Train Loss: 0.0121, Val Loss: 0.7586\n",
      "Epoch [8156/10000], Train Loss: 0.0121, Val Loss: 0.7951\n",
      "Epoch [8157/10000], Train Loss: 0.0118, Val Loss: 0.7601\n",
      "Epoch [8158/10000], Train Loss: 0.0117, Val Loss: 0.7920\n",
      "Epoch [8159/10000], Train Loss: 0.0114, Val Loss: 0.7617\n",
      "Epoch [8160/10000], Train Loss: 0.0112, Val Loss: 0.7885\n",
      "Epoch [8161/10000], Train Loss: 0.0108, Val Loss: 0.7656\n",
      "Epoch [8162/10000], Train Loss: 0.0105, Val Loss: 0.7815\n",
      "Epoch [8163/10000], Train Loss: 0.0102, Val Loss: 0.7714\n",
      "Epoch [8164/10000], Train Loss: 0.0099, Val Loss: 0.7737\n",
      "Epoch [8165/10000], Train Loss: 0.0096, Val Loss: 0.7768\n",
      "Epoch [8166/10000], Train Loss: 0.0095, Val Loss: 0.7671\n",
      "Epoch [8167/10000], Train Loss: 0.0095, Val Loss: 0.7815\n",
      "Epoch [8168/10000], Train Loss: 0.0095, Val Loss: 0.7626\n",
      "Epoch [8169/10000], Train Loss: 0.0096, Val Loss: 0.7845\n",
      "Epoch [8170/10000], Train Loss: 0.0098, Val Loss: 0.7597\n",
      "Epoch [8171/10000], Train Loss: 0.0100, Val Loss: 0.7889\n",
      "Epoch [8172/10000], Train Loss: 0.0102, Val Loss: 0.7557\n",
      "Epoch [8173/10000], Train Loss: 0.0106, Val Loss: 0.7954\n",
      "Epoch [8174/10000], Train Loss: 0.0110, Val Loss: 0.7512\n",
      "Epoch [8175/10000], Train Loss: 0.0116, Val Loss: 0.8039\n",
      "Epoch [8176/10000], Train Loss: 0.0122, Val Loss: 0.7455\n",
      "Epoch [8177/10000], Train Loss: 0.0133, Val Loss: 0.8149\n",
      "Epoch [8178/10000], Train Loss: 0.0141, Val Loss: 0.7389\n",
      "Epoch [8179/10000], Train Loss: 0.0156, Val Loss: 0.8278\n",
      "Epoch [8180/10000], Train Loss: 0.0167, Val Loss: 0.7315\n",
      "Epoch [8181/10000], Train Loss: 0.0186, Val Loss: 0.8417\n",
      "Epoch [8182/10000], Train Loss: 0.0197, Val Loss: 0.7240\n",
      "Epoch [8183/10000], Train Loss: 0.0216, Val Loss: 0.8538\n",
      "Epoch [8184/10000], Train Loss: 0.0221, Val Loss: 0.7177\n",
      "Epoch [8185/10000], Train Loss: 0.0233, Val Loss: 0.8592\n",
      "Epoch [8186/10000], Train Loss: 0.0225, Val Loss: 0.7153\n",
      "Epoch [8187/10000], Train Loss: 0.0222, Val Loss: 0.8529\n",
      "Epoch [8188/10000], Train Loss: 0.0198, Val Loss: 0.7208\n",
      "Epoch [8189/10000], Train Loss: 0.0175, Val Loss: 0.8305\n",
      "Epoch [8190/10000], Train Loss: 0.0145, Val Loss: 0.7354\n",
      "Epoch [8191/10000], Train Loss: 0.0125, Val Loss: 0.8023\n",
      "Epoch [8192/10000], Train Loss: 0.0112, Val Loss: 0.7597\n",
      "Epoch [8193/10000], Train Loss: 0.0109, Val Loss: 0.7742\n",
      "Epoch [8194/10000], Train Loss: 0.0114, Val Loss: 0.7820\n",
      "Epoch [8195/10000], Train Loss: 0.0122, Val Loss: 0.7569\n",
      "Epoch [8196/10000], Train Loss: 0.0129, Val Loss: 0.7966\n",
      "Epoch [8197/10000], Train Loss: 0.0131, Val Loss: 0.7476\n",
      "Epoch [8198/10000], Train Loss: 0.0129, Val Loss: 0.8017\n",
      "Epoch [8199/10000], Train Loss: 0.0121, Val Loss: 0.7442\n",
      "Epoch [8200/10000], Train Loss: 0.0115, Val Loss: 0.8021\n",
      "Epoch [8201/10000], Train Loss: 0.0106, Val Loss: 0.7473\n",
      "Epoch [8202/10000], Train Loss: 0.0101, Val Loss: 0.7975\n",
      "Epoch [8203/10000], Train Loss: 0.0097, Val Loss: 0.7551\n",
      "Epoch [8204/10000], Train Loss: 0.0097, Val Loss: 0.7908\n",
      "Epoch [8205/10000], Train Loss: 0.0097, Val Loss: 0.7647\n",
      "Epoch [8206/10000], Train Loss: 0.0099, Val Loss: 0.7817\n",
      "Epoch [8207/10000], Train Loss: 0.0100, Val Loss: 0.7739\n",
      "Epoch [8208/10000], Train Loss: 0.0099, Val Loss: 0.7739\n",
      "Epoch [8209/10000], Train Loss: 0.0098, Val Loss: 0.7787\n",
      "Epoch [8210/10000], Train Loss: 0.0095, Val Loss: 0.7694\n",
      "Epoch [8211/10000], Train Loss: 0.0092, Val Loss: 0.7813\n",
      "Epoch [8212/10000], Train Loss: 0.0088, Val Loss: 0.7663\n",
      "Epoch [8213/10000], Train Loss: 0.0086, Val Loss: 0.7826\n",
      "Epoch [8214/10000], Train Loss: 0.0085, Val Loss: 0.7660\n",
      "Epoch [8215/10000], Train Loss: 0.0085, Val Loss: 0.7822\n",
      "Epoch [8216/10000], Train Loss: 0.0085, Val Loss: 0.7660\n",
      "Epoch [8217/10000], Train Loss: 0.0086, Val Loss: 0.7819\n",
      "Epoch [8218/10000], Train Loss: 0.0088, Val Loss: 0.7665\n",
      "Epoch [8219/10000], Train Loss: 0.0089, Val Loss: 0.7810\n",
      "Epoch [8220/10000], Train Loss: 0.0089, Val Loss: 0.7676\n",
      "Epoch [8221/10000], Train Loss: 0.0089, Val Loss: 0.7790\n",
      "Epoch [8222/10000], Train Loss: 0.0089, Val Loss: 0.7696\n",
      "Epoch [8223/10000], Train Loss: 0.0088, Val Loss: 0.7765\n",
      "Epoch [8224/10000], Train Loss: 0.0087, Val Loss: 0.7718\n",
      "Epoch [8225/10000], Train Loss: 0.0085, Val Loss: 0.7740\n",
      "Epoch [8226/10000], Train Loss: 0.0084, Val Loss: 0.7745\n",
      "Epoch [8227/10000], Train Loss: 0.0082, Val Loss: 0.7711\n",
      "Epoch [8228/10000], Train Loss: 0.0081, Val Loss: 0.7774\n",
      "Epoch [8229/10000], Train Loss: 0.0081, Val Loss: 0.7685\n",
      "Epoch [8230/10000], Train Loss: 0.0080, Val Loss: 0.7803\n",
      "Epoch [8231/10000], Train Loss: 0.0080, Val Loss: 0.7653\n",
      "Epoch [8232/10000], Train Loss: 0.0081, Val Loss: 0.7841\n",
      "Epoch [8233/10000], Train Loss: 0.0081, Val Loss: 0.7614\n",
      "Epoch [8234/10000], Train Loss: 0.0082, Val Loss: 0.7883\n",
      "Epoch [8235/10000], Train Loss: 0.0083, Val Loss: 0.7564\n",
      "Epoch [8236/10000], Train Loss: 0.0085, Val Loss: 0.7942\n",
      "Epoch [8237/10000], Train Loss: 0.0087, Val Loss: 0.7497\n",
      "Epoch [8238/10000], Train Loss: 0.0090, Val Loss: 0.8023\n",
      "Epoch [8239/10000], Train Loss: 0.0094, Val Loss: 0.7409\n",
      "Epoch [8240/10000], Train Loss: 0.0101, Val Loss: 0.8141\n",
      "Epoch [8241/10000], Train Loss: 0.0108, Val Loss: 0.7297\n",
      "Epoch [8242/10000], Train Loss: 0.0121, Val Loss: 0.8309\n",
      "Epoch [8243/10000], Train Loss: 0.0135, Val Loss: 0.7159\n",
      "Epoch [8244/10000], Train Loss: 0.0159, Val Loss: 0.8545\n",
      "Epoch [8245/10000], Train Loss: 0.0184, Val Loss: 0.7003\n",
      "Epoch [8246/10000], Train Loss: 0.0224, Val Loss: 0.8845\n",
      "Epoch [8247/10000], Train Loss: 0.0262, Val Loss: 0.6856\n",
      "Epoch [8248/10000], Train Loss: 0.0318, Val Loss: 0.9154\n",
      "Epoch [8249/10000], Train Loss: 0.0356, Val Loss: 0.6760\n",
      "Epoch [8250/10000], Train Loss: 0.0403, Val Loss: 0.9297\n",
      "Epoch [8251/10000], Train Loss: 0.0402, Val Loss: 0.6776\n",
      "Epoch [8252/10000], Train Loss: 0.0390, Val Loss: 0.9055\n",
      "Epoch [8253/10000], Train Loss: 0.0317, Val Loss: 0.6998\n",
      "Epoch [8254/10000], Train Loss: 0.0233, Val Loss: 0.8369\n",
      "Epoch [8255/10000], Train Loss: 0.0144, Val Loss: 0.7543\n",
      "Epoch [8256/10000], Train Loss: 0.0092, Val Loss: 0.7587\n",
      "Epoch [8257/10000], Train Loss: 0.0092, Val Loss: 0.8190\n",
      "Epoch [8258/10000], Train Loss: 0.0127, Val Loss: 0.7188\n",
      "Epoch [8259/10000], Train Loss: 0.0172, Val Loss: 0.8515\n",
      "Epoch [8260/10000], Train Loss: 0.0192, Val Loss: 0.7077\n",
      "Epoch [8261/10000], Train Loss: 0.0198, Val Loss: 0.8456\n",
      "Epoch [8262/10000], Train Loss: 0.0167, Val Loss: 0.7244\n",
      "Epoch [8263/10000], Train Loss: 0.0132, Val Loss: 0.8032\n",
      "Epoch [8264/10000], Train Loss: 0.0094, Val Loss: 0.7659\n",
      "Epoch [8265/10000], Train Loss: 0.0075, Val Loss: 0.7572\n",
      "Epoch [8266/10000], Train Loss: 0.0079, Val Loss: 0.8037\n",
      "Epoch [8267/10000], Train Loss: 0.0098, Val Loss: 0.7358\n",
      "Epoch [8268/10000], Train Loss: 0.0115, Val Loss: 0.8191\n",
      "Epoch [8269/10000], Train Loss: 0.0119, Val Loss: 0.7306\n",
      "Epoch [8270/10000], Train Loss: 0.0116, Val Loss: 0.8100\n",
      "Epoch [8271/10000], Train Loss: 0.0101, Val Loss: 0.7486\n",
      "Epoch [8272/10000], Train Loss: 0.0087, Val Loss: 0.7818\n",
      "Epoch [8273/10000], Train Loss: 0.0075, Val Loss: 0.7754\n",
      "Epoch [8274/10000], Train Loss: 0.0072, Val Loss: 0.7578\n",
      "Epoch [8275/10000], Train Loss: 0.0075, Val Loss: 0.7948\n",
      "Epoch [8276/10000], Train Loss: 0.0083, Val Loss: 0.7447\n",
      "Epoch [8277/10000], Train Loss: 0.0088, Val Loss: 0.8036\n",
      "Epoch [8278/10000], Train Loss: 0.0089, Val Loss: 0.7424\n",
      "Epoch [8279/10000], Train Loss: 0.0087, Val Loss: 0.7959\n",
      "Epoch [8280/10000], Train Loss: 0.0081, Val Loss: 0.7561\n",
      "Epoch [8281/10000], Train Loss: 0.0076, Val Loss: 0.7786\n",
      "Epoch [8282/10000], Train Loss: 0.0071, Val Loss: 0.7716\n",
      "Epoch [8283/10000], Train Loss: 0.0069, Val Loss: 0.7644\n",
      "Epoch [8284/10000], Train Loss: 0.0070, Val Loss: 0.7845\n",
      "Epoch [8285/10000], Train Loss: 0.0073, Val Loss: 0.7531\n",
      "Epoch [8286/10000], Train Loss: 0.0075, Val Loss: 0.7918\n",
      "Epoch [8287/10000], Train Loss: 0.0076, Val Loss: 0.7511\n",
      "Epoch [8288/10000], Train Loss: 0.0076, Val Loss: 0.7882\n",
      "Epoch [8289/10000], Train Loss: 0.0074, Val Loss: 0.7573\n",
      "Epoch [8290/10000], Train Loss: 0.0072, Val Loss: 0.7812\n",
      "Epoch [8291/10000], Train Loss: 0.0070, Val Loss: 0.7649\n",
      "Epoch [8292/10000], Train Loss: 0.0068, Val Loss: 0.7723\n",
      "Epoch [8293/10000], Train Loss: 0.0067, Val Loss: 0.7751\n",
      "Epoch [8294/10000], Train Loss: 0.0067, Val Loss: 0.7636\n",
      "Epoch [8295/10000], Train Loss: 0.0068, Val Loss: 0.7813\n",
      "Epoch [8296/10000], Train Loss: 0.0068, Val Loss: 0.7602\n",
      "Epoch [8297/10000], Train Loss: 0.0069, Val Loss: 0.7826\n",
      "Epoch [8298/10000], Train Loss: 0.0069, Val Loss: 0.7612\n",
      "Epoch [8299/10000], Train Loss: 0.0068, Val Loss: 0.7800\n",
      "Epoch [8300/10000], Train Loss: 0.0067, Val Loss: 0.7646\n",
      "Epoch [8301/10000], Train Loss: 0.0066, Val Loss: 0.7751\n",
      "Epoch [8302/10000], Train Loss: 0.0066, Val Loss: 0.7700\n",
      "Epoch [8303/10000], Train Loss: 0.0065, Val Loss: 0.7692\n",
      "Epoch [8304/10000], Train Loss: 0.0065, Val Loss: 0.7743\n",
      "Epoch [8305/10000], Train Loss: 0.0065, Val Loss: 0.7658\n",
      "Epoch [8306/10000], Train Loss: 0.0066, Val Loss: 0.7763\n",
      "Epoch [8307/10000], Train Loss: 0.0066, Val Loss: 0.7635\n",
      "Epoch [8308/10000], Train Loss: 0.0066, Val Loss: 0.7783\n",
      "Epoch [8309/10000], Train Loss: 0.0066, Val Loss: 0.7622\n",
      "Epoch [8310/10000], Train Loss: 0.0067, Val Loss: 0.7782\n",
      "Epoch [8311/10000], Train Loss: 0.0067, Val Loss: 0.7632\n",
      "Epoch [8312/10000], Train Loss: 0.0067, Val Loss: 0.7773\n",
      "Epoch [8313/10000], Train Loss: 0.0068, Val Loss: 0.7643\n",
      "Epoch [8314/10000], Train Loss: 0.0069, Val Loss: 0.7759\n",
      "Epoch [8315/10000], Train Loss: 0.0070, Val Loss: 0.7669\n",
      "Epoch [8316/10000], Train Loss: 0.0072, Val Loss: 0.7732\n",
      "Epoch [8317/10000], Train Loss: 0.0074, Val Loss: 0.7706\n",
      "Epoch [8318/10000], Train Loss: 0.0078, Val Loss: 0.7707\n",
      "Epoch [8319/10000], Train Loss: 0.0083, Val Loss: 0.7749\n",
      "Epoch [8320/10000], Train Loss: 0.0090, Val Loss: 0.7681\n",
      "Epoch [8321/10000], Train Loss: 0.0098, Val Loss: 0.7809\n",
      "Epoch [8322/10000], Train Loss: 0.0110, Val Loss: 0.7655\n",
      "Epoch [8323/10000], Train Loss: 0.0123, Val Loss: 0.7884\n",
      "Epoch [8324/10000], Train Loss: 0.0139, Val Loss: 0.7634\n",
      "Epoch [8325/10000], Train Loss: 0.0154, Val Loss: 0.7952\n",
      "Epoch [8326/10000], Train Loss: 0.0167, Val Loss: 0.7611\n",
      "Epoch [8327/10000], Train Loss: 0.0173, Val Loss: 0.7986\n",
      "Epoch [8328/10000], Train Loss: 0.0170, Val Loss: 0.7564\n",
      "Epoch [8329/10000], Train Loss: 0.0154, Val Loss: 0.7949\n",
      "Epoch [8330/10000], Train Loss: 0.0130, Val Loss: 0.7522\n",
      "Epoch [8331/10000], Train Loss: 0.0103, Val Loss: 0.7870\n",
      "Epoch [8332/10000], Train Loss: 0.0080, Val Loss: 0.7495\n",
      "Epoch [8333/10000], Train Loss: 0.0068, Val Loss: 0.7825\n",
      "Epoch [8334/10000], Train Loss: 0.0067, Val Loss: 0.7518\n",
      "Epoch [8335/10000], Train Loss: 0.0076, Val Loss: 0.7810\n",
      "Epoch [8336/10000], Train Loss: 0.0087, Val Loss: 0.7558\n",
      "Epoch [8337/10000], Train Loss: 0.0097, Val Loss: 0.7801\n",
      "Epoch [8338/10000], Train Loss: 0.0100, Val Loss: 0.7568\n",
      "Epoch [8339/10000], Train Loss: 0.0097, Val Loss: 0.7780\n",
      "Epoch [8340/10000], Train Loss: 0.0087, Val Loss: 0.7562\n",
      "Epoch [8341/10000], Train Loss: 0.0076, Val Loss: 0.7747\n",
      "Epoch [8342/10000], Train Loss: 0.0066, Val Loss: 0.7574\n",
      "Epoch [8343/10000], Train Loss: 0.0060, Val Loss: 0.7714\n",
      "Epoch [8344/10000], Train Loss: 0.0060, Val Loss: 0.7607\n",
      "Epoch [8345/10000], Train Loss: 0.0064, Val Loss: 0.7693\n",
      "Epoch [8346/10000], Train Loss: 0.0069, Val Loss: 0.7636\n",
      "Epoch [8347/10000], Train Loss: 0.0072, Val Loss: 0.7677\n",
      "Epoch [8348/10000], Train Loss: 0.0073, Val Loss: 0.7649\n",
      "Epoch [8349/10000], Train Loss: 0.0071, Val Loss: 0.7662\n",
      "Epoch [8350/10000], Train Loss: 0.0066, Val Loss: 0.7652\n",
      "Epoch [8351/10000], Train Loss: 0.0062, Val Loss: 0.7651\n",
      "Epoch [8352/10000], Train Loss: 0.0058, Val Loss: 0.7656\n",
      "Epoch [8353/10000], Train Loss: 0.0057, Val Loss: 0.7649\n",
      "Epoch [8354/10000], Train Loss: 0.0057, Val Loss: 0.7666\n",
      "Epoch [8355/10000], Train Loss: 0.0059, Val Loss: 0.7646\n",
      "Epoch [8356/10000], Train Loss: 0.0060, Val Loss: 0.7673\n",
      "Epoch [8357/10000], Train Loss: 0.0062, Val Loss: 0.7652\n",
      "Epoch [8358/10000], Train Loss: 0.0062, Val Loss: 0.7669\n",
      "Epoch [8359/10000], Train Loss: 0.0061, Val Loss: 0.7659\n",
      "Epoch [8360/10000], Train Loss: 0.0060, Val Loss: 0.7659\n",
      "Epoch [8361/10000], Train Loss: 0.0058, Val Loss: 0.7674\n",
      "Epoch [8362/10000], Train Loss: 0.0057, Val Loss: 0.7640\n",
      "Epoch [8363/10000], Train Loss: 0.0056, Val Loss: 0.7697\n",
      "Epoch [8364/10000], Train Loss: 0.0055, Val Loss: 0.7619\n",
      "Epoch [8365/10000], Train Loss: 0.0055, Val Loss: 0.7724\n",
      "Epoch [8366/10000], Train Loss: 0.0056, Val Loss: 0.7595\n",
      "Epoch [8367/10000], Train Loss: 0.0056, Val Loss: 0.7755\n",
      "Epoch [8368/10000], Train Loss: 0.0057, Val Loss: 0.7560\n",
      "Epoch [8369/10000], Train Loss: 0.0058, Val Loss: 0.7795\n",
      "Epoch [8370/10000], Train Loss: 0.0058, Val Loss: 0.7514\n",
      "Epoch [8371/10000], Train Loss: 0.0060, Val Loss: 0.7855\n",
      "Epoch [8372/10000], Train Loss: 0.0061, Val Loss: 0.7445\n",
      "Epoch [8373/10000], Train Loss: 0.0064, Val Loss: 0.7950\n",
      "Epoch [8374/10000], Train Loss: 0.0068, Val Loss: 0.7342\n",
      "Epoch [8375/10000], Train Loss: 0.0076, Val Loss: 0.8106\n",
      "Epoch [8376/10000], Train Loss: 0.0087, Val Loss: 0.7202\n",
      "Epoch [8377/10000], Train Loss: 0.0105, Val Loss: 0.8343\n",
      "Epoch [8378/10000], Train Loss: 0.0128, Val Loss: 0.7022\n",
      "Epoch [8379/10000], Train Loss: 0.0167, Val Loss: 0.8702\n",
      "Epoch [8380/10000], Train Loss: 0.0211, Val Loss: 0.6815\n",
      "Epoch [8381/10000], Train Loss: 0.0286, Val Loss: 0.9196\n",
      "Epoch [8382/10000], Train Loss: 0.0359, Val Loss: 0.6640\n",
      "Epoch [8383/10000], Train Loss: 0.0468, Val Loss: 0.9695\n",
      "Epoch [8384/10000], Train Loss: 0.0535, Val Loss: 0.6566\n",
      "Epoch [8385/10000], Train Loss: 0.0602, Val Loss: 0.9757\n",
      "Epoch [8386/10000], Train Loss: 0.0553, Val Loss: 0.6672\n",
      "Epoch [8387/10000], Train Loss: 0.0460, Val Loss: 0.8997\n",
      "Epoch [8388/10000], Train Loss: 0.0282, Val Loss: 0.7167\n",
      "Epoch [8389/10000], Train Loss: 0.0134, Val Loss: 0.7823\n",
      "Epoch [8390/10000], Train Loss: 0.0065, Val Loss: 0.8083\n",
      "Epoch [8391/10000], Train Loss: 0.0093, Val Loss: 0.7094\n",
      "Epoch [8392/10000], Train Loss: 0.0168, Val Loss: 0.8672\n",
      "Epoch [8393/10000], Train Loss: 0.0218, Val Loss: 0.6899\n",
      "Epoch [8394/10000], Train Loss: 0.0233, Val Loss: 0.8557\n",
      "Epoch [8395/10000], Train Loss: 0.0179, Val Loss: 0.7183\n",
      "Epoch [8396/10000], Train Loss: 0.0105, Val Loss: 0.7789\n",
      "Epoch [8397/10000], Train Loss: 0.0061, Val Loss: 0.7837\n",
      "Epoch [8398/10000], Train Loss: 0.0068, Val Loss: 0.7262\n",
      "Epoch [8399/10000], Train Loss: 0.0106, Val Loss: 0.8261\n",
      "Epoch [8400/10000], Train Loss: 0.0134, Val Loss: 0.7103\n",
      "Epoch [8401/10000], Train Loss: 0.0142, Val Loss: 0.8235\n",
      "Epoch [8402/10000], Train Loss: 0.0113, Val Loss: 0.7288\n",
      "Epoch [8403/10000], Train Loss: 0.0077, Val Loss: 0.7770\n",
      "Epoch [8404/10000], Train Loss: 0.0053, Val Loss: 0.7759\n",
      "Epoch [8405/10000], Train Loss: 0.0057, Val Loss: 0.7379\n",
      "Epoch [8406/10000], Train Loss: 0.0075, Val Loss: 0.8040\n",
      "Epoch [8407/10000], Train Loss: 0.0091, Val Loss: 0.7283\n",
      "Epoch [8408/10000], Train Loss: 0.0097, Val Loss: 0.8038\n",
      "Epoch [8409/10000], Train Loss: 0.0084, Val Loss: 0.7381\n",
      "Epoch [8410/10000], Train Loss: 0.0068, Val Loss: 0.7784\n",
      "Epoch [8411/10000], Train Loss: 0.0052, Val Loss: 0.7695\n",
      "Epoch [8412/10000], Train Loss: 0.0049, Val Loss: 0.7480\n",
      "Epoch [8413/10000], Train Loss: 0.0055, Val Loss: 0.7915\n",
      "Epoch [8414/10000], Train Loss: 0.0064, Val Loss: 0.7397\n",
      "Epoch [8415/10000], Train Loss: 0.0068, Val Loss: 0.7908\n",
      "Epoch [8416/10000], Train Loss: 0.0065, Val Loss: 0.7465\n",
      "Epoch [8417/10000], Train Loss: 0.0057, Val Loss: 0.7747\n",
      "Epoch [8418/10000], Train Loss: 0.0050, Val Loss: 0.7654\n",
      "Epoch [8419/10000], Train Loss: 0.0047, Val Loss: 0.7527\n",
      "Epoch [8420/10000], Train Loss: 0.0050, Val Loss: 0.7825\n",
      "Epoch [8421/10000], Train Loss: 0.0054, Val Loss: 0.7438\n",
      "Epoch [8422/10000], Train Loss: 0.0057, Val Loss: 0.7841\n",
      "Epoch [8423/10000], Train Loss: 0.0057, Val Loss: 0.7486\n",
      "Epoch [8424/10000], Train Loss: 0.0055, Val Loss: 0.7755\n",
      "Epoch [8425/10000], Train Loss: 0.0050, Val Loss: 0.7611\n",
      "Epoch [8426/10000], Train Loss: 0.0047, Val Loss: 0.7611\n",
      "Epoch [8427/10000], Train Loss: 0.0047, Val Loss: 0.7761\n",
      "Epoch [8428/10000], Train Loss: 0.0048, Val Loss: 0.7515\n",
      "Epoch [8429/10000], Train Loss: 0.0050, Val Loss: 0.7812\n",
      "Epoch [8430/10000], Train Loss: 0.0050, Val Loss: 0.7524\n",
      "Epoch [8431/10000], Train Loss: 0.0050, Val Loss: 0.7766\n",
      "Epoch [8432/10000], Train Loss: 0.0048, Val Loss: 0.7604\n",
      "Epoch [8433/10000], Train Loss: 0.0046, Val Loss: 0.7661\n",
      "Epoch [8434/10000], Train Loss: 0.0045, Val Loss: 0.7704\n",
      "Epoch [8435/10000], Train Loss: 0.0045, Val Loss: 0.7580\n",
      "Epoch [8436/10000], Train Loss: 0.0046, Val Loss: 0.7757\n",
      "Epoch [8437/10000], Train Loss: 0.0047, Val Loss: 0.7550\n",
      "Epoch [8438/10000], Train Loss: 0.0047, Val Loss: 0.7758\n",
      "Epoch [8439/10000], Train Loss: 0.0046, Val Loss: 0.7577\n",
      "Epoch [8440/10000], Train Loss: 0.0046, Val Loss: 0.7711\n",
      "Epoch [8441/10000], Train Loss: 0.0045, Val Loss: 0.7640\n",
      "Epoch [8442/10000], Train Loss: 0.0044, Val Loss: 0.7645\n",
      "Epoch [8443/10000], Train Loss: 0.0044, Val Loss: 0.7696\n",
      "Epoch [8444/10000], Train Loss: 0.0044, Val Loss: 0.7598\n",
      "Epoch [8445/10000], Train Loss: 0.0045, Val Loss: 0.7730\n",
      "Epoch [8446/10000], Train Loss: 0.0045, Val Loss: 0.7579\n",
      "Epoch [8447/10000], Train Loss: 0.0045, Val Loss: 0.7730\n",
      "Epoch [8448/10000], Train Loss: 0.0044, Val Loss: 0.7598\n",
      "Epoch [8449/10000], Train Loss: 0.0044, Val Loss: 0.7699\n",
      "Epoch [8450/10000], Train Loss: 0.0044, Val Loss: 0.7638\n",
      "Epoch [8451/10000], Train Loss: 0.0043, Val Loss: 0.7655\n",
      "Epoch [8452/10000], Train Loss: 0.0043, Val Loss: 0.7677\n",
      "Epoch [8453/10000], Train Loss: 0.0043, Val Loss: 0.7617\n",
      "Epoch [8454/10000], Train Loss: 0.0043, Val Loss: 0.7700\n",
      "Epoch [8455/10000], Train Loss: 0.0043, Val Loss: 0.7595\n",
      "Epoch [8456/10000], Train Loss: 0.0043, Val Loss: 0.7706\n",
      "Epoch [8457/10000], Train Loss: 0.0043, Val Loss: 0.7595\n",
      "Epoch [8458/10000], Train Loss: 0.0043, Val Loss: 0.7695\n",
      "Epoch [8459/10000], Train Loss: 0.0042, Val Loss: 0.7606\n",
      "Epoch [8460/10000], Train Loss: 0.0042, Val Loss: 0.7678\n",
      "Epoch [8461/10000], Train Loss: 0.0042, Val Loss: 0.7624\n",
      "Epoch [8462/10000], Train Loss: 0.0042, Val Loss: 0.7655\n",
      "Epoch [8463/10000], Train Loss: 0.0042, Val Loss: 0.7652\n",
      "Epoch [8464/10000], Train Loss: 0.0041, Val Loss: 0.7625\n",
      "Epoch [8465/10000], Train Loss: 0.0041, Val Loss: 0.7672\n",
      "Epoch [8466/10000], Train Loss: 0.0041, Val Loss: 0.7607\n",
      "Epoch [8467/10000], Train Loss: 0.0041, Val Loss: 0.7680\n",
      "Epoch [8468/10000], Train Loss: 0.0041, Val Loss: 0.7595\n",
      "Epoch [8469/10000], Train Loss: 0.0041, Val Loss: 0.7686\n",
      "Epoch [8470/10000], Train Loss: 0.0041, Val Loss: 0.7594\n",
      "Epoch [8471/10000], Train Loss: 0.0041, Val Loss: 0.7683\n",
      "Epoch [8472/10000], Train Loss: 0.0041, Val Loss: 0.7601\n",
      "Epoch [8473/10000], Train Loss: 0.0041, Val Loss: 0.7675\n",
      "Epoch [8474/10000], Train Loss: 0.0041, Val Loss: 0.7607\n",
      "Epoch [8475/10000], Train Loss: 0.0041, Val Loss: 0.7670\n",
      "Epoch [8476/10000], Train Loss: 0.0041, Val Loss: 0.7614\n",
      "Epoch [8477/10000], Train Loss: 0.0042, Val Loss: 0.7663\n",
      "Epoch [8478/10000], Train Loss: 0.0042, Val Loss: 0.7619\n",
      "Epoch [8479/10000], Train Loss: 0.0043, Val Loss: 0.7662\n",
      "Epoch [8480/10000], Train Loss: 0.0044, Val Loss: 0.7618\n",
      "Epoch [8481/10000], Train Loss: 0.0045, Val Loss: 0.7671\n",
      "Epoch [8482/10000], Train Loss: 0.0047, Val Loss: 0.7613\n",
      "Epoch [8483/10000], Train Loss: 0.0050, Val Loss: 0.7687\n",
      "Epoch [8484/10000], Train Loss: 0.0054, Val Loss: 0.7603\n",
      "Epoch [8485/10000], Train Loss: 0.0058, Val Loss: 0.7721\n",
      "Epoch [8486/10000], Train Loss: 0.0065, Val Loss: 0.7585\n",
      "Epoch [8487/10000], Train Loss: 0.0073, Val Loss: 0.7775\n",
      "Epoch [8488/10000], Train Loss: 0.0083, Val Loss: 0.7564\n",
      "Epoch [8489/10000], Train Loss: 0.0096, Val Loss: 0.7850\n",
      "Epoch [8490/10000], Train Loss: 0.0111, Val Loss: 0.7539\n",
      "Epoch [8491/10000], Train Loss: 0.0127, Val Loss: 0.7944\n",
      "Epoch [8492/10000], Train Loss: 0.0142, Val Loss: 0.7497\n",
      "Epoch [8493/10000], Train Loss: 0.0153, Val Loss: 0.8026\n",
      "Epoch [8494/10000], Train Loss: 0.0157, Val Loss: 0.7433\n",
      "Epoch [8495/10000], Train Loss: 0.0150, Val Loss: 0.8056\n",
      "Epoch [8496/10000], Train Loss: 0.0133, Val Loss: 0.7350\n",
      "Epoch [8497/10000], Train Loss: 0.0110, Val Loss: 0.8043\n",
      "Epoch [8498/10000], Train Loss: 0.0087, Val Loss: 0.7282\n",
      "Epoch [8499/10000], Train Loss: 0.0071, Val Loss: 0.8018\n",
      "Epoch [8500/10000], Train Loss: 0.0065, Val Loss: 0.7279\n",
      "Epoch [8501/10000], Train Loss: 0.0069, Val Loss: 0.8008\n",
      "Epoch [8502/10000], Train Loss: 0.0077, Val Loss: 0.7314\n",
      "Epoch [8503/10000], Train Loss: 0.0091, Val Loss: 0.8012\n",
      "Epoch [8504/10000], Train Loss: 0.0096, Val Loss: 0.7353\n",
      "Epoch [8505/10000], Train Loss: 0.0102, Val Loss: 0.7993\n",
      "Epoch [8506/10000], Train Loss: 0.0094, Val Loss: 0.7389\n",
      "Epoch [8507/10000], Train Loss: 0.0082, Val Loss: 0.7909\n",
      "Epoch [8508/10000], Train Loss: 0.0064, Val Loss: 0.7449\n",
      "Epoch [8509/10000], Train Loss: 0.0049, Val Loss: 0.7780\n",
      "Epoch [8510/10000], Train Loss: 0.0041, Val Loss: 0.7556\n",
      "Epoch [8511/10000], Train Loss: 0.0041, Val Loss: 0.7652\n",
      "Epoch [8512/10000], Train Loss: 0.0047, Val Loss: 0.7659\n",
      "Epoch [8513/10000], Train Loss: 0.0054, Val Loss: 0.7576\n",
      "Epoch [8514/10000], Train Loss: 0.0057, Val Loss: 0.7693\n",
      "Epoch [8515/10000], Train Loss: 0.0056, Val Loss: 0.7531\n",
      "Epoch [8516/10000], Train Loss: 0.0051, Val Loss: 0.7689\n",
      "Epoch [8517/10000], Train Loss: 0.0045, Val Loss: 0.7523\n",
      "Epoch [8518/10000], Train Loss: 0.0039, Val Loss: 0.7662\n",
      "Epoch [8519/10000], Train Loss: 0.0036, Val Loss: 0.7552\n",
      "Epoch [8520/10000], Train Loss: 0.0036, Val Loss: 0.7640\n",
      "Epoch [8521/10000], Train Loss: 0.0039, Val Loss: 0.7579\n",
      "Epoch [8522/10000], Train Loss: 0.0041, Val Loss: 0.7633\n",
      "Epoch [8523/10000], Train Loss: 0.0044, Val Loss: 0.7600\n",
      "Epoch [8524/10000], Train Loss: 0.0044, Val Loss: 0.7625\n",
      "Epoch [8525/10000], Train Loss: 0.0043, Val Loss: 0.7616\n",
      "Epoch [8526/10000], Train Loss: 0.0040, Val Loss: 0.7616\n",
      "Epoch [8527/10000], Train Loss: 0.0037, Val Loss: 0.7621\n",
      "Epoch [8528/10000], Train Loss: 0.0035, Val Loss: 0.7612\n",
      "Epoch [8529/10000], Train Loss: 0.0034, Val Loss: 0.7629\n",
      "Epoch [8530/10000], Train Loss: 0.0034, Val Loss: 0.7609\n",
      "Epoch [8531/10000], Train Loss: 0.0035, Val Loss: 0.7639\n",
      "Epoch [8532/10000], Train Loss: 0.0036, Val Loss: 0.7608\n",
      "Epoch [8533/10000], Train Loss: 0.0037, Val Loss: 0.7642\n",
      "Epoch [8534/10000], Train Loss: 0.0037, Val Loss: 0.7610\n",
      "Epoch [8535/10000], Train Loss: 0.0037, Val Loss: 0.7645\n",
      "Epoch [8536/10000], Train Loss: 0.0037, Val Loss: 0.7603\n",
      "Epoch [8537/10000], Train Loss: 0.0036, Val Loss: 0.7657\n",
      "Epoch [8538/10000], Train Loss: 0.0035, Val Loss: 0.7588\n",
      "Epoch [8539/10000], Train Loss: 0.0034, Val Loss: 0.7672\n",
      "Epoch [8540/10000], Train Loss: 0.0034, Val Loss: 0.7563\n",
      "Epoch [8541/10000], Train Loss: 0.0034, Val Loss: 0.7705\n",
      "Epoch [8542/10000], Train Loss: 0.0034, Val Loss: 0.7516\n",
      "Epoch [8543/10000], Train Loss: 0.0036, Val Loss: 0.7770\n",
      "Epoch [8544/10000], Train Loss: 0.0038, Val Loss: 0.7439\n",
      "Epoch [8545/10000], Train Loss: 0.0041, Val Loss: 0.7870\n",
      "Epoch [8546/10000], Train Loss: 0.0045, Val Loss: 0.7334\n",
      "Epoch [8547/10000], Train Loss: 0.0053, Val Loss: 0.8030\n",
      "Epoch [8548/10000], Train Loss: 0.0063, Val Loss: 0.7181\n",
      "Epoch [8549/10000], Train Loss: 0.0080, Val Loss: 0.8283\n",
      "Epoch [8550/10000], Train Loss: 0.0102, Val Loss: 0.6988\n",
      "Epoch [8551/10000], Train Loss: 0.0140, Val Loss: 0.8660\n",
      "Epoch [8552/10000], Train Loss: 0.0185, Val Loss: 0.6768\n",
      "Epoch [8553/10000], Train Loss: 0.0262, Val Loss: 0.9198\n",
      "Epoch [8554/10000], Train Loss: 0.0342, Val Loss: 0.6566\n",
      "Epoch [8555/10000], Train Loss: 0.0462, Val Loss: 0.9772\n",
      "Epoch [8556/10000], Train Loss: 0.0548, Val Loss: 0.6468\n",
      "Epoch [8557/10000], Train Loss: 0.0638, Val Loss: 0.9926\n",
      "Epoch [8558/10000], Train Loss: 0.0609, Val Loss: 0.6546\n",
      "Epoch [8559/10000], Train Loss: 0.0522, Val Loss: 0.9167\n",
      "Epoch [8560/10000], Train Loss: 0.0327, Val Loss: 0.7018\n",
      "Epoch [8561/10000], Train Loss: 0.0150, Val Loss: 0.7859\n",
      "Epoch [8562/10000], Train Loss: 0.0053, Val Loss: 0.8016\n",
      "Epoch [8563/10000], Train Loss: 0.0070, Val Loss: 0.6998\n",
      "Epoch [8564/10000], Train Loss: 0.0152, Val Loss: 0.8727\n",
      "Epoch [8565/10000], Train Loss: 0.0215, Val Loss: 0.6833\n",
      "Epoch [8566/10000], Train Loss: 0.0218, Val Loss: 0.8493\n",
      "Epoch [8567/10000], Train Loss: 0.0152, Val Loss: 0.7199\n",
      "Epoch [8568/10000], Train Loss: 0.0078, Val Loss: 0.7683\n",
      "Epoch [8569/10000], Train Loss: 0.0048, Val Loss: 0.7931\n",
      "Epoch [8570/10000], Train Loss: 0.0071, Val Loss: 0.7145\n",
      "Epoch [8571/10000], Train Loss: 0.0115, Val Loss: 0.8352\n",
      "Epoch [8572/10000], Train Loss: 0.0135, Val Loss: 0.7035\n",
      "Epoch [8573/10000], Train Loss: 0.0136, Val Loss: 0.8246\n",
      "Epoch [8574/10000], Train Loss: 0.0097, Val Loss: 0.7300\n",
      "Epoch [8575/10000], Train Loss: 0.0056, Val Loss: 0.7732\n",
      "Epoch [8576/10000], Train Loss: 0.0033, Val Loss: 0.7803\n",
      "Epoch [8577/10000], Train Loss: 0.0042, Val Loss: 0.7315\n",
      "Epoch [8578/10000], Train Loss: 0.0067, Val Loss: 0.8135\n",
      "Epoch [8579/10000], Train Loss: 0.0086, Val Loss: 0.7199\n",
      "Epoch [8580/10000], Train Loss: 0.0090, Val Loss: 0.8079\n",
      "Epoch [8581/10000], Train Loss: 0.0071, Val Loss: 0.7369\n",
      "Epoch [8582/10000], Train Loss: 0.0047, Val Loss: 0.7713\n",
      "Epoch [8583/10000], Train Loss: 0.0031, Val Loss: 0.7737\n",
      "Epoch [8584/10000], Train Loss: 0.0033, Val Loss: 0.7374\n",
      "Epoch [8585/10000], Train Loss: 0.0045, Val Loss: 0.7976\n",
      "Epoch [8586/10000], Train Loss: 0.0057, Val Loss: 0.7288\n",
      "Epoch [8587/10000], Train Loss: 0.0064, Val Loss: 0.7955\n",
      "Epoch [8588/10000], Train Loss: 0.0057, Val Loss: 0.7415\n",
      "Epoch [8589/10000], Train Loss: 0.0044, Val Loss: 0.7702\n",
      "Epoch [8590/10000], Train Loss: 0.0032, Val Loss: 0.7689\n",
      "Epoch [8591/10000], Train Loss: 0.0030, Val Loss: 0.7431\n",
      "Epoch [8592/10000], Train Loss: 0.0035, Val Loss: 0.7881\n",
      "Epoch [8593/10000], Train Loss: 0.0042, Val Loss: 0.7357\n",
      "Epoch [8594/10000], Train Loss: 0.0046, Val Loss: 0.7860\n",
      "Epoch [8595/10000], Train Loss: 0.0043, Val Loss: 0.7460\n",
      "Epoch [8596/10000], Train Loss: 0.0037, Val Loss: 0.7680\n",
      "Epoch [8597/10000], Train Loss: 0.0031, Val Loss: 0.7661\n",
      "Epoch [8598/10000], Train Loss: 0.0029, Val Loss: 0.7481\n",
      "Epoch [8599/10000], Train Loss: 0.0031, Val Loss: 0.7813\n",
      "Epoch [8600/10000], Train Loss: 0.0035, Val Loss: 0.7423\n",
      "Epoch [8601/10000], Train Loss: 0.0037, Val Loss: 0.7799\n",
      "Epoch [8602/10000], Train Loss: 0.0035, Val Loss: 0.7508\n",
      "Epoch [8603/10000], Train Loss: 0.0031, Val Loss: 0.7664\n",
      "Epoch [8604/10000], Train Loss: 0.0028, Val Loss: 0.7656\n",
      "Epoch [8605/10000], Train Loss: 0.0028, Val Loss: 0.7524\n",
      "Epoch [8606/10000], Train Loss: 0.0029, Val Loss: 0.7765\n",
      "Epoch [8607/10000], Train Loss: 0.0031, Val Loss: 0.7466\n",
      "Epoch [8608/10000], Train Loss: 0.0032, Val Loss: 0.7768\n",
      "Epoch [8609/10000], Train Loss: 0.0031, Val Loss: 0.7503\n",
      "Epoch [8610/10000], Train Loss: 0.0030, Val Loss: 0.7690\n",
      "Epoch [8611/10000], Train Loss: 0.0028, Val Loss: 0.7597\n",
      "Epoch [8612/10000], Train Loss: 0.0027, Val Loss: 0.7585\n",
      "Epoch [8613/10000], Train Loss: 0.0027, Val Loss: 0.7684\n",
      "Epoch [8614/10000], Train Loss: 0.0028, Val Loss: 0.7519\n",
      "Epoch [8615/10000], Train Loss: 0.0029, Val Loss: 0.7727\n",
      "Epoch [8616/10000], Train Loss: 0.0029, Val Loss: 0.7504\n",
      "Epoch [8617/10000], Train Loss: 0.0029, Val Loss: 0.7715\n",
      "Epoch [8618/10000], Train Loss: 0.0028, Val Loss: 0.7549\n",
      "Epoch [8619/10000], Train Loss: 0.0027, Val Loss: 0.7655\n",
      "Epoch [8620/10000], Train Loss: 0.0026, Val Loss: 0.7620\n",
      "Epoch [8621/10000], Train Loss: 0.0026, Val Loss: 0.7591\n",
      "Epoch [8622/10000], Train Loss: 0.0026, Val Loss: 0.7671\n",
      "Epoch [8623/10000], Train Loss: 0.0027, Val Loss: 0.7552\n",
      "Epoch [8624/10000], Train Loss: 0.0027, Val Loss: 0.7689\n",
      "Epoch [8625/10000], Train Loss: 0.0027, Val Loss: 0.7550\n",
      "Epoch [8626/10000], Train Loss: 0.0027, Val Loss: 0.7664\n",
      "Epoch [8627/10000], Train Loss: 0.0026, Val Loss: 0.7583\n",
      "Epoch [8628/10000], Train Loss: 0.0026, Val Loss: 0.7619\n",
      "Epoch [8629/10000], Train Loss: 0.0025, Val Loss: 0.7622\n",
      "Epoch [8630/10000], Train Loss: 0.0025, Val Loss: 0.7583\n",
      "Epoch [8631/10000], Train Loss: 0.0025, Val Loss: 0.7645\n",
      "Epoch [8632/10000], Train Loss: 0.0026, Val Loss: 0.7568\n",
      "Epoch [8633/10000], Train Loss: 0.0026, Val Loss: 0.7650\n",
      "Epoch [8634/10000], Train Loss: 0.0026, Val Loss: 0.7575\n",
      "Epoch [8635/10000], Train Loss: 0.0025, Val Loss: 0.7634\n",
      "Epoch [8636/10000], Train Loss: 0.0025, Val Loss: 0.7603\n",
      "Epoch [8637/10000], Train Loss: 0.0025, Val Loss: 0.7605\n",
      "Epoch [8638/10000], Train Loss: 0.0025, Val Loss: 0.7630\n",
      "Epoch [8639/10000], Train Loss: 0.0025, Val Loss: 0.7583\n",
      "Epoch [8640/10000], Train Loss: 0.0025, Val Loss: 0.7647\n",
      "Epoch [8641/10000], Train Loss: 0.0025, Val Loss: 0.7568\n",
      "Epoch [8642/10000], Train Loss: 0.0025, Val Loss: 0.7654\n",
      "Epoch [8643/10000], Train Loss: 0.0025, Val Loss: 0.7565\n",
      "Epoch [8644/10000], Train Loss: 0.0025, Val Loss: 0.7649\n",
      "Epoch [8645/10000], Train Loss: 0.0025, Val Loss: 0.7572\n",
      "Epoch [8646/10000], Train Loss: 0.0024, Val Loss: 0.7639\n",
      "Epoch [8647/10000], Train Loss: 0.0024, Val Loss: 0.7584\n",
      "Epoch [8648/10000], Train Loss: 0.0024, Val Loss: 0.7624\n",
      "Epoch [8649/10000], Train Loss: 0.0024, Val Loss: 0.7598\n",
      "Epoch [8650/10000], Train Loss: 0.0024, Val Loss: 0.7609\n",
      "Epoch [8651/10000], Train Loss: 0.0024, Val Loss: 0.7610\n",
      "Epoch [8652/10000], Train Loss: 0.0024, Val Loss: 0.7596\n",
      "Epoch [8653/10000], Train Loss: 0.0024, Val Loss: 0.7616\n",
      "Epoch [8654/10000], Train Loss: 0.0024, Val Loss: 0.7589\n",
      "Epoch [8655/10000], Train Loss: 0.0024, Val Loss: 0.7620\n",
      "Epoch [8656/10000], Train Loss: 0.0024, Val Loss: 0.7585\n",
      "Epoch [8657/10000], Train Loss: 0.0024, Val Loss: 0.7623\n",
      "Epoch [8658/10000], Train Loss: 0.0024, Val Loss: 0.7584\n",
      "Epoch [8659/10000], Train Loss: 0.0024, Val Loss: 0.7623\n",
      "Epoch [8660/10000], Train Loss: 0.0024, Val Loss: 0.7586\n",
      "Epoch [8661/10000], Train Loss: 0.0024, Val Loss: 0.7620\n",
      "Epoch [8662/10000], Train Loss: 0.0024, Val Loss: 0.7592\n",
      "Epoch [8663/10000], Train Loss: 0.0024, Val Loss: 0.7613\n",
      "Epoch [8664/10000], Train Loss: 0.0024, Val Loss: 0.7602\n",
      "Epoch [8665/10000], Train Loss: 0.0024, Val Loss: 0.7602\n",
      "Epoch [8666/10000], Train Loss: 0.0025, Val Loss: 0.7618\n",
      "Epoch [8667/10000], Train Loss: 0.0026, Val Loss: 0.7585\n",
      "Epoch [8668/10000], Train Loss: 0.0027, Val Loss: 0.7641\n",
      "Epoch [8669/10000], Train Loss: 0.0028, Val Loss: 0.7562\n",
      "Epoch [8670/10000], Train Loss: 0.0030, Val Loss: 0.7675\n",
      "Epoch [8671/10000], Train Loss: 0.0034, Val Loss: 0.7535\n",
      "Epoch [8672/10000], Train Loss: 0.0038, Val Loss: 0.7724\n",
      "Epoch [8673/10000], Train Loss: 0.0045, Val Loss: 0.7504\n",
      "Epoch [8674/10000], Train Loss: 0.0055, Val Loss: 0.7799\n",
      "Epoch [8675/10000], Train Loss: 0.0070, Val Loss: 0.7474\n",
      "Epoch [8676/10000], Train Loss: 0.0089, Val Loss: 0.7914\n",
      "Epoch [8677/10000], Train Loss: 0.0116, Val Loss: 0.7454\n",
      "Epoch [8678/10000], Train Loss: 0.0149, Val Loss: 0.8064\n",
      "Epoch [8679/10000], Train Loss: 0.0189, Val Loss: 0.7464\n",
      "Epoch [8680/10000], Train Loss: 0.0226, Val Loss: 0.8192\n",
      "Epoch [8681/10000], Train Loss: 0.0254, Val Loss: 0.7467\n",
      "Epoch [8682/10000], Train Loss: 0.0252, Val Loss: 0.8175\n",
      "Epoch [8683/10000], Train Loss: 0.0219, Val Loss: 0.7410\n",
      "Epoch [8684/10000], Train Loss: 0.0155, Val Loss: 0.8011\n",
      "Epoch [8685/10000], Train Loss: 0.0087, Val Loss: 0.7343\n",
      "Epoch [8686/10000], Train Loss: 0.0046, Val Loss: 0.7907\n",
      "Epoch [8687/10000], Train Loss: 0.0043, Val Loss: 0.7411\n",
      "Epoch [8688/10000], Train Loss: 0.0068, Val Loss: 0.7893\n",
      "Epoch [8689/10000], Train Loss: 0.0098, Val Loss: 0.7472\n",
      "Epoch [8690/10000], Train Loss: 0.0122, Val Loss: 0.7914\n",
      "Epoch [8691/10000], Train Loss: 0.0116, Val Loss: 0.7422\n",
      "Epoch [8692/10000], Train Loss: 0.0098, Val Loss: 0.7904\n",
      "Epoch [8693/10000], Train Loss: 0.0064, Val Loss: 0.7350\n",
      "Epoch [8694/10000], Train Loss: 0.0041, Val Loss: 0.7878\n",
      "Epoch [8695/10000], Train Loss: 0.0034, Val Loss: 0.7379\n",
      "Epoch [8696/10000], Train Loss: 0.0044, Val Loss: 0.7853\n",
      "Epoch [8697/10000], Train Loss: 0.0059, Val Loss: 0.7457\n",
      "Epoch [8698/10000], Train Loss: 0.0067, Val Loss: 0.7772\n",
      "Epoch [8699/10000], Train Loss: 0.0060, Val Loss: 0.7494\n",
      "Epoch [8700/10000], Train Loss: 0.0044, Val Loss: 0.7665\n",
      "Epoch [8701/10000], Train Loss: 0.0028, Val Loss: 0.7522\n",
      "Epoch [8702/10000], Train Loss: 0.0021, Val Loss: 0.7597\n",
      "Epoch [8703/10000], Train Loss: 0.0024, Val Loss: 0.7583\n",
      "Epoch [8704/10000], Train Loss: 0.0033, Val Loss: 0.7557\n",
      "Epoch [8705/10000], Train Loss: 0.0039, Val Loss: 0.7638\n",
      "Epoch [8706/10000], Train Loss: 0.0040, Val Loss: 0.7515\n",
      "Epoch [8707/10000], Train Loss: 0.0034, Val Loss: 0.7667\n",
      "Epoch [8708/10000], Train Loss: 0.0027, Val Loss: 0.7477\n",
      "Epoch [8709/10000], Train Loss: 0.0023, Val Loss: 0.7694\n",
      "Epoch [8710/10000], Train Loss: 0.0023, Val Loss: 0.7463\n",
      "Epoch [8711/10000], Train Loss: 0.0026, Val Loss: 0.7720\n",
      "Epoch [8712/10000], Train Loss: 0.0030, Val Loss: 0.7458\n",
      "Epoch [8713/10000], Train Loss: 0.0032, Val Loss: 0.7745\n",
      "Epoch [8714/10000], Train Loss: 0.0031, Val Loss: 0.7436\n",
      "Epoch [8715/10000], Train Loss: 0.0030, Val Loss: 0.7775\n",
      "Epoch [8716/10000], Train Loss: 0.0027, Val Loss: 0.7405\n",
      "Epoch [8717/10000], Train Loss: 0.0027, Val Loss: 0.7812\n",
      "Epoch [8718/10000], Train Loss: 0.0028, Val Loss: 0.7369\n",
      "Epoch [8719/10000], Train Loss: 0.0032, Val Loss: 0.7863\n",
      "Epoch [8720/10000], Train Loss: 0.0035, Val Loss: 0.7323\n",
      "Epoch [8721/10000], Train Loss: 0.0039, Val Loss: 0.7916\n",
      "Epoch [8722/10000], Train Loss: 0.0040, Val Loss: 0.7266\n",
      "Epoch [8723/10000], Train Loss: 0.0042, Val Loss: 0.7976\n",
      "Epoch [8724/10000], Train Loss: 0.0044, Val Loss: 0.7197\n",
      "Epoch [8725/10000], Train Loss: 0.0050, Val Loss: 0.8072\n",
      "Epoch [8726/10000], Train Loss: 0.0057, Val Loss: 0.7111\n",
      "Epoch [8727/10000], Train Loss: 0.0072, Val Loss: 0.8223\n",
      "Epoch [8728/10000], Train Loss: 0.0085, Val Loss: 0.6992\n",
      "Epoch [8729/10000], Train Loss: 0.0113, Val Loss: 0.8477\n",
      "Epoch [8730/10000], Train Loss: 0.0138, Val Loss: 0.6843\n",
      "Epoch [8731/10000], Train Loss: 0.0186, Val Loss: 0.8824\n",
      "Epoch [8732/10000], Train Loss: 0.0222, Val Loss: 0.6701\n",
      "Epoch [8733/10000], Train Loss: 0.0278, Val Loss: 0.9128\n",
      "Epoch [8734/10000], Train Loss: 0.0305, Val Loss: 0.6626\n",
      "Epoch [8735/10000], Train Loss: 0.0329, Val Loss: 0.9139\n",
      "Epoch [8736/10000], Train Loss: 0.0309, Val Loss: 0.6686\n",
      "Epoch [8737/10000], Train Loss: 0.0277, Val Loss: 0.8757\n",
      "Epoch [8738/10000], Train Loss: 0.0207, Val Loss: 0.6955\n",
      "Epoch [8739/10000], Train Loss: 0.0139, Val Loss: 0.8074\n",
      "Epoch [8740/10000], Train Loss: 0.0075, Val Loss: 0.7458\n",
      "Epoch [8741/10000], Train Loss: 0.0036, Val Loss: 0.7394\n",
      "Epoch [8742/10000], Train Loss: 0.0030, Val Loss: 0.7984\n",
      "Epoch [8743/10000], Train Loss: 0.0051, Val Loss: 0.7041\n",
      "Epoch [8744/10000], Train Loss: 0.0084, Val Loss: 0.8303\n",
      "Epoch [8745/10000], Train Loss: 0.0108, Val Loss: 0.6977\n",
      "Epoch [8746/10000], Train Loss: 0.0115, Val Loss: 0.8255\n",
      "Epoch [8747/10000], Train Loss: 0.0099, Val Loss: 0.7120\n",
      "Epoch [8748/10000], Train Loss: 0.0075, Val Loss: 0.7953\n",
      "Epoch [8749/10000], Train Loss: 0.0046, Val Loss: 0.7440\n",
      "Epoch [8750/10000], Train Loss: 0.0025, Val Loss: 0.7546\n",
      "Epoch [8751/10000], Train Loss: 0.0019, Val Loss: 0.7793\n",
      "Epoch [8752/10000], Train Loss: 0.0026, Val Loss: 0.7291\n",
      "Epoch [8753/10000], Train Loss: 0.0040, Val Loss: 0.8024\n",
      "Epoch [8754/10000], Train Loss: 0.0053, Val Loss: 0.7164\n",
      "Epoch [8755/10000], Train Loss: 0.0061, Val Loss: 0.8099\n",
      "Epoch [8756/10000], Train Loss: 0.0060, Val Loss: 0.7177\n",
      "Epoch [8757/10000], Train Loss: 0.0054, Val Loss: 0.7975\n",
      "Epoch [8758/10000], Train Loss: 0.0042, Val Loss: 0.7329\n",
      "Epoch [8759/10000], Train Loss: 0.0031, Val Loss: 0.7762\n",
      "Epoch [8760/10000], Train Loss: 0.0023, Val Loss: 0.7528\n",
      "Epoch [8761/10000], Train Loss: 0.0019, Val Loss: 0.7554\n",
      "Epoch [8762/10000], Train Loss: 0.0019, Val Loss: 0.7723\n",
      "Epoch [8763/10000], Train Loss: 0.0022, Val Loss: 0.7388\n",
      "Epoch [8764/10000], Train Loss: 0.0026, Val Loss: 0.7845\n",
      "Epoch [8765/10000], Train Loss: 0.0029, Val Loss: 0.7324\n",
      "Epoch [8766/10000], Train Loss: 0.0031, Val Loss: 0.7847\n",
      "Epoch [8767/10000], Train Loss: 0.0030, Val Loss: 0.7350\n",
      "Epoch [8768/10000], Train Loss: 0.0028, Val Loss: 0.7785\n",
      "Epoch [8769/10000], Train Loss: 0.0025, Val Loss: 0.7422\n",
      "Epoch [8770/10000], Train Loss: 0.0023, Val Loss: 0.7690\n",
      "Epoch [8771/10000], Train Loss: 0.0020, Val Loss: 0.7533\n",
      "Epoch [8772/10000], Train Loss: 0.0018, Val Loss: 0.7569\n",
      "Epoch [8773/10000], Train Loss: 0.0018, Val Loss: 0.7649\n",
      "Epoch [8774/10000], Train Loss: 0.0018, Val Loss: 0.7481\n",
      "Epoch [8775/10000], Train Loss: 0.0019, Val Loss: 0.7715\n",
      "Epoch [8776/10000], Train Loss: 0.0020, Val Loss: 0.7446\n",
      "Epoch [8777/10000], Train Loss: 0.0020, Val Loss: 0.7728\n",
      "Epoch [8778/10000], Train Loss: 0.0020, Val Loss: 0.7459\n",
      "Epoch [8779/10000], Train Loss: 0.0019, Val Loss: 0.7679\n",
      "Epoch [8780/10000], Train Loss: 0.0018, Val Loss: 0.7521\n",
      "Epoch [8781/10000], Train Loss: 0.0017, Val Loss: 0.7597\n",
      "Epoch [8782/10000], Train Loss: 0.0016, Val Loss: 0.7592\n",
      "Epoch [8783/10000], Train Loss: 0.0016, Val Loss: 0.7529\n",
      "Epoch [8784/10000], Train Loss: 0.0016, Val Loss: 0.7642\n",
      "Epoch [8785/10000], Train Loss: 0.0017, Val Loss: 0.7482\n",
      "Epoch [8786/10000], Train Loss: 0.0018, Val Loss: 0.7676\n",
      "Epoch [8787/10000], Train Loss: 0.0018, Val Loss: 0.7457\n",
      "Epoch [8788/10000], Train Loss: 0.0018, Val Loss: 0.7687\n",
      "Epoch [8789/10000], Train Loss: 0.0018, Val Loss: 0.7454\n",
      "Epoch [8790/10000], Train Loss: 0.0019, Val Loss: 0.7687\n",
      "Epoch [8791/10000], Train Loss: 0.0018, Val Loss: 0.7460\n",
      "Epoch [8792/10000], Train Loss: 0.0018, Val Loss: 0.7680\n",
      "Epoch [8793/10000], Train Loss: 0.0018, Val Loss: 0.7474\n",
      "Epoch [8794/10000], Train Loss: 0.0017, Val Loss: 0.7657\n",
      "Epoch [8795/10000], Train Loss: 0.0017, Val Loss: 0.7500\n",
      "Epoch [8796/10000], Train Loss: 0.0016, Val Loss: 0.7626\n",
      "Epoch [8797/10000], Train Loss: 0.0016, Val Loss: 0.7526\n",
      "Epoch [8798/10000], Train Loss: 0.0016, Val Loss: 0.7594\n",
      "Epoch [8799/10000], Train Loss: 0.0016, Val Loss: 0.7554\n",
      "Epoch [8800/10000], Train Loss: 0.0015, Val Loss: 0.7560\n",
      "Epoch [8801/10000], Train Loss: 0.0015, Val Loss: 0.7578\n",
      "Epoch [8802/10000], Train Loss: 0.0015, Val Loss: 0.7536\n",
      "Epoch [8803/10000], Train Loss: 0.0015, Val Loss: 0.7591\n",
      "Epoch [8804/10000], Train Loss: 0.0015, Val Loss: 0.7525\n",
      "Epoch [8805/10000], Train Loss: 0.0015, Val Loss: 0.7598\n",
      "Epoch [8806/10000], Train Loss: 0.0015, Val Loss: 0.7521\n",
      "Epoch [8807/10000], Train Loss: 0.0015, Val Loss: 0.7598\n",
      "Epoch [8808/10000], Train Loss: 0.0015, Val Loss: 0.7524\n",
      "Epoch [8809/10000], Train Loss: 0.0015, Val Loss: 0.7592\n",
      "Epoch [8810/10000], Train Loss: 0.0015, Val Loss: 0.7532\n",
      "Epoch [8811/10000], Train Loss: 0.0015, Val Loss: 0.7584\n",
      "Epoch [8812/10000], Train Loss: 0.0015, Val Loss: 0.7539\n",
      "Epoch [8813/10000], Train Loss: 0.0015, Val Loss: 0.7576\n",
      "Epoch [8814/10000], Train Loss: 0.0015, Val Loss: 0.7546\n",
      "Epoch [8815/10000], Train Loss: 0.0015, Val Loss: 0.7568\n",
      "Epoch [8816/10000], Train Loss: 0.0015, Val Loss: 0.7553\n",
      "Epoch [8817/10000], Train Loss: 0.0015, Val Loss: 0.7562\n",
      "Epoch [8818/10000], Train Loss: 0.0014, Val Loss: 0.7557\n",
      "Epoch [8819/10000], Train Loss: 0.0014, Val Loss: 0.7557\n",
      "Epoch [8820/10000], Train Loss: 0.0014, Val Loss: 0.7561\n",
      "Epoch [8821/10000], Train Loss: 0.0014, Val Loss: 0.7551\n",
      "Epoch [8822/10000], Train Loss: 0.0014, Val Loss: 0.7566\n",
      "Epoch [8823/10000], Train Loss: 0.0014, Val Loss: 0.7545\n",
      "Epoch [8824/10000], Train Loss: 0.0014, Val Loss: 0.7571\n",
      "Epoch [8825/10000], Train Loss: 0.0014, Val Loss: 0.7537\n",
      "Epoch [8826/10000], Train Loss: 0.0014, Val Loss: 0.7579\n",
      "Epoch [8827/10000], Train Loss: 0.0014, Val Loss: 0.7526\n",
      "Epoch [8828/10000], Train Loss: 0.0014, Val Loss: 0.7590\n",
      "Epoch [8829/10000], Train Loss: 0.0014, Val Loss: 0.7510\n",
      "Epoch [8830/10000], Train Loss: 0.0014, Val Loss: 0.7608\n",
      "Epoch [8831/10000], Train Loss: 0.0014, Val Loss: 0.7487\n",
      "Epoch [8832/10000], Train Loss: 0.0015, Val Loss: 0.7637\n",
      "Epoch [8833/10000], Train Loss: 0.0015, Val Loss: 0.7450\n",
      "Epoch [8834/10000], Train Loss: 0.0016, Val Loss: 0.7684\n",
      "Epoch [8835/10000], Train Loss: 0.0017, Val Loss: 0.7394\n",
      "Epoch [8836/10000], Train Loss: 0.0019, Val Loss: 0.7760\n",
      "Epoch [8837/10000], Train Loss: 0.0021, Val Loss: 0.7308\n",
      "Epoch [8838/10000], Train Loss: 0.0026, Val Loss: 0.7885\n",
      "Epoch [8839/10000], Train Loss: 0.0032, Val Loss: 0.7177\n",
      "Epoch [8840/10000], Train Loss: 0.0045, Val Loss: 0.8095\n",
      "Epoch [8841/10000], Train Loss: 0.0061, Val Loss: 0.6984\n",
      "Epoch [8842/10000], Train Loss: 0.0091, Val Loss: 0.8452\n",
      "Epoch [8843/10000], Train Loss: 0.0132, Val Loss: 0.6721\n",
      "Epoch [8844/10000], Train Loss: 0.0214, Val Loss: 0.9101\n",
      "Epoch [8845/10000], Train Loss: 0.0317, Val Loss: 0.6445\n",
      "Epoch [8846/10000], Train Loss: 0.0513, Val Loss: 1.0123\n",
      "Epoch [8847/10000], Train Loss: 0.0711, Val Loss: 0.6423\n",
      "Epoch [8848/10000], Train Loss: 0.1017, Val Loss: 1.1031\n",
      "Epoch [8849/10000], Train Loss: 0.1126, Val Loss: 0.6533\n",
      "Epoch [8850/10000], Train Loss: 0.1085, Val Loss: 1.0056\n",
      "Epoch [8851/10000], Train Loss: 0.0675, Val Loss: 0.6919\n",
      "Epoch [8852/10000], Train Loss: 0.0236, Val Loss: 0.7712\n",
      "Epoch [8853/10000], Train Loss: 0.0032, Val Loss: 0.8511\n",
      "Epoch [8854/10000], Train Loss: 0.0167, Val Loss: 0.6748\n",
      "Epoch [8855/10000], Train Loss: 0.0410, Val Loss: 0.9340\n",
      "Epoch [8856/10000], Train Loss: 0.0469, Val Loss: 0.6693\n",
      "Epoch [8857/10000], Train Loss: 0.0348, Val Loss: 0.8208\n",
      "Epoch [8858/10000], Train Loss: 0.0116, Val Loss: 0.7598\n",
      "Epoch [8859/10000], Train Loss: 0.0021, Val Loss: 0.6862\n",
      "Epoch [8860/10000], Train Loss: 0.0123, Val Loss: 0.8687\n",
      "Epoch [8861/10000], Train Loss: 0.0253, Val Loss: 0.6765\n",
      "Epoch [8862/10000], Train Loss: 0.0275, Val Loss: 0.8198\n",
      "Epoch [8863/10000], Train Loss: 0.0151, Val Loss: 0.7417\n",
      "Epoch [8864/10000], Train Loss: 0.0039, Val Loss: 0.7127\n",
      "Epoch [8865/10000], Train Loss: 0.0046, Val Loss: 0.8350\n",
      "Epoch [8866/10000], Train Loss: 0.0130, Val Loss: 0.6798\n",
      "Epoch [8867/10000], Train Loss: 0.0182, Val Loss: 0.8337\n",
      "Epoch [8868/10000], Train Loss: 0.0130, Val Loss: 0.7159\n",
      "Epoch [8869/10000], Train Loss: 0.0048, Val Loss: 0.7476\n",
      "Epoch [8870/10000], Train Loss: 0.0015, Val Loss: 0.7958\n",
      "Epoch [8871/10000], Train Loss: 0.0053, Val Loss: 0.6980\n",
      "Epoch [8872/10000], Train Loss: 0.0102, Val Loss: 0.8170\n",
      "Epoch [8873/10000], Train Loss: 0.0096, Val Loss: 0.7117\n",
      "Epoch [8874/10000], Train Loss: 0.0057, Val Loss: 0.7699\n",
      "Epoch [8875/10000], Train Loss: 0.0019, Val Loss: 0.7627\n",
      "Epoch [8876/10000], Train Loss: 0.0022, Val Loss: 0.7234\n",
      "Epoch [8877/10000], Train Loss: 0.0050, Val Loss: 0.7975\n",
      "Epoch [8878/10000], Train Loss: 0.0062, Val Loss: 0.7178\n",
      "Epoch [8879/10000], Train Loss: 0.0047, Val Loss: 0.7736\n",
      "Epoch [8880/10000], Train Loss: 0.0021, Val Loss: 0.7534\n",
      "Epoch [8881/10000], Train Loss: 0.0014, Val Loss: 0.7329\n",
      "Epoch [8882/10000], Train Loss: 0.0026, Val Loss: 0.7843\n",
      "Epoch [8883/10000], Train Loss: 0.0038, Val Loss: 0.7245\n",
      "Epoch [8884/10000], Train Loss: 0.0036, Val Loss: 0.7704\n",
      "Epoch [8885/10000], Train Loss: 0.0022, Val Loss: 0.7509\n",
      "Epoch [8886/10000], Train Loss: 0.0013, Val Loss: 0.7370\n",
      "Epoch [8887/10000], Train Loss: 0.0018, Val Loss: 0.7786\n",
      "Epoch [8888/10000], Train Loss: 0.0026, Val Loss: 0.7260\n",
      "Epoch [8889/10000], Train Loss: 0.0028, Val Loss: 0.7744\n",
      "Epoch [8890/10000], Train Loss: 0.0021, Val Loss: 0.7458\n",
      "Epoch [8891/10000], Train Loss: 0.0013, Val Loss: 0.7463\n",
      "Epoch [8892/10000], Train Loss: 0.0013, Val Loss: 0.7745\n",
      "Epoch [8893/10000], Train Loss: 0.0019, Val Loss: 0.7313\n",
      "Epoch [8894/10000], Train Loss: 0.0022, Val Loss: 0.7763\n",
      "Epoch [8895/10000], Train Loss: 0.0019, Val Loss: 0.7441\n",
      "Epoch [8896/10000], Train Loss: 0.0014, Val Loss: 0.7550\n",
      "Epoch [8897/10000], Train Loss: 0.0013, Val Loss: 0.7646\n",
      "Epoch [8898/10000], Train Loss: 0.0015, Val Loss: 0.7415\n",
      "Epoch [8899/10000], Train Loss: 0.0017, Val Loss: 0.7683\n",
      "Epoch [8900/10000], Train Loss: 0.0016, Val Loss: 0.7456\n",
      "Epoch [8901/10000], Train Loss: 0.0013, Val Loss: 0.7558\n",
      "Epoch [8902/10000], Train Loss: 0.0011, Val Loss: 0.7595\n",
      "Epoch [8903/10000], Train Loss: 0.0012, Val Loss: 0.7436\n",
      "Epoch [8904/10000], Train Loss: 0.0014, Val Loss: 0.7644\n",
      "Epoch [8905/10000], Train Loss: 0.0014, Val Loss: 0.7453\n",
      "Epoch [8906/10000], Train Loss: 0.0014, Val Loss: 0.7564\n",
      "Epoch [8907/10000], Train Loss: 0.0012, Val Loss: 0.7565\n",
      "Epoch [8908/10000], Train Loss: 0.0012, Val Loss: 0.7458\n",
      "Epoch [8909/10000], Train Loss: 0.0012, Val Loss: 0.7637\n",
      "Epoch [8910/10000], Train Loss: 0.0013, Val Loss: 0.7435\n",
      "Epoch [8911/10000], Train Loss: 0.0013, Val Loss: 0.7619\n",
      "Epoch [8912/10000], Train Loss: 0.0012, Val Loss: 0.7491\n",
      "Epoch [8913/10000], Train Loss: 0.0012, Val Loss: 0.7541\n",
      "Epoch [8914/10000], Train Loss: 0.0011, Val Loss: 0.7567\n",
      "Epoch [8915/10000], Train Loss: 0.0012, Val Loss: 0.7490\n",
      "Epoch [8916/10000], Train Loss: 0.0012, Val Loss: 0.7580\n",
      "Epoch [8917/10000], Train Loss: 0.0012, Val Loss: 0.7510\n",
      "Epoch [8918/10000], Train Loss: 0.0011, Val Loss: 0.7534\n",
      "Epoch [8919/10000], Train Loss: 0.0011, Val Loss: 0.7557\n",
      "Epoch [8920/10000], Train Loss: 0.0011, Val Loss: 0.7496\n",
      "Epoch [8921/10000], Train Loss: 0.0011, Val Loss: 0.7571\n",
      "Epoch [8922/10000], Train Loss: 0.0011, Val Loss: 0.7500\n",
      "Epoch [8923/10000], Train Loss: 0.0011, Val Loss: 0.7544\n",
      "Epoch [8924/10000], Train Loss: 0.0011, Val Loss: 0.7536\n",
      "Epoch [8925/10000], Train Loss: 0.0011, Val Loss: 0.7501\n",
      "Epoch [8926/10000], Train Loss: 0.0011, Val Loss: 0.7567\n",
      "Epoch [8927/10000], Train Loss: 0.0011, Val Loss: 0.7486\n",
      "Epoch [8928/10000], Train Loss: 0.0011, Val Loss: 0.7560\n",
      "Epoch [8929/10000], Train Loss: 0.0011, Val Loss: 0.7504\n",
      "Epoch [8930/10000], Train Loss: 0.0011, Val Loss: 0.7533\n",
      "Epoch [8931/10000], Train Loss: 0.0011, Val Loss: 0.7526\n",
      "Epoch [8932/10000], Train Loss: 0.0011, Val Loss: 0.7515\n",
      "Epoch [8933/10000], Train Loss: 0.0011, Val Loss: 0.7532\n",
      "Epoch [8934/10000], Train Loss: 0.0011, Val Loss: 0.7519\n",
      "Epoch [8935/10000], Train Loss: 0.0011, Val Loss: 0.7517\n",
      "Epoch [8936/10000], Train Loss: 0.0011, Val Loss: 0.7540\n",
      "Epoch [8937/10000], Train Loss: 0.0010, Val Loss: 0.7495\n",
      "Epoch [8938/10000], Train Loss: 0.0011, Val Loss: 0.7556\n",
      "Epoch [8939/10000], Train Loss: 0.0011, Val Loss: 0.7486\n",
      "Epoch [8940/10000], Train Loss: 0.0011, Val Loss: 0.7556\n",
      "Epoch [8941/10000], Train Loss: 0.0011, Val Loss: 0.7491\n",
      "Epoch [8942/10000], Train Loss: 0.0011, Val Loss: 0.7548\n",
      "Epoch [8943/10000], Train Loss: 0.0011, Val Loss: 0.7500\n",
      "Epoch [8944/10000], Train Loss: 0.0011, Val Loss: 0.7540\n",
      "Epoch [8945/10000], Train Loss: 0.0011, Val Loss: 0.7501\n",
      "Epoch [8946/10000], Train Loss: 0.0011, Val Loss: 0.7545\n",
      "Epoch [8947/10000], Train Loss: 0.0012, Val Loss: 0.7489\n",
      "Epoch [8948/10000], Train Loss: 0.0012, Val Loss: 0.7564\n",
      "Epoch [8949/10000], Train Loss: 0.0012, Val Loss: 0.7466\n",
      "Epoch [8950/10000], Train Loss: 0.0013, Val Loss: 0.7589\n",
      "Epoch [8951/10000], Train Loss: 0.0014, Val Loss: 0.7444\n",
      "Epoch [8952/10000], Train Loss: 0.0016, Val Loss: 0.7617\n",
      "Epoch [8953/10000], Train Loss: 0.0018, Val Loss: 0.7424\n",
      "Epoch [8954/10000], Train Loss: 0.0021, Val Loss: 0.7651\n",
      "Epoch [8955/10000], Train Loss: 0.0026, Val Loss: 0.7404\n",
      "Epoch [8956/10000], Train Loss: 0.0032, Val Loss: 0.7705\n",
      "Epoch [8957/10000], Train Loss: 0.0042, Val Loss: 0.7379\n",
      "Epoch [8958/10000], Train Loss: 0.0055, Val Loss: 0.7795\n",
      "Epoch [8959/10000], Train Loss: 0.0074, Val Loss: 0.7348\n",
      "Epoch [8960/10000], Train Loss: 0.0098, Val Loss: 0.7934\n",
      "Epoch [8961/10000], Train Loss: 0.0132, Val Loss: 0.7334\n",
      "Epoch [8962/10000], Train Loss: 0.0172, Val Loss: 0.8113\n",
      "Epoch [8963/10000], Train Loss: 0.0219, Val Loss: 0.7332\n",
      "Epoch [8964/10000], Train Loss: 0.0256, Val Loss: 0.8252\n",
      "Epoch [8965/10000], Train Loss: 0.0278, Val Loss: 0.7296\n",
      "Epoch [8966/10000], Train Loss: 0.0261, Val Loss: 0.8202\n",
      "Epoch [8967/10000], Train Loss: 0.0207, Val Loss: 0.7200\n",
      "Epoch [8968/10000], Train Loss: 0.0131, Val Loss: 0.7961\n",
      "Epoch [8969/10000], Train Loss: 0.0061, Val Loss: 0.7249\n",
      "Epoch [8970/10000], Train Loss: 0.0026, Val Loss: 0.7680\n",
      "Epoch [8971/10000], Train Loss: 0.0025, Val Loss: 0.7553\n",
      "Epoch [8972/10000], Train Loss: 0.0046, Val Loss: 0.7389\n",
      "Epoch [8973/10000], Train Loss: 0.0072, Val Loss: 0.7881\n",
      "Epoch [8974/10000], Train Loss: 0.0088, Val Loss: 0.7166\n",
      "Epoch [8975/10000], Train Loss: 0.0087, Val Loss: 0.7980\n",
      "Epoch [8976/10000], Train Loss: 0.0071, Val Loss: 0.7096\n",
      "Epoch [8977/10000], Train Loss: 0.0051, Val Loss: 0.7849\n",
      "Epoch [8978/10000], Train Loss: 0.0032, Val Loss: 0.7256\n",
      "Epoch [8979/10000], Train Loss: 0.0021, Val Loss: 0.7570\n",
      "Epoch [8980/10000], Train Loss: 0.0019, Val Loss: 0.7582\n",
      "Epoch [8981/10000], Train Loss: 0.0024, Val Loss: 0.7286\n",
      "Epoch [8982/10000], Train Loss: 0.0033, Val Loss: 0.7841\n",
      "Epoch [8983/10000], Train Loss: 0.0040, Val Loss: 0.7146\n",
      "Epoch [8984/10000], Train Loss: 0.0042, Val Loss: 0.7895\n",
      "Epoch [8985/10000], Train Loss: 0.0037, Val Loss: 0.7185\n",
      "Epoch [8986/10000], Train Loss: 0.0029, Val Loss: 0.7741\n",
      "Epoch [8987/10000], Train Loss: 0.0018, Val Loss: 0.7396\n",
      "Epoch [8988/10000], Train Loss: 0.0011, Val Loss: 0.7476\n",
      "Epoch [8989/10000], Train Loss: 0.0010, Val Loss: 0.7657\n",
      "Epoch [8990/10000], Train Loss: 0.0014, Val Loss: 0.7289\n",
      "Epoch [8991/10000], Train Loss: 0.0019, Val Loss: 0.7779\n",
      "Epoch [8992/10000], Train Loss: 0.0022, Val Loss: 0.7254\n",
      "Epoch [8993/10000], Train Loss: 0.0023, Val Loss: 0.7750\n",
      "Epoch [8994/10000], Train Loss: 0.0019, Val Loss: 0.7337\n",
      "Epoch [8995/10000], Train Loss: 0.0015, Val Loss: 0.7606\n",
      "Epoch [8996/10000], Train Loss: 0.0011, Val Loss: 0.7503\n",
      "Epoch [8997/10000], Train Loss: 0.0009, Val Loss: 0.7439\n",
      "Epoch [8998/10000], Train Loss: 0.0010, Val Loss: 0.7632\n",
      "Epoch [8999/10000], Train Loss: 0.0011, Val Loss: 0.7371\n",
      "Epoch [9000/10000], Train Loss: 0.0013, Val Loss: 0.7655\n",
      "Epoch [9001/10000], Train Loss: 0.0013, Val Loss: 0.7383\n",
      "Epoch [9002/10000], Train Loss: 0.0013, Val Loss: 0.7620\n",
      "Epoch [9003/10000], Train Loss: 0.0012, Val Loss: 0.7448\n",
      "Epoch [9004/10000], Train Loss: 0.0011, Val Loss: 0.7538\n",
      "Epoch [9005/10000], Train Loss: 0.0010, Val Loss: 0.7528\n",
      "Epoch [9006/10000], Train Loss: 0.0010, Val Loss: 0.7478\n",
      "Epoch [9007/10000], Train Loss: 0.0009, Val Loss: 0.7567\n",
      "Epoch [9008/10000], Train Loss: 0.0009, Val Loss: 0.7466\n",
      "Epoch [9009/10000], Train Loss: 0.0009, Val Loss: 0.7570\n",
      "Epoch [9010/10000], Train Loss: 0.0009, Val Loss: 0.7475\n",
      "Epoch [9011/10000], Train Loss: 0.0010, Val Loss: 0.7560\n",
      "Epoch [9012/10000], Train Loss: 0.0010, Val Loss: 0.7493\n",
      "Epoch [9013/10000], Train Loss: 0.0010, Val Loss: 0.7541\n",
      "Epoch [9014/10000], Train Loss: 0.0010, Val Loss: 0.7508\n",
      "Epoch [9015/10000], Train Loss: 0.0009, Val Loss: 0.7530\n",
      "Epoch [9016/10000], Train Loss: 0.0009, Val Loss: 0.7508\n",
      "Epoch [9017/10000], Train Loss: 0.0008, Val Loss: 0.7527\n",
      "Epoch [9018/10000], Train Loss: 0.0008, Val Loss: 0.7512\n",
      "Epoch [9019/10000], Train Loss: 0.0008, Val Loss: 0.7513\n",
      "Epoch [9020/10000], Train Loss: 0.0009, Val Loss: 0.7527\n",
      "Epoch [9021/10000], Train Loss: 0.0009, Val Loss: 0.7496\n",
      "Epoch [9022/10000], Train Loss: 0.0009, Val Loss: 0.7540\n",
      "Epoch [9023/10000], Train Loss: 0.0009, Val Loss: 0.7483\n",
      "Epoch [9024/10000], Train Loss: 0.0009, Val Loss: 0.7549\n",
      "Epoch [9025/10000], Train Loss: 0.0008, Val Loss: 0.7476\n",
      "Epoch [9026/10000], Train Loss: 0.0008, Val Loss: 0.7549\n",
      "Epoch [9027/10000], Train Loss: 0.0008, Val Loss: 0.7482\n",
      "Epoch [9028/10000], Train Loss: 0.0008, Val Loss: 0.7536\n",
      "Epoch [9029/10000], Train Loss: 0.0008, Val Loss: 0.7501\n",
      "Epoch [9030/10000], Train Loss: 0.0008, Val Loss: 0.7514\n",
      "Epoch [9031/10000], Train Loss: 0.0008, Val Loss: 0.7521\n",
      "Epoch [9032/10000], Train Loss: 0.0008, Val Loss: 0.7496\n",
      "Epoch [9033/10000], Train Loss: 0.0008, Val Loss: 0.7536\n",
      "Epoch [9034/10000], Train Loss: 0.0008, Val Loss: 0.7482\n",
      "Epoch [9035/10000], Train Loss: 0.0008, Val Loss: 0.7543\n",
      "Epoch [9036/10000], Train Loss: 0.0008, Val Loss: 0.7478\n",
      "Epoch [9037/10000], Train Loss: 0.0008, Val Loss: 0.7540\n",
      "Epoch [9038/10000], Train Loss: 0.0008, Val Loss: 0.7484\n",
      "Epoch [9039/10000], Train Loss: 0.0008, Val Loss: 0.7531\n",
      "Epoch [9040/10000], Train Loss: 0.0008, Val Loss: 0.7492\n",
      "Epoch [9041/10000], Train Loss: 0.0008, Val Loss: 0.7520\n",
      "Epoch [9042/10000], Train Loss: 0.0008, Val Loss: 0.7501\n",
      "Epoch [9043/10000], Train Loss: 0.0008, Val Loss: 0.7510\n",
      "Epoch [9044/10000], Train Loss: 0.0008, Val Loss: 0.7508\n",
      "Epoch [9045/10000], Train Loss: 0.0008, Val Loss: 0.7503\n",
      "Epoch [9046/10000], Train Loss: 0.0008, Val Loss: 0.7510\n",
      "Epoch [9047/10000], Train Loss: 0.0008, Val Loss: 0.7502\n",
      "Epoch [9048/10000], Train Loss: 0.0008, Val Loss: 0.7508\n",
      "Epoch [9049/10000], Train Loss: 0.0008, Val Loss: 0.7503\n",
      "Epoch [9050/10000], Train Loss: 0.0007, Val Loss: 0.7507\n",
      "Epoch [9051/10000], Train Loss: 0.0007, Val Loss: 0.7502\n",
      "Epoch [9052/10000], Train Loss: 0.0007, Val Loss: 0.7507\n",
      "Epoch [9053/10000], Train Loss: 0.0007, Val Loss: 0.7501\n",
      "Epoch [9054/10000], Train Loss: 0.0007, Val Loss: 0.7508\n",
      "Epoch [9055/10000], Train Loss: 0.0007, Val Loss: 0.7498\n",
      "Epoch [9056/10000], Train Loss: 0.0007, Val Loss: 0.7512\n",
      "Epoch [9057/10000], Train Loss: 0.0007, Val Loss: 0.7493\n",
      "Epoch [9058/10000], Train Loss: 0.0007, Val Loss: 0.7515\n",
      "Epoch [9059/10000], Train Loss: 0.0007, Val Loss: 0.7489\n",
      "Epoch [9060/10000], Train Loss: 0.0007, Val Loss: 0.7519\n",
      "Epoch [9061/10000], Train Loss: 0.0007, Val Loss: 0.7484\n",
      "Epoch [9062/10000], Train Loss: 0.0007, Val Loss: 0.7522\n",
      "Epoch [9063/10000], Train Loss: 0.0007, Val Loss: 0.7479\n",
      "Epoch [9064/10000], Train Loss: 0.0007, Val Loss: 0.7527\n",
      "Epoch [9065/10000], Train Loss: 0.0007, Val Loss: 0.7474\n",
      "Epoch [9066/10000], Train Loss: 0.0007, Val Loss: 0.7531\n",
      "Epoch [9067/10000], Train Loss: 0.0007, Val Loss: 0.7467\n",
      "Epoch [9068/10000], Train Loss: 0.0007, Val Loss: 0.7538\n",
      "Epoch [9069/10000], Train Loss: 0.0007, Val Loss: 0.7459\n",
      "Epoch [9070/10000], Train Loss: 0.0008, Val Loss: 0.7548\n",
      "Epoch [9071/10000], Train Loss: 0.0008, Val Loss: 0.7447\n",
      "Epoch [9072/10000], Train Loss: 0.0008, Val Loss: 0.7562\n",
      "Epoch [9073/10000], Train Loss: 0.0008, Val Loss: 0.7429\n",
      "Epoch [9074/10000], Train Loss: 0.0008, Val Loss: 0.7585\n",
      "Epoch [9075/10000], Train Loss: 0.0009, Val Loss: 0.7402\n",
      "Epoch [9076/10000], Train Loss: 0.0010, Val Loss: 0.7620\n",
      "Epoch [9077/10000], Train Loss: 0.0011, Val Loss: 0.7363\n",
      "Epoch [9078/10000], Train Loss: 0.0012, Val Loss: 0.7673\n",
      "Epoch [9079/10000], Train Loss: 0.0015, Val Loss: 0.7306\n",
      "Epoch [9080/10000], Train Loss: 0.0018, Val Loss: 0.7756\n",
      "Epoch [9081/10000], Train Loss: 0.0023, Val Loss: 0.7223\n",
      "Epoch [9082/10000], Train Loss: 0.0031, Val Loss: 0.7889\n",
      "Epoch [9083/10000], Train Loss: 0.0042, Val Loss: 0.7106\n",
      "Epoch [9084/10000], Train Loss: 0.0059, Val Loss: 0.8101\n",
      "Epoch [9085/10000], Train Loss: 0.0083, Val Loss: 0.6951\n",
      "Epoch [9086/10000], Train Loss: 0.0121, Val Loss: 0.8440\n",
      "Epoch [9087/10000], Train Loss: 0.0171, Val Loss: 0.6767\n",
      "Epoch [9088/10000], Train Loss: 0.0247, Val Loss: 0.8950\n",
      "Epoch [9089/10000], Train Loss: 0.0340, Val Loss: 0.6592\n",
      "Epoch [9090/10000], Train Loss: 0.0464, Val Loss: 0.9572\n",
      "Epoch [9091/10000], Train Loss: 0.0580, Val Loss: 0.6463\n",
      "Epoch [9092/10000], Train Loss: 0.0690, Val Loss: 0.9923\n",
      "Epoch [9093/10000], Train Loss: 0.0706, Val Loss: 0.6377\n",
      "Epoch [9094/10000], Train Loss: 0.0648, Val Loss: 0.9476\n",
      "Epoch [9095/10000], Train Loss: 0.0467, Val Loss: 0.6532\n",
      "Epoch [9096/10000], Train Loss: 0.0287, Val Loss: 0.8432\n",
      "Epoch [9097/10000], Train Loss: 0.0132, Val Loss: 0.7347\n",
      "Epoch [9098/10000], Train Loss: 0.0086, Val Loss: 0.7417\n",
      "Epoch [9099/10000], Train Loss: 0.0130, Val Loss: 0.8423\n",
      "Epoch [9100/10000], Train Loss: 0.0209, Val Loss: 0.6884\n",
      "Epoch [9101/10000], Train Loss: 0.0252, Val Loss: 0.8752\n",
      "Epoch [9102/10000], Train Loss: 0.0227, Val Loss: 0.6776\n",
      "Epoch [9103/10000], Train Loss: 0.0170, Val Loss: 0.8344\n",
      "Epoch [9104/10000], Train Loss: 0.0102, Val Loss: 0.7182\n",
      "Epoch [9105/10000], Train Loss: 0.0070, Val Loss: 0.7611\n",
      "Epoch [9106/10000], Train Loss: 0.0068, Val Loss: 0.7867\n",
      "Epoch [9107/10000], Train Loss: 0.0089, Val Loss: 0.7101\n",
      "Epoch [9108/10000], Train Loss: 0.0100, Val Loss: 0.8156\n",
      "Epoch [9109/10000], Train Loss: 0.0089, Val Loss: 0.7010\n",
      "Epoch [9110/10000], Train Loss: 0.0066, Val Loss: 0.7942\n",
      "Epoch [9111/10000], Train Loss: 0.0046, Val Loss: 0.7253\n",
      "Epoch [9112/10000], Train Loss: 0.0046, Val Loss: 0.7642\n",
      "Epoch [9113/10000], Train Loss: 0.0053, Val Loss: 0.7622\n",
      "Epoch [9114/10000], Train Loss: 0.0058, Val Loss: 0.7329\n",
      "Epoch [9115/10000], Train Loss: 0.0050, Val Loss: 0.7849\n",
      "Epoch [9116/10000], Train Loss: 0.0036, Val Loss: 0.7195\n",
      "Epoch [9117/10000], Train Loss: 0.0027, Val Loss: 0.7822\n",
      "Epoch [9118/10000], Train Loss: 0.0027, Val Loss: 0.7316\n",
      "Epoch [9119/10000], Train Loss: 0.0035, Val Loss: 0.7674\n",
      "Epoch [9120/10000], Train Loss: 0.0038, Val Loss: 0.7482\n",
      "Epoch [9121/10000], Train Loss: 0.0034, Val Loss: 0.7494\n",
      "Epoch [9122/10000], Train Loss: 0.0023, Val Loss: 0.7630\n",
      "Epoch [9123/10000], Train Loss: 0.0013, Val Loss: 0.7335\n",
      "Epoch [9124/10000], Train Loss: 0.0012, Val Loss: 0.7705\n",
      "Epoch [9125/10000], Train Loss: 0.0017, Val Loss: 0.7334\n",
      "Epoch [9126/10000], Train Loss: 0.0025, Val Loss: 0.7664\n",
      "Epoch [9127/10000], Train Loss: 0.0027, Val Loss: 0.7413\n",
      "Epoch [9128/10000], Train Loss: 0.0024, Val Loss: 0.7566\n",
      "Epoch [9129/10000], Train Loss: 0.0016, Val Loss: 0.7496\n",
      "Epoch [9130/10000], Train Loss: 0.0008, Val Loss: 0.7454\n",
      "Epoch [9131/10000], Train Loss: 0.0007, Val Loss: 0.7585\n",
      "Epoch [9132/10000], Train Loss: 0.0010, Val Loss: 0.7397\n",
      "Epoch [9133/10000], Train Loss: 0.0015, Val Loss: 0.7610\n",
      "Epoch [9134/10000], Train Loss: 0.0017, Val Loss: 0.7409\n",
      "Epoch [9135/10000], Train Loss: 0.0015, Val Loss: 0.7560\n",
      "Epoch [9136/10000], Train Loss: 0.0011, Val Loss: 0.7467\n",
      "Epoch [9137/10000], Train Loss: 0.0007, Val Loss: 0.7485\n",
      "Epoch [9138/10000], Train Loss: 0.0006, Val Loss: 0.7529\n",
      "Epoch [9139/10000], Train Loss: 0.0008, Val Loss: 0.7444\n",
      "Epoch [9140/10000], Train Loss: 0.0010, Val Loss: 0.7566\n",
      "Epoch [9141/10000], Train Loss: 0.0011, Val Loss: 0.7428\n",
      "Epoch [9142/10000], Train Loss: 0.0011, Val Loss: 0.7567\n",
      "Epoch [9143/10000], Train Loss: 0.0009, Val Loss: 0.7451\n",
      "Epoch [9144/10000], Train Loss: 0.0007, Val Loss: 0.7524\n",
      "Epoch [9145/10000], Train Loss: 0.0006, Val Loss: 0.7501\n",
      "Epoch [9146/10000], Train Loss: 0.0007, Val Loss: 0.7481\n",
      "Epoch [9147/10000], Train Loss: 0.0008, Val Loss: 0.7537\n",
      "Epoch [9148/10000], Train Loss: 0.0008, Val Loss: 0.7455\n",
      "Epoch [9149/10000], Train Loss: 0.0008, Val Loss: 0.7549\n",
      "Epoch [9150/10000], Train Loss: 0.0007, Val Loss: 0.7448\n",
      "Epoch [9151/10000], Train Loss: 0.0007, Val Loss: 0.7537\n",
      "Epoch [9152/10000], Train Loss: 0.0006, Val Loss: 0.7467\n",
      "Epoch [9153/10000], Train Loss: 0.0006, Val Loss: 0.7505\n",
      "Epoch [9154/10000], Train Loss: 0.0006, Val Loss: 0.7500\n",
      "Epoch [9155/10000], Train Loss: 0.0007, Val Loss: 0.7476\n",
      "Epoch [9156/10000], Train Loss: 0.0007, Val Loss: 0.7523\n",
      "Epoch [9157/10000], Train Loss: 0.0007, Val Loss: 0.7461\n",
      "Epoch [9158/10000], Train Loss: 0.0006, Val Loss: 0.7532\n",
      "Epoch [9159/10000], Train Loss: 0.0006, Val Loss: 0.7462\n",
      "Epoch [9160/10000], Train Loss: 0.0006, Val Loss: 0.7524\n",
      "Epoch [9161/10000], Train Loss: 0.0006, Val Loss: 0.7480\n",
      "Epoch [9162/10000], Train Loss: 0.0006, Val Loss: 0.7503\n",
      "Epoch [9163/10000], Train Loss: 0.0006, Val Loss: 0.7502\n",
      "Epoch [9164/10000], Train Loss: 0.0006, Val Loss: 0.7485\n",
      "Epoch [9165/10000], Train Loss: 0.0006, Val Loss: 0.7514\n",
      "Epoch [9166/10000], Train Loss: 0.0006, Val Loss: 0.7476\n",
      "Epoch [9167/10000], Train Loss: 0.0006, Val Loss: 0.7517\n",
      "Epoch [9168/10000], Train Loss: 0.0006, Val Loss: 0.7475\n",
      "Epoch [9169/10000], Train Loss: 0.0006, Val Loss: 0.7512\n",
      "Epoch [9170/10000], Train Loss: 0.0006, Val Loss: 0.7482\n",
      "Epoch [9171/10000], Train Loss: 0.0006, Val Loss: 0.7500\n",
      "Epoch [9172/10000], Train Loss: 0.0006, Val Loss: 0.7492\n",
      "Epoch [9173/10000], Train Loss: 0.0006, Val Loss: 0.7489\n",
      "Epoch [9174/10000], Train Loss: 0.0006, Val Loss: 0.7499\n",
      "Epoch [9175/10000], Train Loss: 0.0006, Val Loss: 0.7483\n",
      "Epoch [9176/10000], Train Loss: 0.0005, Val Loss: 0.7503\n",
      "Epoch [9177/10000], Train Loss: 0.0006, Val Loss: 0.7479\n",
      "Epoch [9178/10000], Train Loss: 0.0006, Val Loss: 0.7504\n",
      "Epoch [9179/10000], Train Loss: 0.0006, Val Loss: 0.7481\n",
      "Epoch [9180/10000], Train Loss: 0.0006, Val Loss: 0.7500\n",
      "Epoch [9181/10000], Train Loss: 0.0006, Val Loss: 0.7486\n",
      "Epoch [9182/10000], Train Loss: 0.0005, Val Loss: 0.7494\n",
      "Epoch [9183/10000], Train Loss: 0.0005, Val Loss: 0.7491\n",
      "Epoch [9184/10000], Train Loss: 0.0005, Val Loss: 0.7488\n",
      "Epoch [9185/10000], Train Loss: 0.0005, Val Loss: 0.7496\n",
      "Epoch [9186/10000], Train Loss: 0.0005, Val Loss: 0.7484\n",
      "Epoch [9187/10000], Train Loss: 0.0005, Val Loss: 0.7498\n",
      "Epoch [9188/10000], Train Loss: 0.0005, Val Loss: 0.7482\n",
      "Epoch [9189/10000], Train Loss: 0.0005, Val Loss: 0.7498\n",
      "Epoch [9190/10000], Train Loss: 0.0005, Val Loss: 0.7483\n",
      "Epoch [9191/10000], Train Loss: 0.0005, Val Loss: 0.7495\n",
      "Epoch [9192/10000], Train Loss: 0.0005, Val Loss: 0.7485\n",
      "Epoch [9193/10000], Train Loss: 0.0005, Val Loss: 0.7493\n",
      "Epoch [9194/10000], Train Loss: 0.0005, Val Loss: 0.7487\n",
      "Epoch [9195/10000], Train Loss: 0.0005, Val Loss: 0.7489\n",
      "Epoch [9196/10000], Train Loss: 0.0005, Val Loss: 0.7490\n",
      "Epoch [9197/10000], Train Loss: 0.0005, Val Loss: 0.7486\n",
      "Epoch [9198/10000], Train Loss: 0.0005, Val Loss: 0.7491\n",
      "Epoch [9199/10000], Train Loss: 0.0005, Val Loss: 0.7484\n",
      "Epoch [9200/10000], Train Loss: 0.0005, Val Loss: 0.7492\n",
      "Epoch [9201/10000], Train Loss: 0.0005, Val Loss: 0.7483\n",
      "Epoch [9202/10000], Train Loss: 0.0005, Val Loss: 0.7493\n",
      "Epoch [9203/10000], Train Loss: 0.0005, Val Loss: 0.7482\n",
      "Epoch [9204/10000], Train Loss: 0.0005, Val Loss: 0.7493\n",
      "Epoch [9205/10000], Train Loss: 0.0005, Val Loss: 0.7483\n",
      "Epoch [9206/10000], Train Loss: 0.0005, Val Loss: 0.7492\n",
      "Epoch [9207/10000], Train Loss: 0.0005, Val Loss: 0.7484\n",
      "Epoch [9208/10000], Train Loss: 0.0005, Val Loss: 0.7491\n",
      "Epoch [9209/10000], Train Loss: 0.0005, Val Loss: 0.7485\n",
      "Epoch [9210/10000], Train Loss: 0.0005, Val Loss: 0.7489\n",
      "Epoch [9211/10000], Train Loss: 0.0005, Val Loss: 0.7486\n",
      "Epoch [9212/10000], Train Loss: 0.0005, Val Loss: 0.7488\n",
      "Epoch [9213/10000], Train Loss: 0.0005, Val Loss: 0.7486\n",
      "Epoch [9214/10000], Train Loss: 0.0005, Val Loss: 0.7487\n",
      "Epoch [9215/10000], Train Loss: 0.0005, Val Loss: 0.7487\n",
      "Epoch [9216/10000], Train Loss: 0.0005, Val Loss: 0.7486\n",
      "Epoch [9217/10000], Train Loss: 0.0005, Val Loss: 0.7487\n",
      "Epoch [9218/10000], Train Loss: 0.0005, Val Loss: 0.7486\n",
      "Epoch [9219/10000], Train Loss: 0.0005, Val Loss: 0.7487\n",
      "Epoch [9220/10000], Train Loss: 0.0005, Val Loss: 0.7485\n",
      "Epoch [9221/10000], Train Loss: 0.0005, Val Loss: 0.7487\n",
      "Epoch [9222/10000], Train Loss: 0.0005, Val Loss: 0.7484\n",
      "Epoch [9223/10000], Train Loss: 0.0005, Val Loss: 0.7488\n",
      "Epoch [9224/10000], Train Loss: 0.0005, Val Loss: 0.7484\n",
      "Epoch [9225/10000], Train Loss: 0.0005, Val Loss: 0.7488\n",
      "Epoch [9226/10000], Train Loss: 0.0005, Val Loss: 0.7484\n",
      "Epoch [9227/10000], Train Loss: 0.0005, Val Loss: 0.7488\n",
      "Epoch [9228/10000], Train Loss: 0.0005, Val Loss: 0.7483\n",
      "Epoch [9229/10000], Train Loss: 0.0005, Val Loss: 0.7488\n",
      "Epoch [9230/10000], Train Loss: 0.0005, Val Loss: 0.7483\n",
      "Epoch [9231/10000], Train Loss: 0.0005, Val Loss: 0.7488\n",
      "Epoch [9232/10000], Train Loss: 0.0005, Val Loss: 0.7482\n",
      "Epoch [9233/10000], Train Loss: 0.0005, Val Loss: 0.7489\n",
      "Epoch [9234/10000], Train Loss: 0.0005, Val Loss: 0.7482\n",
      "Epoch [9235/10000], Train Loss: 0.0005, Val Loss: 0.7489\n",
      "Epoch [9236/10000], Train Loss: 0.0005, Val Loss: 0.7481\n",
      "Epoch [9237/10000], Train Loss: 0.0005, Val Loss: 0.7490\n",
      "Epoch [9238/10000], Train Loss: 0.0005, Val Loss: 0.7479\n",
      "Epoch [9239/10000], Train Loss: 0.0005, Val Loss: 0.7491\n",
      "Epoch [9240/10000], Train Loss: 0.0005, Val Loss: 0.7478\n",
      "Epoch [9241/10000], Train Loss: 0.0005, Val Loss: 0.7493\n",
      "Epoch [9242/10000], Train Loss: 0.0005, Val Loss: 0.7475\n",
      "Epoch [9243/10000], Train Loss: 0.0005, Val Loss: 0.7496\n",
      "Epoch [9244/10000], Train Loss: 0.0005, Val Loss: 0.7471\n",
      "Epoch [9245/10000], Train Loss: 0.0005, Val Loss: 0.7501\n",
      "Epoch [9246/10000], Train Loss: 0.0005, Val Loss: 0.7463\n",
      "Epoch [9247/10000], Train Loss: 0.0005, Val Loss: 0.7510\n",
      "Epoch [9248/10000], Train Loss: 0.0005, Val Loss: 0.7451\n",
      "Epoch [9249/10000], Train Loss: 0.0005, Val Loss: 0.7526\n",
      "Epoch [9250/10000], Train Loss: 0.0005, Val Loss: 0.7429\n",
      "Epoch [9251/10000], Train Loss: 0.0005, Val Loss: 0.7555\n",
      "Epoch [9252/10000], Train Loss: 0.0005, Val Loss: 0.7391\n",
      "Epoch [9253/10000], Train Loss: 0.0006, Val Loss: 0.7606\n",
      "Epoch [9254/10000], Train Loss: 0.0007, Val Loss: 0.7325\n",
      "Epoch [9255/10000], Train Loss: 0.0009, Val Loss: 0.7698\n",
      "Epoch [9256/10000], Train Loss: 0.0012, Val Loss: 0.7208\n",
      "Epoch [9257/10000], Train Loss: 0.0019, Val Loss: 0.7884\n",
      "Epoch [9258/10000], Train Loss: 0.0030, Val Loss: 0.7004\n",
      "Epoch [9259/10000], Train Loss: 0.0054, Val Loss: 0.8263\n",
      "Epoch [9260/10000], Train Loss: 0.0093, Val Loss: 0.6666\n",
      "Epoch [9261/10000], Train Loss: 0.0184, Val Loss: 0.9127\n",
      "Epoch [9262/10000], Train Loss: 0.0335, Val Loss: 0.6324\n",
      "Epoch [9263/10000], Train Loss: 0.0670, Val Loss: 1.1020\n",
      "Epoch [9264/10000], Train Loss: 0.1152, Val Loss: 0.6501\n",
      "Epoch [9265/10000], Train Loss: 0.2019, Val Loss: 1.3573\n",
      "Epoch [9266/10000], Train Loss: 0.2586, Val Loss: 0.6936\n",
      "Epoch [9267/10000], Train Loss: 0.2728, Val Loss: 1.1511\n",
      "Epoch [9268/10000], Train Loss: 0.1419, Val Loss: 0.7403\n",
      "Epoch [9269/10000], Train Loss: 0.0181, Val Loss: 0.7000\n",
      "Epoch [9270/10000], Train Loss: 0.0301, Val Loss: 1.1180\n",
      "Epoch [9271/10000], Train Loss: 0.1185, Val Loss: 0.6632\n",
      "Epoch [9272/10000], Train Loss: 0.1350, Val Loss: 0.9381\n",
      "Epoch [9273/10000], Train Loss: 0.0467, Val Loss: 0.7925\n",
      "Epoch [9274/10000], Train Loss: 0.0089, Val Loss: 0.6494\n",
      "Epoch [9275/10000], Train Loss: 0.0632, Val Loss: 1.0189\n",
      "Epoch [9276/10000], Train Loss: 0.0879, Val Loss: 0.6685\n",
      "Epoch [9277/10000], Train Loss: 0.0425, Val Loss: 0.7264\n",
      "Epoch [9278/10000], Train Loss: 0.0063, Val Loss: 0.9115\n",
      "Epoch [9279/10000], Train Loss: 0.0365, Val Loss: 0.6353\n",
      "Epoch [9280/10000], Train Loss: 0.0590, Val Loss: 0.8689\n",
      "Epoch [9281/10000], Train Loss: 0.0261, Val Loss: 0.7653\n",
      "Epoch [9282/10000], Train Loss: 0.0047, Val Loss: 0.6564\n",
      "Epoch [9283/10000], Train Loss: 0.0265, Val Loss: 0.9169\n",
      "Epoch [9284/10000], Train Loss: 0.0363, Val Loss: 0.6749\n",
      "Epoch [9285/10000], Train Loss: 0.0148, Val Loss: 0.7334\n",
      "Epoch [9286/10000], Train Loss: 0.0040, Val Loss: 0.8562\n",
      "Epoch [9287/10000], Train Loss: 0.0193, Val Loss: 0.6560\n",
      "Epoch [9288/10000], Train Loss: 0.0246, Val Loss: 0.8071\n",
      "Epoch [9289/10000], Train Loss: 0.0075, Val Loss: 0.7705\n",
      "Epoch [9290/10000], Train Loss: 0.0035, Val Loss: 0.6785\n",
      "Epoch [9291/10000], Train Loss: 0.0148, Val Loss: 0.8335\n",
      "Epoch [9292/10000], Train Loss: 0.0144, Val Loss: 0.7164\n",
      "Epoch [9293/10000], Train Loss: 0.0048, Val Loss: 0.7192\n",
      "Epoch [9294/10000], Train Loss: 0.0027, Val Loss: 0.8222\n",
      "Epoch [9295/10000], Train Loss: 0.0092, Val Loss: 0.6889\n",
      "Epoch [9296/10000], Train Loss: 0.0091, Val Loss: 0.7725\n",
      "Epoch [9297/10000], Train Loss: 0.0024, Val Loss: 0.7787\n",
      "Epoch [9298/10000], Train Loss: 0.0026, Val Loss: 0.6934\n",
      "Epoch [9299/10000], Train Loss: 0.0072, Val Loss: 0.8032\n",
      "Epoch [9300/10000], Train Loss: 0.0053, Val Loss: 0.7329\n",
      "Epoch [9301/10000], Train Loss: 0.0013, Val Loss: 0.7225\n",
      "Epoch [9302/10000], Train Loss: 0.0025, Val Loss: 0.7962\n",
      "Epoch [9303/10000], Train Loss: 0.0049, Val Loss: 0.7150\n",
      "Epoch [9304/10000], Train Loss: 0.0028, Val Loss: 0.7476\n",
      "Epoch [9305/10000], Train Loss: 0.0008, Val Loss: 0.7764\n",
      "Epoch [9306/10000], Train Loss: 0.0025, Val Loss: 0.7124\n",
      "Epoch [9307/10000], Train Loss: 0.0036, Val Loss: 0.7683\n",
      "Epoch [9308/10000], Train Loss: 0.0017, Val Loss: 0.7552\n",
      "Epoch [9309/10000], Train Loss: 0.0008, Val Loss: 0.7205\n",
      "Epoch [9310/10000], Train Loss: 0.0020, Val Loss: 0.7817\n",
      "Epoch [9311/10000], Train Loss: 0.0022, Val Loss: 0.7344\n",
      "Epoch [9312/10000], Train Loss: 0.0009, Val Loss: 0.7412\n",
      "Epoch [9313/10000], Train Loss: 0.0007, Val Loss: 0.7754\n",
      "Epoch [9314/10000], Train Loss: 0.0017, Val Loss: 0.7255\n",
      "Epoch [9315/10000], Train Loss: 0.0016, Val Loss: 0.7612\n",
      "Epoch [9316/10000], Train Loss: 0.0007, Val Loss: 0.7579\n",
      "Epoch [9317/10000], Train Loss: 0.0008, Val Loss: 0.7316\n",
      "Epoch [9318/10000], Train Loss: 0.0014, Val Loss: 0.7663\n",
      "Epoch [9319/10000], Train Loss: 0.0011, Val Loss: 0.7452\n",
      "Epoch [9320/10000], Train Loss: 0.0005, Val Loss: 0.7395\n",
      "Epoch [9321/10000], Train Loss: 0.0007, Val Loss: 0.7654\n",
      "Epoch [9322/10000], Train Loss: 0.0010, Val Loss: 0.7361\n",
      "Epoch [9323/10000], Train Loss: 0.0008, Val Loss: 0.7500\n",
      "Epoch [9324/10000], Train Loss: 0.0005, Val Loss: 0.7596\n",
      "Epoch [9325/10000], Train Loss: 0.0006, Val Loss: 0.7329\n",
      "Epoch [9326/10000], Train Loss: 0.0009, Val Loss: 0.7602\n",
      "Epoch [9327/10000], Train Loss: 0.0006, Val Loss: 0.7475\n",
      "Epoch [9328/10000], Train Loss: 0.0004, Val Loss: 0.7402\n",
      "Epoch [9329/10000], Train Loss: 0.0006, Val Loss: 0.7609\n",
      "Epoch [9330/10000], Train Loss: 0.0007, Val Loss: 0.7406\n",
      "Epoch [9331/10000], Train Loss: 0.0005, Val Loss: 0.7492\n",
      "Epoch [9332/10000], Train Loss: 0.0004, Val Loss: 0.7552\n",
      "Epoch [9333/10000], Train Loss: 0.0005, Val Loss: 0.7409\n",
      "Epoch [9334/10000], Train Loss: 0.0006, Val Loss: 0.7533\n",
      "Epoch [9335/10000], Train Loss: 0.0005, Val Loss: 0.7506\n",
      "Epoch [9336/10000], Train Loss: 0.0004, Val Loss: 0.7421\n",
      "Epoch [9337/10000], Train Loss: 0.0005, Val Loss: 0.7560\n",
      "Epoch [9338/10000], Train Loss: 0.0005, Val Loss: 0.7451\n",
      "Epoch [9339/10000], Train Loss: 0.0004, Val Loss: 0.7465\n",
      "Epoch [9340/10000], Train Loss: 0.0004, Val Loss: 0.7549\n",
      "Epoch [9341/10000], Train Loss: 0.0005, Val Loss: 0.7417\n",
      "Epoch [9342/10000], Train Loss: 0.0005, Val Loss: 0.7520\n",
      "Epoch [9343/10000], Train Loss: 0.0004, Val Loss: 0.7494\n",
      "Epoch [9344/10000], Train Loss: 0.0004, Val Loss: 0.7438\n",
      "Epoch [9345/10000], Train Loss: 0.0004, Val Loss: 0.7528\n",
      "Epoch [9346/10000], Train Loss: 0.0004, Val Loss: 0.7460\n",
      "Epoch [9347/10000], Train Loss: 0.0004, Val Loss: 0.7466\n",
      "Epoch [9348/10000], Train Loss: 0.0004, Val Loss: 0.7515\n",
      "Epoch [9349/10000], Train Loss: 0.0004, Val Loss: 0.7445\n",
      "Epoch [9350/10000], Train Loss: 0.0004, Val Loss: 0.7488\n",
      "Epoch [9351/10000], Train Loss: 0.0004, Val Loss: 0.7495\n",
      "Epoch [9352/10000], Train Loss: 0.0004, Val Loss: 0.7441\n",
      "Epoch [9353/10000], Train Loss: 0.0004, Val Loss: 0.7510\n",
      "Epoch [9354/10000], Train Loss: 0.0004, Val Loss: 0.7460\n",
      "Epoch [9355/10000], Train Loss: 0.0004, Val Loss: 0.7466\n",
      "Epoch [9356/10000], Train Loss: 0.0004, Val Loss: 0.7500\n",
      "Epoch [9357/10000], Train Loss: 0.0004, Val Loss: 0.7449\n",
      "Epoch [9358/10000], Train Loss: 0.0004, Val Loss: 0.7487\n",
      "Epoch [9359/10000], Train Loss: 0.0004, Val Loss: 0.7480\n",
      "Epoch [9360/10000], Train Loss: 0.0004, Val Loss: 0.7457\n",
      "Epoch [9361/10000], Train Loss: 0.0004, Val Loss: 0.7492\n",
      "Epoch [9362/10000], Train Loss: 0.0004, Val Loss: 0.7468\n",
      "Epoch [9363/10000], Train Loss: 0.0004, Val Loss: 0.7465\n",
      "Epoch [9364/10000], Train Loss: 0.0004, Val Loss: 0.7492\n",
      "Epoch [9365/10000], Train Loss: 0.0004, Val Loss: 0.7454\n",
      "Epoch [9366/10000], Train Loss: 0.0004, Val Loss: 0.7482\n",
      "Epoch [9367/10000], Train Loss: 0.0004, Val Loss: 0.7476\n",
      "Epoch [9368/10000], Train Loss: 0.0004, Val Loss: 0.7459\n",
      "Epoch [9369/10000], Train Loss: 0.0004, Val Loss: 0.7486\n",
      "Epoch [9370/10000], Train Loss: 0.0004, Val Loss: 0.7463\n",
      "Epoch [9371/10000], Train Loss: 0.0004, Val Loss: 0.7470\n",
      "Epoch [9372/10000], Train Loss: 0.0004, Val Loss: 0.7478\n",
      "Epoch [9373/10000], Train Loss: 0.0004, Val Loss: 0.7461\n",
      "Epoch [9374/10000], Train Loss: 0.0004, Val Loss: 0.7475\n",
      "Epoch [9375/10000], Train Loss: 0.0004, Val Loss: 0.7472\n",
      "Epoch [9376/10000], Train Loss: 0.0004, Val Loss: 0.7460\n",
      "Epoch [9377/10000], Train Loss: 0.0004, Val Loss: 0.7480\n",
      "Epoch [9378/10000], Train Loss: 0.0004, Val Loss: 0.7462\n",
      "Epoch [9379/10000], Train Loss: 0.0004, Val Loss: 0.7470\n",
      "Epoch [9380/10000], Train Loss: 0.0004, Val Loss: 0.7474\n",
      "Epoch [9381/10000], Train Loss: 0.0004, Val Loss: 0.7462\n",
      "Epoch [9382/10000], Train Loss: 0.0004, Val Loss: 0.7475\n",
      "Epoch [9383/10000], Train Loss: 0.0004, Val Loss: 0.7467\n",
      "Epoch [9384/10000], Train Loss: 0.0004, Val Loss: 0.7466\n",
      "Epoch [9385/10000], Train Loss: 0.0004, Val Loss: 0.7474\n",
      "Epoch [9386/10000], Train Loss: 0.0004, Val Loss: 0.7465\n",
      "Epoch [9387/10000], Train Loss: 0.0004, Val Loss: 0.7469\n",
      "Epoch [9388/10000], Train Loss: 0.0004, Val Loss: 0.7472\n",
      "Epoch [9389/10000], Train Loss: 0.0004, Val Loss: 0.7462\n",
      "Epoch [9390/10000], Train Loss: 0.0004, Val Loss: 0.7474\n",
      "Epoch [9391/10000], Train Loss: 0.0004, Val Loss: 0.7465\n",
      "Epoch [9392/10000], Train Loss: 0.0004, Val Loss: 0.7468\n",
      "Epoch [9393/10000], Train Loss: 0.0004, Val Loss: 0.7471\n",
      "Epoch [9394/10000], Train Loss: 0.0004, Val Loss: 0.7465\n",
      "Epoch [9395/10000], Train Loss: 0.0004, Val Loss: 0.7470\n",
      "Epoch [9396/10000], Train Loss: 0.0004, Val Loss: 0.7469\n",
      "Epoch [9397/10000], Train Loss: 0.0004, Val Loss: 0.7465\n",
      "Epoch [9398/10000], Train Loss: 0.0004, Val Loss: 0.7472\n",
      "Epoch [9399/10000], Train Loss: 0.0004, Val Loss: 0.7465\n",
      "Epoch [9400/10000], Train Loss: 0.0004, Val Loss: 0.7469\n",
      "Epoch [9401/10000], Train Loss: 0.0004, Val Loss: 0.7469\n",
      "Epoch [9402/10000], Train Loss: 0.0004, Val Loss: 0.7466\n",
      "Epoch [9403/10000], Train Loss: 0.0004, Val Loss: 0.7470\n",
      "Epoch [9404/10000], Train Loss: 0.0004, Val Loss: 0.7467\n",
      "Epoch [9405/10000], Train Loss: 0.0003, Val Loss: 0.7467\n",
      "Epoch [9406/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9407/10000], Train Loss: 0.0003, Val Loss: 0.7466\n",
      "Epoch [9408/10000], Train Loss: 0.0003, Val Loss: 0.7469\n",
      "Epoch [9409/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9410/10000], Train Loss: 0.0003, Val Loss: 0.7466\n",
      "Epoch [9411/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9412/10000], Train Loss: 0.0003, Val Loss: 0.7466\n",
      "Epoch [9413/10000], Train Loss: 0.0003, Val Loss: 0.7469\n",
      "Epoch [9414/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9415/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9416/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9417/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9418/10000], Train Loss: 0.0003, Val Loss: 0.7467\n",
      "Epoch [9419/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9420/10000], Train Loss: 0.0003, Val Loss: 0.7465\n",
      "Epoch [9421/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9422/10000], Train Loss: 0.0003, Val Loss: 0.7465\n",
      "Epoch [9423/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9424/10000], Train Loss: 0.0003, Val Loss: 0.7465\n",
      "Epoch [9425/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9426/10000], Train Loss: 0.0003, Val Loss: 0.7464\n",
      "Epoch [9427/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9428/10000], Train Loss: 0.0003, Val Loss: 0.7460\n",
      "Epoch [9429/10000], Train Loss: 0.0003, Val Loss: 0.7477\n",
      "Epoch [9430/10000], Train Loss: 0.0003, Val Loss: 0.7457\n",
      "Epoch [9431/10000], Train Loss: 0.0003, Val Loss: 0.7481\n",
      "Epoch [9432/10000], Train Loss: 0.0004, Val Loss: 0.7453\n",
      "Epoch [9433/10000], Train Loss: 0.0004, Val Loss: 0.7486\n",
      "Epoch [9434/10000], Train Loss: 0.0004, Val Loss: 0.7446\n",
      "Epoch [9435/10000], Train Loss: 0.0004, Val Loss: 0.7496\n",
      "Epoch [9436/10000], Train Loss: 0.0004, Val Loss: 0.7435\n",
      "Epoch [9437/10000], Train Loss: 0.0004, Val Loss: 0.7512\n",
      "Epoch [9438/10000], Train Loss: 0.0005, Val Loss: 0.7416\n",
      "Epoch [9439/10000], Train Loss: 0.0006, Val Loss: 0.7541\n",
      "Epoch [9440/10000], Train Loss: 0.0008, Val Loss: 0.7386\n",
      "Epoch [9441/10000], Train Loss: 0.0010, Val Loss: 0.7589\n",
      "Epoch [9442/10000], Train Loss: 0.0014, Val Loss: 0.7343\n",
      "Epoch [9443/10000], Train Loss: 0.0021, Val Loss: 0.7670\n",
      "Epoch [9444/10000], Train Loss: 0.0032, Val Loss: 0.7290\n",
      "Epoch [9445/10000], Train Loss: 0.0051, Val Loss: 0.7819\n",
      "Epoch [9446/10000], Train Loss: 0.0082, Val Loss: 0.7241\n",
      "Epoch [9447/10000], Train Loss: 0.0132, Val Loss: 0.8114\n",
      "Epoch [9448/10000], Train Loss: 0.0214, Val Loss: 0.7233\n",
      "Epoch [9449/10000], Train Loss: 0.0334, Val Loss: 0.8650\n",
      "Epoch [9450/10000], Train Loss: 0.0504, Val Loss: 0.7310\n",
      "Epoch [9451/10000], Train Loss: 0.0686, Val Loss: 0.9229\n",
      "Epoch [9452/10000], Train Loss: 0.0826, Val Loss: 0.7264\n",
      "Epoch [9453/10000], Train Loss: 0.0800, Val Loss: 0.9004\n",
      "Epoch [9454/10000], Train Loss: 0.0583, Val Loss: 0.6996\n",
      "Epoch [9455/10000], Train Loss: 0.0268, Val Loss: 0.8000\n",
      "Epoch [9456/10000], Train Loss: 0.0051, Val Loss: 0.7487\n",
      "Epoch [9457/10000], Train Loss: 0.0043, Val Loss: 0.7272\n",
      "Epoch [9458/10000], Train Loss: 0.0180, Val Loss: 0.8536\n",
      "Epoch [9459/10000], Train Loss: 0.0313, Val Loss: 0.6838\n",
      "Epoch [9460/10000], Train Loss: 0.0332, Val Loss: 0.8536\n",
      "Epoch [9461/10000], Train Loss: 0.0217, Val Loss: 0.6934\n",
      "Epoch [9462/10000], Train Loss: 0.0077, Val Loss: 0.7562\n",
      "Epoch [9463/10000], Train Loss: 0.0013, Val Loss: 0.7837\n",
      "Epoch [9464/10000], Train Loss: 0.0061, Val Loss: 0.6883\n",
      "Epoch [9465/10000], Train Loss: 0.0151, Val Loss: 0.8374\n",
      "Epoch [9466/10000], Train Loss: 0.0180, Val Loss: 0.6915\n",
      "Epoch [9467/10000], Train Loss: 0.0119, Val Loss: 0.7744\n",
      "Epoch [9468/10000], Train Loss: 0.0034, Val Loss: 0.7526\n",
      "Epoch [9469/10000], Train Loss: 0.0005, Val Loss: 0.7076\n",
      "Epoch [9470/10000], Train Loss: 0.0042, Val Loss: 0.8075\n",
      "Epoch [9471/10000], Train Loss: 0.0089, Val Loss: 0.6996\n",
      "Epoch [9472/10000], Train Loss: 0.0100, Val Loss: 0.7902\n",
      "Epoch [9473/10000], Train Loss: 0.0065, Val Loss: 0.7335\n",
      "Epoch [9474/10000], Train Loss: 0.0022, Val Loss: 0.7372\n",
      "Epoch [9475/10000], Train Loss: 0.0006, Val Loss: 0.7764\n",
      "Epoch [9476/10000], Train Loss: 0.0022, Val Loss: 0.7163\n",
      "Epoch [9477/10000], Train Loss: 0.0048, Val Loss: 0.7859\n",
      "Epoch [9478/10000], Train Loss: 0.0055, Val Loss: 0.7274\n",
      "Epoch [9479/10000], Train Loss: 0.0039, Val Loss: 0.7608\n",
      "Epoch [9480/10000], Train Loss: 0.0015, Val Loss: 0.7507\n",
      "Epoch [9481/10000], Train Loss: 0.0004, Val Loss: 0.7364\n",
      "Epoch [9482/10000], Train Loss: 0.0012, Val Loss: 0.7705\n",
      "Epoch [9483/10000], Train Loss: 0.0026, Val Loss: 0.7288\n",
      "Epoch [9484/10000], Train Loss: 0.0031, Val Loss: 0.7699\n",
      "Epoch [9485/10000], Train Loss: 0.0023, Val Loss: 0.7360\n",
      "Epoch [9486/10000], Train Loss: 0.0010, Val Loss: 0.7516\n",
      "Epoch [9487/10000], Train Loss: 0.0003, Val Loss: 0.7548\n",
      "Epoch [9488/10000], Train Loss: 0.0007, Val Loss: 0.7353\n",
      "Epoch [9489/10000], Train Loss: 0.0015, Val Loss: 0.7668\n",
      "Epoch [9490/10000], Train Loss: 0.0018, Val Loss: 0.7322\n",
      "Epoch [9491/10000], Train Loss: 0.0014, Val Loss: 0.7601\n",
      "Epoch [9492/10000], Train Loss: 0.0007, Val Loss: 0.7436\n",
      "Epoch [9493/10000], Train Loss: 0.0003, Val Loss: 0.7439\n",
      "Epoch [9494/10000], Train Loss: 0.0005, Val Loss: 0.7600\n",
      "Epoch [9495/10000], Train Loss: 0.0009, Val Loss: 0.7339\n",
      "Epoch [9496/10000], Train Loss: 0.0011, Val Loss: 0.7636\n",
      "Epoch [9497/10000], Train Loss: 0.0010, Val Loss: 0.7391\n",
      "Epoch [9498/10000], Train Loss: 0.0006, Val Loss: 0.7517\n",
      "Epoch [9499/10000], Train Loss: 0.0003, Val Loss: 0.7530\n",
      "Epoch [9500/10000], Train Loss: 0.0004, Val Loss: 0.7402\n",
      "Epoch [9501/10000], Train Loss: 0.0006, Val Loss: 0.7605\n",
      "Epoch [9502/10000], Train Loss: 0.0007, Val Loss: 0.7390\n",
      "Epoch [9503/10000], Train Loss: 0.0007, Val Loss: 0.7569\n",
      "Epoch [9504/10000], Train Loss: 0.0005, Val Loss: 0.7458\n",
      "Epoch [9505/10000], Train Loss: 0.0004, Val Loss: 0.7476\n",
      "Epoch [9506/10000], Train Loss: 0.0003, Val Loss: 0.7540\n",
      "Epoch [9507/10000], Train Loss: 0.0004, Val Loss: 0.7418\n",
      "Epoch [9508/10000], Train Loss: 0.0005, Val Loss: 0.7560\n",
      "Epoch [9509/10000], Train Loss: 0.0005, Val Loss: 0.7430\n",
      "Epoch [9510/10000], Train Loss: 0.0005, Val Loss: 0.7516\n",
      "Epoch [9511/10000], Train Loss: 0.0004, Val Loss: 0.7478\n",
      "Epoch [9512/10000], Train Loss: 0.0003, Val Loss: 0.7464\n",
      "Epoch [9513/10000], Train Loss: 0.0003, Val Loss: 0.7516\n",
      "Epoch [9514/10000], Train Loss: 0.0004, Val Loss: 0.7440\n",
      "Epoch [9515/10000], Train Loss: 0.0004, Val Loss: 0.7524\n",
      "Epoch [9516/10000], Train Loss: 0.0004, Val Loss: 0.7446\n",
      "Epoch [9517/10000], Train Loss: 0.0004, Val Loss: 0.7503\n",
      "Epoch [9518/10000], Train Loss: 0.0003, Val Loss: 0.7475\n",
      "Epoch [9519/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9520/10000], Train Loss: 0.0003, Val Loss: 0.7505\n",
      "Epoch [9521/10000], Train Loss: 0.0003, Val Loss: 0.7451\n",
      "Epoch [9522/10000], Train Loss: 0.0004, Val Loss: 0.7514\n",
      "Epoch [9523/10000], Train Loss: 0.0004, Val Loss: 0.7453\n",
      "Epoch [9524/10000], Train Loss: 0.0003, Val Loss: 0.7499\n",
      "Epoch [9525/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9526/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9527/10000], Train Loss: 0.0003, Val Loss: 0.7498\n",
      "Epoch [9528/10000], Train Loss: 0.0003, Val Loss: 0.7453\n",
      "Epoch [9529/10000], Train Loss: 0.0003, Val Loss: 0.7506\n",
      "Epoch [9530/10000], Train Loss: 0.0003, Val Loss: 0.7455\n",
      "Epoch [9531/10000], Train Loss: 0.0003, Val Loss: 0.7491\n",
      "Epoch [9532/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9533/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9534/10000], Train Loss: 0.0003, Val Loss: 0.7489\n",
      "Epoch [9535/10000], Train Loss: 0.0003, Val Loss: 0.7458\n",
      "Epoch [9536/10000], Train Loss: 0.0003, Val Loss: 0.7494\n",
      "Epoch [9537/10000], Train Loss: 0.0003, Val Loss: 0.7459\n",
      "Epoch [9538/10000], Train Loss: 0.0003, Val Loss: 0.7486\n",
      "Epoch [9539/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9540/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9541/10000], Train Loss: 0.0003, Val Loss: 0.7481\n",
      "Epoch [9542/10000], Train Loss: 0.0003, Val Loss: 0.7464\n",
      "Epoch [9543/10000], Train Loss: 0.0003, Val Loss: 0.7485\n",
      "Epoch [9544/10000], Train Loss: 0.0003, Val Loss: 0.7464\n",
      "Epoch [9545/10000], Train Loss: 0.0003, Val Loss: 0.7482\n",
      "Epoch [9546/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9547/10000], Train Loss: 0.0003, Val Loss: 0.7477\n",
      "Epoch [9548/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9549/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9550/10000], Train Loss: 0.0003, Val Loss: 0.7479\n",
      "Epoch [9551/10000], Train Loss: 0.0003, Val Loss: 0.7467\n",
      "Epoch [9552/10000], Train Loss: 0.0003, Val Loss: 0.7481\n",
      "Epoch [9553/10000], Train Loss: 0.0003, Val Loss: 0.7467\n",
      "Epoch [9554/10000], Train Loss: 0.0003, Val Loss: 0.7478\n",
      "Epoch [9555/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9556/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9557/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9558/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9559/10000], Train Loss: 0.0003, Val Loss: 0.7477\n",
      "Epoch [9560/10000], Train Loss: 0.0003, Val Loss: 0.7467\n",
      "Epoch [9561/10000], Train Loss: 0.0003, Val Loss: 0.7478\n",
      "Epoch [9562/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9563/10000], Train Loss: 0.0003, Val Loss: 0.7475\n",
      "Epoch [9564/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9565/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9566/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9567/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9568/10000], Train Loss: 0.0003, Val Loss: 0.7476\n",
      "Epoch [9569/10000], Train Loss: 0.0003, Val Loss: 0.7469\n",
      "Epoch [9570/10000], Train Loss: 0.0003, Val Loss: 0.7476\n",
      "Epoch [9571/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9572/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9573/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9574/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9575/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9576/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9577/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9578/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9579/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9580/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9581/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9582/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9583/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9584/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9585/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9586/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9587/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9588/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9589/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9590/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9591/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9592/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9593/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9594/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9595/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9596/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9597/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9598/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9599/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9600/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9601/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9602/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9603/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9604/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9605/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9606/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9607/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9608/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9609/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9610/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9611/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9612/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9613/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9614/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9615/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9616/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9617/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9618/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9619/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9620/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9621/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9622/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9623/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9624/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9625/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9626/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9627/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9628/10000], Train Loss: 0.0003, Val Loss: 0.7473\n",
      "Epoch [9629/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9630/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9631/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9632/10000], Train Loss: 0.0003, Val Loss: 0.7474\n",
      "Epoch [9633/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9634/10000], Train Loss: 0.0003, Val Loss: 0.7475\n",
      "Epoch [9635/10000], Train Loss: 0.0003, Val Loss: 0.7469\n",
      "Epoch [9636/10000], Train Loss: 0.0003, Val Loss: 0.7475\n",
      "Epoch [9637/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9638/10000], Train Loss: 0.0003, Val Loss: 0.7476\n",
      "Epoch [9639/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9640/10000], Train Loss: 0.0003, Val Loss: 0.7476\n",
      "Epoch [9641/10000], Train Loss: 0.0003, Val Loss: 0.7467\n",
      "Epoch [9642/10000], Train Loss: 0.0003, Val Loss: 0.7478\n",
      "Epoch [9643/10000], Train Loss: 0.0003, Val Loss: 0.7465\n",
      "Epoch [9644/10000], Train Loss: 0.0003, Val Loss: 0.7480\n",
      "Epoch [9645/10000], Train Loss: 0.0003, Val Loss: 0.7462\n",
      "Epoch [9646/10000], Train Loss: 0.0003, Val Loss: 0.7483\n",
      "Epoch [9647/10000], Train Loss: 0.0003, Val Loss: 0.7459\n",
      "Epoch [9648/10000], Train Loss: 0.0003, Val Loss: 0.7487\n",
      "Epoch [9649/10000], Train Loss: 0.0003, Val Loss: 0.7453\n",
      "Epoch [9650/10000], Train Loss: 0.0003, Val Loss: 0.7494\n",
      "Epoch [9651/10000], Train Loss: 0.0003, Val Loss: 0.7444\n",
      "Epoch [9652/10000], Train Loss: 0.0003, Val Loss: 0.7505\n",
      "Epoch [9653/10000], Train Loss: 0.0003, Val Loss: 0.7431\n",
      "Epoch [9654/10000], Train Loss: 0.0003, Val Loss: 0.7523\n",
      "Epoch [9655/10000], Train Loss: 0.0004, Val Loss: 0.7409\n",
      "Epoch [9656/10000], Train Loss: 0.0004, Val Loss: 0.7552\n",
      "Epoch [9657/10000], Train Loss: 0.0005, Val Loss: 0.7374\n",
      "Epoch [9658/10000], Train Loss: 0.0006, Val Loss: 0.7600\n",
      "Epoch [9659/10000], Train Loss: 0.0008, Val Loss: 0.7320\n",
      "Epoch [9660/10000], Train Loss: 0.0011, Val Loss: 0.7682\n",
      "Epoch [9661/10000], Train Loss: 0.0016, Val Loss: 0.7236\n",
      "Epoch [9662/10000], Train Loss: 0.0025, Val Loss: 0.7823\n",
      "Epoch [9663/10000], Train Loss: 0.0038, Val Loss: 0.7112\n",
      "Epoch [9664/10000], Train Loss: 0.0060, Val Loss: 0.8078\n",
      "Epoch [9665/10000], Train Loss: 0.0095, Val Loss: 0.6944\n",
      "Epoch [9666/10000], Train Loss: 0.0154, Val Loss: 0.8540\n",
      "Epoch [9667/10000], Train Loss: 0.0244, Val Loss: 0.6770\n",
      "Epoch [9668/10000], Train Loss: 0.0388, Val Loss: 0.9336\n",
      "Epoch [9669/10000], Train Loss: 0.0586, Val Loss: 0.6698\n",
      "Epoch [9670/10000], Train Loss: 0.0859, Val Loss: 1.0395\n",
      "Epoch [9671/10000], Train Loss: 0.1131, Val Loss: 0.6718\n",
      "Epoch [9672/10000], Train Loss: 0.1343, Val Loss: 1.0757\n",
      "Epoch [9673/10000], Train Loss: 0.1285, Val Loss: 0.6510\n",
      "Epoch [9674/10000], Train Loss: 0.0970, Val Loss: 0.9344\n",
      "Epoch [9675/10000], Train Loss: 0.0474, Val Loss: 0.6716\n",
      "Epoch [9676/10000], Train Loss: 0.0136, Val Loss: 0.7675\n",
      "Epoch [9677/10000], Train Loss: 0.0087, Val Loss: 0.8196\n",
      "Epoch [9678/10000], Train Loss: 0.0282, Val Loss: 0.6984\n",
      "Epoch [9679/10000], Train Loss: 0.0474, Val Loss: 0.9088\n",
      "Epoch [9680/10000], Train Loss: 0.0482, Val Loss: 0.6734\n",
      "Epoch [9681/10000], Train Loss: 0.0303, Val Loss: 0.8356\n",
      "Epoch [9682/10000], Train Loss: 0.0110, Val Loss: 0.7280\n",
      "Epoch [9683/10000], Train Loss: 0.0054, Val Loss: 0.7442\n",
      "Epoch [9684/10000], Train Loss: 0.0129, Val Loss: 0.8354\n",
      "Epoch [9685/10000], Train Loss: 0.0217, Val Loss: 0.6866\n",
      "Epoch [9686/10000], Train Loss: 0.0232, Val Loss: 0.8613\n",
      "Epoch [9687/10000], Train Loss: 0.0172, Val Loss: 0.6829\n",
      "Epoch [9688/10000], Train Loss: 0.0112, Val Loss: 0.8060\n",
      "Epoch [9689/10000], Train Loss: 0.0079, Val Loss: 0.7462\n",
      "Epoch [9690/10000], Train Loss: 0.0091, Val Loss: 0.7378\n",
      "Epoch [9691/10000], Train Loss: 0.0093, Val Loss: 0.8056\n",
      "Epoch [9692/10000], Train Loss: 0.0082, Val Loss: 0.6963\n",
      "Epoch [9693/10000], Train Loss: 0.0070, Val Loss: 0.8145\n",
      "Epoch [9694/10000], Train Loss: 0.0066, Val Loss: 0.7103\n",
      "Epoch [9695/10000], Train Loss: 0.0073, Val Loss: 0.7797\n",
      "Epoch [9696/10000], Train Loss: 0.0060, Val Loss: 0.7538\n",
      "Epoch [9697/10000], Train Loss: 0.0039, Val Loss: 0.7279\n",
      "Epoch [9698/10000], Train Loss: 0.0023, Val Loss: 0.7915\n",
      "Epoch [9699/10000], Train Loss: 0.0030, Val Loss: 0.7071\n",
      "Epoch [9700/10000], Train Loss: 0.0048, Val Loss: 0.7922\n",
      "Epoch [9701/10000], Train Loss: 0.0050, Val Loss: 0.7253\n",
      "Epoch [9702/10000], Train Loss: 0.0036, Val Loss: 0.7549\n",
      "Epoch [9703/10000], Train Loss: 0.0013, Val Loss: 0.7617\n",
      "Epoch [9704/10000], Train Loss: 0.0006, Val Loss: 0.7206\n",
      "Epoch [9705/10000], Train Loss: 0.0018, Val Loss: 0.7831\n",
      "Epoch [9706/10000], Train Loss: 0.0031, Val Loss: 0.7200\n",
      "Epoch [9707/10000], Train Loss: 0.0033, Val Loss: 0.7690\n",
      "Epoch [9708/10000], Train Loss: 0.0019, Val Loss: 0.7431\n",
      "Epoch [9709/10000], Train Loss: 0.0005, Val Loss: 0.7386\n",
      "Epoch [9710/10000], Train Loss: 0.0005, Val Loss: 0.7701\n",
      "Epoch [9711/10000], Train Loss: 0.0015, Val Loss: 0.7248\n",
      "Epoch [9712/10000], Train Loss: 0.0021, Val Loss: 0.7724\n",
      "Epoch [9713/10000], Train Loss: 0.0017, Val Loss: 0.7331\n",
      "Epoch [9714/10000], Train Loss: 0.0008, Val Loss: 0.7529\n",
      "Epoch [9715/10000], Train Loss: 0.0003, Val Loss: 0.7542\n",
      "Epoch [9716/10000], Train Loss: 0.0005, Val Loss: 0.7342\n",
      "Epoch [9717/10000], Train Loss: 0.0011, Val Loss: 0.7658\n",
      "Epoch [9718/10000], Train Loss: 0.0012, Val Loss: 0.7314\n",
      "Epoch [9719/10000], Train Loss: 0.0009, Val Loss: 0.7592\n",
      "Epoch [9720/10000], Train Loss: 0.0005, Val Loss: 0.7427\n",
      "Epoch [9721/10000], Train Loss: 0.0004, Val Loss: 0.7454\n",
      "Epoch [9722/10000], Train Loss: 0.0005, Val Loss: 0.7555\n",
      "Epoch [9723/10000], Train Loss: 0.0007, Val Loss: 0.7373\n",
      "Epoch [9724/10000], Train Loss: 0.0007, Val Loss: 0.7596\n",
      "Epoch [9725/10000], Train Loss: 0.0006, Val Loss: 0.7390\n",
      "Epoch [9726/10000], Train Loss: 0.0004, Val Loss: 0.7543\n",
      "Epoch [9727/10000], Train Loss: 0.0004, Val Loss: 0.7478\n",
      "Epoch [9728/10000], Train Loss: 0.0005, Val Loss: 0.7460\n",
      "Epoch [9729/10000], Train Loss: 0.0005, Val Loss: 0.7550\n",
      "Epoch [9730/10000], Train Loss: 0.0004, Val Loss: 0.7425\n",
      "Epoch [9731/10000], Train Loss: 0.0003, Val Loss: 0.7549\n",
      "Epoch [9732/10000], Train Loss: 0.0003, Val Loss: 0.7455\n",
      "Epoch [9733/10000], Train Loss: 0.0004, Val Loss: 0.7509\n",
      "Epoch [9734/10000], Train Loss: 0.0004, Val Loss: 0.7496\n",
      "Epoch [9735/10000], Train Loss: 0.0004, Val Loss: 0.7475\n",
      "Epoch [9736/10000], Train Loss: 0.0003, Val Loss: 0.7516\n",
      "Epoch [9737/10000], Train Loss: 0.0003, Val Loss: 0.7463\n",
      "Epoch [9738/10000], Train Loss: 0.0003, Val Loss: 0.7516\n",
      "Epoch [9739/10000], Train Loss: 0.0003, Val Loss: 0.7471\n",
      "Epoch [9740/10000], Train Loss: 0.0004, Val Loss: 0.7502\n",
      "Epoch [9741/10000], Train Loss: 0.0003, Val Loss: 0.7486\n",
      "Epoch [9742/10000], Train Loss: 0.0003, Val Loss: 0.7487\n",
      "Epoch [9743/10000], Train Loss: 0.0003, Val Loss: 0.7496\n",
      "Epoch [9744/10000], Train Loss: 0.0003, Val Loss: 0.7481\n",
      "Epoch [9745/10000], Train Loss: 0.0003, Val Loss: 0.7500\n",
      "Epoch [9746/10000], Train Loss: 0.0003, Val Loss: 0.7477\n",
      "Epoch [9747/10000], Train Loss: 0.0003, Val Loss: 0.7503\n",
      "Epoch [9748/10000], Train Loss: 0.0003, Val Loss: 0.7475\n",
      "Epoch [9749/10000], Train Loss: 0.0003, Val Loss: 0.7500\n",
      "Epoch [9750/10000], Train Loss: 0.0003, Val Loss: 0.7483\n",
      "Epoch [9751/10000], Train Loss: 0.0003, Val Loss: 0.7488\n",
      "Epoch [9752/10000], Train Loss: 0.0003, Val Loss: 0.7496\n",
      "Epoch [9753/10000], Train Loss: 0.0003, Val Loss: 0.7476\n",
      "Epoch [9754/10000], Train Loss: 0.0003, Val Loss: 0.7504\n",
      "Epoch [9755/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9756/10000], Train Loss: 0.0003, Val Loss: 0.7503\n",
      "Epoch [9757/10000], Train Loss: 0.0003, Val Loss: 0.7477\n",
      "Epoch [9758/10000], Train Loss: 0.0003, Val Loss: 0.7492\n",
      "Epoch [9759/10000], Train Loss: 0.0003, Val Loss: 0.7490\n",
      "Epoch [9760/10000], Train Loss: 0.0003, Val Loss: 0.7476\n",
      "Epoch [9761/10000], Train Loss: 0.0003, Val Loss: 0.7501\n",
      "Epoch [9762/10000], Train Loss: 0.0003, Val Loss: 0.7468\n",
      "Epoch [9763/10000], Train Loss: 0.0003, Val Loss: 0.7501\n",
      "Epoch [9764/10000], Train Loss: 0.0003, Val Loss: 0.7472\n",
      "Epoch [9765/10000], Train Loss: 0.0003, Val Loss: 0.7490\n",
      "Epoch [9766/10000], Train Loss: 0.0003, Val Loss: 0.7484\n",
      "Epoch [9767/10000], Train Loss: 0.0002, Val Loss: 0.7477\n",
      "Epoch [9768/10000], Train Loss: 0.0002, Val Loss: 0.7494\n",
      "Epoch [9769/10000], Train Loss: 0.0002, Val Loss: 0.7469\n",
      "Epoch [9770/10000], Train Loss: 0.0002, Val Loss: 0.7496\n",
      "Epoch [9771/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9772/10000], Train Loss: 0.0002, Val Loss: 0.7491\n",
      "Epoch [9773/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9774/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9775/10000], Train Loss: 0.0002, Val Loss: 0.7488\n",
      "Epoch [9776/10000], Train Loss: 0.0002, Val Loss: 0.7473\n",
      "Epoch [9777/10000], Train Loss: 0.0002, Val Loss: 0.7492\n",
      "Epoch [9778/10000], Train Loss: 0.0002, Val Loss: 0.7473\n",
      "Epoch [9779/10000], Train Loss: 0.0002, Val Loss: 0.7489\n",
      "Epoch [9780/10000], Train Loss: 0.0002, Val Loss: 0.7477\n",
      "Epoch [9781/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9782/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9783/10000], Train Loss: 0.0002, Val Loss: 0.7477\n",
      "Epoch [9784/10000], Train Loss: 0.0002, Val Loss: 0.7486\n",
      "Epoch [9785/10000], Train Loss: 0.0002, Val Loss: 0.7475\n",
      "Epoch [9786/10000], Train Loss: 0.0002, Val Loss: 0.7486\n",
      "Epoch [9787/10000], Train Loss: 0.0002, Val Loss: 0.7476\n",
      "Epoch [9788/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9789/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9790/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9791/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9792/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9793/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9794/10000], Train Loss: 0.0002, Val Loss: 0.7478\n",
      "Epoch [9795/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9796/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9797/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9798/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9799/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9800/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9801/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9802/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9803/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9804/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9805/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9806/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9807/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9808/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9809/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9810/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9811/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9812/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9813/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9814/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9815/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9816/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9817/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9818/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9819/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9820/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9821/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9822/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9823/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9824/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9825/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9826/10000], Train Loss: 0.0002, Val Loss: 0.7478\n",
      "Epoch [9827/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9828/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9829/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9830/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9831/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9832/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9833/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9834/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9835/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9836/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9837/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9838/10000], Train Loss: 0.0002, Val Loss: 0.7482\n",
      "Epoch [9839/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9840/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9841/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9842/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9843/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9844/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9845/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9846/10000], Train Loss: 0.0002, Val Loss: 0.7483\n",
      "Epoch [9847/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9848/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9849/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9850/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9851/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9852/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9853/10000], Train Loss: 0.0002, Val Loss: 0.7480\n",
      "Epoch [9854/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9855/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9856/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9857/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9858/10000], Train Loss: 0.0002, Val Loss: 0.7485\n",
      "Epoch [9859/10000], Train Loss: 0.0002, Val Loss: 0.7478\n",
      "Epoch [9860/10000], Train Loss: 0.0002, Val Loss: 0.7486\n",
      "Epoch [9861/10000], Train Loss: 0.0002, Val Loss: 0.7477\n",
      "Epoch [9862/10000], Train Loss: 0.0002, Val Loss: 0.7488\n",
      "Epoch [9863/10000], Train Loss: 0.0002, Val Loss: 0.7475\n",
      "Epoch [9864/10000], Train Loss: 0.0002, Val Loss: 0.7490\n",
      "Epoch [9865/10000], Train Loss: 0.0002, Val Loss: 0.7472\n",
      "Epoch [9866/10000], Train Loss: 0.0002, Val Loss: 0.7494\n",
      "Epoch [9867/10000], Train Loss: 0.0002, Val Loss: 0.7468\n",
      "Epoch [9868/10000], Train Loss: 0.0002, Val Loss: 0.7499\n",
      "Epoch [9869/10000], Train Loss: 0.0002, Val Loss: 0.7461\n",
      "Epoch [9870/10000], Train Loss: 0.0002, Val Loss: 0.7507\n",
      "Epoch [9871/10000], Train Loss: 0.0002, Val Loss: 0.7451\n",
      "Epoch [9872/10000], Train Loss: 0.0003, Val Loss: 0.7522\n",
      "Epoch [9873/10000], Train Loss: 0.0003, Val Loss: 0.7430\n",
      "Epoch [9874/10000], Train Loss: 0.0003, Val Loss: 0.7548\n",
      "Epoch [9875/10000], Train Loss: 0.0003, Val Loss: 0.7395\n",
      "Epoch [9876/10000], Train Loss: 0.0004, Val Loss: 0.7598\n",
      "Epoch [9877/10000], Train Loss: 0.0005, Val Loss: 0.7330\n",
      "Epoch [9878/10000], Train Loss: 0.0007, Val Loss: 0.7690\n",
      "Epoch [9879/10000], Train Loss: 0.0010, Val Loss: 0.7215\n",
      "Epoch [9880/10000], Train Loss: 0.0016, Val Loss: 0.7869\n",
      "Epoch [9881/10000], Train Loss: 0.0026, Val Loss: 0.7017\n",
      "Epoch [9882/10000], Train Loss: 0.0046, Val Loss: 0.8224\n",
      "Epoch [9883/10000], Train Loss: 0.0081, Val Loss: 0.6683\n",
      "Epoch [9884/10000], Train Loss: 0.0155, Val Loss: 0.9017\n",
      "Epoch [9885/10000], Train Loss: 0.0279, Val Loss: 0.6228\n",
      "Epoch [9886/10000], Train Loss: 0.0543, Val Loss: 1.0770\n",
      "Epoch [9887/10000], Train Loss: 0.0952, Val Loss: 0.6154\n",
      "Epoch [9888/10000], Train Loss: 0.1713, Val Loss: 1.3732\n",
      "Epoch [9889/10000], Train Loss: 0.2482, Val Loss: 0.6646\n",
      "Epoch [9890/10000], Train Loss: 0.3179, Val Loss: 1.3824\n",
      "Epoch [9891/10000], Train Loss: 0.2500, Val Loss: 0.6513\n",
      "Epoch [9892/10000], Train Loss: 0.1044, Val Loss: 0.8171\n",
      "Epoch [9893/10000], Train Loss: 0.0180, Val Loss: 1.0054\n",
      "Epoch [9894/10000], Train Loss: 0.0717, Val Loss: 0.6502\n",
      "Epoch [9895/10000], Train Loss: 0.1392, Val Loss: 1.0762\n",
      "Epoch [9896/10000], Train Loss: 0.0966, Val Loss: 0.7009\n",
      "Epoch [9897/10000], Train Loss: 0.0210, Val Loss: 0.7087\n",
      "Epoch [9898/10000], Train Loss: 0.0193, Val Loss: 1.0061\n",
      "Epoch [9899/10000], Train Loss: 0.0723, Val Loss: 0.6726\n",
      "Epoch [9900/10000], Train Loss: 0.0814, Val Loss: 0.8639\n",
      "Epoch [9901/10000], Train Loss: 0.0258, Val Loss: 0.8300\n",
      "Epoch [9902/10000], Train Loss: 0.0092, Val Loss: 0.6588\n",
      "Epoch [9903/10000], Train Loss: 0.0449, Val Loss: 0.9649\n",
      "Epoch [9904/10000], Train Loss: 0.0515, Val Loss: 0.6966\n",
      "Epoch [9905/10000], Train Loss: 0.0172, Val Loss: 0.7160\n",
      "Epoch [9906/10000], Train Loss: 0.0046, Val Loss: 0.9034\n",
      "Epoch [9907/10000], Train Loss: 0.0287, Val Loss: 0.6371\n",
      "Epoch [9908/10000], Train Loss: 0.0371, Val Loss: 0.8379\n",
      "Epoch [9909/10000], Train Loss: 0.0125, Val Loss: 0.7603\n",
      "Epoch [9910/10000], Train Loss: 0.0022, Val Loss: 0.6629\n",
      "Epoch [9911/10000], Train Loss: 0.0165, Val Loss: 0.8707\n",
      "Epoch [9912/10000], Train Loss: 0.0208, Val Loss: 0.6770\n",
      "Epoch [9913/10000], Train Loss: 0.0095, Val Loss: 0.7409\n",
      "Epoch [9914/10000], Train Loss: 0.0013, Val Loss: 0.8207\n",
      "Epoch [9915/10000], Train Loss: 0.0095, Val Loss: 0.6662\n",
      "Epoch [9916/10000], Train Loss: 0.0158, Val Loss: 0.8096\n",
      "Epoch [9917/10000], Train Loss: 0.0066, Val Loss: 0.7526\n",
      "Epoch [9918/10000], Train Loss: 0.0008, Val Loss: 0.6957\n",
      "Epoch [9919/10000], Train Loss: 0.0068, Val Loss: 0.8260\n",
      "Epoch [9920/10000], Train Loss: 0.0097, Val Loss: 0.7123\n",
      "Epoch [9921/10000], Train Loss: 0.0039, Val Loss: 0.7380\n",
      "Epoch [9922/10000], Train Loss: 0.0006, Val Loss: 0.8035\n",
      "Epoch [9923/10000], Train Loss: 0.0048, Val Loss: 0.6995\n",
      "Epoch [9924/10000], Train Loss: 0.0063, Val Loss: 0.7765\n",
      "Epoch [9925/10000], Train Loss: 0.0020, Val Loss: 0.7651\n",
      "Epoch [9926/10000], Train Loss: 0.0007, Val Loss: 0.7067\n",
      "Epoch [9927/10000], Train Loss: 0.0039, Val Loss: 0.7975\n",
      "Epoch [9928/10000], Train Loss: 0.0040, Val Loss: 0.7297\n",
      "Epoch [9929/10000], Train Loss: 0.0010, Val Loss: 0.7337\n",
      "Epoch [9930/10000], Train Loss: 0.0007, Val Loss: 0.7879\n",
      "Epoch [9931/10000], Train Loss: 0.0028, Val Loss: 0.7153\n",
      "Epoch [9932/10000], Train Loss: 0.0025, Val Loss: 0.7627\n",
      "Epoch [9933/10000], Train Loss: 0.0006, Val Loss: 0.7625\n",
      "Epoch [9934/10000], Train Loss: 0.0008, Val Loss: 0.7211\n",
      "Epoch [9935/10000], Train Loss: 0.0021, Val Loss: 0.7768\n",
      "Epoch [9936/10000], Train Loss: 0.0016, Val Loss: 0.7401\n",
      "Epoch [9937/10000], Train Loss: 0.0004, Val Loss: 0.7376\n",
      "Epoch [9938/10000], Train Loss: 0.0006, Val Loss: 0.7746\n",
      "Epoch [9939/10000], Train Loss: 0.0014, Val Loss: 0.7279\n",
      "Epoch [9940/10000], Train Loss: 0.0013, Val Loss: 0.7577\n",
      "Epoch [9941/10000], Train Loss: 0.0004, Val Loss: 0.7621\n",
      "Epoch [9942/10000], Train Loss: 0.0005, Val Loss: 0.7283\n",
      "Epoch [9943/10000], Train Loss: 0.0011, Val Loss: 0.7718\n",
      "Epoch [9944/10000], Train Loss: 0.0009, Val Loss: 0.7438\n",
      "Epoch [9945/10000], Train Loss: 0.0003, Val Loss: 0.7426\n",
      "Epoch [9946/10000], Train Loss: 0.0004, Val Loss: 0.7694\n",
      "Epoch [9947/10000], Train Loss: 0.0007, Val Loss: 0.7350\n",
      "Epoch [9948/10000], Train Loss: 0.0007, Val Loss: 0.7576\n",
      "Epoch [9949/10000], Train Loss: 0.0003, Val Loss: 0.7569\n",
      "Epoch [9950/10000], Train Loss: 0.0003, Val Loss: 0.7387\n",
      "Epoch [9951/10000], Train Loss: 0.0006, Val Loss: 0.7624\n",
      "Epoch [9952/10000], Train Loss: 0.0005, Val Loss: 0.7473\n",
      "Epoch [9953/10000], Train Loss: 0.0003, Val Loss: 0.7453\n",
      "Epoch [9954/10000], Train Loss: 0.0003, Val Loss: 0.7609\n",
      "Epoch [9955/10000], Train Loss: 0.0005, Val Loss: 0.7418\n",
      "Epoch [9956/10000], Train Loss: 0.0004, Val Loss: 0.7526\n",
      "Epoch [9957/10000], Train Loss: 0.0003, Val Loss: 0.7551\n",
      "Epoch [9958/10000], Train Loss: 0.0003, Val Loss: 0.7412\n",
      "Epoch [9959/10000], Train Loss: 0.0004, Val Loss: 0.7583\n",
      "Epoch [9960/10000], Train Loss: 0.0003, Val Loss: 0.7470\n",
      "Epoch [9961/10000], Train Loss: 0.0002, Val Loss: 0.7470\n",
      "Epoch [9962/10000], Train Loss: 0.0003, Val Loss: 0.7572\n",
      "Epoch [9963/10000], Train Loss: 0.0003, Val Loss: 0.7434\n",
      "Epoch [9964/10000], Train Loss: 0.0003, Val Loss: 0.7531\n",
      "Epoch [9965/10000], Train Loss: 0.0002, Val Loss: 0.7522\n",
      "Epoch [9966/10000], Train Loss: 0.0002, Val Loss: 0.7450\n",
      "Epoch [9967/10000], Train Loss: 0.0003, Val Loss: 0.7553\n",
      "Epoch [9968/10000], Train Loss: 0.0003, Val Loss: 0.7483\n",
      "Epoch [9969/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9970/10000], Train Loss: 0.0002, Val Loss: 0.7548\n",
      "Epoch [9971/10000], Train Loss: 0.0003, Val Loss: 0.7457\n",
      "Epoch [9972/10000], Train Loss: 0.0003, Val Loss: 0.7516\n",
      "Epoch [9973/10000], Train Loss: 0.0002, Val Loss: 0.7516\n",
      "Epoch [9974/10000], Train Loss: 0.0002, Val Loss: 0.7458\n",
      "Epoch [9975/10000], Train Loss: 0.0003, Val Loss: 0.7535\n",
      "Epoch [9976/10000], Train Loss: 0.0003, Val Loss: 0.7477\n",
      "Epoch [9977/10000], Train Loss: 0.0002, Val Loss: 0.7486\n",
      "Epoch [9978/10000], Train Loss: 0.0002, Val Loss: 0.7521\n",
      "Epoch [9979/10000], Train Loss: 0.0002, Val Loss: 0.7465\n",
      "Epoch [9980/10000], Train Loss: 0.0002, Val Loss: 0.7508\n",
      "Epoch [9981/10000], Train Loss: 0.0002, Val Loss: 0.7496\n",
      "Epoch [9982/10000], Train Loss: 0.0002, Val Loss: 0.7473\n",
      "Epoch [9983/10000], Train Loss: 0.0002, Val Loss: 0.7514\n",
      "Epoch [9984/10000], Train Loss: 0.0002, Val Loss: 0.7479\n",
      "Epoch [9985/10000], Train Loss: 0.0002, Val Loss: 0.7489\n",
      "Epoch [9986/10000], Train Loss: 0.0002, Val Loss: 0.7508\n",
      "Epoch [9987/10000], Train Loss: 0.0002, Val Loss: 0.7470\n",
      "Epoch [9988/10000], Train Loss: 0.0002, Val Loss: 0.7507\n",
      "Epoch [9989/10000], Train Loss: 0.0002, Val Loss: 0.7488\n",
      "Epoch [9990/10000], Train Loss: 0.0002, Val Loss: 0.7481\n",
      "Epoch [9991/10000], Train Loss: 0.0002, Val Loss: 0.7508\n",
      "Epoch [9992/10000], Train Loss: 0.0002, Val Loss: 0.7476\n",
      "Epoch [9993/10000], Train Loss: 0.0002, Val Loss: 0.7496\n",
      "Epoch [9994/10000], Train Loss: 0.0002, Val Loss: 0.7496\n",
      "Epoch [9995/10000], Train Loss: 0.0002, Val Loss: 0.7478\n",
      "Epoch [9996/10000], Train Loss: 0.0002, Val Loss: 0.7501\n",
      "Epoch [9997/10000], Train Loss: 0.0002, Val Loss: 0.7485\n",
      "Epoch [9998/10000], Train Loss: 0.0002, Val Loss: 0.7484\n",
      "Epoch [9999/10000], Train Loss: 0.0002, Val Loss: 0.7500\n",
      "Epoch [10000/10000], Train Loss: 0.0002, Val Loss: 0.7477\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T19:57:21.130898Z",
     "start_time": "2024-11-16T19:57:21.126121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), '/Users/defeee/Documents/GitHub/FormAI-ML/Models/Core/Plank/plank_cnn.pth')"
   ],
   "id": "d785e640f0f88abe",
   "outputs": [],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
